{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import accelerate\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from getpass import getpass\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading samples from a file \"vul_sample.csv\"\n",
    "df = pd.read_csv(\"../data/vul_sample.csv\")\n",
    "parsed_data = df[[\"CWE ID\", \"func_before\", \"len\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass(\n",
    "    prompt=\"Введите ваш HuggingFaceHub API ключ\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"codellama/CodeLlama-13b-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloom = HuggingFaceEndpoint(\n",
    "    repo_id=model_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for question and answer\n",
    "template = \"\"\"System: You are a security researcher, expert in detecting security vulnerabilities. Provide response only in following format: vulnerability: <YES or NO> | vulnerability type: <CWE ID> | explanation: <explanation for prediction>. Use N/A in other fields if there are no vulnerabilities. Do not include anything else in response.\n",
    "User: Evaluate the security of the following code snippet for potential vulnerabilities:\n",
    "{vulnerable_code}\n",
    "\n",
    "Response:\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"vulnerable_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a LLMChain\n",
    "llm_chain = LLMChain(prompt=prompt, llm=bloom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# Running iterations over all sals from a parsed_data\n",
    "for index, row in tqdm(parsed_data.iterrows(), total=len(parsed_data), desc=\"Processing\", unit=\" row\"):\n",
    "    result = {}\n",
    "    retry = True\n",
    "    \n",
    "    while retry:\n",
    "        # Sending a question to a model\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            generated_text = llm_chain.invoke(row[\"func_before\"])['text'].strip()\n",
    "            end_time = time.time()\n",
    "\n",
    "            print(f\"Expected CWE ID: {row['CWE ID']}. The model answers:\\n{generated_text}\")\n",
    "            print(f\"\\nExecution time: {(end_time - start_time):.2f} seconds\")\n",
    "        \n",
    "            result[\"Expected CWE ID:\"] = row[\"CWE ID\"]\n",
    "            result[\"generated_text\"] = generated_text\n",
    "            result[\"lead_time\"] = end_time - start_time\n",
    "\n",
    "            results.append(result)\n",
    "            retry = False\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {e}. Going for a break.\")\n",
    "            time.sleep(60 * 10)\n",
    "            continue\n",
    "\n",
    "# Saving results to a JSON file\n",
    "model_name = model_id.split(\"/\")[1]\n",
    "output_file = f\"../data/collected_generated_text/results_API_{model_name}.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4636248,
     "sourceId": 7895548,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
