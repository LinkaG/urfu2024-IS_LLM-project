{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ded98b07",
   "metadata": {},
   "source": [
    "# File paths and custom names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69574148",
   "metadata": {},
   "source": [
    "- PATH_TO_HASH_PAIRS_FILES — Path to the directory of the resulting hash pairs from parsing files from two commit versions. Is the result of [this script (getting_all_changes)](getting_all_changes.ipynb).\n",
    "- JSON_PWS_STUDIO — Set name for PVS-Studio JSON report.\n",
    "- CSV_OUTPUT_CWE_FIX — Found fixes.\n",
    "- CSV_OUTPUT_FOUND_CWE — Vulnerabilities found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec9981",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_HASH_PAIRS_FILES = 'result_hash_pairs'\n",
    "JSON_PWS_STUDIO = 'PVS-Studio.json'\n",
    "CSV_OUTPUT_CWE_FIX = 'bug_fix_functions.csv'\n",
    "CSV_OUTPUT_FOUND_CWE = 'vulnerable_functions.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af778d7",
   "metadata": {},
   "source": [
    "# Installing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9142d744",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade tqdm\n",
    "!pip install --upgrade pandas\n",
    "!pip install --upgrade tree-sitter\n",
    "!pip install --upgrade tree-sitter-java"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a297c8cc",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3501d945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import tree_sitter_java as tsjava\n",
    "from tree_sitter import Language, Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00ae3d0",
   "metadata": {},
   "source": [
    "# Selecting an installed language for parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169e20fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "JAVA_LANGUAGE = Language(tsjava.language())\n",
    "\n",
    "# Creating a parser\n",
    "parser = Parser()\n",
    "parser.set_language(JAVA_LANGUAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d57fa6",
   "metadata": {},
   "source": [
    "# Parsing Java functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f02818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse Java file and extract function\n",
    "import time\n",
    "\n",
    "\n",
    "def extract_functions_from_file(filepath, parser, line):\n",
    "    with open(filepath, 'r') as f:\n",
    "        code = f.read()\n",
    "\n",
    "    functions = []\n",
    "    code_lines = code.split(\"\\n\")\n",
    "\n",
    "    # Query to retrieve method declarations\n",
    "    query = JAVA_LANGUAGE.query(\"\"\"\n",
    "    (method_declaration\n",
    "        name: (identifier) @method_name\n",
    "        body: (block) @method_body)\n",
    "    \"\"\")\n",
    "\n",
    "    # Getting syntax tree node captures\n",
    "    captures = query.captures(parser.parse(bytes(code, \"utf-8\")).root_node)\n",
    "    for capture in captures:\n",
    "        node = capture[0]\n",
    "        start_line = node.start_point[0]\n",
    "        end_line = node.end_point[0]\n",
    "        if start_line + 1 <= line <= end_line + 1:\n",
    "            return \"\\n\".join(code_lines[start_line:end_line + 1])\n",
    "\n",
    "# List of all vulnerable functions\n",
    "vulnerable_functions = []\n",
    "\n",
    "# List of all fixed features\n",
    "bug_fix_functions = []\n",
    "\n",
    "# Get a list of all commit hashes\n",
    "hash_pairs = os.listdir(PATH_TO_HASH_PAIRS_FILES)\n",
    "\n",
    "for hash_dir in tqdm(hash_pairs, total=len(hash_pairs), desc=\"Processing:\", ascii=True):\n",
    "    hash_dir_path = os.path.join(PATH_TO_HASH_PAIRS_FILES, hash_dir)\n",
    "\n",
    "    curr_version_dir = os.path.join(hash_dir_path, 'curr')\n",
    "    prev_version_dir = os.path.join(hash_dir_path, 'prev')\n",
    "\n",
    "    curr_json_path = os.path.join(curr_version_dir, JSON_PWS_STUDIO)\n",
    "    prev_json_path = os.path.join(prev_version_dir, JSON_PWS_STUDIO)\n",
    "\n",
    "    if os.path.exists(curr_json_path) and os.path.exists(prev_json_path):\n",
    "        with open(curr_json_path, 'r') as curr_file:\n",
    "            curr_data = json.load(curr_file)\n",
    "        \n",
    "        with open(prev_json_path, 'r') as prev_file:\n",
    "            prev_data = json.load(prev_file)\n",
    "        \n",
    "        curr_positions = []\n",
    "        prev_positions = []\n",
    "        \n",
    "        for warning in curr_data.get('warnings', []):\n",
    "            for position in warning.get('positions', []):\n",
    "                if warning.get('cwe') != 0:\n",
    "                    curr_positions.append((warning.get('cwe'), position['file'], position['line']))\n",
    "        curr_positions.sort(key=lambda x: (x[1], x[2]))\n",
    "        \n",
    "        for warning in prev_data.get('warnings', []):\n",
    "            for position in warning.get('positions', []):\n",
    "                if warning.get('cwe') != 0:\n",
    "                    prev_positions.append((warning.get('cwe'), position['file'], position['line']))\n",
    "        prev_positions.sort(key=lambda x: (x[1], x[2]))\n",
    "        \n",
    "        # Transform positions into sets with file paths update\n",
    "        curr_positions_set = set((cwe, re.sub(r'.*curr', '', filepath), line) for cwe, filepath, line in curr_positions)\n",
    "        prev_positions_set = set((cwe, re.sub(r'.*prev', '', filepath), line) for cwe, filepath, line in prev_positions)\n",
    "\n",
    "        # Determining the positions of corrections\n",
    "        if len(curr_positions) < len(prev_positions):\n",
    "            bug_fix_positions_set = prev_positions_set - curr_positions_set\n",
    "\n",
    "            # Set for storing unique functions with fixes\n",
    "            bug_fix_functions_set = set()\n",
    "\n",
    "            for fix_cwe, filepath, line in bug_fix_positions_set:\n",
    "                function_from_bad_code = extract_functions_from_file(f'{prev_version_dir}{filepath}', parser, line)\n",
    "                function_from_good_code = extract_functions_from_file(f'{curr_version_dir}{filepath}', parser, line)\n",
    "\n",
    "                # Checking and recording unique corrections\n",
    "                if function_from_bad_code and function_from_good_code and function_from_bad_code != function_from_good_code and function_from_good_code.count('\\n') > 1 and function_from_bad_code.count('\\n') > 1:\n",
    "                    if function_from_bad_code not in bug_fix_functions_set:\n",
    "                        bug_fix_functions_set.add(function_from_bad_code)\n",
    "                        bug_fix_functions.append({\n",
    "                            'Hash': hash_dir,\n",
    "                            'Fixed_CWE': fix_cwe,\n",
    "                            'Line_in_vulnerable_code': line,\n",
    "                            'Vulnerable_code': function_from_bad_code.strip(),\n",
    "                            'Fixed_code': function_from_good_code.strip(),\n",
    "                            'File_path': re.sub(fr'.*{hash_dir}', '', filepath)\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb9274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving results\n",
    "df_bug_fix = pd.DataFrame(bug_fix_functions)\n",
    "df_bug_fix.to_csv(CSV_OUTPUT_CWE_FIX, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c085b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of commits with fixes\n",
    "df_bug_fix['Hash'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a59acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bug_fix.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
