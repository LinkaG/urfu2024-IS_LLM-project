Hash,Fixed_CWE,Line_in_vulnerable_code,Vulnerable_code,Fixed_code,File_path
2f93cf52df72fd7342d941490fd601dfaafe3022,682,319,") {
        // when our incoming buffer fills up, we combine our existing centroids with the incoming data,
        // and then reduce the centroids by merging if possible
        assert lastUsedCell <= 0 || weight[0] == 1;
        assert lastUsedCell <= 0 || weight[lastUsedCell - 1] == 1;
        System.arraycopy(mean, 0, incomingMean, incomingCount, lastUsedCell);
        System.arraycopy(weight, 0, incomingWeight, incomingCount, lastUsedCell);
        incomingCount += lastUsedCell;

        if (incomingOrder == null) {
            incomingOrder = new int[incomingCount];
        }
        Sort.stableSort(incomingOrder, incomingMean, incomingCount);

        totalWeight += unmergedWeight;

        // option to run backwards is to help investigate bias in errors
        if (runBackwards) {
            Sort.reverse(incomingOrder, 0, incomingCount);
        }

        // start by copying the least incoming value to the normal buffer
        lastUsedCell = 0;
        mean[lastUsedCell] = incomingMean[incomingOrder[0]];
        weight[lastUsedCell] = incomingWeight[incomingOrder[0]];
        double wSoFar = 0;

        // weight will contain all zeros after this loop

        double normalizer = scale.normalizer(compression, totalWeight);
        double k1 = scale.k(0, normalizer);
        double wLimit = totalWeight * scale.q(k1 + 1, normalizer);
        for (int i = 1; i < incomingCount; i++) {
            int ix = incomingOrder[i];
            double proposedWeight = weight[lastUsedCell] + incomingWeight[ix];
            double projectedW = wSoFar + proposedWeight;
            boolean addThis;
            if (useWeightLimit) {
                double q0 = wSoFar / totalWeight;
                double q2 = (wSoFar + proposedWeight) / totalWeight;
                addThis = proposedWeight <= totalWeight * Math.min(scale.max(q0, normalizer), scale.max(q2, normalizer));
            } else {
                addThis = projectedW <= wLimit;
            }
            if (i == 1 || i == incomingCount - 1) {
                // force last centroid to never merge
                addThis = false;
            }

            if (addThis) {
                // next point will fit
                // so merge into existing centroid
                weight[lastUsedCell] += incomingWeight[ix];
                mean[lastUsedCell] = mean[lastUsedCell] + (incomingMean[ix] - mean[lastUsedCell]) * incomingWeight[ix]
                    / weight[lastUsedCell];
                incomingWeight[ix] = 0;
            } else {
                // didn't fit ... move to next output, copy out first centroid
                wSoFar += weight[lastUsedCell];
                if (useWeightLimit == false) {
                    k1 = scale.k(wSoFar / totalWeight, normalizer);
                    wLimit = totalWeight * scale.q(k1 + 1, normalizer);
                }

                lastUsedCell++;
                mean[lastUsedCell] = incomingMean[ix];
                weight[lastUsedCell] = incomingWeight[ix];
                incomingWeight[ix] = 0;
            }
        }
        // points to next empty cell
        lastUsedCell++;

        // sanity check
        double sum = 0;
        for (int i = 0; i < lastUsedCell; i++) {
            sum += weight[i];
        }
        assert sum == totalWeight;
        if (runBackwards) {
            Sort.reverse(mean, 0, lastUsedCell);
            Sort.reverse(weight, 0, lastUsedCell);
        }
        if (totalWeight > 0) {
            min = Math.min(min, mean[0]);
            max = Math.max(max, mean[lastUsedCell - 1]);
        }
    }",") {
        // when our incoming buffer fills up, we combine our existing centroids with the incoming data,
        // and then reduce the centroids by merging if possible
        System.arraycopy(mean, 0, incomingMean, incomingCount, lastUsedCell);
        System.arraycopy(weight, 0, incomingWeight, incomingCount, lastUsedCell);
        incomingCount += lastUsedCell;

        if (incomingOrder == null) {
            incomingOrder = new int[incomingCount];
        }
        Sort.stableSort(incomingOrder, incomingMean, incomingCount);

        totalWeight += unmergedWeight;

        // option to run backwards is to help investigate bias in errors
        if (runBackwards) {
            Sort.reverse(incomingOrder, 0, incomingCount);
        }

        // start by copying the least incoming value to the normal buffer
        lastUsedCell = 0;
        mean[lastUsedCell] = incomingMean[incomingOrder[0]];
        weight[lastUsedCell] = incomingWeight[incomingOrder[0]];
        double wSoFar = 0;

        // weight will contain all zeros after this loop

        double normalizer = scale.normalizer(compression, totalWeight);
        double k1 = scale.k(0, normalizer);
        double wLimit = totalWeight * scale.q(k1 + 1, normalizer);
        for (int i = 1; i < incomingCount; i++) {
            int ix = incomingOrder[i];
            double proposedWeight = weight[lastUsedCell] + incomingWeight[ix];
            double projectedW = wSoFar + proposedWeight;
            boolean addThis;
            if (useWeightLimit) {
                double q0 = wSoFar / totalWeight;
                double q2 = (wSoFar + proposedWeight) / totalWeight;
                addThis = proposedWeight <= totalWeight * Math.min(scale.max(q0, normalizer), scale.max(q2, normalizer));
            } else {
                addThis = projectedW <= wLimit;
            }
            if (i == 1 || i == incomingCount - 1) {
                // force last centroid to never merge
                addThis = false;
            }

            if (addThis) {
                // next point will fit
                // so merge into existing centroid
                weight[lastUsedCell] += incomingWeight[ix];
                mean[lastUsedCell] = mean[lastUsedCell] + (incomingMean[ix] - mean[lastUsedCell]) * incomingWeight[ix]
                    / weight[lastUsedCell];
                incomingWeight[ix] = 0;
            } else {
                // didn't fit ... move to next output, copy out first centroid
                wSoFar += weight[lastUsedCell];
                if (useWeightLimit == false) {
                    k1 = scale.k(wSoFar / totalWeight, normalizer);
                    wLimit = totalWeight * scale.q(k1 + 1, normalizer);
                }

                lastUsedCell++;
                mean[lastUsedCell] = incomingMean[ix];
                weight[lastUsedCell] = incomingWeight[ix];
                incomingWeight[ix] = 0;
            }
        }
        // points to next empty cell
        lastUsedCell++;

        // sanity check
        double sum = 0;
        for (int i = 0; i < lastUsedCell; i++) {
            sum += weight[i];
        }
        assert sum == totalWeight;
        if (runBackwards) {
            Sort.reverse(mean, 0, lastUsedCell);
            Sort.reverse(weight, 0, lastUsedCell);
        }
        if (totalWeight > 0) {
            min = Math.min(min, mean[0]);
            max = Math.max(max, mean[lastUsedCell - 1]);
        }
    }",/libs/tdigest/src/main/java/org/elasticsearch/tdigest/MergingDigest.java
d8ff6e9831ede9782d913b67fa04102c2d1182d1,682,216,"public Query termQuery(Object value, QueryShardContext context) {
            failIfNotIndexed();
            double queryValue = NumberFieldMapper.NumberType.DOUBLE.parse(value, false).doubleValue();
            long scaledValue = Math.round(queryValue * scalingFactor);
            Query query = NumberFieldMapper.NumberType.LONG.termQuery(name(), scaledValue);
            if (boost() != 1f) {
                query = new BoostQuery(query, boost());
            }
            return query;
        }","public Query termQuery(Object value, QueryShardContext context) {
            failIfNotIndexed();
            double queryValue = parse(value);
            long scaledValue = Math.round(queryValue * scalingFactor);
            Query query = NumberFieldMapper.NumberType.LONG.termQuery(name(), scaledValue);
            if (boost() != 1f) {
                query = new BoostQuery(query, boost());
            }
            return query;
        }",/core/src/main/java/org/elasticsearch/index/mapper/ScaledFloatFieldMapper.java
d8ff6e9831ede9782d913b67fa04102c2d1182d1,682,258,"public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {
            failIfNotIndexed();
            Long lo = null;
            if (lowerTerm != null) {
                double dValue = NumberFieldMapper.NumberType.DOUBLE.parse(lowerTerm, false).doubleValue();
                if (includeLower == false) {
                    dValue = Math.nextUp(dValue);
                }
                lo = Math.round(Math.ceil(dValue * scalingFactor));
            }
            Long hi = null;
            if (upperTerm != null) {
                double dValue = NumberFieldMapper.NumberType.DOUBLE.parse(upperTerm, false).doubleValue();
                if (includeUpper == false) {
                    dValue = Math.nextDown(dValue);
                }
                hi = Math.round(Math.floor(dValue * scalingFactor));
            }
            Query query = NumberFieldMapper.NumberType.LONG.rangeQuery(name(), lo, hi, true, true, hasDocValues());
            if (boost() != 1f) {
                query = new BoostQuery(query, boost());
            }
            return query;
        }","public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {
            failIfNotIndexed();
            Long lo = null;
            if (lowerTerm != null) {
                double dValue = parse(lowerTerm);
                if (includeLower == false) {
                    dValue = Math.nextUp(dValue);
                }
                lo = Math.round(Math.ceil(dValue * scalingFactor));
            }
            Long hi = null;
            if (upperTerm != null) {
                double dValue = parse(upperTerm);
                if (includeUpper == false) {
                    dValue = Math.nextDown(dValue);
                }
                hi = Math.round(Math.floor(dValue * scalingFactor));
            }
            Query query = NumberFieldMapper.NumberType.LONG.rangeQuery(name(), lo, hi, true, true, hasDocValues());
            if (boost() != 1f) {
                query = new BoostQuery(query, boost());
            }
            return query;
        }",/core/src/main/java/org/elasticsearch/index/mapper/ScaledFloatFieldMapper.java
d8ff6e9831ede9782d913b67fa04102c2d1182d1,682,232,"public Query termsQuery(List<?> values, QueryShardContext context) {
            failIfNotIndexed();
            List<Long> scaledValues = new ArrayList<>(values.size());
            for (Object value : values) {
                double queryValue = NumberFieldMapper.NumberType.DOUBLE.parse(value, false).doubleValue();
                long scaledValue = Math.round(queryValue * scalingFactor);
                scaledValues.add(scaledValue);
            }
            Query query = NumberFieldMapper.NumberType.LONG.termsQuery(name(), Collections.unmodifiableList(scaledValues));
            if (boost() != 1f) {
                query = new BoostQuery(query, boost());
            }
            return query;
        }","public Query termsQuery(List<?> values, QueryShardContext context) {
            failIfNotIndexed();
            List<Long> scaledValues = new ArrayList<>(values.size());
            for (Object value : values) {
                double queryValue = parse(value);
                long scaledValue = Math.round(queryValue * scalingFactor);
                scaledValues.add(scaledValue);
            }
            Query query = NumberFieldMapper.NumberType.LONG.termsQuery(name(), Collections.unmodifiableList(scaledValues));
            if (boost() != 1f) {
                query = new BoostQuery(query, boost());
            }
            return query;
        }",/core/src/main/java/org/elasticsearch/index/mapper/ScaledFloatFieldMapper.java
d8ff6e9831ede9782d913b67fa04102c2d1182d1,682,834,"public Query termQuery(Object value, QueryShardContext context) {
            failIfNotIndexed();
            Query query = type.termQuery(name(), value);
            if (boost() != 1f) {
                query = new BoostQuery(query, boost());
            }
            return query;
        }","private static double objectToDouble(Object value) {
            double doubleValue;

            if (value instanceof Number) {
                doubleValue = ((Number) value).doubleValue();
            } else if (value instanceof BytesRef) {
                doubleValue = Double.parseDouble(((BytesRef) value).utf8ToString());
            } else {
                doubleValue = Double.parseDouble(value.toString());
            }

            return doubleValue;
        }",/core/src/main/java/org/elasticsearch/index/mapper/NumberFieldMapper.java
d8ff6e9831ede9782d913b67fa04102c2d1182d1,682,759,"boolean hasDecimalPart(Object number) {
            if (number instanceof Number) {
                double doubleValue = ((Number) number).doubleValue();
                return doubleValue % 1 != 0;
            }
            if (number instanceof BytesRef) {
                number = ((BytesRef) number).utf8ToString();
            }
            if (number instanceof String) {
                return Double.parseDouble((String) number) % 1 != 0;
            }
            return false;
        }","boolean indexed, boolean docValued, boolean stored) {
                List<Field> fields = new ArrayList<>();
                if (indexed) {
                    fields.add(new LongPoint(name, value.longValue()));
                }
                if (docValued) {
                    fields.add(new SortedNumericDocValuesField(name, value.longValue()));
                }
                if (stored) {
                    fields.add(new StoredField(name, value.longValue()));
                }
                return fields;
            }",/core/src/main/java/org/elasticsearch/index/mapper/NumberFieldMapper.java
1787d7f9881df801bc64be67a2fc48ed9c3c0fa6,563,128,"public void testGeoIpDatabasesDownload() throws Exception {
        ClusterUpdateSettingsResponse settingsResponse = client().admin().cluster()
            .prepareUpdateSettings()
            .setPersistentSettings(Settings.builder().put(GeoIpDownloaderTaskExecutor.ENABLED_SETTING.getKey(), true))
            .get();
        assertTrue(settingsResponse.isAcknowledged());
        assertBusy(() -> {
            PersistentTasksCustomMetadata.PersistentTask<PersistentTaskParams> task = getTask();
            assertNotNull(task);
            GeoIpTaskState state = (GeoIpTaskState) task.getState();
            assertNotNull(state);
            assertEquals(Set.of(""GeoLite2-ASN.mmdb"", ""GeoLite2-City.mmdb"", ""GeoLite2-Country.mmdb""), state.getDatabases().keySet());
        }, 2, TimeUnit.MINUTES);

        GeoIpTaskState state = (GeoIpTaskState) getTask().getState();
        for (String id : List.of(""GeoLite2-ASN.mmdb"", ""GeoLite2-City.mmdb"", ""GeoLite2-Country.mmdb"")) {
            assertBusy(() -> {
                GeoIpTaskState.Metadata metadata = state.get(id);
                BoolQueryBuilder queryBuilder = new BoolQueryBuilder()
                    .filter(new MatchQueryBuilder(""name"", id))
                    .filter(new RangeQueryBuilder(""chunk"")
                        .from(metadata.getFirstChunk())
                        .to(metadata.getLastChunk(), true));
                int size = metadata.getLastChunk() - metadata.getFirstChunk() + 1;
                SearchResponse res = client().prepareSearch(GeoIpDownloader.DATABASES_INDEX)
                    .setSize(size)
                    .setQuery(queryBuilder)
                    .addSort(""chunk"", SortOrder.ASC)
                    .get();
                TotalHits totalHits = res.getHits().getTotalHits();
                assertEquals(TotalHits.Relation.EQUAL_TO, totalHits.relation);
                assertEquals(size, totalHits.value);
                assertEquals(size, res.getHits().getHits().length);

                List<byte[]> data = new ArrayList<>();

                for (SearchHit hit : res.getHits().getHits()) {
                    data.add((byte[]) hit.getSourceAsMap().get(""data""));
                }

                GZIPInputStream stream = new GZIPInputStream(new MultiByteArrayInputStream(data));
                Path tempFile = createTempFile();
                try (OutputStream os = new BufferedOutputStream(Files.newOutputStream(tempFile, TRUNCATE_EXISTING, WRITE, CREATE))) {
                    stream.transferTo(os);
                }

                parseDatabase(tempFile);
            });
        }
    }","public void testGeoIpDatabasesDownload() throws Exception {
        ClusterUpdateSettingsResponse settingsResponse = client().admin().cluster()
            .prepareUpdateSettings()
            .setPersistentSettings(Settings.builder().put(GeoIpDownloaderTaskExecutor.ENABLED_SETTING.getKey(), true))
            .get();
        assertTrue(settingsResponse.isAcknowledged());
        assertBusy(() -> {
            PersistentTasksCustomMetadata.PersistentTask<PersistentTaskParams> task = getTask();
            assertNotNull(task);
            GeoIpTaskState state = (GeoIpTaskState) task.getState();
            assertNotNull(state);
            assertEquals(Set.of(""GeoLite2-ASN.mmdb"", ""GeoLite2-City.mmdb"", ""GeoLite2-Country.mmdb""), state.getDatabases().keySet());
        }, 2, TimeUnit.MINUTES);

        for (String id : List.of(""GeoLite2-ASN.mmdb"", ""GeoLite2-City.mmdb"", ""GeoLite2-Country.mmdb"")) {
            assertBusy(() -> {
                try {
                    GeoIpTaskState state = (GeoIpTaskState) getTask().getState();
                    assertEquals(Set.of(""GeoLite2-ASN.mmdb"", ""GeoLite2-City.mmdb"", ""GeoLite2-Country.mmdb""), state.getDatabases().keySet());
                    GeoIpTaskState.Metadata metadata = state.get(id);
                    BoolQueryBuilder queryBuilder = new BoolQueryBuilder()
                        .filter(new MatchQueryBuilder(""name"", id))
                        .filter(new RangeQueryBuilder(""chunk"")
                            .from(metadata.getFirstChunk())
                            .to(metadata.getLastChunk(), true));
                    int size = metadata.getLastChunk() - metadata.getFirstChunk() + 1;
                    SearchResponse res = client().prepareSearch(GeoIpDownloader.DATABASES_INDEX)
                        .setSize(size)
                        .setQuery(queryBuilder)
                        .addSort(""chunk"", SortOrder.ASC)
                        .get();
                    TotalHits totalHits = res.getHits().getTotalHits();
                    assertEquals(TotalHits.Relation.EQUAL_TO, totalHits.relation);
                    assertEquals(size, totalHits.value);
                    assertEquals(size, res.getHits().getHits().length);

                    List<byte[]> data = new ArrayList<>();

                    for (SearchHit hit : res.getHits().getHits()) {
                        data.add((byte[]) hit.getSourceAsMap().get(""data""));
                    }

                    GZIPInputStream stream = new GZIPInputStream(new MultiByteArrayInputStream(data));
                    Path tempFile = createTempFile();
                    try (OutputStream os = new BufferedOutputStream(Files.newOutputStream(tempFile, TRUNCATE_EXISTING, WRITE, CREATE))) {
                        stream.transferTo(os);
                    }
                    parseDatabase(tempFile);
                } catch (Exception e) {
                    throw new AssertionError(e);
                }
            });
        }
    }",/modules/ingest-geoip/src/internalClusterTest/java/org/elasticsearch/ingest/geoip/GeoIpDownloaderIT.java
2a00f25f573e1c1078c1f864eea52397a081c5c8,704,45,"public void testReleaseInternalBitSet() {
        int numBits = (short) randomIntBetween(8, 4096);
        final CountedBitSet countedBitSet = new CountedBitSet((short) numBits);
        final List<Integer> values = IntStream.range(0, numBits).boxed().collect(Collectors.toList());

        for (int i = 1; i < numBits; i++) {
            final int value = values.get(i);
            assertThat(countedBitSet.get(value), equalTo(false));
            assertThat(countedBitSet.isInternalBitsetReleased(), equalTo(false));

            countedBitSet.set(value);

            assertThat(countedBitSet.get(value), equalTo(true));
            assertThat(countedBitSet.isInternalBitsetReleased(), equalTo(false));
            assertThat(countedBitSet.length(), equalTo(numBits));
            assertThat(countedBitSet.cardinality(), equalTo(i));
        }

        // The missing piece to fill all bits.
        {
            final int value = values.get(0);
            assertThat(countedBitSet.get(value), equalTo(false));
            assertThat(countedBitSet.isInternalBitsetReleased(), equalTo(false));

            countedBitSet.set(value);

            assertThat(countedBitSet.get(value), equalTo(true));
            assertThat(countedBitSet.isInternalBitsetReleased(), equalTo(true));
            assertThat(countedBitSet.length(), equalTo(numBits));
            assertThat(countedBitSet.cardinality(), equalTo(numBits));
        }

        // Tests with released internal bitset.
        final int iterations = iterations(1000, 10000);
        for (int i = 0; i < iterations; i++) {
            final int value = randomInt(numBits - 1);
            assertThat(countedBitSet.get(value), equalTo(true));
            assertThat(countedBitSet.isInternalBitsetReleased(), equalTo(true));
            assertThat(countedBitSet.length(), equalTo(numBits));
            assertThat(countedBitSet.cardinality(), equalTo(numBits));
            if (frequently()) {
                assertThat(countedBitSet.get(value), equalTo(true));
            }
        }
    }","public void testReleaseInternalBitSet() {
        int numBits = (short) randomIntBetween(8, 4096);
        final CountedBitSet countedBitSet = new CountedBitSet((short) numBits);
        final List<Integer> values = IntStream.range(0, numBits).boxed().toList();

        for (int i = 1; i < numBits; i++) {
            final int value = values.get(i);
            assertThat(countedBitSet.get(value), equalTo(false));
            assertThat(countedBitSet.isInternalBitsetReleased(), equalTo(false));

            countedBitSet.set(value);

            assertThat(countedBitSet.get(value), equalTo(true));
            assertThat(countedBitSet.isInternalBitsetReleased(), equalTo(false));
            assertThat(countedBitSet.length(), equalTo(numBits));
            assertThat(countedBitSet.cardinality(), equalTo(i));
        }

        // The missing piece to fill all bits.
        {
            final int value = values.get(0);
            assertThat(countedBitSet.get(value), equalTo(false));
            assertThat(countedBitSet.isInternalBitsetReleased(), equalTo(false));

            countedBitSet.set(value);

            assertThat(countedBitSet.get(value), equalTo(true));
            assertThat(countedBitSet.isInternalBitsetReleased(), equalTo(true));
            assertThat(countedBitSet.length(), equalTo(numBits));
            assertThat(countedBitSet.cardinality(), equalTo(numBits));
        }

        // Tests with released internal bitset.
        final int iterations = iterations(1000, 10000);
        for (int i = 0; i < iterations; i++) {
            final int value = randomInt(numBits - 1);
            assertThat(countedBitSet.get(value), equalTo(true));
            assertThat(countedBitSet.isInternalBitsetReleased(), equalTo(true));
            assertThat(countedBitSet.length(), equalTo(numBits));
            assertThat(countedBitSet.cardinality(), equalTo(numBits));
            if (frequently()) {
                assertThat(countedBitSet.get(value), equalTo(true));
            }
        }
    }",/server/src/test/java/org/elasticsearch/index/seqno/CountedBitSetTests.java
2a00f25f573e1c1078c1f864eea52397a081c5c8,570,878,"public void testReplicaProxy() throws InterruptedException, ExecutionException {
        final String index = ""test"";
        final ShardId shardId = new ShardId(index, ""_na_"", 0);
        ClusterState state = stateWithActivePrimary(index, true, 1 + randomInt(3), randomInt(2));
        logger.info(""using state: {}"", state);
        setState(clusterService, state);
        final long primaryTerm = state.metadata().index(index).primaryTerm(0);
        ReplicationOperation.Replicas<Request> proxy = action.newReplicasProxy();

        // check that at unknown node fails
        PlainActionFuture<ReplicaResponse> listener = new PlainActionFuture<>();
        ShardRoutingState routingState = randomFrom(
            ShardRoutingState.INITIALIZING,
            ShardRoutingState.STARTED,
            ShardRoutingState.RELOCATING
        );
        proxy.performOn(
            TestShardRouting.newShardRouting(
                shardId,
                ""NOT THERE"",
                routingState == ShardRoutingState.RELOCATING ? state.nodes().iterator().next().getId() : null,
                false,
                routingState
            ),
            new Request(NO_SHARD_ID),
            primaryTerm,
            randomNonNegativeLong(),
            randomNonNegativeLong(),
            listener
        );
        assertTrue(listener.isDone());
        assertListenerThrows(""non existent node should throw a NoNodeAvailableException"", listener, NoNodeAvailableException.class);

        final IndexShardRoutingTable shardRoutings = state.routingTable().shardRoutingTable(shardId);
        final ShardRouting replica = randomFrom(
            shardRoutings.replicaShards().stream().filter(ShardRouting::assignedToNode).collect(Collectors.toList())
        );
        listener = new PlainActionFuture<>();
        proxy.performOn(replica, new Request(NO_SHARD_ID), primaryTerm, randomNonNegativeLong(), randomNonNegativeLong(), listener);
        assertFalse(listener.isDone());

        CapturingTransport.CapturedRequest[] captures = transport.getCapturedRequestsAndClear();
        assertThat(captures, arrayWithSize(1));
        if (randomBoolean()) {
            final TransportReplicationAction.ReplicaResponse response = new TransportReplicationAction.ReplicaResponse(
                randomLong(),
                randomLong()
            );
            transport.handleResponse(captures[0].requestId(), response);
            assertTrue(listener.isDone());
            assertThat(listener.get(), equalTo(response));
        } else if (randomBoolean()) {
            transport.handleRemoteError(captures[0].requestId(), new ElasticsearchException(""simulated""));
            assertTrue(listener.isDone());
            assertListenerThrows(""listener should reflect remote error"", listener, ElasticsearchException.class);
        } else {
            transport.handleError(captures[0].requestId(), new TransportException(""simulated""));
            assertTrue(listener.isDone());
            assertListenerThrows(""listener should reflect remote error"", listener, TransportException.class);
        }

        AtomicReference<Object> failure = new AtomicReference<>();
        AtomicBoolean success = new AtomicBoolean();
        proxy.failShardIfNeeded(
            replica,
            primaryTerm,
            ""test"",
            new ElasticsearchException(""simulated""),
            ActionListener.wrap(r -> success.set(true), failure::set)
        );
        CapturingTransport.CapturedRequest[] shardFailedRequests = transport.getCapturedRequestsAndClear();
        // A replication action doesn't not fail the request
        assertEquals(0, shardFailedRequests.length);
    }","public void testReplicaProxy() throws InterruptedException, ExecutionException {
        final String index = ""test"";
        final ShardId shardId = new ShardId(index, ""_na_"", 0);
        ClusterState state = stateWithActivePrimary(index, true, 1 + randomInt(3), randomInt(2));
        logger.info(""using state: {}"", state);
        setState(clusterService, state);
        final long primaryTerm = state.metadata().index(index).primaryTerm(0);
        ReplicationOperation.Replicas<Request> proxy = action.newReplicasProxy();

        // check that at unknown node fails
        PlainActionFuture<ReplicaResponse> listener = new PlainActionFuture<>();
        ShardRoutingState routingState = randomFrom(
            ShardRoutingState.INITIALIZING,
            ShardRoutingState.STARTED,
            ShardRoutingState.RELOCATING
        );
        proxy.performOn(
            TestShardRouting.newShardRouting(
                shardId,
                ""NOT THERE"",
                routingState == ShardRoutingState.RELOCATING ? state.nodes().iterator().next().getId() : null,
                false,
                routingState
            ),
            new Request(NO_SHARD_ID),
            primaryTerm,
            randomNonNegativeLong(),
            randomNonNegativeLong(),
            listener
        );
        assertTrue(listener.isDone());
        assertListenerThrows(""non existent node should throw a NoNodeAvailableException"", listener, NoNodeAvailableException.class);

        final IndexShardRoutingTable shardRoutings = state.routingTable().shardRoutingTable(shardId);
        final ShardRouting replica = randomFrom(shardRoutings.replicaShards().stream().filter(ShardRouting::assignedToNode).toList());
        listener = new PlainActionFuture<>();
        proxy.performOn(replica, new Request(NO_SHARD_ID), primaryTerm, randomNonNegativeLong(), randomNonNegativeLong(), listener);
        assertFalse(listener.isDone());

        CapturingTransport.CapturedRequest[] captures = transport.getCapturedRequestsAndClear();
        assertThat(captures, arrayWithSize(1));
        if (randomBoolean()) {
            final TransportReplicationAction.ReplicaResponse response = new TransportReplicationAction.ReplicaResponse(
                randomLong(),
                randomLong()
            );
            transport.handleResponse(captures[0].requestId(), response);
            assertTrue(listener.isDone());
            assertThat(listener.get(), equalTo(response));
        } else if (randomBoolean()) {
            transport.handleRemoteError(captures[0].requestId(), new ElasticsearchException(""simulated""));
            assertTrue(listener.isDone());
            assertListenerThrows(""listener should reflect remote error"", listener, ElasticsearchException.class);
        } else {
            transport.handleError(captures[0].requestId(), new TransportException(""simulated""));
            assertTrue(listener.isDone());
            assertListenerThrows(""listener should reflect remote error"", listener, TransportException.class);
        }

        AtomicReference<Object> failure = new AtomicReference<>();
        AtomicBoolean success = new AtomicBoolean();
        proxy.failShardIfNeeded(
            replica,
            primaryTerm,
            ""test"",
            new ElasticsearchException(""simulated""),
            ActionListener.wrap(r -> success.set(true), failure::set)
        );
        CapturingTransport.CapturedRequest[] shardFailedRequests = transport.getCapturedRequestsAndClear();
        // A replication action doesn't not fail the request
        assertEquals(0, shardFailedRequests.length);
    }",/server/src/test/java/org/elasticsearch/action/support/replication/TransportReplicationActionTests.java
2a00f25f573e1c1078c1f864eea52397a081c5c8,391,204,"public void testPreferCopyCanPerformNoopRecovery() throws Exception {
        String indexName = ""test"";
        String nodeWithPrimary = internalCluster().startNode();
        assertAcked(
            client().admin()
                .indices()
                .prepareCreate(indexName)
                .setSettings(
                    Settings.builder()
                        .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)
                        .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1)
                        .put(IndexSettings.INDEX_SOFT_DELETES_RETENTION_LEASE_PERIOD_SETTING.getKey(), ""1ms"") // expire PRRLs quickly
                        .put(IndexService.RETENTION_LEASE_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(IndexService.GLOBAL_CHECKPOINT_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), ""1ms"")
                )
        );
        String nodeWithReplica = internalCluster().startDataOnlyNode();
        Settings nodeWithReplicaSettings = internalCluster().dataPathSettings(nodeWithReplica);
        ensureGreen(indexName);
        indexRandom(
            randomBoolean(),
            randomBoolean(),
            randomBoolean(),
            IntStream.range(0, between(100, 500))
                .mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v""))
                .collect(Collectors.toList())
        );
        if (randomBoolean()) {
            client().admin().indices().prepareFlush(indexName).get();
        }
        ensureGlobalCheckpointAdvancedAndSynced(indexName);
        syncFlush(indexName);
        internalCluster().stopRandomNode(InternalTestCluster.nameFilter(nodeWithReplica));
        // Wait until the peer recovery retention leases of the offline node are expired
        assertBusy(() -> {
            for (ShardStats shardStats : client().admin().indices().prepareStats(indexName).get().getShards()) {
                assertThat(shardStats.getRetentionLeaseStats().retentionLeases().leases(), hasSize(1));
            }
        });
        CountDownLatch blockRecovery = new CountDownLatch(1);
        CountDownLatch recoveryStarted = new CountDownLatch(1);
        MockTransportService transportServiceOnPrimary = (MockTransportService) internalCluster().getInstance(
            TransportService.class,
            nodeWithPrimary
        );
        transportServiceOnPrimary.addSendBehavior((connection, requestId, action, request, options) -> {
            if (PeerRecoveryTargetService.Actions.FILES_INFO.equals(action)) {
                recoveryStarted.countDown();
                try {
                    blockRecovery.await();
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
            }
            connection.sendRequest(requestId, action, request, options);
        });
        internalCluster().startDataOnlyNode();
        recoveryStarted.await();
        nodeWithReplica = internalCluster().startDataOnlyNode(nodeWithReplicaSettings);
        // AllocationService only calls GatewayAllocator if there're unassigned shards
        assertAcked(client().admin().indices().prepareCreate(""dummy-index"").setWaitForActiveShards(0));
        ensureGreen(indexName);
        assertThat(internalCluster().nodesInclude(indexName), hasItem(nodeWithReplica));
        assertNoOpRecoveries(indexName);
        blockRecovery.countDown();
        transportServiceOnPrimary.clearAllRules();
    }","public void testPreferCopyCanPerformNoopRecovery() throws Exception {
        String indexName = ""test"";
        String nodeWithPrimary = internalCluster().startNode();
        assertAcked(
            client().admin()
                .indices()
                .prepareCreate(indexName)
                .setSettings(
                    Settings.builder()
                        .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)
                        .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1)
                        .put(IndexSettings.INDEX_SOFT_DELETES_RETENTION_LEASE_PERIOD_SETTING.getKey(), ""1ms"") // expire PRRLs quickly
                        .put(IndexService.RETENTION_LEASE_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(IndexService.GLOBAL_CHECKPOINT_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), ""1ms"")
                )
        );
        String nodeWithReplica = internalCluster().startDataOnlyNode();
        Settings nodeWithReplicaSettings = internalCluster().dataPathSettings(nodeWithReplica);
        ensureGreen(indexName);
        indexRandom(
            randomBoolean(),
            randomBoolean(),
            randomBoolean(),
            IntStream.range(0, between(100, 500)).mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v"")).toList()
        );
        if (randomBoolean()) {
            client().admin().indices().prepareFlush(indexName).get();
        }
        ensureGlobalCheckpointAdvancedAndSynced(indexName);
        syncFlush(indexName);
        internalCluster().stopRandomNode(InternalTestCluster.nameFilter(nodeWithReplica));
        // Wait until the peer recovery retention leases of the offline node are expired
        assertBusy(() -> {
            for (ShardStats shardStats : client().admin().indices().prepareStats(indexName).get().getShards()) {
                assertThat(shardStats.getRetentionLeaseStats().retentionLeases().leases(), hasSize(1));
            }
        });
        CountDownLatch blockRecovery = new CountDownLatch(1);
        CountDownLatch recoveryStarted = new CountDownLatch(1);
        MockTransportService transportServiceOnPrimary = (MockTransportService) internalCluster().getInstance(
            TransportService.class,
            nodeWithPrimary
        );
        transportServiceOnPrimary.addSendBehavior((connection, requestId, action, request, options) -> {
            if (PeerRecoveryTargetService.Actions.FILES_INFO.equals(action)) {
                recoveryStarted.countDown();
                try {
                    blockRecovery.await();
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
            }
            connection.sendRequest(requestId, action, request, options);
        });
        internalCluster().startDataOnlyNode();
        recoveryStarted.await();
        nodeWithReplica = internalCluster().startDataOnlyNode(nodeWithReplicaSettings);
        // AllocationService only calls GatewayAllocator if there're unassigned shards
        assertAcked(client().admin().indices().prepareCreate(""dummy-index"").setWaitForActiveShards(0));
        ensureGreen(indexName);
        assertThat(internalCluster().nodesInclude(indexName), hasItem(nodeWithReplica));
        assertNoOpRecoveries(indexName);
        blockRecovery.countDown();
        transportServiceOnPrimary.clearAllRules();
    }",/server/src/internalClusterTest/java/org/elasticsearch/gateway/ReplicaShardAllocatorSyncIdIT.java
2a00f25f573e1c1078c1f864eea52397a081c5c8,563,79,"throws Exception {
        try (ThreadContext.StoredContext ignore = threadContext.stashWithOrigin(MONITORING_ORIGIN)) {
            final long timestamp = timestamp();
            final String clusterUuid = clusterUuid(clusterState);

            final CcrStatsAction.Request request = new CcrStatsAction.Request();
            final CcrStatsAction.Response response = client.execute(CcrStatsAction.INSTANCE, request).actionGet(getCollectionTimeout());

            final AutoFollowStatsMonitoringDoc autoFollowStatsDoc = new AutoFollowStatsMonitoringDoc(
                clusterUuid,
                timestamp,
                interval,
                node,
                response.getAutoFollowStats()
            );

            Set<String> collectionIndices = new HashSet<>(Arrays.asList(getCollectionIndices()));
            List<MonitoringDoc> docs = response.getFollowStats()
                .getStatsResponses()
                .stream()
                .filter(statsResponse -> collectionIndices.isEmpty() || collectionIndices.contains(statsResponse.status().followerIndex()))
                .map(stats -> new FollowStatsMonitoringDoc(clusterUuid, timestamp, interval, node, stats.status()))
                .collect(Collectors.toList());
            docs.add(autoFollowStatsDoc);
            return docs;
        }
    }","throws Exception {
        try (ThreadContext.StoredContext ignore = threadContext.stashWithOrigin(MONITORING_ORIGIN)) {
            final long timestamp = timestamp();
            final String clusterUuid = clusterUuid(clusterState);

            final CcrStatsAction.Request request = new CcrStatsAction.Request();
            final CcrStatsAction.Response response = client.execute(CcrStatsAction.INSTANCE, request).actionGet(getCollectionTimeout());

            final AutoFollowStatsMonitoringDoc autoFollowStatsDoc = new AutoFollowStatsMonitoringDoc(
                clusterUuid,
                timestamp,
                interval,
                node,
                response.getAutoFollowStats()
            );

            Set<String> collectionIndices = new HashSet<>(Arrays.asList(getCollectionIndices()));
            List<MonitoringDoc> docs = response.getFollowStats()
                .getStatsResponses()
                .stream()
                .filter(statsResponse -> collectionIndices.isEmpty() || collectionIndices.contains(statsResponse.status().followerIndex()))
                .map(stats -> new FollowStatsMonitoringDoc(clusterUuid, timestamp, interval, node, stats.status()))
                .collect(Collectors.toCollection(ArrayList::new));
            docs.add(autoFollowStatsDoc);
            return docs;
        }
    }",/x-pack/plugin/monitoring/src/main/java/org/elasticsearch/xpack/monitoring/collector/ccr/StatsCollector.java
2a00f25f573e1c1078c1f864eea52397a081c5c8,563,87,"throws Exception {
        // fetch details about all jobs
        try (ThreadContext.StoredContext ignore = threadContext.stashWithOrigin(MONITORING_ORIGIN)) {
            final GetJobsStatsAction.Request request = new GetJobsStatsAction.Request(Metadata.ALL).setTimeout(getCollectionTimeout());
            final GetJobsStatsAction.Response jobs = client.execute(GetJobsStatsAction.INSTANCE, request).actionGet();

            ensureNoTimeouts(getCollectionTimeout(), jobs);

            final long timestamp = timestamp();
            final String clusterUuid = clusterUuid(clusterState);

            return jobs.getResponse()
                .results()
                .stream()
                .map(jobStats -> new JobStatsMonitoringDoc(clusterUuid, timestamp, interval, node, jobStats))
                .collect(Collectors.toList());
        }
    }","throws Exception {
        // fetch details about all jobs
        try (ThreadContext.StoredContext ignore = threadContext.stashWithOrigin(MONITORING_ORIGIN)) {
            final GetJobsStatsAction.Request request = new GetJobsStatsAction.Request(Metadata.ALL).setTimeout(getCollectionTimeout());
            final GetJobsStatsAction.Response jobs = client.execute(GetJobsStatsAction.INSTANCE, request).actionGet();

            ensureNoTimeouts(getCollectionTimeout(), jobs);

            final long timestamp = timestamp();
            final String clusterUuid = clusterUuid(clusterState);

            return jobs.getResponse()
                .results()
                .stream()
                .<MonitoringDoc>map(jobStats -> new JobStatsMonitoringDoc(clusterUuid, timestamp, interval, node, jobStats))
                .toList();
        }
    }",/x-pack/plugin/monitoring/src/main/java/org/elasticsearch/xpack/monitoring/collector/ml/JobStatsCollector.java
2a00f25f573e1c1078c1f864eea52397a081c5c8,391,195,"public void testRecentPrimaryInformation() throws Exception {
        String indexName = ""test"";
        String nodeWithPrimary = internalCluster().startNode();
        assertAcked(
            client().admin()
                .indices()
                .prepareCreate(indexName)
                .setSettings(
                    Settings.builder()
                        .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)
                        .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1)
                        .put(IndexSettings.FILE_BASED_RECOVERY_THRESHOLD_SETTING.getKey(), 0.1f)
                        .put(IndexService.GLOBAL_CHECKPOINT_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(IndexService.RETENTION_LEASE_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), ""1ms"")
                )
        );
        String nodeWithReplica = internalCluster().startDataOnlyNode();
        DiscoveryNode discoNodeWithReplica = internalCluster().getInstance(ClusterService.class, nodeWithReplica).localNode();
        Settings nodeWithReplicaSettings = internalCluster().dataPathSettings(nodeWithReplica);
        ensureGreen(indexName);

        indexRandom(
            randomBoolean(),
            false,
            randomBoolean(),
            IntStream.range(0, between(10, 100))
                .mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v""))
                .collect(Collectors.toList())
        );
        internalCluster().stopRandomNode(InternalTestCluster.nameFilter(nodeWithReplica));
        if (randomBoolean()) {
            indexRandom(
                randomBoolean(),
                false,
                randomBoolean(),
                IntStream.range(0, between(10, 100))
                    .mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v""))
                    .collect(Collectors.toList())
            );
        }
        CountDownLatch blockRecovery = new CountDownLatch(1);
        CountDownLatch recoveryStarted = new CountDownLatch(1);
        MockTransportService transportServiceOnPrimary = (MockTransportService) internalCluster().getInstance(
            TransportService.class,
            nodeWithPrimary
        );
        transportServiceOnPrimary.addSendBehavior((connection, requestId, action, request, options) -> {
            if (PeerRecoveryTargetService.Actions.FILES_INFO.equals(action)) {
                recoveryStarted.countDown();
                try {
                    blockRecovery.await();
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
            }
            connection.sendRequest(requestId, action, request, options);
        });
        String newNode = internalCluster().startDataOnlyNode();
        recoveryStarted.await();
        // Index more documents and flush to destroy sync_id and remove the retention lease (as file_based_recovery_threshold reached).
        indexRandom(
            randomBoolean(),
            randomBoolean(),
            randomBoolean(),
            IntStream.range(0, between(50, 200))
                .mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v""))
                .collect(Collectors.toList())
        );
        client().admin().indices().prepareFlush(indexName).get();
        assertBusy(() -> {
            for (ShardStats shardStats : client().admin().indices().prepareStats(indexName).get().getShards()) {
                for (RetentionLease lease : shardStats.getRetentionLeaseStats().retentionLeases().leases()) {
                    assertThat(lease.id(), not(equalTo(ReplicationTracker.getPeerRecoveryRetentionLeaseId(discoNodeWithReplica.getId()))));
                }
            }
        });
        // AllocationService only calls GatewayAllocator if there are unassigned shards
        assertAcked(
            client().admin()
                .indices()
                .prepareCreate(""dummy-index"")
                .setWaitForActiveShards(0)
                .setSettings(Settings.builder().put(""index.routing.allocation.require.attr"", ""not-found""))
        );
        internalCluster().startDataOnlyNode(nodeWithReplicaSettings);
        // need to wait for events to ensure the reroute has happened since we perform it async when a new node joins.
        client().admin().cluster().prepareHealth(indexName).setWaitForYellowStatus().setWaitForEvents(Priority.LANGUID).get();
        blockRecovery.countDown();
        ensureGreen(indexName);
        assertThat(internalCluster().nodesInclude(indexName), hasItem(newNode));
        for (RecoveryState recovery : client().admin().indices().prepareRecoveries(indexName).get().shardRecoveryStates().get(indexName)) {
            if (recovery.getPrimary() == false) {
                assertThat(recovery.getIndex().fileDetails(), not(empty()));
            }
        }
        transportServiceOnPrimary.clearAllRules();
    }","public void testRecentPrimaryInformation() throws Exception {
        String indexName = ""test"";
        String nodeWithPrimary = internalCluster().startNode();
        assertAcked(
            client().admin()
                .indices()
                .prepareCreate(indexName)
                .setSettings(
                    Settings.builder()
                        .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)
                        .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1)
                        .put(IndexSettings.FILE_BASED_RECOVERY_THRESHOLD_SETTING.getKey(), 0.1f)
                        .put(IndexService.GLOBAL_CHECKPOINT_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(IndexService.RETENTION_LEASE_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), ""1ms"")
                )
        );
        String nodeWithReplica = internalCluster().startDataOnlyNode();
        DiscoveryNode discoNodeWithReplica = internalCluster().getInstance(ClusterService.class, nodeWithReplica).localNode();
        Settings nodeWithReplicaSettings = internalCluster().dataPathSettings(nodeWithReplica);
        ensureGreen(indexName);

        indexRandom(
            randomBoolean(),
            false,
            randomBoolean(),
            IntStream.range(0, between(10, 100)).mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v"")).toList()
        );
        internalCluster().stopRandomNode(InternalTestCluster.nameFilter(nodeWithReplica));
        if (randomBoolean()) {
            indexRandom(
                randomBoolean(),
                false,
                randomBoolean(),
                IntStream.range(0, between(10, 100)).mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v"")).toList()
            );
        }
        CountDownLatch blockRecovery = new CountDownLatch(1);
        CountDownLatch recoveryStarted = new CountDownLatch(1);
        MockTransportService transportServiceOnPrimary = (MockTransportService) internalCluster().getInstance(
            TransportService.class,
            nodeWithPrimary
        );
        transportServiceOnPrimary.addSendBehavior((connection, requestId, action, request, options) -> {
            if (PeerRecoveryTargetService.Actions.FILES_INFO.equals(action)) {
                recoveryStarted.countDown();
                try {
                    blockRecovery.await();
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
            }
            connection.sendRequest(requestId, action, request, options);
        });
        String newNode = internalCluster().startDataOnlyNode();
        recoveryStarted.await();
        // Index more documents and flush to destroy sync_id and remove the retention lease (as file_based_recovery_threshold reached).
        indexRandom(
            randomBoolean(),
            randomBoolean(),
            randomBoolean(),
            IntStream.range(0, between(50, 200)).mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v"")).toList()
        );
        client().admin().indices().prepareFlush(indexName).get();
        assertBusy(() -> {
            for (ShardStats shardStats : client().admin().indices().prepareStats(indexName).get().getShards()) {
                for (RetentionLease lease : shardStats.getRetentionLeaseStats().retentionLeases().leases()) {
                    assertThat(lease.id(), not(equalTo(ReplicationTracker.getPeerRecoveryRetentionLeaseId(discoNodeWithReplica.getId()))));
                }
            }
        });
        // AllocationService only calls GatewayAllocator if there are unassigned shards
        assertAcked(
            client().admin()
                .indices()
                .prepareCreate(""dummy-index"")
                .setWaitForActiveShards(0)
                .setSettings(Settings.builder().put(""index.routing.allocation.require.attr"", ""not-found""))
        );
        internalCluster().startDataOnlyNode(nodeWithReplicaSettings);
        // need to wait for events to ensure the reroute has happened since we perform it async when a new node joins.
        client().admin().cluster().prepareHealth(indexName).setWaitForYellowStatus().setWaitForEvents(Priority.LANGUID).get();
        blockRecovery.countDown();
        ensureGreen(indexName);
        assertThat(internalCluster().nodesInclude(indexName), hasItem(newNode));
        for (RecoveryState recovery : client().admin().indices().prepareRecoveries(indexName).get().shardRecoveryStates().get(indexName)) {
            if (recovery.getPrimary() == false) {
                assertThat(recovery.getIndex().fileDetails(), not(empty()));
            }
        }
        transportServiceOnPrimary.clearAllRules();
    }",/server/src/internalClusterTest/java/org/elasticsearch/gateway/ReplicaShardAllocatorIT.java
2a00f25f573e1c1078c1f864eea52397a081c5c8,563,1854,"public void testReuseIndicesLookup() {
        String indexName = ""my-index"";
        String aliasName = ""my-alias"";
        String dataStreamName = ""logs-mysql-prod"";
        String dataStreamAliasName = ""logs-mysql"";
        Metadata previous = Metadata.builder().build();

        // Things that should change indices lookup
        {
            Metadata.Builder builder = Metadata.builder(previous);
            IndexMetadata idx = DataStreamTestHelper.createFirstBackingIndex(dataStreamName).build();
            builder.put(idx, true);
            DataStream dataStream = newInstance(dataStreamName, new DataStream.TimestampField(""@timestamp""), List.of(idx.getIndex()));
            builder.put(dataStream);
            Metadata metadata = builder.build();
            assertThat(previous.getIndicesLookup(), not(sameInstance(metadata.getIndicesLookup())));
            previous = metadata;
        }
        {
            Metadata.Builder builder = Metadata.builder(previous);
            builder.put(dataStreamAliasName, dataStreamName, false, null);
            Metadata metadata = builder.build();
            assertThat(previous.getIndicesLookup(), not(sameInstance(metadata.getIndicesLookup())));
            previous = metadata;
        }
        {
            Metadata.Builder builder = Metadata.builder(previous);
            builder.put(dataStreamAliasName, dataStreamName, true, null);
            Metadata metadata = builder.build();
            assertThat(previous.getIndicesLookup(), not(sameInstance(metadata.getIndicesLookup())));
            previous = metadata;
        }
        {
            Metadata.Builder builder = Metadata.builder(previous);
            builder.put(
                IndexMetadata.builder(indexName)
                    .settings(settings(Version.CURRENT))
                    .creationDate(randomNonNegativeLong())
                    .numberOfShards(1)
                    .numberOfReplicas(0)
            );
            Metadata metadata = builder.build();
            assertThat(previous.getIndicesLookup(), not(sameInstance(metadata.getIndicesLookup())));
            previous = metadata;
        }
        {
            Metadata.Builder builder = Metadata.builder(previous);
            IndexMetadata.Builder imBuilder = IndexMetadata.builder(builder.get(indexName));
            imBuilder.putAlias(AliasMetadata.builder(aliasName).build());
            builder.put(imBuilder);
            Metadata metadata = builder.build();
            assertThat(previous.getIndicesLookup(), not(sameInstance(metadata.getIndicesLookup())));
            previous = metadata;
        }
        {
            Metadata.Builder builder = Metadata.builder(previous);
            IndexMetadata.Builder imBuilder = IndexMetadata.builder(builder.get(indexName));
            imBuilder.putAlias(AliasMetadata.builder(aliasName).writeIndex(true).build());
            builder.put(imBuilder);
            Metadata metadata = builder.build();
            assertThat(previous.getIndicesLookup(), not(sameInstance(metadata.getIndicesLookup())));
            previous = metadata;
        }
        {
            Metadata.Builder builder = Metadata.builder(previous);
            IndexMetadata.Builder imBuilder = IndexMetadata.builder(builder.get(indexName));
            Settings.Builder sBuilder = Settings.builder()
                .put(builder.get(indexName).getSettings())
                .put(IndexMetadata.INDEX_HIDDEN_SETTING.getKey(), true);
            imBuilder.settings(sBuilder.build());
            builder.put(imBuilder);
            Metadata metadata = builder.build();
            assertThat(previous.getIndicesLookup(), not(sameInstance(metadata.getIndicesLookup())));
            previous = metadata;
        }

        // Things that shouldn't change indices lookup
        {
            Metadata.Builder builder = Metadata.builder(previous);
            IndexMetadata.Builder imBuilder = IndexMetadata.builder(builder.get(indexName));
            imBuilder.numberOfReplicas(2);
            builder.put(imBuilder);
            Metadata metadata = builder.build();
            assertThat(previous.getIndicesLookup(), sameInstance(metadata.getIndicesLookup()));
            previous = metadata;
        }
        {
            Metadata.Builder builder = Metadata.builder(previous);
            IndexMetadata.Builder imBuilder = IndexMetadata.builder(builder.get(indexName));
            Settings.Builder sBuilder = Settings.builder()
                .put(builder.get(indexName).getSettings())
                .put(IndexSettings.DEFAULT_FIELD_SETTING.getKey(), ""val"");
            imBuilder.settings(sBuilder.build());
            builder.put(imBuilder);
            Metadata metadata = builder.build();
            assertThat(previous.getIndicesLookup(), sameInstance(metadata.getIndicesLookup()));
            previous = metadata;
        }
    }","public void testAliasedIndices() {
        int numAliases = randomIntBetween(32, 64);
        int numIndicesPerAlias = randomIntBetween(8, 16);

        Metadata.Builder builder = Metadata.builder();
        for (int i = 0; i < numAliases; i++) {
            String aliasName = ""alias-"" + i;
            for (int j = 0; j < numIndicesPerAlias; j++) {
                AliasMetadata.Builder alias = new AliasMetadata.Builder(aliasName);
                if (j == 0) {
                    alias.writeIndex(true);
                }

                String indexName = aliasName + ""-"" + j;
                builder.put(
                    IndexMetadata.builder(indexName)
                        .settings(settings(Version.CURRENT))
                        .creationDate(randomNonNegativeLong())
                        .numberOfShards(1)
                        .numberOfReplicas(0)
                        .putAlias(alias)
                );
            }
        }

        Metadata metadata = builder.build();
        for (int i = 0; i < numAliases; i++) {
            String aliasName = ""alias-"" + i;
            Set<Index> result = metadata.aliasedIndices(aliasName);
            Index[] expected = IntStream.range(0, numIndicesPerAlias)
                .mapToObj(j -> aliasName + ""-"" + j)
                .map(name -> new Index(name, ClusterState.UNKNOWN_UUID))
                .toArray(Index[]::new);
            assertThat(result, containsInAnyOrder(expected));
        }

        // Add a new alias and index
        builder = Metadata.builder(metadata);
        String newAliasName = ""alias-new"";
        {
            builder.put(
                IndexMetadata.builder(newAliasName + ""-1"")
                    .settings(settings(Version.CURRENT))
                    .creationDate(randomNonNegativeLong())
                    .numberOfShards(1)
                    .numberOfReplicas(0)
                    .putAlias(new AliasMetadata.Builder(newAliasName).writeIndex(true))
            );
        }
        metadata = builder.build();
        assertThat(metadata.aliasedIndices(), hasSize(numAliases + 1));
        assertThat(metadata.aliasedIndices(newAliasName), contains(new Index(newAliasName + ""-1"", ClusterState.UNKNOWN_UUID)));

        // Remove the new alias/index
        builder = Metadata.builder(metadata);
        {
            builder.remove(newAliasName + ""-1"");
        }
        metadata = builder.build();
        assertThat(metadata.aliasedIndices(), hasSize(numAliases));
        assertThat(metadata.aliasedIndices(newAliasName), empty());

        // Add a new alias that points to existing indices
        builder = Metadata.builder(metadata);
        {
            IndexMetadata.Builder imBuilder = new IndexMetadata.Builder(metadata.index(""alias-1-0""));
            imBuilder.putAlias(new AliasMetadata.Builder(newAliasName));
            builder.put(imBuilder);

            imBuilder = new IndexMetadata.Builder(metadata.index(""alias-2-1""));
            imBuilder.putAlias(new AliasMetadata.Builder(newAliasName));
            builder.put(imBuilder);

            imBuilder = new IndexMetadata.Builder(metadata.index(""alias-3-2""));
            imBuilder.putAlias(new AliasMetadata.Builder(newAliasName));
            builder.put(imBuilder);
        }
        metadata = builder.build();
        assertThat(metadata.aliasedIndices(), hasSize(numAliases + 1));
        assertThat(
            metadata.aliasedIndices(newAliasName),
            containsInAnyOrder(
                new Index(""alias-1-0"", ClusterState.UNKNOWN_UUID),
                new Index(""alias-2-1"", ClusterState.UNKNOWN_UUID),
                new Index(""alias-3-2"", ClusterState.UNKNOWN_UUID)
            )
        );

        // Remove the new alias that points to existing indices
        builder = Metadata.builder(metadata);
        {
            IndexMetadata.Builder imBuilder = new IndexMetadata.Builder(metadata.index(""alias-1-0""));
            imBuilder.removeAlias(newAliasName);
            builder.put(imBuilder);

            imBuilder = new IndexMetadata.Builder(metadata.index(""alias-2-1""));
            imBuilder.removeAlias(newAliasName);
            builder.put(imBuilder);

            imBuilder = new IndexMetadata.Builder(metadata.index(""alias-3-2""));
            imBuilder.removeAlias(newAliasName);
            builder.put(imBuilder);
        }
        metadata = builder.build();
        assertThat(metadata.aliasedIndices(), hasSize(numAliases));
        assertThat(metadata.aliasedIndices(newAliasName), empty());
    }",/server/src/test/java/org/elasticsearch/cluster/metadata/MetadataTests.java
2a00f25f573e1c1078c1f864eea52397a081c5c8,570,361,"public void testReplicaProxy() throws InterruptedException, ExecutionException {
        CapturingTransport transport = new CapturingTransport();
        TransportService transportService = transport.createTransportService(
            clusterService.getSettings(),
            threadPool,
            TransportService.NOOP_TRANSPORT_INTERCEPTOR,
            x -> clusterService.localNode(),
            null,
            Collections.emptySet()
        );
        transportService.start();
        transportService.acceptIncomingRequests();
        ShardStateAction shardStateAction = new ShardStateAction(clusterService, transportService, null, null, threadPool);
        TestAction action = new TestAction(
            Settings.EMPTY,
            ""internal:testAction"",
            transportService,
            clusterService,
            shardStateAction,
            threadPool
        );
        final String index = ""test"";
        final ShardId shardId = new ShardId(index, ""_na_"", 0);
        ClusterState state = ClusterStateCreationUtils.stateWithActivePrimary(index, true, 1 + randomInt(3), randomInt(2));
        logger.info(""using state: {}"", state);
        ClusterServiceUtils.setState(clusterService, state);
        final long primaryTerm = state.metadata().index(index).primaryTerm(0);
        ReplicationOperation.Replicas<TestRequest> proxy = action.newReplicasProxy();

        // check that at unknown node fails
        PlainActionFuture<ReplicaResponse> listener = new PlainActionFuture<>();
        ShardRoutingState routingState = randomFrom(
            ShardRoutingState.INITIALIZING,
            ShardRoutingState.STARTED,
            ShardRoutingState.RELOCATING
        );
        proxy.performOn(
            TestShardRouting.newShardRouting(
                shardId,
                ""NOT THERE"",
                routingState == ShardRoutingState.RELOCATING ? state.nodes().iterator().next().getId() : null,
                false,
                routingState
            ),
            new TestRequest(),
            primaryTerm,
            randomNonNegativeLong(),
            randomNonNegativeLong(),
            listener
        );
        assertTrue(listener.isDone());
        assertListenerThrows(""non existent node should throw a NoNodeAvailableException"", listener, NoNodeAvailableException.class);

        final IndexShardRoutingTable shardRoutings = state.routingTable().shardRoutingTable(shardId);
        final ShardRouting replica = randomFrom(
            shardRoutings.replicaShards().stream().filter(ShardRouting::assignedToNode).collect(Collectors.toList())
        );
        listener = new PlainActionFuture<>();
        proxy.performOn(replica, new TestRequest(), primaryTerm, randomNonNegativeLong(), randomNonNegativeLong(), listener);
        assertFalse(listener.isDone());

        CapturingTransport.CapturedRequest[] captures = transport.getCapturedRequestsAndClear();
        assertThat(captures, arrayWithSize(1));
        if (randomBoolean()) {
            final TransportReplicationAction.ReplicaResponse response = new TransportReplicationAction.ReplicaResponse(
                randomLong(),
                randomLong()
            );
            transport.handleResponse(captures[0].requestId(), response);
            assertTrue(listener.isDone());
            assertThat(listener.get(), equalTo(response));
        } else if (randomBoolean()) {
            transport.handleRemoteError(captures[0].requestId(), new ElasticsearchException(""simulated""));
            assertTrue(listener.isDone());
            assertListenerThrows(""listener should reflect remote error"", listener, ElasticsearchException.class);
        } else {
            transport.handleError(captures[0].requestId(), new TransportException(""simulated""));
            assertTrue(listener.isDone());
            assertListenerThrows(""listener should reflect remote error"", listener, TransportException.class);
        }

        AtomicReference<Object> failure = new AtomicReference<>();
        AtomicBoolean success = new AtomicBoolean();
        proxy.failShardIfNeeded(
            replica,
            primaryTerm,
            ""test"",
            new ElasticsearchException(""simulated""),
            ActionListener.wrap(r -> success.set(true), failure::set)
        );
        CapturingTransport.CapturedRequest[] shardFailedRequests = transport.getCapturedRequestsAndClear();
        // A write replication action proxy should fail the shard
        assertEquals(1, shardFailedRequests.length);
        CapturingTransport.CapturedRequest shardFailedRequest = shardFailedRequests[0];
        ShardStateAction.FailedShardEntry shardEntry = (ShardStateAction.FailedShardEntry) shardFailedRequest.request();
        // the shard the request was sent to and the shard to be failed should be the same
        assertEquals(shardEntry.getShardId(), replica.shardId());
        assertEquals(shardEntry.getAllocationId(), replica.allocationId().getId());
        if (randomBoolean()) {
            // simulate success
            transport.handleResponse(shardFailedRequest.requestId(), TransportResponse.Empty.INSTANCE);
            assertTrue(success.get());
            assertNull(failure.get());
        } else if (randomBoolean()) {
            // simulate the primary has been demoted
            transport.handleRemoteError(
                shardFailedRequest.requestId(),
                new ShardStateAction.NoLongerPrimaryShardException(replica.shardId(), ""shard-failed-test"")
            );
            assertFalse(success.get());
            assertNotNull(failure.get());
        } else {
            // simulated a node closing exception
            transport.handleRemoteError(shardFailedRequest.requestId(), new NodeClosedException(state.nodes().getLocalNode()));
            assertFalse(success.get());
            assertNotNull(failure.get());
        }
    }","public void testReplicaProxy() throws InterruptedException, ExecutionException {
        CapturingTransport transport = new CapturingTransport();
        TransportService transportService = transport.createTransportService(
            clusterService.getSettings(),
            threadPool,
            TransportService.NOOP_TRANSPORT_INTERCEPTOR,
            x -> clusterService.localNode(),
            null,
            Collections.emptySet()
        );
        transportService.start();
        transportService.acceptIncomingRequests();
        ShardStateAction shardStateAction = new ShardStateAction(clusterService, transportService, null, null, threadPool);
        TestAction action = new TestAction(
            Settings.EMPTY,
            ""internal:testAction"",
            transportService,
            clusterService,
            shardStateAction,
            threadPool
        );
        final String index = ""test"";
        final ShardId shardId = new ShardId(index, ""_na_"", 0);
        ClusterState state = ClusterStateCreationUtils.stateWithActivePrimary(index, true, 1 + randomInt(3), randomInt(2));
        logger.info(""using state: {}"", state);
        ClusterServiceUtils.setState(clusterService, state);
        final long primaryTerm = state.metadata().index(index).primaryTerm(0);
        ReplicationOperation.Replicas<TestRequest> proxy = action.newReplicasProxy();

        // check that at unknown node fails
        PlainActionFuture<ReplicaResponse> listener = new PlainActionFuture<>();
        ShardRoutingState routingState = randomFrom(
            ShardRoutingState.INITIALIZING,
            ShardRoutingState.STARTED,
            ShardRoutingState.RELOCATING
        );
        proxy.performOn(
            TestShardRouting.newShardRouting(
                shardId,
                ""NOT THERE"",
                routingState == ShardRoutingState.RELOCATING ? state.nodes().iterator().next().getId() : null,
                false,
                routingState
            ),
            new TestRequest(),
            primaryTerm,
            randomNonNegativeLong(),
            randomNonNegativeLong(),
            listener
        );
        assertTrue(listener.isDone());
        assertListenerThrows(""non existent node should throw a NoNodeAvailableException"", listener, NoNodeAvailableException.class);

        final IndexShardRoutingTable shardRoutings = state.routingTable().shardRoutingTable(shardId);
        final ShardRouting replica = randomFrom(shardRoutings.replicaShards().stream().filter(ShardRouting::assignedToNode).toList());
        listener = new PlainActionFuture<>();
        proxy.performOn(replica, new TestRequest(), primaryTerm, randomNonNegativeLong(), randomNonNegativeLong(), listener);
        assertFalse(listener.isDone());

        CapturingTransport.CapturedRequest[] captures = transport.getCapturedRequestsAndClear();
        assertThat(captures, arrayWithSize(1));
        if (randomBoolean()) {
            final TransportReplicationAction.ReplicaResponse response = new TransportReplicationAction.ReplicaResponse(
                randomLong(),
                randomLong()
            );
            transport.handleResponse(captures[0].requestId(), response);
            assertTrue(listener.isDone());
            assertThat(listener.get(), equalTo(response));
        } else if (randomBoolean()) {
            transport.handleRemoteError(captures[0].requestId(), new ElasticsearchException(""simulated""));
            assertTrue(listener.isDone());
            assertListenerThrows(""listener should reflect remote error"", listener, ElasticsearchException.class);
        } else {
            transport.handleError(captures[0].requestId(), new TransportException(""simulated""));
            assertTrue(listener.isDone());
            assertListenerThrows(""listener should reflect remote error"", listener, TransportException.class);
        }

        AtomicReference<Object> failure = new AtomicReference<>();
        AtomicBoolean success = new AtomicBoolean();
        proxy.failShardIfNeeded(
            replica,
            primaryTerm,
            ""test"",
            new ElasticsearchException(""simulated""),
            ActionListener.wrap(r -> success.set(true), failure::set)
        );
        CapturingTransport.CapturedRequest[] shardFailedRequests = transport.getCapturedRequestsAndClear();
        // A write replication action proxy should fail the shard
        assertEquals(1, shardFailedRequests.length);
        CapturingTransport.CapturedRequest shardFailedRequest = shardFailedRequests[0];
        ShardStateAction.FailedShardEntry shardEntry = (ShardStateAction.FailedShardEntry) shardFailedRequest.request();
        // the shard the request was sent to and the shard to be failed should be the same
        assertEquals(shardEntry.getShardId(), replica.shardId());
        assertEquals(shardEntry.getAllocationId(), replica.allocationId().getId());
        if (randomBoolean()) {
            // simulate success
            transport.handleResponse(shardFailedRequest.requestId(), TransportResponse.Empty.INSTANCE);
            assertTrue(success.get());
            assertNull(failure.get());
        } else if (randomBoolean()) {
            // simulate the primary has been demoted
            transport.handleRemoteError(
                shardFailedRequest.requestId(),
                new ShardStateAction.NoLongerPrimaryShardException(replica.shardId(), ""shard-failed-test"")
            );
            assertFalse(success.get());
            assertNotNull(failure.get());
        } else {
            // simulated a node closing exception
            transport.handleRemoteError(shardFailedRequest.requestId(), new NodeClosedException(state.nodes().getLocalNode()));
            assertFalse(success.get());
            assertNotNull(failure.get());
        }
    }",/server/src/test/java/org/elasticsearch/action/support/replication/TransportWriteActionTests.java
2a00f25f573e1c1078c1f864eea52397a081c5c8,571,123,"public void testNodeCounts() {
        int total = 1;
        internalCluster().startNode();
        Map<String, Integer> expectedCounts = new HashMap<>();
        expectedCounts.put(DiscoveryNodeRole.DATA_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.DATA_CONTENT_NODE_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.DATA_COLD_NODE_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.DATA_FROZEN_NODE_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.DATA_HOT_NODE_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.DATA_WARM_NODE_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.INGEST_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.MASTER_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.ML_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.REMOTE_CLUSTER_CLIENT_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.TRANSFORM_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.VOTING_ONLY_NODE_ROLE.roleName(), 0);
        expectedCounts.put(ClusterStatsNodes.Counts.COORDINATING_ONLY, 0);
        int numNodes = randomIntBetween(1, 5);

        ClusterStatsResponse response = client().admin().cluster().prepareClusterStats().get();
        assertCounts(response.getNodesStats().getCounts(), total, expectedCounts);

        for (int i = 0; i < numNodes; i++) {
            boolean isDataNode = randomBoolean();
            boolean isIngestNode = randomBoolean();
            boolean isMasterNode = randomBoolean();
            boolean isRemoteClusterClientNode = false;
            final Set<DiscoveryNodeRole> roles = new HashSet<>();
            if (isDataNode) {
                roles.add(DiscoveryNodeRole.DATA_ROLE);
            }
            if (isIngestNode) {
                roles.add(DiscoveryNodeRole.INGEST_ROLE);
            }
            if (isMasterNode) {
                roles.add(DiscoveryNodeRole.MASTER_ROLE);
            }
            if (isRemoteClusterClientNode) {
                roles.add(DiscoveryNodeRole.REMOTE_CLUSTER_CLIENT_ROLE);
            }
            Settings settings = Settings.builder()
                .putList(
                    NodeRoleSettings.NODE_ROLES_SETTING.getKey(),
                    roles.stream().map(DiscoveryNodeRole::roleName).collect(Collectors.toList())
                )
                .build();
            internalCluster().startNode(settings);
            total++;
            waitForNodes(total);

            if (isDataNode) {
                incrementCountForRole(DiscoveryNodeRole.DATA_ROLE.roleName(), expectedCounts);
            }
            if (isIngestNode) {
                incrementCountForRole(DiscoveryNodeRole.INGEST_ROLE.roleName(), expectedCounts);
            }
            if (isMasterNode) {
                incrementCountForRole(DiscoveryNodeRole.MASTER_ROLE.roleName(), expectedCounts);
            }
            if (isRemoteClusterClientNode) {
                incrementCountForRole(DiscoveryNodeRole.REMOTE_CLUSTER_CLIENT_ROLE.roleName(), expectedCounts);
            }
            if (isDataNode == false && isMasterNode == false && isIngestNode == false && isRemoteClusterClientNode == false) {
                incrementCountForRole(ClusterStatsNodes.Counts.COORDINATING_ONLY, expectedCounts);
            }

            response = client().admin().cluster().prepareClusterStats().get();
            assertCounts(response.getNodesStats().getCounts(), total, expectedCounts);
        }
    }","public void testNodeCounts() {
        int total = 1;
        internalCluster().startNode();
        Map<String, Integer> expectedCounts = new HashMap<>();
        expectedCounts.put(DiscoveryNodeRole.DATA_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.DATA_CONTENT_NODE_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.DATA_COLD_NODE_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.DATA_FROZEN_NODE_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.DATA_HOT_NODE_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.DATA_WARM_NODE_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.INGEST_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.MASTER_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.ML_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.REMOTE_CLUSTER_CLIENT_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.TRANSFORM_ROLE.roleName(), 1);
        expectedCounts.put(DiscoveryNodeRole.VOTING_ONLY_NODE_ROLE.roleName(), 0);
        expectedCounts.put(ClusterStatsNodes.Counts.COORDINATING_ONLY, 0);
        int numNodes = randomIntBetween(1, 5);

        ClusterStatsResponse response = client().admin().cluster().prepareClusterStats().get();
        assertCounts(response.getNodesStats().getCounts(), total, expectedCounts);

        for (int i = 0; i < numNodes; i++) {
            boolean isDataNode = randomBoolean();
            boolean isIngestNode = randomBoolean();
            boolean isMasterNode = randomBoolean();
            boolean isRemoteClusterClientNode = false;
            final Set<DiscoveryNodeRole> roles = new HashSet<>();
            if (isDataNode) {
                roles.add(DiscoveryNodeRole.DATA_ROLE);
            }
            if (isIngestNode) {
                roles.add(DiscoveryNodeRole.INGEST_ROLE);
            }
            if (isMasterNode) {
                roles.add(DiscoveryNodeRole.MASTER_ROLE);
            }
            if (isRemoteClusterClientNode) {
                roles.add(DiscoveryNodeRole.REMOTE_CLUSTER_CLIENT_ROLE);
            }
            Settings settings = Settings.builder()
                .putList(NodeRoleSettings.NODE_ROLES_SETTING.getKey(), roles.stream().map(DiscoveryNodeRole::roleName).toList())
                .build();
            internalCluster().startNode(settings);
            total++;
            waitForNodes(total);

            if (isDataNode) {
                incrementCountForRole(DiscoveryNodeRole.DATA_ROLE.roleName(), expectedCounts);
            }
            if (isIngestNode) {
                incrementCountForRole(DiscoveryNodeRole.INGEST_ROLE.roleName(), expectedCounts);
            }
            if (isMasterNode) {
                incrementCountForRole(DiscoveryNodeRole.MASTER_ROLE.roleName(), expectedCounts);
            }
            if (isRemoteClusterClientNode) {
                incrementCountForRole(DiscoveryNodeRole.REMOTE_CLUSTER_CLIENT_ROLE.roleName(), expectedCounts);
            }
            if (isDataNode == false && isMasterNode == false && isIngestNode == false && isRemoteClusterClientNode == false) {
                incrementCountForRole(ClusterStatsNodes.Counts.COORDINATING_ONLY, expectedCounts);
            }

            response = client().admin().cluster().prepareClusterStats().get();
            assertCounts(response.getNodesStats().getCounts(), total, expectedCounts);
        }
    }",/server/src/internalClusterTest/java/org/elasticsearch/action/admin/cluster/stats/ClusterStatsIT.java
2a00f25f573e1c1078c1f864eea52397a081c5c8,570,447,") {
        assert numReducePhases >= 0 : ""num reduce phases must be >= 0 but was: "" + numReducePhases;
        numReducePhases++; // increment for this phase
        if (queryResults.isEmpty()) { // early terminate we have nothing to reduce
            final TotalHits totalHits = topDocsStats.getTotalHits();
            return new ReducedQueryPhase(
                totalHits,
                topDocsStats.fetchHits,
                topDocsStats.getMaxScore(),
                false,
                null,
                null,
                null,
                null,
                SortedTopDocs.EMPTY,
                null,
                numReducePhases,
                0,
                0,
                true
            );
        }
        int total = queryResults.size();
        queryResults = queryResults.stream().filter(res -> res.queryResult().isNull() == false).collect(Collectors.toList());
        String errorMsg = ""must have at least one non-empty search result, got 0 out of "" + total;
        assert queryResults.isEmpty() == false : errorMsg;
        if (queryResults.isEmpty()) {
            throw new IllegalStateException(errorMsg);
        }
        validateMergeSortValueFormats(queryResults);
        final boolean hasSuggest = queryResults.stream().anyMatch(res -> res.queryResult().suggest() != null);
        final boolean hasProfileResults = queryResults.stream().anyMatch(res -> res.queryResult().hasProfileResults());

        // count the total (we use the query result provider here, since we might not get any hits (we scrolled past them))
        final Map<String, List<Suggestion<?>>> groupedSuggestions = hasSuggest ? new HashMap<>() : Collections.emptyMap();
        final Map<String, SearchProfileQueryPhaseResult> profileShardResults = hasProfileResults
            ? Maps.newMapWithExpectedSize(queryResults.size())
            : Collections.emptyMap();
        int from = 0;
        int size = 0;
        DocValueFormat[] sortValueFormats = null;
        for (SearchPhaseResult entry : queryResults) {
            QuerySearchResult result = entry.queryResult();
            from = result.from();
            // sorted queries can set the size to 0 if they have enough competitive hits.
            size = Math.max(result.size(), size);
            if (result.sortValueFormats() != null) {
                sortValueFormats = result.sortValueFormats();
            }

            if (hasSuggest) {
                assert result.suggest() != null;
                for (Suggestion<? extends Suggestion.Entry<? extends Suggestion.Entry.Option>> suggestion : result.suggest()) {
                    List<Suggestion<?>> suggestionList = groupedSuggestions.computeIfAbsent(suggestion.getName(), s -> new ArrayList<>());
                    suggestionList.add(suggestion);
                    if (suggestion instanceof CompletionSuggestion completionSuggestion) {
                        completionSuggestion.setShardIndex(result.getShardIndex());
                    }
                }
            }
            if (bufferedTopDocs.isEmpty() == false) {
                assert result.hasConsumedTopDocs() : ""firstResult has no aggs but we got non null buffered aggs?"";
            }
            if (hasProfileResults) {
                String key = result.getSearchShardTarget().toString();
                profileShardResults.put(key, result.consumeProfileResult());
            }
        }
        final Suggest reducedSuggest;
        final List<CompletionSuggestion> reducedCompletionSuggestions;
        if (groupedSuggestions.isEmpty()) {
            reducedSuggest = null;
            reducedCompletionSuggestions = Collections.emptyList();
        } else {
            reducedSuggest = new Suggest(Suggest.reduce(groupedSuggestions));
            reducedCompletionSuggestions = reducedSuggest.filter(CompletionSuggestion.class);
        }
        final InternalAggregations aggregations = reduceAggs(aggReduceContextBuilder, performFinalReduce, bufferedAggs);
        final SearchProfileResultsBuilder profileBuilder = profileShardResults.isEmpty()
            ? null
            : new SearchProfileResultsBuilder(profileShardResults);
        final SortedTopDocs sortedTopDocs = sortDocs(isScrollRequest, bufferedTopDocs, from, size, reducedCompletionSuggestions);
        final TotalHits totalHits = topDocsStats.getTotalHits();
        return new ReducedQueryPhase(
            totalHits,
            topDocsStats.fetchHits,
            topDocsStats.getMaxScore(),
            topDocsStats.timedOut,
            topDocsStats.terminatedEarly,
            reducedSuggest,
            aggregations,
            profileBuilder,
            sortedTopDocs,
            sortValueFormats,
            numReducePhases,
            size,
            from,
            false
        );
    }",") {
        assert numReducePhases >= 0 : ""num reduce phases must be >= 0 but was: "" + numReducePhases;
        numReducePhases++; // increment for this phase
        if (queryResults.isEmpty()) { // early terminate we have nothing to reduce
            final TotalHits totalHits = topDocsStats.getTotalHits();
            return new ReducedQueryPhase(
                totalHits,
                topDocsStats.fetchHits,
                topDocsStats.getMaxScore(),
                false,
                null,
                null,
                null,
                null,
                SortedTopDocs.EMPTY,
                null,
                numReducePhases,
                0,
                0,
                true
            );
        }
        int total = queryResults.size();
        queryResults = queryResults.stream().filter(res -> res.queryResult().isNull() == false).toList();
        String errorMsg = ""must have at least one non-empty search result, got 0 out of "" + total;
        assert queryResults.isEmpty() == false : errorMsg;
        if (queryResults.isEmpty()) {
            throw new IllegalStateException(errorMsg);
        }
        validateMergeSortValueFormats(queryResults);
        final boolean hasSuggest = queryResults.stream().anyMatch(res -> res.queryResult().suggest() != null);
        final boolean hasProfileResults = queryResults.stream().anyMatch(res -> res.queryResult().hasProfileResults());

        // count the total (we use the query result provider here, since we might not get any hits (we scrolled past them))
        final Map<String, List<Suggestion<?>>> groupedSuggestions = hasSuggest ? new HashMap<>() : Collections.emptyMap();
        final Map<String, SearchProfileQueryPhaseResult> profileShardResults = hasProfileResults
            ? Maps.newMapWithExpectedSize(queryResults.size())
            : Collections.emptyMap();
        int from = 0;
        int size = 0;
        DocValueFormat[] sortValueFormats = null;
        for (SearchPhaseResult entry : queryResults) {
            QuerySearchResult result = entry.queryResult();
            from = result.from();
            // sorted queries can set the size to 0 if they have enough competitive hits.
            size = Math.max(result.size(), size);
            if (result.sortValueFormats() != null) {
                sortValueFormats = result.sortValueFormats();
            }

            if (hasSuggest) {
                assert result.suggest() != null;
                for (Suggestion<? extends Suggestion.Entry<? extends Suggestion.Entry.Option>> suggestion : result.suggest()) {
                    List<Suggestion<?>> suggestionList = groupedSuggestions.computeIfAbsent(suggestion.getName(), s -> new ArrayList<>());
                    suggestionList.add(suggestion);
                    if (suggestion instanceof CompletionSuggestion completionSuggestion) {
                        completionSuggestion.setShardIndex(result.getShardIndex());
                    }
                }
            }
            if (bufferedTopDocs.isEmpty() == false) {
                assert result.hasConsumedTopDocs() : ""firstResult has no aggs but we got non null buffered aggs?"";
            }
            if (hasProfileResults) {
                String key = result.getSearchShardTarget().toString();
                profileShardResults.put(key, result.consumeProfileResult());
            }
        }
        final Suggest reducedSuggest;
        final List<CompletionSuggestion> reducedCompletionSuggestions;
        if (groupedSuggestions.isEmpty()) {
            reducedSuggest = null;
            reducedCompletionSuggestions = Collections.emptyList();
        } else {
            reducedSuggest = new Suggest(Suggest.reduce(groupedSuggestions));
            reducedCompletionSuggestions = reducedSuggest.filter(CompletionSuggestion.class);
        }
        final InternalAggregations aggregations = reduceAggs(aggReduceContextBuilder, performFinalReduce, bufferedAggs);
        final SearchProfileResultsBuilder profileBuilder = profileShardResults.isEmpty()
            ? null
            : new SearchProfileResultsBuilder(profileShardResults);
        final SortedTopDocs sortedTopDocs = sortDocs(isScrollRequest, bufferedTopDocs, from, size, reducedCompletionSuggestions);
        final TotalHits totalHits = topDocsStats.getTotalHits();
        return new ReducedQueryPhase(
            totalHits,
            topDocsStats.fetchHits,
            topDocsStats.getMaxScore(),
            topDocsStats.timedOut,
            topDocsStats.terminatedEarly,
            reducedSuggest,
            aggregations,
            profileBuilder,
            sortedTopDocs,
            sortValueFormats,
            numReducePhases,
            size,
            from,
            false
        );
    }",/server/src/main/java/org/elasticsearch/action/search/SearchPhaseController.java
2a00f25f573e1c1078c1f864eea52397a081c5c8,391,180,"public void testCloseWhileRelocatingShards() throws Exception {
        final String[] indices = new String[randomIntBetween(3, 5)];
        final Map<String, Long> docsPerIndex = new HashMap<>();
        final Map<String, BackgroundIndexer> indexers = new HashMap<>();

        for (int i = 0; i < indices.length; i++) {
            final String indexName = ""index-"" + i;
            int nbDocs = 0;
            switch (i) {
                case 0 -> {
                    logger.debug(""creating empty index {}"", indexName);
                    createIndex(indexName);
                }
                case 1 -> {
                    nbDocs = scaledRandomIntBetween(1, 100);
                    logger.debug(""creating index {} with {} documents"", indexName, nbDocs);
                    createIndex(indexName);
                    indexRandom(
                        randomBoolean(),
                        IntStream.range(0, nbDocs)
                            .mapToObj(n -> client().prepareIndex(indexName).setSource(""num"", n))
                            .collect(Collectors.toList())
                    );
                }
                default -> {
                    logger.debug(""creating index {} with background indexing"", indexName);
                    final BackgroundIndexer indexer = new BackgroundIndexer(indexName, client(), -1, 1);
                    indexers.put(indexName, indexer);
                    indexer.setFailureAssertion(t -> assertException(t, indexName));
                    waitForDocs(1, indexer);
                }
            }
            docsPerIndex.put(indexName, (long) nbDocs);
            indices[i] = indexName;
        }

        ensureGreen(TimeValue.timeValueSeconds(60L), indices);
        assertAcked(
            client().admin()
                .cluster()
                .prepareUpdateSettings()
                .setPersistentSettings(
                    Settings.builder()
                        .put(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), Rebalance.NONE.toString())
                )
        );

        final String targetNode = internalCluster().startDataOnlyNode();
        ensureClusterSizeConsistency(); // wait for the master to finish processing join.

        try {
            final ClusterService clusterService = internalCluster().getInstance(ClusterService.class, internalCluster().getMasterName());
            final ClusterState state = clusterService.state();
            final CountDownLatch latch = new CountDownLatch(indices.length);
            final CountDownLatch release = new CountDownLatch(indices.length);

            // relocate one shard for every index to be closed
            final AllocationCommands commands = new AllocationCommands();
            for (final String index : indices) {
                final NumShards numShards = getNumShards(index);
                final int shardId = numShards.numPrimaries == 1 ? 0 : randomIntBetween(0, numShards.numPrimaries - 1);
                final IndexRoutingTable indexRoutingTable = state.routingTable().index(index);

                final ShardRouting primary = indexRoutingTable.shard(shardId).primaryShard();
                assertTrue(primary.started());

                String currentNodeId = primary.currentNodeId();
                if (numShards.numReplicas > 0) {
                    final ShardRouting replica = indexRoutingTable.shard(shardId).replicaShards().iterator().next();
                    assertTrue(replica.started());
                    if (randomBoolean()) {
                        currentNodeId = replica.currentNodeId();
                    }
                }
                commands.add(new MoveAllocationCommand(index, shardId, state.nodes().resolveNode(currentNodeId).getName(), targetNode));
            }

            // Build the list of shards for which recoveries will be blocked
            final Set<ShardId> blockedShards = commands.commands()
                .stream()
                .map(c -> (MoveAllocationCommand) c)
                .map(c -> new ShardId(clusterService.state().metadata().index(c.index()).getIndex(), c.shardId()))
                .collect(Collectors.toSet());
            assertThat(blockedShards, hasSize(indices.length));

            final Set<String> acknowledgedCloses = ConcurrentCollections.newConcurrentSet();
            final Set<String> interruptedRecoveries = ConcurrentCollections.newConcurrentSet();

            // Create a SendRequestBehavior that will block outgoing start recovery request
            final StubbableTransport.SendRequestBehavior sendBehavior = (connection, requestId, action, request, options) -> {
                if (PeerRecoverySourceService.Actions.START_RECOVERY.equals(action)) {
                    final StartRecoveryRequest startRecoveryRequest = ((StartRecoveryRequest) request);
                    if (blockedShards.contains(startRecoveryRequest.shardId())) {
                        logger.debug(""blocking recovery of shard {}"", startRecoveryRequest.shardId());
                        latch.countDown();
                        try {
                            release.await();
                            logger.debug(""releasing recovery of shard {}"", startRecoveryRequest.shardId());
                        } catch (final InterruptedException e) {
                            logger.warn(
                                () -> new ParameterizedMessage(
                                    ""exception when releasing recovery of shard {}"",
                                    startRecoveryRequest.shardId()
                                ),
                                e
                            );
                            interruptedRecoveries.add(startRecoveryRequest.shardId().getIndexName());
                            Thread.currentThread().interrupt();
                            return;
                        }
                    }
                }
                connection.sendRequest(requestId, action, request, options);
            };

            final MockTransportService targetTransportService = (MockTransportService) internalCluster().getInstance(
                TransportService.class,
                targetNode
            );

            for (DiscoveryNode node : state.getNodes()) {
                if (node.canContainData() && node.getName().equals(targetNode) == false) {
                    final TransportService sourceTransportService = internalCluster().getInstance(TransportService.class, node.getName());
                    targetTransportService.addSendBehavior(sourceTransportService, sendBehavior);
                }
            }

            assertAcked(client().admin().cluster().reroute(new ClusterRerouteRequest().commands(commands)).get());

            // start index closing threads
            final List<Thread> threads = new ArrayList<>();
            for (final String indexToClose : indices) {
                final Thread thread = new Thread(() -> {
                    try {
                        latch.await();
                    } catch (InterruptedException e) {
                        throw new AssertionError(e);
                    } finally {
                        release.countDown();
                    }
                    // Closing is not always acknowledged when shards are relocating: this is the case when the target shard is initializing
                    // or is catching up operations. In these cases the TransportVerifyShardBeforeCloseAction will detect that the global
                    // and max sequence number don't match and will not ack the close.
                    AcknowledgedResponse closeResponse = client().admin().indices().prepareClose(indexToClose).get();
                    if (closeResponse.isAcknowledged()) {
                        assertTrue(""Index closing should not be acknowledged twice"", acknowledgedCloses.add(indexToClose));
                    }
                });
                threads.add(thread);
                thread.start();
            }

            latch.countDown();
            for (Thread thread : threads) {
                thread.join();
            }

            // stop indexers first without waiting for stop to not redundantly index on some while waiting for another one to stop
            for (BackgroundIndexer indexer : indexers.values()) {
                indexer.stop();
            }
            for (Map.Entry<String, BackgroundIndexer> entry : indexers.entrySet()) {
                final BackgroundIndexer indexer = entry.getValue();
                indexer.awaitStopped();
                final String indexName = entry.getKey();
                docsPerIndex.computeIfPresent(indexName, (key, value) -> value + indexer.totalIndexedDocs());
            }

            for (String index : indices) {
                if (acknowledgedCloses.contains(index)) {
                    assertIndexIsClosed(index);
                } else {
                    assertIndexIsOpened(index);
                }
            }

            targetTransportService.clearAllRules();

            // If a shard recovery has been interrupted, we expect its index to be closed
            interruptedRecoveries.forEach(CloseIndexIT::assertIndexIsClosed);

            assertThat(""Consider that the test failed if no indices were successfully closed"", acknowledgedCloses.size(), greaterThan(0));
            assertAcked(client().admin().indices().prepareOpen(""index-*""));
            ensureGreen(indices);

            for (String index : acknowledgedCloses) {
                long docsCount = client().prepareSearch(index).setSize(0).setTrackTotalHits(true).get().getHits().getTotalHits().value;
                assertEquals(
                    ""Expected ""
                        + docsPerIndex.get(index)
                        + "" docs in index ""
                        + index
                        + "" but got ""
                        + docsCount
                        + "" (close acknowledged=""
                        + acknowledgedCloses.contains(index)
                        + "")"",
                    (long) docsPerIndex.get(index),
                    docsCount
                );
            }
        } finally {
            assertAcked(
                client().admin()
                    .cluster()
                    .prepareUpdateSettings()
                    .setPersistentSettings(
                        Settings.builder().putNull(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey())
                    )
            );
        }
    }","public void testCloseWhileRelocatingShards() throws Exception {
        final String[] indices = new String[randomIntBetween(3, 5)];
        final Map<String, Long> docsPerIndex = new HashMap<>();
        final Map<String, BackgroundIndexer> indexers = new HashMap<>();

        for (int i = 0; i < indices.length; i++) {
            final String indexName = ""index-"" + i;
            int nbDocs = 0;
            switch (i) {
                case 0 -> {
                    logger.debug(""creating empty index {}"", indexName);
                    createIndex(indexName);
                }
                case 1 -> {
                    nbDocs = scaledRandomIntBetween(1, 100);
                    logger.debug(""creating index {} with {} documents"", indexName, nbDocs);
                    createIndex(indexName);
                    indexRandom(
                        randomBoolean(),
                        IntStream.range(0, nbDocs).mapToObj(n -> client().prepareIndex(indexName).setSource(""num"", n)).toList()
                    );
                }
                default -> {
                    logger.debug(""creating index {} with background indexing"", indexName);
                    final BackgroundIndexer indexer = new BackgroundIndexer(indexName, client(), -1, 1);
                    indexers.put(indexName, indexer);
                    indexer.setFailureAssertion(t -> assertException(t, indexName));
                    waitForDocs(1, indexer);
                }
            }
            docsPerIndex.put(indexName, (long) nbDocs);
            indices[i] = indexName;
        }

        ensureGreen(TimeValue.timeValueSeconds(60L), indices);
        assertAcked(
            client().admin()
                .cluster()
                .prepareUpdateSettings()
                .setPersistentSettings(
                    Settings.builder()
                        .put(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), Rebalance.NONE.toString())
                )
        );

        final String targetNode = internalCluster().startDataOnlyNode();
        ensureClusterSizeConsistency(); // wait for the master to finish processing join.

        try {
            final ClusterService clusterService = internalCluster().getInstance(ClusterService.class, internalCluster().getMasterName());
            final ClusterState state = clusterService.state();
            final CountDownLatch latch = new CountDownLatch(indices.length);
            final CountDownLatch release = new CountDownLatch(indices.length);

            // relocate one shard for every index to be closed
            final AllocationCommands commands = new AllocationCommands();
            for (final String index : indices) {
                final NumShards numShards = getNumShards(index);
                final int shardId = numShards.numPrimaries == 1 ? 0 : randomIntBetween(0, numShards.numPrimaries - 1);
                final IndexRoutingTable indexRoutingTable = state.routingTable().index(index);

                final ShardRouting primary = indexRoutingTable.shard(shardId).primaryShard();
                assertTrue(primary.started());

                String currentNodeId = primary.currentNodeId();
                if (numShards.numReplicas > 0) {
                    final ShardRouting replica = indexRoutingTable.shard(shardId).replicaShards().iterator().next();
                    assertTrue(replica.started());
                    if (randomBoolean()) {
                        currentNodeId = replica.currentNodeId();
                    }
                }
                commands.add(new MoveAllocationCommand(index, shardId, state.nodes().resolveNode(currentNodeId).getName(), targetNode));
            }

            // Build the list of shards for which recoveries will be blocked
            final Set<ShardId> blockedShards = commands.commands()
                .stream()
                .map(c -> (MoveAllocationCommand) c)
                .map(c -> new ShardId(clusterService.state().metadata().index(c.index()).getIndex(), c.shardId()))
                .collect(Collectors.toSet());
            assertThat(blockedShards, hasSize(indices.length));

            final Set<String> acknowledgedCloses = ConcurrentCollections.newConcurrentSet();
            final Set<String> interruptedRecoveries = ConcurrentCollections.newConcurrentSet();

            // Create a SendRequestBehavior that will block outgoing start recovery request
            final StubbableTransport.SendRequestBehavior sendBehavior = (connection, requestId, action, request, options) -> {
                if (PeerRecoverySourceService.Actions.START_RECOVERY.equals(action)) {
                    final StartRecoveryRequest startRecoveryRequest = ((StartRecoveryRequest) request);
                    if (blockedShards.contains(startRecoveryRequest.shardId())) {
                        logger.debug(""blocking recovery of shard {}"", startRecoveryRequest.shardId());
                        latch.countDown();
                        try {
                            release.await();
                            logger.debug(""releasing recovery of shard {}"", startRecoveryRequest.shardId());
                        } catch (final InterruptedException e) {
                            logger.warn(
                                () -> new ParameterizedMessage(
                                    ""exception when releasing recovery of shard {}"",
                                    startRecoveryRequest.shardId()
                                ),
                                e
                            );
                            interruptedRecoveries.add(startRecoveryRequest.shardId().getIndexName());
                            Thread.currentThread().interrupt();
                            return;
                        }
                    }
                }
                connection.sendRequest(requestId, action, request, options);
            };

            final MockTransportService targetTransportService = (MockTransportService) internalCluster().getInstance(
                TransportService.class,
                targetNode
            );

            for (DiscoveryNode node : state.getNodes()) {
                if (node.canContainData() && node.getName().equals(targetNode) == false) {
                    final TransportService sourceTransportService = internalCluster().getInstance(TransportService.class, node.getName());
                    targetTransportService.addSendBehavior(sourceTransportService, sendBehavior);
                }
            }

            assertAcked(client().admin().cluster().reroute(new ClusterRerouteRequest().commands(commands)).get());

            // start index closing threads
            final List<Thread> threads = new ArrayList<>();
            for (final String indexToClose : indices) {
                final Thread thread = new Thread(() -> {
                    try {
                        latch.await();
                    } catch (InterruptedException e) {
                        throw new AssertionError(e);
                    } finally {
                        release.countDown();
                    }
                    // Closing is not always acknowledged when shards are relocating: this is the case when the target shard is initializing
                    // or is catching up operations. In these cases the TransportVerifyShardBeforeCloseAction will detect that the global
                    // and max sequence number don't match and will not ack the close.
                    AcknowledgedResponse closeResponse = client().admin().indices().prepareClose(indexToClose).get();
                    if (closeResponse.isAcknowledged()) {
                        assertTrue(""Index closing should not be acknowledged twice"", acknowledgedCloses.add(indexToClose));
                    }
                });
                threads.add(thread);
                thread.start();
            }

            latch.countDown();
            for (Thread thread : threads) {
                thread.join();
            }

            // stop indexers first without waiting for stop to not redundantly index on some while waiting for another one to stop
            for (BackgroundIndexer indexer : indexers.values()) {
                indexer.stop();
            }
            for (Map.Entry<String, BackgroundIndexer> entry : indexers.entrySet()) {
                final BackgroundIndexer indexer = entry.getValue();
                indexer.awaitStopped();
                final String indexName = entry.getKey();
                docsPerIndex.computeIfPresent(indexName, (key, value) -> value + indexer.totalIndexedDocs());
            }

            for (String index : indices) {
                if (acknowledgedCloses.contains(index)) {
                    assertIndexIsClosed(index);
                } else {
                    assertIndexIsOpened(index);
                }
            }

            targetTransportService.clearAllRules();

            // If a shard recovery has been interrupted, we expect its index to be closed
            interruptedRecoveries.forEach(CloseIndexIT::assertIndexIsClosed);

            assertThat(""Consider that the test failed if no indices were successfully closed"", acknowledgedCloses.size(), greaterThan(0));
            assertAcked(client().admin().indices().prepareOpen(""index-*""));
            ensureGreen(indices);

            for (String index : acknowledgedCloses) {
                long docsCount = client().prepareSearch(index).setSize(0).setTrackTotalHits(true).get().getHits().getTotalHits().value;
                assertEquals(
                    ""Expected ""
                        + docsPerIndex.get(index)
                        + "" docs in index ""
                        + index
                        + "" but got ""
                        + docsCount
                        + "" (close acknowledged=""
                        + acknowledgedCloses.contains(index)
                        + "")"",
                    (long) docsPerIndex.get(index),
                    docsCount
                );
            }
        } finally {
            assertAcked(
                client().admin()
                    .cluster()
                    .prepareUpdateSettings()
                    .setPersistentSettings(
                        Settings.builder().putNull(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey())
                    )
            );
        }
    }",/server/src/internalClusterTest/java/org/elasticsearch/indices/state/CloseWhileRelocatingShardsIT.java
2a00f25f573e1c1078c1f864eea52397a081c5c8,391,417,"public void testDoNotCancelRecoveryForBrokenNode() throws Exception {
        internalCluster().startMasterOnlyNode();
        String nodeWithPrimary = internalCluster().startDataOnlyNode();
        String indexName = ""test"";
        assertAcked(
            client().admin()
                .indices()
                .prepareCreate(indexName)
                .setSettings(
                    Settings.builder()
                        .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)
                        .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)
                        .put(IndexService.GLOBAL_CHECKPOINT_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(IndexService.RETENTION_LEASE_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                )
        );
        indexRandom(
            randomBoolean(),
            randomBoolean(),
            randomBoolean(),
            IntStream.range(0, between(200, 500))
                .mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v""))
                .collect(Collectors.toList())
        );
        client().admin().indices().prepareFlush(indexName).get();
        String brokenNode = internalCluster().startDataOnlyNode();
        MockTransportService transportService = (MockTransportService) internalCluster().getInstance(
            TransportService.class,
            nodeWithPrimary
        );
        CountDownLatch newNodeStarted = new CountDownLatch(1);
        transportService.addSendBehavior((connection, requestId, action, request, options) -> {
            if (action.equals(PeerRecoveryTargetService.Actions.TRANSLOG_OPS)) {
                if (brokenNode.equals(connection.getNode().getName())) {
                    try {
                        newNodeStarted.await();
                    } catch (InterruptedException e) {
                        throw new AssertionError(e);
                    }
                    throw new CircuitBreakingException(""not enough memory for indexing"", 100, 50, CircuitBreaker.Durability.TRANSIENT);
                }
            }
            connection.sendRequest(requestId, action, request, options);
        });
        assertAcked(
            client().admin()
                .indices()
                .prepareUpdateSettings(indexName)
                .setSettings(Settings.builder().put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1))
        );
        internalCluster().startDataOnlyNode();
        newNodeStarted.countDown();
        ensureGreen(indexName);
        transportService.clearAllRules();
    }","public void testPeerRecoveryForClosedIndices() throws Exception {
        String indexName = ""peer_recovery_closed_indices"";
        internalCluster().ensureAtLeastNumDataNodes(1);
        createIndex(
            indexName,
            Settings.builder()
                .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)
                .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)
                .put(IndexService.GLOBAL_CHECKPOINT_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                .put(IndexService.RETENTION_LEASE_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                .build()
        );
        indexRandom(
            randomBoolean(),
            randomBoolean(),
            randomBoolean(),
            IntStream.range(0, randomIntBetween(1, 100)).mapToObj(n -> client().prepareIndex(indexName).setSource(""num"", n)).toList()
        );
        ensureActivePeerRecoveryRetentionLeasesAdvanced(indexName);
        assertAcked(client().admin().indices().prepareClose(indexName));
        int numberOfReplicas = randomIntBetween(1, 2);
        internalCluster().ensureAtLeastNumDataNodes(2 + numberOfReplicas);
        assertAcked(
            client().admin()
                .indices()
                .prepareUpdateSettings(indexName)
                .setSettings(Settings.builder().put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, numberOfReplicas))
        );
        ensureGreen(indexName);
        ensureActivePeerRecoveryRetentionLeasesAdvanced(indexName);
        assertAcked(
            client().admin()
                .cluster()
                .prepareUpdateSettings()
                .setPersistentSettings(Settings.builder().put(""cluster.routing.allocation.enable"", ""primaries"").build())
        );
        internalCluster().fullRestart();
        ensureYellow(indexName);
        if (randomBoolean()) {
            assertAcked(client().admin().indices().prepareOpen(indexName));
            client().admin().indices().prepareForceMerge(indexName).get();
        }
        assertAcked(
            client().admin()
                .cluster()
                .prepareUpdateSettings()
                .setPersistentSettings(Settings.builder().putNull(""cluster.routing.allocation.enable"").build())
        );
        ensureGreen(indexName);
        assertNoOpRecoveries(indexName);
    }",/server/src/internalClusterTest/java/org/elasticsearch/gateway/ReplicaShardAllocatorIT.java
2a00f25f573e1c1078c1f864eea52397a081c5c8,563,279,"public void usageStats(ActionListener<Map<String, Object>> listener) {
        final XPackLicenseState licenseStateSnapshot = licenseState.copyCurrentLicenseState();
        Map<String, Object> realmMap = new HashMap<>();
        final AtomicBoolean failed = new AtomicBoolean(false);
        final List<Realm> realmList = getActiveRealms().stream()
            .filter(r -> ReservedRealm.TYPE.equals(r.type()) == false)
            .collect(Collectors.toList());
        final Set<String> realmTypes = realmList.stream().map(Realm::type).collect(Collectors.toSet());
        final CountDown countDown = new CountDown(realmList.size());
        final Runnable doCountDown = () -> {
            if ((realmList.isEmpty() || countDown.countDown()) && failed.get() == false) {
                // iterate over the factories so we can add enabled & available info
                for (String type : factories.keySet()) {
                    assert ReservedRealm.TYPE.equals(type) == false;
                    realmMap.compute(type, (key, value) -> {
                        if (value == null) {
                            return MapBuilder.<String, Object>newMapBuilder()
                                .put(""enabled"", false)
                                .put(""available"", isRealmTypeAvailable(licenseStateSnapshot, type))
                                .map();
                        }

                        assert value instanceof Map;
                        @SuppressWarnings(""unchecked"")
                        Map<String, Object> realmTypeUsage = (Map<String, Object>) value;
                        realmTypeUsage.put(""enabled"", true);
                        realmTypeUsage.put(""available"", true);
                        return value;
                    });
                }
                listener.onResponse(realmMap);
            }
        };

        if (realmList.isEmpty()) {
            doCountDown.run();
        } else {
            for (Realm realm : realmList) {
                realm.usageStats(ActionListener.wrap(stats -> {
                    if (failed.get() == false) {
                        synchronized (realmMap) {
                            realmMap.compute(realm.type(), (key, value) -> {
                                if (value == null) {
                                    Object realmTypeUsage = convertToMapOfLists(stats);
                                    return realmTypeUsage;
                                }
                                assert value instanceof Map;
                                combineMaps((Map<String, Object>) value, stats);
                                return value;
                            });
                        }
                        doCountDown.run();
                    }
                }, e -> {
                    if (failed.compareAndSet(false, true)) {
                        listener.onFailure(e);
                    }
                }));
            }
        }
    }","public void usageStats(ActionListener<Map<String, Object>> listener) {
        final XPackLicenseState licenseStateSnapshot = licenseState.copyCurrentLicenseState();
        Map<String, Object> realmMap = new HashMap<>();
        final AtomicBoolean failed = new AtomicBoolean(false);
        final List<Realm> realmList = getActiveRealms().stream().filter(r -> ReservedRealm.TYPE.equals(r.type()) == false).toList();
        final CountDown countDown = new CountDown(realmList.size());
        final Runnable doCountDown = () -> {
            if ((realmList.isEmpty() || countDown.countDown()) && failed.get() == false) {
                // iterate over the factories so we can add enabled & available info
                for (String type : factories.keySet()) {
                    assert ReservedRealm.TYPE.equals(type) == false;
                    realmMap.compute(type, (key, value) -> {
                        if (value == null) {
                            return MapBuilder.<String, Object>newMapBuilder()
                                .put(""enabled"", false)
                                .put(""available"", isRealmTypeAvailable(licenseStateSnapshot, type))
                                .map();
                        }

                        assert value instanceof Map;
                        @SuppressWarnings(""unchecked"")
                        Map<String, Object> realmTypeUsage = (Map<String, Object>) value;
                        realmTypeUsage.put(""enabled"", true);
                        realmTypeUsage.put(""available"", true);
                        return value;
                    });
                }
                listener.onResponse(realmMap);
            }
        };

        if (realmList.isEmpty()) {
            doCountDown.run();
        } else {
            for (Realm realm : realmList) {
                realm.usageStats(ActionListener.wrap(stats -> {
                    if (failed.get() == false) {
                        synchronized (realmMap) {
                            realmMap.compute(realm.type(), (key, value) -> {
                                if (value == null) {
                                    Object realmTypeUsage = convertToMapOfLists(stats);
                                    return realmTypeUsage;
                                }
                                assert value instanceof Map;
                                combineMaps((Map<String, Object>) value, stats);
                                return value;
                            });
                        }
                        doCountDown.run();
                    }
                }, e -> {
                    if (failed.compareAndSet(false, true)) {
                        listener.onFailure(e);
                    }
                }));
            }
        }
    }",/x-pack/plugin/security/src/main/java/org/elasticsearch/xpack/security/authc/Realms.java
2a00f25f573e1c1078c1f864eea52397a081c5c8,690,512,"public void testSnapshot() {
        var preSnapshotDataStream = DataStreamTestHelper.randomInstance();
        var indicesToRemove = randomSubsetOf(preSnapshotDataStream.getIndices());
        if (indicesToRemove.size() == preSnapshotDataStream.getIndices().size()) {
            // never remove them all
            indicesToRemove.remove(0);
        }
        var indicesToAdd = DataStreamTestHelper.randomIndexInstances();
        var postSnapshotIndices = new ArrayList<>(preSnapshotDataStream.getIndices());
        postSnapshotIndices.removeAll(indicesToRemove);
        postSnapshotIndices.addAll(indicesToAdd);

        var postSnapshotDataStream = new DataStream(
            preSnapshotDataStream.getName(),
            preSnapshotDataStream.getTimeStampField(),
            postSnapshotIndices,
            preSnapshotDataStream.getGeneration() + randomIntBetween(0, 5),
            preSnapshotDataStream.getMetadata() == null ? null : new HashMap<>(preSnapshotDataStream.getMetadata()),
            preSnapshotDataStream.isHidden(),
            preSnapshotDataStream.isReplicated() && randomBoolean(),
            preSnapshotDataStream.isSystem(),
            preSnapshotDataStream.isAllowCustomRouting(),
            preSnapshotDataStream.getIndexMode()
        );

        var reconciledDataStream = postSnapshotDataStream.snapshot(
            preSnapshotDataStream.getIndices().stream().map(Index::getName).collect(Collectors.toList())
        );

        assertThat(reconciledDataStream.getName(), equalTo(postSnapshotDataStream.getName()));
        assertThat(reconciledDataStream.getTimeStampField(), equalTo(postSnapshotDataStream.getTimeStampField()));
        assertThat(reconciledDataStream.getGeneration(), equalTo(postSnapshotDataStream.getGeneration()));
        if (reconciledDataStream.getMetadata() != null) {
            assertThat(
                new HashSet<>(reconciledDataStream.getMetadata().entrySet()),
                hasItems(postSnapshotDataStream.getMetadata().entrySet().toArray())
            );
        } else {
            assertNull(postSnapshotDataStream.getMetadata());
        }
        assertThat(reconciledDataStream.isHidden(), equalTo(postSnapshotDataStream.isHidden()));
        assertThat(reconciledDataStream.isReplicated(), equalTo(postSnapshotDataStream.isReplicated()));
        assertThat(reconciledDataStream.getIndices(), everyItem(not(in(indicesToRemove))));
        assertThat(reconciledDataStream.getIndices(), everyItem(not(in(indicesToAdd))));
        assertThat(reconciledDataStream.getIndices().size(), equalTo(preSnapshotDataStream.getIndices().size() - indicesToRemove.size()));
    }","public void testSnapshot() {
        var preSnapshotDataStream = DataStreamTestHelper.randomInstance();
        var indicesToRemove = randomSubsetOf(preSnapshotDataStream.getIndices());
        if (indicesToRemove.size() == preSnapshotDataStream.getIndices().size()) {
            // never remove them all
            indicesToRemove.remove(0);
        }
        var indicesToAdd = DataStreamTestHelper.randomIndexInstances();
        var postSnapshotIndices = new ArrayList<>(preSnapshotDataStream.getIndices());
        postSnapshotIndices.removeAll(indicesToRemove);
        postSnapshotIndices.addAll(indicesToAdd);

        var postSnapshotDataStream = new DataStream(
            preSnapshotDataStream.getName(),
            preSnapshotDataStream.getTimeStampField(),
            postSnapshotIndices,
            preSnapshotDataStream.getGeneration() + randomIntBetween(0, 5),
            preSnapshotDataStream.getMetadata() == null ? null : new HashMap<>(preSnapshotDataStream.getMetadata()),
            preSnapshotDataStream.isHidden(),
            preSnapshotDataStream.isReplicated() && randomBoolean(),
            preSnapshotDataStream.isSystem(),
            preSnapshotDataStream.isAllowCustomRouting(),
            preSnapshotDataStream.getIndexMode()
        );

        var reconciledDataStream = postSnapshotDataStream.snapshot(
            preSnapshotDataStream.getIndices().stream().map(Index::getName).toList()
        );

        assertThat(reconciledDataStream.getName(), equalTo(postSnapshotDataStream.getName()));
        assertThat(reconciledDataStream.getTimeStampField(), equalTo(postSnapshotDataStream.getTimeStampField()));
        assertThat(reconciledDataStream.getGeneration(), equalTo(postSnapshotDataStream.getGeneration()));
        if (reconciledDataStream.getMetadata() != null) {
            assertThat(
                new HashSet<>(reconciledDataStream.getMetadata().entrySet()),
                hasItems(postSnapshotDataStream.getMetadata().entrySet().toArray())
            );
        } else {
            assertNull(postSnapshotDataStream.getMetadata());
        }
        assertThat(reconciledDataStream.isHidden(), equalTo(postSnapshotDataStream.isHidden()));
        assertThat(reconciledDataStream.isReplicated(), equalTo(postSnapshotDataStream.isReplicated()));
        assertThat(reconciledDataStream.getIndices(), everyItem(not(in(indicesToRemove))));
        assertThat(reconciledDataStream.getIndices(), everyItem(not(in(indicesToAdd))));
        assertThat(reconciledDataStream.getIndices().size(), equalTo(preSnapshotDataStream.getIndices().size() - indicesToRemove.size()));
    }",/server/src/test/java/org/elasticsearch/cluster/metadata/DataStreamTests.java
2a00f25f573e1c1078c1f864eea52397a081c5c8,563,35,"public void testCompilationCircuitBreaking() throws Exception {
        String context = randomFrom(
            ScriptModule.CORE_CONTEXTS.values().stream().filter(c -> c.compilationRateLimited).collect(Collectors.toList())
        ).name;
        final TimeValue expire = ScriptService.SCRIPT_CACHE_EXPIRE_SETTING.getConcreteSettingForNamespace(context).get(Settings.EMPTY);
        final Integer size = ScriptService.SCRIPT_CACHE_SIZE_SETTING.getConcreteSettingForNamespace(context).get(Settings.EMPTY);
        Setting<ScriptCache.CompilationRate> rateSetting = ScriptService.SCRIPT_MAX_COMPILATIONS_RATE_SETTING
            .getConcreteSettingForNamespace(context);
        ScriptCache.CompilationRate rate = ScriptService.SCRIPT_MAX_COMPILATIONS_RATE_SETTING.getConcreteSettingForNamespace(context)
            .get(Settings.EMPTY);
        String rateSettingName = rateSetting.getKey();
        ScriptCache cache = new ScriptCache(
            size,
            expire,
            new ScriptCache.CompilationRate(1, TimeValue.timeValueMinutes(1)),
            rateSettingName,
            () -> 1L
        );
        cache.checkCompilationLimit(); // should pass
        expectThrows(CircuitBreakingException.class, cache::checkCompilationLimit);
        cache = new ScriptCache(size, expire, new ScriptCache.CompilationRate(2, TimeValue.timeValueMinutes(1)), rateSettingName, time);
        cache.checkCompilationLimit(); // should pass
        cache.checkCompilationLimit(); // should pass
        expectThrows(CircuitBreakingException.class, cache::checkCompilationLimit);
        int count = randomIntBetween(5, 50);
        cache = new ScriptCache(size, expire, new ScriptCache.CompilationRate(count, TimeValue.timeValueMinutes(1)), rateSettingName, time);
        for (int i = 0; i < count; i++) {
            cache.checkCompilationLimit(); // should pass
        }
        expectThrows(CircuitBreakingException.class, cache::checkCompilationLimit);
        cache = new ScriptCache(size, expire, new ScriptCache.CompilationRate(0, TimeValue.timeValueMinutes(1)), rateSettingName, time);
        expectThrows(CircuitBreakingException.class, cache::checkCompilationLimit);
        cache = new ScriptCache(
            size,
            expire,
            new ScriptCache.CompilationRate(Integer.MAX_VALUE, TimeValue.timeValueMinutes(1)),
            rateSettingName,
            () -> 1L
        );
        int largeLimit = randomIntBetween(1000, 10000);
        for (int i = 0; i < largeLimit; i++) {
            cache.checkCompilationLimit();
        }
    }","public void testCompilationCircuitBreaking() throws Exception {
        String context = randomFrom(ScriptModule.CORE_CONTEXTS.values().stream().filter(c -> c.compilationRateLimited).toList()).name;
        final TimeValue expire = ScriptService.SCRIPT_CACHE_EXPIRE_SETTING.getConcreteSettingForNamespace(context).get(Settings.EMPTY);
        final Integer size = ScriptService.SCRIPT_CACHE_SIZE_SETTING.getConcreteSettingForNamespace(context).get(Settings.EMPTY);
        Setting<ScriptCache.CompilationRate> rateSetting = ScriptService.SCRIPT_MAX_COMPILATIONS_RATE_SETTING
            .getConcreteSettingForNamespace(context);
        ScriptCache.CompilationRate rate = ScriptService.SCRIPT_MAX_COMPILATIONS_RATE_SETTING.getConcreteSettingForNamespace(context)
            .get(Settings.EMPTY);
        String rateSettingName = rateSetting.getKey();
        ScriptCache cache = new ScriptCache(
            size,
            expire,
            new ScriptCache.CompilationRate(1, TimeValue.timeValueMinutes(1)),
            rateSettingName,
            () -> 1L
        );
        cache.checkCompilationLimit(); // should pass
        expectThrows(CircuitBreakingException.class, cache::checkCompilationLimit);
        cache = new ScriptCache(size, expire, new ScriptCache.CompilationRate(2, TimeValue.timeValueMinutes(1)), rateSettingName, time);
        cache.checkCompilationLimit(); // should pass
        cache.checkCompilationLimit(); // should pass
        expectThrows(CircuitBreakingException.class, cache::checkCompilationLimit);
        int count = randomIntBetween(5, 50);
        cache = new ScriptCache(size, expire, new ScriptCache.CompilationRate(count, TimeValue.timeValueMinutes(1)), rateSettingName, time);
        for (int i = 0; i < count; i++) {
            cache.checkCompilationLimit(); // should pass
        }
        expectThrows(CircuitBreakingException.class, cache::checkCompilationLimit);
        cache = new ScriptCache(size, expire, new ScriptCache.CompilationRate(0, TimeValue.timeValueMinutes(1)), rateSettingName, time);
        expectThrows(CircuitBreakingException.class, cache::checkCompilationLimit);
        cache = new ScriptCache(
            size,
            expire,
            new ScriptCache.CompilationRate(Integer.MAX_VALUE, TimeValue.timeValueMinutes(1)),
            rateSettingName,
            () -> 1L
        );
        int largeLimit = randomIntBetween(1000, 10000);
        for (int i = 0; i < largeLimit; i++) {
            cache.checkCompilationLimit();
        }
    }",/server/src/test/java/org/elasticsearch/script/ScriptCacheTests.java
2a00f25f573e1c1078c1f864eea52397a081c5c8,457,340,"public void testNoMasterActionsMetadataWriteMasterBlock() throws Exception {
        Settings settings = Settings.builder()
            .put(NoMasterBlockService.NO_MASTER_BLOCK_SETTING.getKey(), ""metadata_write"")
            .put(MappingUpdatedAction.INDICES_MAPPING_DYNAMIC_TIMEOUT_SETTING.getKey(), ""100ms"")
            .build();

        final List<String> nodes = internalCluster().startNodes(3, settings);

        prepareCreate(""test1"").setSettings(
            Settings.builder().put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1).put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1)
        ).get();
        client().admin().cluster().prepareHealth(""_all"").setWaitForGreenStatus().get();
        client().prepareIndex(""test1"").setId(""1"").setSource(""field"", ""value1"").get();
        refresh();

        ensureGreen(""test1"");

        ClusterStateResponse clusterState = client().admin().cluster().prepareState().get();
        logger.info(""Cluster state:\n{}"", clusterState.getState());

        final List<String> nodesWithShards = clusterState.getState()
            .routingTable()
            .index(""test1"")
            .shard(0)
            .activeShards()
            .stream()
            .map(shardRouting -> shardRouting.currentNodeId())
            .map(nodeId -> clusterState.getState().nodes().resolveNode(nodeId))
            .map(DiscoveryNode::getName)
            .collect(Collectors.toList());

        client().execute(
            AddVotingConfigExclusionsAction.INSTANCE,
            new AddVotingConfigExclusionsRequest(nodesWithShards.toArray(new String[0]))
        ).get();
        ensureGreen(""test1"");

        String partitionedNode = nodes.stream().filter(n -> nodesWithShards.contains(n) == false).findFirst().get();

        final NetworkDisruption disruptionScheme = new NetworkDisruption(
            new NetworkDisruption.TwoPartitions(Collections.singleton(partitionedNode), new HashSet<>(nodesWithShards)),
            NetworkDisruption.DISCONNECT
        );
        internalCluster().setDisruptionScheme(disruptionScheme);
        disruptionScheme.startDisrupting();

        assertBusy(() -> {
            for (String node : nodesWithShards) {
                ClusterState state = client(node).admin().cluster().prepareState().setLocal(true).get().getState();
                assertTrue(state.blocks().hasGlobalBlockWithId(NoMasterBlockService.NO_MASTER_BLOCK_ID));
            }
        });

        GetResponse getResponse = client(randomFrom(nodesWithShards)).prepareGet(""test1"", ""1"").get();
        assertExists(getResponse);

        expectThrows(Exception.class, () -> client(partitionedNode).prepareGet(""test1"", ""1"").get());

        SearchResponse countResponse = client(randomFrom(nodesWithShards)).prepareSearch(""test1"")
            .setAllowPartialSearchResults(true)
            .setSize(0)
            .get();
        assertHitCount(countResponse, 1L);

        expectThrows(
            Exception.class,
            () -> client(partitionedNode).prepareSearch(""test1"").setAllowPartialSearchResults(true).setSize(0).get()
        );

        TimeValue timeout = TimeValue.timeValueMillis(200);
        client(randomFrom(nodesWithShards)).prepareUpdate(""test1"", ""1"")
            .setDoc(Requests.INDEX_CONTENT_TYPE, ""field"", ""value2"")
            .setTimeout(timeout)
            .get();

        expectThrows(
            Exception.class,
            () -> client(partitionedNode).prepareUpdate(""test1"", ""1"")
                .setDoc(Requests.INDEX_CONTENT_TYPE, ""field"", ""value2"")
                .setTimeout(timeout)
                .get()
        );

        client(randomFrom(nodesWithShards)).prepareIndex(""test1"")
            .setId(""1"")
            .setSource(XContentFactory.jsonBuilder().startObject().endObject())
            .setTimeout(timeout)
            .get();

        // dynamic mapping updates fail
        expectThrows(
            MasterNotDiscoveredException.class,
            () -> client(randomFrom(nodesWithShards)).prepareIndex(""test1"")
                .setId(""1"")
                .setSource(XContentFactory.jsonBuilder().startObject().field(""new_field"", ""value"").endObject())
                .setTimeout(timeout)
                .get()
        );

        // dynamic index creation fails
        expectThrows(
            MasterNotDiscoveredException.class,
            () -> client(randomFrom(nodesWithShards)).prepareIndex(""test2"")
                .setId(""1"")
                .setSource(XContentFactory.jsonBuilder().startObject().endObject())
                .setTimeout(timeout)
                .get()
        );

        expectThrows(
            Exception.class,
            () -> client(partitionedNode).prepareIndex(""test1"")
                .setId(""1"")
                .setSource(XContentFactory.jsonBuilder().startObject().endObject())
                .setTimeout(timeout)
                .get()
        );

        internalCluster().clearDisruptionScheme(true);
    }","public void testNoMasterActionsMetadataWriteMasterBlock() throws Exception {
        Settings settings = Settings.builder()
            .put(NoMasterBlockService.NO_MASTER_BLOCK_SETTING.getKey(), ""metadata_write"")
            .put(MappingUpdatedAction.INDICES_MAPPING_DYNAMIC_TIMEOUT_SETTING.getKey(), ""100ms"")
            .build();

        final List<String> nodes = internalCluster().startNodes(3, settings);

        prepareCreate(""test1"").setSettings(
            Settings.builder().put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1).put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1)
        ).get();
        client().admin().cluster().prepareHealth(""_all"").setWaitForGreenStatus().get();
        client().prepareIndex(""test1"").setId(""1"").setSource(""field"", ""value1"").get();
        refresh();

        ensureGreen(""test1"");

        ClusterStateResponse clusterState = client().admin().cluster().prepareState().get();
        logger.info(""Cluster state:\n{}"", clusterState.getState());

        final List<String> nodesWithShards = clusterState.getState()
            .routingTable()
            .index(""test1"")
            .shard(0)
            .activeShards()
            .stream()
            .map(shardRouting -> shardRouting.currentNodeId())
            .map(nodeId -> clusterState.getState().nodes().resolveNode(nodeId))
            .map(DiscoveryNode::getName)
            .toList();

        client().execute(
            AddVotingConfigExclusionsAction.INSTANCE,
            new AddVotingConfigExclusionsRequest(nodesWithShards.toArray(new String[0]))
        ).get();
        ensureGreen(""test1"");

        String partitionedNode = nodes.stream().filter(n -> nodesWithShards.contains(n) == false).findFirst().get();

        final NetworkDisruption disruptionScheme = new NetworkDisruption(
            new NetworkDisruption.TwoPartitions(Collections.singleton(partitionedNode), new HashSet<>(nodesWithShards)),
            NetworkDisruption.DISCONNECT
        );
        internalCluster().setDisruptionScheme(disruptionScheme);
        disruptionScheme.startDisrupting();

        assertBusy(() -> {
            for (String node : nodesWithShards) {
                ClusterState state = client(node).admin().cluster().prepareState().setLocal(true).get().getState();
                assertTrue(state.blocks().hasGlobalBlockWithId(NoMasterBlockService.NO_MASTER_BLOCK_ID));
            }
        });

        GetResponse getResponse = client(randomFrom(nodesWithShards)).prepareGet(""test1"", ""1"").get();
        assertExists(getResponse);

        expectThrows(Exception.class, () -> client(partitionedNode).prepareGet(""test1"", ""1"").get());

        SearchResponse countResponse = client(randomFrom(nodesWithShards)).prepareSearch(""test1"")
            .setAllowPartialSearchResults(true)
            .setSize(0)
            .get();
        assertHitCount(countResponse, 1L);

        expectThrows(
            Exception.class,
            () -> client(partitionedNode).prepareSearch(""test1"").setAllowPartialSearchResults(true).setSize(0).get()
        );

        TimeValue timeout = TimeValue.timeValueMillis(200);
        client(randomFrom(nodesWithShards)).prepareUpdate(""test1"", ""1"")
            .setDoc(Requests.INDEX_CONTENT_TYPE, ""field"", ""value2"")
            .setTimeout(timeout)
            .get();

        expectThrows(
            Exception.class,
            () -> client(partitionedNode).prepareUpdate(""test1"", ""1"")
                .setDoc(Requests.INDEX_CONTENT_TYPE, ""field"", ""value2"")
                .setTimeout(timeout)
                .get()
        );

        client(randomFrom(nodesWithShards)).prepareIndex(""test1"")
            .setId(""1"")
            .setSource(XContentFactory.jsonBuilder().startObject().endObject())
            .setTimeout(timeout)
            .get();

        // dynamic mapping updates fail
        expectThrows(
            MasterNotDiscoveredException.class,
            () -> client(randomFrom(nodesWithShards)).prepareIndex(""test1"")
                .setId(""1"")
                .setSource(XContentFactory.jsonBuilder().startObject().field(""new_field"", ""value"").endObject())
                .setTimeout(timeout)
                .get()
        );

        // dynamic index creation fails
        expectThrows(
            MasterNotDiscoveredException.class,
            () -> client(randomFrom(nodesWithShards)).prepareIndex(""test2"")
                .setId(""1"")
                .setSource(XContentFactory.jsonBuilder().startObject().endObject())
                .setTimeout(timeout)
                .get()
        );

        expectThrows(
            Exception.class,
            () -> client(partitionedNode).prepareIndex(""test1"")
                .setId(""1"")
                .setSource(XContentFactory.jsonBuilder().startObject().endObject())
                .setTimeout(timeout)
                .get()
        );

        internalCluster().clearDisruptionScheme(true);
    }",/server/src/internalClusterTest/java/org/elasticsearch/cluster/NoMasterNodeIT.java
2a00f25f573e1c1078c1f864eea52397a081c5c8,391,121,"public void testPreferCopyCanPerformNoopRecovery() throws Exception {
        String indexName = ""test"";
        String nodeWithPrimary = internalCluster().startNode();
        assertAcked(
            client().admin()
                .indices()
                .prepareCreate(indexName)
                .setSettings(
                    Settings.builder()
                        .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)
                        .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1)
                        .put(IndexSettings.FILE_BASED_RECOVERY_THRESHOLD_SETTING.getKey(), 1.0f)
                        .put(IndexService.RETENTION_LEASE_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(IndexService.GLOBAL_CHECKPOINT_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), ""1ms"")
                )
        );
        String nodeWithReplica = internalCluster().startDataOnlyNode();
        Settings nodeWithReplicaSettings = internalCluster().dataPathSettings(nodeWithReplica);
        ensureGreen(indexName);
        indexRandom(
            randomBoolean(),
            randomBoolean(),
            randomBoolean(),
            IntStream.range(0, between(100, 500))
                .mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v""))
                .collect(Collectors.toList())
        );
        client().admin().indices().prepareFlush(indexName).get();
        if (randomBoolean()) {
            indexRandom(
                randomBoolean(),
                false,
                randomBoolean(),
                IntStream.range(0, between(0, 80))
                    .mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v""))
                    .collect(Collectors.toList())
            );
        }
        ensureActivePeerRecoveryRetentionLeasesAdvanced(indexName);
        internalCluster().stopRandomNode(InternalTestCluster.nameFilter(nodeWithReplica));
        if (randomBoolean()) {
            client().admin().indices().prepareForceMerge(indexName).setFlush(true).get();
        }
        CountDownLatch blockRecovery = new CountDownLatch(1);
        CountDownLatch recoveryStarted = new CountDownLatch(1);
        MockTransportService transportServiceOnPrimary = (MockTransportService) internalCluster().getInstance(
            TransportService.class,
            nodeWithPrimary
        );
        transportServiceOnPrimary.addSendBehavior((connection, requestId, action, request, options) -> {
            if (PeerRecoveryTargetService.Actions.FILES_INFO.equals(action)) {
                recoveryStarted.countDown();
                try {
                    blockRecovery.await();
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
            }
            connection.sendRequest(requestId, action, request, options);
        });
        internalCluster().startDataOnlyNode();
        recoveryStarted.await();
        nodeWithReplica = internalCluster().startDataOnlyNode(nodeWithReplicaSettings);
        // AllocationService only calls GatewayAllocator if there're unassigned shards
        assertAcked(client().admin().indices().prepareCreate(""dummy-index"").setWaitForActiveShards(0));
        ensureGreen(indexName);
        assertThat(internalCluster().nodesInclude(indexName), hasItem(nodeWithReplica));
        assertNoOpRecoveries(indexName);
        blockRecovery.countDown();
        transportServiceOnPrimary.clearAllRules();
    }","public void testPreferCopyCanPerformNoopRecovery() throws Exception {
        String indexName = ""test"";
        String nodeWithPrimary = internalCluster().startNode();
        assertAcked(
            client().admin()
                .indices()
                .prepareCreate(indexName)
                .setSettings(
                    Settings.builder()
                        .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)
                        .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1)
                        .put(IndexSettings.FILE_BASED_RECOVERY_THRESHOLD_SETTING.getKey(), 1.0f)
                        .put(IndexService.RETENTION_LEASE_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(IndexService.GLOBAL_CHECKPOINT_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), ""1ms"")
                )
        );
        String nodeWithReplica = internalCluster().startDataOnlyNode();
        Settings nodeWithReplicaSettings = internalCluster().dataPathSettings(nodeWithReplica);
        ensureGreen(indexName);
        indexRandom(
            randomBoolean(),
            randomBoolean(),
            randomBoolean(),
            IntStream.range(0, between(100, 500)).mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v"")).toList()
        );
        client().admin().indices().prepareFlush(indexName).get();
        if (randomBoolean()) {
            indexRandom(
                randomBoolean(),
                false,
                randomBoolean(),
                IntStream.range(0, between(0, 80)).mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v"")).toList()
            );
        }
        ensureActivePeerRecoveryRetentionLeasesAdvanced(indexName);
        internalCluster().stopRandomNode(InternalTestCluster.nameFilter(nodeWithReplica));
        if (randomBoolean()) {
            client().admin().indices().prepareForceMerge(indexName).setFlush(true).get();
        }
        CountDownLatch blockRecovery = new CountDownLatch(1);
        CountDownLatch recoveryStarted = new CountDownLatch(1);
        MockTransportService transportServiceOnPrimary = (MockTransportService) internalCluster().getInstance(
            TransportService.class,
            nodeWithPrimary
        );
        transportServiceOnPrimary.addSendBehavior((connection, requestId, action, request, options) -> {
            if (PeerRecoveryTargetService.Actions.FILES_INFO.equals(action)) {
                recoveryStarted.countDown();
                try {
                    blockRecovery.await();
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
            }
            connection.sendRequest(requestId, action, request, options);
        });
        internalCluster().startDataOnlyNode();
        recoveryStarted.await();
        nodeWithReplica = internalCluster().startDataOnlyNode(nodeWithReplicaSettings);
        // AllocationService only calls GatewayAllocator if there're unassigned shards
        assertAcked(client().admin().indices().prepareCreate(""dummy-index"").setWaitForActiveShards(0));
        ensureGreen(indexName);
        assertThat(internalCluster().nodesInclude(indexName), hasItem(nodeWithReplica));
        assertNoOpRecoveries(indexName);
        blockRecovery.countDown();
        transportServiceOnPrimary.clearAllRules();
    }",/server/src/internalClusterTest/java/org/elasticsearch/gateway/ReplicaShardAllocatorIT.java
2a00f25f573e1c1078c1f864eea52397a081c5c8,563,481,"public void testSerialization() throws IOException {
        NodeStats nodeStats = createNodeStats();
        try (BytesStreamOutput out = new BytesStreamOutput()) {
            nodeStats.writeTo(out);
            try (StreamInput in = out.bytes().streamInput()) {
                NodeStats deserializedNodeStats = new NodeStats(in);
                assertEquals(nodeStats.getNode(), deserializedNodeStats.getNode());
                assertEquals(nodeStats.getTimestamp(), deserializedNodeStats.getTimestamp());
                if (nodeStats.getOs() == null) {
                    assertNull(deserializedNodeStats.getOs());
                } else {
                    assertEquals(nodeStats.getOs().getTimestamp(), deserializedNodeStats.getOs().getTimestamp());
                    assertEquals(nodeStats.getOs().getSwap().getFree(), deserializedNodeStats.getOs().getSwap().getFree());
                    assertEquals(nodeStats.getOs().getSwap().getTotal(), deserializedNodeStats.getOs().getSwap().getTotal());
                    assertEquals(nodeStats.getOs().getSwap().getUsed(), deserializedNodeStats.getOs().getSwap().getUsed());
                    assertEquals(nodeStats.getOs().getMem().getFree(), deserializedNodeStats.getOs().getMem().getFree());
                    assertEquals(nodeStats.getOs().getMem().getTotal(), deserializedNodeStats.getOs().getMem().getTotal());
                    assertEquals(nodeStats.getOs().getMem().getUsed(), deserializedNodeStats.getOs().getMem().getUsed());
                    assertEquals(nodeStats.getOs().getMem().getFreePercent(), deserializedNodeStats.getOs().getMem().getFreePercent());
                    assertEquals(nodeStats.getOs().getMem().getUsedPercent(), deserializedNodeStats.getOs().getMem().getUsedPercent());
                    assertEquals(nodeStats.getOs().getCpu().getPercent(), deserializedNodeStats.getOs().getCpu().getPercent());
                    assertEquals(
                        nodeStats.getOs().getCgroup().getCpuAcctControlGroup(),
                        deserializedNodeStats.getOs().getCgroup().getCpuAcctControlGroup()
                    );
                    assertEquals(
                        nodeStats.getOs().getCgroup().getCpuAcctUsageNanos(),
                        deserializedNodeStats.getOs().getCgroup().getCpuAcctUsageNanos()
                    );
                    assertEquals(
                        nodeStats.getOs().getCgroup().getCpuControlGroup(),
                        deserializedNodeStats.getOs().getCgroup().getCpuControlGroup()
                    );
                    assertEquals(
                        nodeStats.getOs().getCgroup().getCpuCfsPeriodMicros(),
                        deserializedNodeStats.getOs().getCgroup().getCpuCfsPeriodMicros()
                    );
                    assertEquals(
                        nodeStats.getOs().getCgroup().getCpuCfsQuotaMicros(),
                        deserializedNodeStats.getOs().getCgroup().getCpuCfsQuotaMicros()
                    );
                    assertEquals(
                        nodeStats.getOs().getCgroup().getCpuStat().getNumberOfElapsedPeriods(),
                        deserializedNodeStats.getOs().getCgroup().getCpuStat().getNumberOfElapsedPeriods()
                    );
                    assertEquals(
                        nodeStats.getOs().getCgroup().getCpuStat().getNumberOfTimesThrottled(),
                        deserializedNodeStats.getOs().getCgroup().getCpuStat().getNumberOfTimesThrottled()
                    );
                    assertEquals(
                        nodeStats.getOs().getCgroup().getCpuStat().getTimeThrottledNanos(),
                        deserializedNodeStats.getOs().getCgroup().getCpuStat().getTimeThrottledNanos()
                    );
                    assertEquals(
                        nodeStats.getOs().getCgroup().getMemoryLimitInBytes(),
                        deserializedNodeStats.getOs().getCgroup().getMemoryLimitInBytes()
                    );
                    assertEquals(
                        nodeStats.getOs().getCgroup().getMemoryUsageInBytes(),
                        deserializedNodeStats.getOs().getCgroup().getMemoryUsageInBytes()
                    );
                    assertArrayEquals(
                        nodeStats.getOs().getCpu().getLoadAverage(),
                        deserializedNodeStats.getOs().getCpu().getLoadAverage(),
                        0
                    );
                }
                if (nodeStats.getProcess() == null) {
                    assertNull(deserializedNodeStats.getProcess());
                } else {
                    assertEquals(nodeStats.getProcess().getTimestamp(), deserializedNodeStats.getProcess().getTimestamp());
                    assertEquals(nodeStats.getProcess().getCpu().getTotal(), deserializedNodeStats.getProcess().getCpu().getTotal());
                    assertEquals(nodeStats.getProcess().getCpu().getPercent(), deserializedNodeStats.getProcess().getCpu().getPercent());
                    assertEquals(
                        nodeStats.getProcess().getMem().getTotalVirtual(),
                        deserializedNodeStats.getProcess().getMem().getTotalVirtual()
                    );
                    assertEquals(
                        nodeStats.getProcess().getMaxFileDescriptors(),
                        deserializedNodeStats.getProcess().getMaxFileDescriptors()
                    );
                    assertEquals(
                        nodeStats.getProcess().getOpenFileDescriptors(),
                        deserializedNodeStats.getProcess().getOpenFileDescriptors()
                    );
                }
                JvmStats jvm = nodeStats.getJvm();
                JvmStats deserializedJvm = deserializedNodeStats.getJvm();
                if (jvm == null) {
                    assertNull(deserializedJvm);
                } else {
                    JvmStats.Mem mem = jvm.getMem();
                    JvmStats.Mem deserializedMem = deserializedJvm.getMem();
                    assertEquals(jvm.getTimestamp(), deserializedJvm.getTimestamp());
                    assertEquals(mem.getHeapUsedPercent(), deserializedMem.getHeapUsedPercent());
                    assertEquals(mem.getHeapUsed(), deserializedMem.getHeapUsed());
                    assertEquals(mem.getHeapCommitted(), deserializedMem.getHeapCommitted());
                    assertEquals(mem.getNonHeapCommitted(), deserializedMem.getNonHeapCommitted());
                    assertEquals(mem.getNonHeapUsed(), deserializedMem.getNonHeapUsed());
                    assertEquals(mem.getHeapMax(), deserializedMem.getHeapMax());
                    JvmStats.Classes classes = jvm.getClasses();
                    assertEquals(classes.getLoadedClassCount(), deserializedJvm.getClasses().getLoadedClassCount());
                    assertEquals(classes.getTotalLoadedClassCount(), deserializedJvm.getClasses().getTotalLoadedClassCount());
                    assertEquals(classes.getUnloadedClassCount(), deserializedJvm.getClasses().getUnloadedClassCount());
                    assertEquals(jvm.getGc().getCollectors().length, deserializedJvm.getGc().getCollectors().length);
                    for (int i = 0; i < jvm.getGc().getCollectors().length; i++) {
                        JvmStats.GarbageCollector garbageCollector = jvm.getGc().getCollectors()[i];
                        JvmStats.GarbageCollector deserializedGarbageCollector = deserializedJvm.getGc().getCollectors()[i];
                        assertEquals(garbageCollector.getName(), deserializedGarbageCollector.getName());
                        assertEquals(garbageCollector.getCollectionCount(), deserializedGarbageCollector.getCollectionCount());
                        assertEquals(garbageCollector.getCollectionTime(), deserializedGarbageCollector.getCollectionTime());
                    }
                    assertEquals(jvm.getThreads().getCount(), deserializedJvm.getThreads().getCount());
                    assertEquals(jvm.getThreads().getPeakCount(), deserializedJvm.getThreads().getPeakCount());
                    assertEquals(jvm.getUptime(), deserializedJvm.getUptime());
                    if (jvm.getBufferPools() == null) {
                        assertNull(deserializedJvm.getBufferPools());
                    } else {
                        assertEquals(jvm.getBufferPools().size(), deserializedJvm.getBufferPools().size());
                        for (int i = 0; i < jvm.getBufferPools().size(); i++) {
                            JvmStats.BufferPool bufferPool = jvm.getBufferPools().get(i);
                            JvmStats.BufferPool deserializedBufferPool = deserializedJvm.getBufferPools().get(i);
                            assertEquals(bufferPool.getName(), deserializedBufferPool.getName());
                            assertEquals(bufferPool.getCount(), deserializedBufferPool.getCount());
                            assertEquals(bufferPool.getTotalCapacity(), deserializedBufferPool.getTotalCapacity());
                            assertEquals(bufferPool.getUsed(), deserializedBufferPool.getUsed());
                        }
                    }
                }
                if (nodeStats.getThreadPool() == null) {
                    assertNull(deserializedNodeStats.getThreadPool());
                } else {
                    Iterator<ThreadPoolStats.Stats> threadPoolIterator = nodeStats.getThreadPool().iterator();
                    Iterator<ThreadPoolStats.Stats> deserializedThreadPoolIterator = deserializedNodeStats.getThreadPool().iterator();
                    while (threadPoolIterator.hasNext()) {
                        ThreadPoolStats.Stats stats = threadPoolIterator.next();
                        ThreadPoolStats.Stats deserializedStats = deserializedThreadPoolIterator.next();
                        assertEquals(stats.getName(), deserializedStats.getName());
                        assertEquals(stats.getThreads(), deserializedStats.getThreads());
                        assertEquals(stats.getActive(), deserializedStats.getActive());
                        assertEquals(stats.getLargest(), deserializedStats.getLargest());
                        assertEquals(stats.getCompleted(), deserializedStats.getCompleted());
                        assertEquals(stats.getQueue(), deserializedStats.getQueue());
                        assertEquals(stats.getRejected(), deserializedStats.getRejected());
                    }
                }
                FsInfo fs = nodeStats.getFs();
                FsInfo deserializedFs = deserializedNodeStats.getFs();
                if (fs == null) {
                    assertNull(deserializedFs);
                } else {
                    assertEquals(fs.getTimestamp(), deserializedFs.getTimestamp());
                    assertEquals(fs.getTotal().getAvailable(), deserializedFs.getTotal().getAvailable());
                    assertEquals(fs.getTotal().getTotal(), deserializedFs.getTotal().getTotal());
                    assertEquals(fs.getTotal().getFree(), deserializedFs.getTotal().getFree());
                    assertEquals(fs.getTotal().getMount(), deserializedFs.getTotal().getMount());
                    assertEquals(fs.getTotal().getPath(), deserializedFs.getTotal().getPath());
                    assertEquals(fs.getTotal().getType(), deserializedFs.getTotal().getType());
                    FsInfo.IoStats ioStats = fs.getIoStats();
                    FsInfo.IoStats deserializedIoStats = deserializedFs.getIoStats();
                    assertEquals(ioStats.getTotalOperations(), deserializedIoStats.getTotalOperations());
                    assertEquals(ioStats.getTotalReadKilobytes(), deserializedIoStats.getTotalReadKilobytes());
                    assertEquals(ioStats.getTotalReadOperations(), deserializedIoStats.getTotalReadOperations());
                    assertEquals(ioStats.getTotalWriteKilobytes(), deserializedIoStats.getTotalWriteKilobytes());
                    assertEquals(ioStats.getTotalWriteOperations(), deserializedIoStats.getTotalWriteOperations());
                    assertEquals(ioStats.getTotalIOTimeMillis(), deserializedIoStats.getTotalIOTimeMillis());
                    assertEquals(ioStats.getDevicesStats().length, deserializedIoStats.getDevicesStats().length);
                    for (int i = 0; i < ioStats.getDevicesStats().length; i++) {
                        FsInfo.DeviceStats deviceStats = ioStats.getDevicesStats()[i];
                        FsInfo.DeviceStats deserializedDeviceStats = deserializedIoStats.getDevicesStats()[i];
                        assertEquals(deviceStats.operations(), deserializedDeviceStats.operations());
                        assertEquals(deviceStats.readKilobytes(), deserializedDeviceStats.readKilobytes());
                        assertEquals(deviceStats.readOperations(), deserializedDeviceStats.readOperations());
                        assertEquals(deviceStats.writeKilobytes(), deserializedDeviceStats.writeKilobytes());
                        assertEquals(deviceStats.writeOperations(), deserializedDeviceStats.writeOperations());
                        assertEquals(deviceStats.ioTimeInMillis(), deserializedDeviceStats.ioTimeInMillis());
                    }
                }
                if (nodeStats.getTransport() == null) {
                    assertNull(deserializedNodeStats.getTransport());
                } else {
                    assertEquals(nodeStats.getTransport().getRxCount(), deserializedNodeStats.getTransport().getRxCount());
                    assertEquals(nodeStats.getTransport().getRxSize(), deserializedNodeStats.getTransport().getRxSize());
                    assertEquals(nodeStats.getTransport().getServerOpen(), deserializedNodeStats.getTransport().getServerOpen());
                    assertEquals(nodeStats.getTransport().getTxCount(), deserializedNodeStats.getTransport().getTxCount());
                    assertEquals(nodeStats.getTransport().getTxSize(), deserializedNodeStats.getTransport().getTxSize());
                    assertArrayEquals(
                        nodeStats.getTransport().getInboundHandlingTimeBucketFrequencies(),
                        deserializedNodeStats.getTransport().getInboundHandlingTimeBucketFrequencies()
                    );
                    assertArrayEquals(
                        nodeStats.getTransport().getOutboundHandlingTimeBucketFrequencies(),
                        deserializedNodeStats.getTransport().getOutboundHandlingTimeBucketFrequencies()
                    );
                }
                if (nodeStats.getHttp() == null) {
                    assertNull(deserializedNodeStats.getHttp());
                } else {
                    assertEquals(nodeStats.getHttp().getServerOpen(), deserializedNodeStats.getHttp().getServerOpen());
                    assertEquals(nodeStats.getHttp().getTotalOpen(), deserializedNodeStats.getHttp().getTotalOpen());
                }
                if (nodeStats.getBreaker() == null) {
                    assertNull(deserializedNodeStats.getBreaker());
                } else {
                    assertEquals(nodeStats.getBreaker().getAllStats().length, deserializedNodeStats.getBreaker().getAllStats().length);
                    for (int i = 0; i < nodeStats.getBreaker().getAllStats().length; i++) {
                        CircuitBreakerStats circuitBreakerStats = nodeStats.getBreaker().getAllStats()[i];
                        CircuitBreakerStats deserializedCircuitBreakerStats = deserializedNodeStats.getBreaker().getAllStats()[i];
                        assertEquals(circuitBreakerStats.getEstimated(), deserializedCircuitBreakerStats.getEstimated());
                        assertEquals(circuitBreakerStats.getLimit(), deserializedCircuitBreakerStats.getLimit());
                        assertEquals(circuitBreakerStats.getName(), deserializedCircuitBreakerStats.getName());
                        assertEquals(circuitBreakerStats.getOverhead(), deserializedCircuitBreakerStats.getOverhead(), 0);
                        assertEquals(circuitBreakerStats.getTrippedCount(), deserializedCircuitBreakerStats.getTrippedCount(), 0);
                    }
                }
                ScriptStats scriptStats = nodeStats.getScriptStats();
                ScriptStats deserializedScriptStats = deserializedNodeStats.getScriptStats();
                if (scriptStats == null) {
                    assertNull(deserializedScriptStats);
                } else {
                    List<ScriptContextStats> deserialized = deserializedScriptStats.getContextStats();
                    long evictions = 0;
                    long limited = 0;
                    long compilations = 0;
                    List<ScriptContextStats> stats = scriptStats.getContextStats();
                    for (ScriptContextStats generatedStats : stats) {
                        List<ScriptContextStats> maybeDeserStats = deserialized.stream()
                            .filter(s -> s.getContext().equals(generatedStats.getContext()))
                            .collect(Collectors.toList());

                        assertEquals(1, maybeDeserStats.size());
                        ScriptContextStats deserStats = maybeDeserStats.get(0);

                        evictions += generatedStats.getCacheEvictions();
                        assertEquals(generatedStats.getCacheEvictions(), deserStats.getCacheEvictions());

                        limited += generatedStats.getCompilationLimitTriggered();
                        assertEquals(generatedStats.getCompilationLimitTriggered(), deserStats.getCompilationLimitTriggered());

                        compilations += generatedStats.getCompilations();
                        assertEquals(generatedStats.getCompilations(), deserStats.getCompilations());

                        assertEquals(generatedStats.getCacheEvictions(), deserStats.getCacheEvictions());
                        assertEquals(generatedStats.getCompilations(), deserStats.getCompilations());
                    }
                    assertEquals(evictions, scriptStats.getCacheEvictions());
                    assertEquals(limited, scriptStats.getCompilationLimitTriggered());
                    assertEquals(compilations, scriptStats.getCompilations());
                }
                DiscoveryStats discoveryStats = nodeStats.getDiscoveryStats();
                DiscoveryStats deserializedDiscoveryStats = deserializedNodeStats.getDiscoveryStats();
                if (discoveryStats == null) {
                    assertNull(deserializedDiscoveryStats);
                } else {
                    PendingClusterStateStats queueStats = discoveryStats.getQueueStats();
                    if (queueStats == null) {
                        assertNull(deserializedDiscoveryStats.getQueueStats());
                    } else {
                        assertEquals(queueStats.getCommitted(), deserializedDiscoveryStats.getQueueStats().getCommitted());
                        assertEquals(queueStats.getTotal(), deserializedDiscoveryStats.getQueueStats().getTotal());
                        assertEquals(queueStats.getPending(), deserializedDiscoveryStats.getQueueStats().getPending());
                    }

                    final PublishClusterStateStats publishStats = discoveryStats.getPublishStats();
                    if (publishStats == null) {
                        assertNull(deserializedDiscoveryStats.getPublishStats());
                    } else {
                        final PublishClusterStateStats deserializedPublishStats = deserializedDiscoveryStats.getPublishStats();
                        assertEquals(
                            publishStats.getFullClusterStateReceivedCount(),
                            deserializedPublishStats.getFullClusterStateReceivedCount()
                        );
                        assertEquals(
                            publishStats.getCompatibleClusterStateDiffReceivedCount(),
                            deserializedPublishStats.getCompatibleClusterStateDiffReceivedCount()
                        );
                        assertEquals(
                            publishStats.getIncompatibleClusterStateDiffReceivedCount(),
                            deserializedPublishStats.getIncompatibleClusterStateDiffReceivedCount()
                        );
                    }

                    final ClusterStateUpdateStats clusterStateUpdateStats = discoveryStats.getClusterStateUpdateStats();
                    if (clusterStateUpdateStats == null) {
                        assertNull(deserializedDiscoveryStats.getClusterStateUpdateStats());
                    } else {
                        final ClusterStateUpdateStats deserializedClusterStateUpdateStats = deserializedDiscoveryStats
                            .getClusterStateUpdateStats();
                        assertEquals(
                            clusterStateUpdateStats.getUnchangedTaskCount(),
                            deserializedClusterStateUpdateStats.getUnchangedTaskCount()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getPublicationSuccessCount(),
                            deserializedClusterStateUpdateStats.getPublicationSuccessCount()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getPublicationFailureCount(),
                            deserializedClusterStateUpdateStats.getPublicationFailureCount()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getUnchangedComputationElapsedMillis(),
                            deserializedClusterStateUpdateStats.getUnchangedComputationElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getUnchangedNotificationElapsedMillis(),
                            deserializedClusterStateUpdateStats.getUnchangedNotificationElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getSuccessfulComputationElapsedMillis(),
                            deserializedClusterStateUpdateStats.getSuccessfulComputationElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getSuccessfulPublicationElapsedMillis(),
                            deserializedClusterStateUpdateStats.getSuccessfulPublicationElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getSuccessfulContextConstructionElapsedMillis(),
                            deserializedClusterStateUpdateStats.getSuccessfulContextConstructionElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getSuccessfulCommitElapsedMillis(),
                            deserializedClusterStateUpdateStats.getSuccessfulCommitElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getSuccessfulCompletionElapsedMillis(),
                            deserializedClusterStateUpdateStats.getSuccessfulCompletionElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getSuccessfulMasterApplyElapsedMillis(),
                            deserializedClusterStateUpdateStats.getSuccessfulMasterApplyElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getSuccessfulNotificationElapsedMillis(),
                            deserializedClusterStateUpdateStats.getSuccessfulNotificationElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getFailedComputationElapsedMillis(),
                            deserializedClusterStateUpdateStats.getFailedComputationElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getFailedPublicationElapsedMillis(),
                            deserializedClusterStateUpdateStats.getFailedPublicationElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getFailedContextConstructionElapsedMillis(),
                            deserializedClusterStateUpdateStats.getFailedContextConstructionElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getFailedCommitElapsedMillis(),
                            deserializedClusterStateUpdateStats.getFailedCommitElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getFailedCompletionElapsedMillis(),
                            deserializedClusterStateUpdateStats.getFailedCompletionElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getFailedMasterApplyElapsedMillis(),
                            deserializedClusterStateUpdateStats.getFailedMasterApplyElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getFailedNotificationElapsedMillis(),
                            deserializedClusterStateUpdateStats.getFailedNotificationElapsedMillis()
                        );
                    }
                }
                IngestStats ingestStats = nodeStats.getIngestStats();
                IngestStats deserializedIngestStats = deserializedNodeStats.getIngestStats();
                if (ingestStats == null) {
                    assertNull(deserializedIngestStats);
                } else {
                    IngestStats.Stats totalStats = ingestStats.getTotalStats();
                    assertEquals(totalStats.getIngestCount(), deserializedIngestStats.getTotalStats().getIngestCount());
                    assertEquals(totalStats.getIngestCurrent(), deserializedIngestStats.getTotalStats().getIngestCurrent());
                    assertEquals(totalStats.getIngestFailedCount(), deserializedIngestStats.getTotalStats().getIngestFailedCount());
                    assertEquals(totalStats.getIngestTimeInMillis(), deserializedIngestStats.getTotalStats().getIngestTimeInMillis());
                    assertEquals(ingestStats.getPipelineStats().size(), deserializedIngestStats.getPipelineStats().size());
                    for (IngestStats.PipelineStat pipelineStat : ingestStats.getPipelineStats()) {
                        String pipelineId = pipelineStat.getPipelineId();
                        IngestStats.Stats deserializedPipelineStats = getPipelineStats(
                            deserializedIngestStats.getPipelineStats(),
                            pipelineId
                        );
                        assertEquals(pipelineStat.getStats().getIngestFailedCount(), deserializedPipelineStats.getIngestFailedCount());
                        assertEquals(pipelineStat.getStats().getIngestTimeInMillis(), deserializedPipelineStats.getIngestTimeInMillis());
                        assertEquals(pipelineStat.getStats().getIngestCurrent(), deserializedPipelineStats.getIngestCurrent());
                        assertEquals(pipelineStat.getStats().getIngestCount(), deserializedPipelineStats.getIngestCount());
                        List<IngestStats.ProcessorStat> processorStats = ingestStats.getProcessorStats().get(pipelineId);
                        // intentionally validating identical order
                        Iterator<IngestStats.ProcessorStat> it = deserializedIngestStats.getProcessorStats().get(pipelineId).iterator();
                        for (IngestStats.ProcessorStat processorStat : processorStats) {
                            IngestStats.ProcessorStat deserializedProcessorStat = it.next();
                            assertEquals(
                                processorStat.getStats().getIngestFailedCount(),
                                deserializedProcessorStat.getStats().getIngestFailedCount()
                            );
                            assertEquals(
                                processorStat.getStats().getIngestTimeInMillis(),
                                deserializedProcessorStat.getStats().getIngestTimeInMillis()
                            );
                            assertEquals(
                                processorStat.getStats().getIngestCurrent(),
                                deserializedProcessorStat.getStats().getIngestCurrent()
                            );
                            assertEquals(processorStat.getStats().getIngestCount(), deserializedProcessorStat.getStats().getIngestCount());
                        }
                        assertFalse(it.hasNext());
                    }
                }
                AdaptiveSelectionStats adaptiveStats = nodeStats.getAdaptiveSelectionStats();
                AdaptiveSelectionStats deserializedAdaptiveStats = deserializedNodeStats.getAdaptiveSelectionStats();
                if (adaptiveStats == null) {
                    assertNull(deserializedAdaptiveStats);
                } else {
                    assertEquals(adaptiveStats.getOutgoingConnections(), deserializedAdaptiveStats.getOutgoingConnections());
                    assertEquals(adaptiveStats.getRanks(), deserializedAdaptiveStats.getRanks());
                    adaptiveStats.getComputedStats().forEach((k, v) -> {
                        ResponseCollectorService.ComputedNodeStats aStats = adaptiveStats.getComputedStats().get(k);
                        ResponseCollectorService.ComputedNodeStats bStats = deserializedAdaptiveStats.getComputedStats().get(k);
                        assertEquals(aStats.nodeId, bStats.nodeId);
                        assertEquals(aStats.queueSize, bStats.queueSize, 0.01);
                        assertEquals(aStats.serviceTime, bStats.serviceTime, 0.01);
                        assertEquals(aStats.responseTime, bStats.responseTime, 0.01);
                    });
                }
                ScriptCacheStats scriptCacheStats = nodeStats.getScriptCacheStats();
                ScriptCacheStats deserializedScriptCacheStats = deserializedNodeStats.getScriptCacheStats();
                if (scriptCacheStats == null) {
                    assertNull(deserializedScriptCacheStats);
                } else if (deserializedScriptCacheStats.getContextStats() != null) {
                    Map<String, ScriptStats> deserialized = deserializedScriptCacheStats.getContextStats();
                    long evictions = 0;
                    long limited = 0;
                    long compilations = 0;
                    Map<String, ScriptStats> stats = scriptCacheStats.getContextStats();
                    for (String context : stats.keySet()) {
                        ScriptStats deserStats = deserialized.get(context);
                        ScriptStats generatedStats = stats.get(context);

                        evictions += generatedStats.getCacheEvictions();
                        assertEquals(generatedStats.getCacheEvictions(), deserStats.getCacheEvictions());

                        limited += generatedStats.getCompilationLimitTriggered();
                        assertEquals(generatedStats.getCompilationLimitTriggered(), deserStats.getCompilationLimitTriggered());

                        compilations += generatedStats.getCompilations();
                        assertEquals(generatedStats.getCompilations(), deserStats.getCompilations());
                    }
                    ScriptStats sum = deserializedScriptCacheStats.sum();
                    assertEquals(evictions, sum.getCacheEvictions());
                    assertEquals(limited, sum.getCompilationLimitTriggered());
                    assertEquals(compilations, sum.getCompilations());
                }
                if (nodeStats.getStatsRequestStats() == null) {
                    assertNull(deserializedNodeStats.getStatsRequestStats());
                } else {
                    Iterator<StatsRequestStats.Stats> statsRequestsStatsIterator = nodeStats.getStatsRequestStats().iterator();
                    Iterator<StatsRequestStats.Stats> deserializedStatsRequestsStatsIterator = deserializedNodeStats.getStatsRequestStats()
                        .iterator();
                    while (statsRequestsStatsIterator.hasNext()) {
                        StatsRequestStats.Stats stats = statsRequestsStatsIterator.next();
                        StatsRequestStats.Stats deserializedStats = deserializedStatsRequestsStatsIterator.next();
                        assertEquals(stats.getRequest(), deserializedStats.getRequest());
                        assertEquals(stats.getCurrent(), deserializedStats.getCurrent());
                        assertEquals(stats.getCompleted(), deserializedStats.getCompleted());
                        assertEquals(stats.getRejected(), deserializedStats.getRejected());
                    }
                }
            }
        }
    }","public void testSerialization() throws IOException {
        NodeStats nodeStats = createNodeStats();
        try (BytesStreamOutput out = new BytesStreamOutput()) {
            nodeStats.writeTo(out);
            try (StreamInput in = out.bytes().streamInput()) {
                NodeStats deserializedNodeStats = new NodeStats(in);
                assertEquals(nodeStats.getNode(), deserializedNodeStats.getNode());
                assertEquals(nodeStats.getTimestamp(), deserializedNodeStats.getTimestamp());
                if (nodeStats.getOs() == null) {
                    assertNull(deserializedNodeStats.getOs());
                } else {
                    assertEquals(nodeStats.getOs().getTimestamp(), deserializedNodeStats.getOs().getTimestamp());
                    assertEquals(nodeStats.getOs().getSwap().getFree(), deserializedNodeStats.getOs().getSwap().getFree());
                    assertEquals(nodeStats.getOs().getSwap().getTotal(), deserializedNodeStats.getOs().getSwap().getTotal());
                    assertEquals(nodeStats.getOs().getSwap().getUsed(), deserializedNodeStats.getOs().getSwap().getUsed());
                    assertEquals(nodeStats.getOs().getMem().getFree(), deserializedNodeStats.getOs().getMem().getFree());
                    assertEquals(nodeStats.getOs().getMem().getTotal(), deserializedNodeStats.getOs().getMem().getTotal());
                    assertEquals(nodeStats.getOs().getMem().getUsed(), deserializedNodeStats.getOs().getMem().getUsed());
                    assertEquals(nodeStats.getOs().getMem().getFreePercent(), deserializedNodeStats.getOs().getMem().getFreePercent());
                    assertEquals(nodeStats.getOs().getMem().getUsedPercent(), deserializedNodeStats.getOs().getMem().getUsedPercent());
                    assertEquals(nodeStats.getOs().getCpu().getPercent(), deserializedNodeStats.getOs().getCpu().getPercent());
                    assertEquals(
                        nodeStats.getOs().getCgroup().getCpuAcctControlGroup(),
                        deserializedNodeStats.getOs().getCgroup().getCpuAcctControlGroup()
                    );
                    assertEquals(
                        nodeStats.getOs().getCgroup().getCpuAcctUsageNanos(),
                        deserializedNodeStats.getOs().getCgroup().getCpuAcctUsageNanos()
                    );
                    assertEquals(
                        nodeStats.getOs().getCgroup().getCpuControlGroup(),
                        deserializedNodeStats.getOs().getCgroup().getCpuControlGroup()
                    );
                    assertEquals(
                        nodeStats.getOs().getCgroup().getCpuCfsPeriodMicros(),
                        deserializedNodeStats.getOs().getCgroup().getCpuCfsPeriodMicros()
                    );
                    assertEquals(
                        nodeStats.getOs().getCgroup().getCpuCfsQuotaMicros(),
                        deserializedNodeStats.getOs().getCgroup().getCpuCfsQuotaMicros()
                    );
                    assertEquals(
                        nodeStats.getOs().getCgroup().getCpuStat().getNumberOfElapsedPeriods(),
                        deserializedNodeStats.getOs().getCgroup().getCpuStat().getNumberOfElapsedPeriods()
                    );
                    assertEquals(
                        nodeStats.getOs().getCgroup().getCpuStat().getNumberOfTimesThrottled(),
                        deserializedNodeStats.getOs().getCgroup().getCpuStat().getNumberOfTimesThrottled()
                    );
                    assertEquals(
                        nodeStats.getOs().getCgroup().getCpuStat().getTimeThrottledNanos(),
                        deserializedNodeStats.getOs().getCgroup().getCpuStat().getTimeThrottledNanos()
                    );
                    assertEquals(
                        nodeStats.getOs().getCgroup().getMemoryLimitInBytes(),
                        deserializedNodeStats.getOs().getCgroup().getMemoryLimitInBytes()
                    );
                    assertEquals(
                        nodeStats.getOs().getCgroup().getMemoryUsageInBytes(),
                        deserializedNodeStats.getOs().getCgroup().getMemoryUsageInBytes()
                    );
                    assertArrayEquals(
                        nodeStats.getOs().getCpu().getLoadAverage(),
                        deserializedNodeStats.getOs().getCpu().getLoadAverage(),
                        0
                    );
                }
                if (nodeStats.getProcess() == null) {
                    assertNull(deserializedNodeStats.getProcess());
                } else {
                    assertEquals(nodeStats.getProcess().getTimestamp(), deserializedNodeStats.getProcess().getTimestamp());
                    assertEquals(nodeStats.getProcess().getCpu().getTotal(), deserializedNodeStats.getProcess().getCpu().getTotal());
                    assertEquals(nodeStats.getProcess().getCpu().getPercent(), deserializedNodeStats.getProcess().getCpu().getPercent());
                    assertEquals(
                        nodeStats.getProcess().getMem().getTotalVirtual(),
                        deserializedNodeStats.getProcess().getMem().getTotalVirtual()
                    );
                    assertEquals(
                        nodeStats.getProcess().getMaxFileDescriptors(),
                        deserializedNodeStats.getProcess().getMaxFileDescriptors()
                    );
                    assertEquals(
                        nodeStats.getProcess().getOpenFileDescriptors(),
                        deserializedNodeStats.getProcess().getOpenFileDescriptors()
                    );
                }
                JvmStats jvm = nodeStats.getJvm();
                JvmStats deserializedJvm = deserializedNodeStats.getJvm();
                if (jvm == null) {
                    assertNull(deserializedJvm);
                } else {
                    JvmStats.Mem mem = jvm.getMem();
                    JvmStats.Mem deserializedMem = deserializedJvm.getMem();
                    assertEquals(jvm.getTimestamp(), deserializedJvm.getTimestamp());
                    assertEquals(mem.getHeapUsedPercent(), deserializedMem.getHeapUsedPercent());
                    assertEquals(mem.getHeapUsed(), deserializedMem.getHeapUsed());
                    assertEquals(mem.getHeapCommitted(), deserializedMem.getHeapCommitted());
                    assertEquals(mem.getNonHeapCommitted(), deserializedMem.getNonHeapCommitted());
                    assertEquals(mem.getNonHeapUsed(), deserializedMem.getNonHeapUsed());
                    assertEquals(mem.getHeapMax(), deserializedMem.getHeapMax());
                    JvmStats.Classes classes = jvm.getClasses();
                    assertEquals(classes.getLoadedClassCount(), deserializedJvm.getClasses().getLoadedClassCount());
                    assertEquals(classes.getTotalLoadedClassCount(), deserializedJvm.getClasses().getTotalLoadedClassCount());
                    assertEquals(classes.getUnloadedClassCount(), deserializedJvm.getClasses().getUnloadedClassCount());
                    assertEquals(jvm.getGc().getCollectors().length, deserializedJvm.getGc().getCollectors().length);
                    for (int i = 0; i < jvm.getGc().getCollectors().length; i++) {
                        JvmStats.GarbageCollector garbageCollector = jvm.getGc().getCollectors()[i];
                        JvmStats.GarbageCollector deserializedGarbageCollector = deserializedJvm.getGc().getCollectors()[i];
                        assertEquals(garbageCollector.getName(), deserializedGarbageCollector.getName());
                        assertEquals(garbageCollector.getCollectionCount(), deserializedGarbageCollector.getCollectionCount());
                        assertEquals(garbageCollector.getCollectionTime(), deserializedGarbageCollector.getCollectionTime());
                    }
                    assertEquals(jvm.getThreads().getCount(), deserializedJvm.getThreads().getCount());
                    assertEquals(jvm.getThreads().getPeakCount(), deserializedJvm.getThreads().getPeakCount());
                    assertEquals(jvm.getUptime(), deserializedJvm.getUptime());
                    if (jvm.getBufferPools() == null) {
                        assertNull(deserializedJvm.getBufferPools());
                    } else {
                        assertEquals(jvm.getBufferPools().size(), deserializedJvm.getBufferPools().size());
                        for (int i = 0; i < jvm.getBufferPools().size(); i++) {
                            JvmStats.BufferPool bufferPool = jvm.getBufferPools().get(i);
                            JvmStats.BufferPool deserializedBufferPool = deserializedJvm.getBufferPools().get(i);
                            assertEquals(bufferPool.getName(), deserializedBufferPool.getName());
                            assertEquals(bufferPool.getCount(), deserializedBufferPool.getCount());
                            assertEquals(bufferPool.getTotalCapacity(), deserializedBufferPool.getTotalCapacity());
                            assertEquals(bufferPool.getUsed(), deserializedBufferPool.getUsed());
                        }
                    }
                }
                if (nodeStats.getThreadPool() == null) {
                    assertNull(deserializedNodeStats.getThreadPool());
                } else {
                    Iterator<ThreadPoolStats.Stats> threadPoolIterator = nodeStats.getThreadPool().iterator();
                    Iterator<ThreadPoolStats.Stats> deserializedThreadPoolIterator = deserializedNodeStats.getThreadPool().iterator();
                    while (threadPoolIterator.hasNext()) {
                        ThreadPoolStats.Stats stats = threadPoolIterator.next();
                        ThreadPoolStats.Stats deserializedStats = deserializedThreadPoolIterator.next();
                        assertEquals(stats.getName(), deserializedStats.getName());
                        assertEquals(stats.getThreads(), deserializedStats.getThreads());
                        assertEquals(stats.getActive(), deserializedStats.getActive());
                        assertEquals(stats.getLargest(), deserializedStats.getLargest());
                        assertEquals(stats.getCompleted(), deserializedStats.getCompleted());
                        assertEquals(stats.getQueue(), deserializedStats.getQueue());
                        assertEquals(stats.getRejected(), deserializedStats.getRejected());
                    }
                }
                FsInfo fs = nodeStats.getFs();
                FsInfo deserializedFs = deserializedNodeStats.getFs();
                if (fs == null) {
                    assertNull(deserializedFs);
                } else {
                    assertEquals(fs.getTimestamp(), deserializedFs.getTimestamp());
                    assertEquals(fs.getTotal().getAvailable(), deserializedFs.getTotal().getAvailable());
                    assertEquals(fs.getTotal().getTotal(), deserializedFs.getTotal().getTotal());
                    assertEquals(fs.getTotal().getFree(), deserializedFs.getTotal().getFree());
                    assertEquals(fs.getTotal().getMount(), deserializedFs.getTotal().getMount());
                    assertEquals(fs.getTotal().getPath(), deserializedFs.getTotal().getPath());
                    assertEquals(fs.getTotal().getType(), deserializedFs.getTotal().getType());
                    FsInfo.IoStats ioStats = fs.getIoStats();
                    FsInfo.IoStats deserializedIoStats = deserializedFs.getIoStats();
                    assertEquals(ioStats.getTotalOperations(), deserializedIoStats.getTotalOperations());
                    assertEquals(ioStats.getTotalReadKilobytes(), deserializedIoStats.getTotalReadKilobytes());
                    assertEquals(ioStats.getTotalReadOperations(), deserializedIoStats.getTotalReadOperations());
                    assertEquals(ioStats.getTotalWriteKilobytes(), deserializedIoStats.getTotalWriteKilobytes());
                    assertEquals(ioStats.getTotalWriteOperations(), deserializedIoStats.getTotalWriteOperations());
                    assertEquals(ioStats.getTotalIOTimeMillis(), deserializedIoStats.getTotalIOTimeMillis());
                    assertEquals(ioStats.getDevicesStats().length, deserializedIoStats.getDevicesStats().length);
                    for (int i = 0; i < ioStats.getDevicesStats().length; i++) {
                        FsInfo.DeviceStats deviceStats = ioStats.getDevicesStats()[i];
                        FsInfo.DeviceStats deserializedDeviceStats = deserializedIoStats.getDevicesStats()[i];
                        assertEquals(deviceStats.operations(), deserializedDeviceStats.operations());
                        assertEquals(deviceStats.readKilobytes(), deserializedDeviceStats.readKilobytes());
                        assertEquals(deviceStats.readOperations(), deserializedDeviceStats.readOperations());
                        assertEquals(deviceStats.writeKilobytes(), deserializedDeviceStats.writeKilobytes());
                        assertEquals(deviceStats.writeOperations(), deserializedDeviceStats.writeOperations());
                        assertEquals(deviceStats.ioTimeInMillis(), deserializedDeviceStats.ioTimeInMillis());
                    }
                }
                if (nodeStats.getTransport() == null) {
                    assertNull(deserializedNodeStats.getTransport());
                } else {
                    assertEquals(nodeStats.getTransport().getRxCount(), deserializedNodeStats.getTransport().getRxCount());
                    assertEquals(nodeStats.getTransport().getRxSize(), deserializedNodeStats.getTransport().getRxSize());
                    assertEquals(nodeStats.getTransport().getServerOpen(), deserializedNodeStats.getTransport().getServerOpen());
                    assertEquals(nodeStats.getTransport().getTxCount(), deserializedNodeStats.getTransport().getTxCount());
                    assertEquals(nodeStats.getTransport().getTxSize(), deserializedNodeStats.getTransport().getTxSize());
                    assertArrayEquals(
                        nodeStats.getTransport().getInboundHandlingTimeBucketFrequencies(),
                        deserializedNodeStats.getTransport().getInboundHandlingTimeBucketFrequencies()
                    );
                    assertArrayEquals(
                        nodeStats.getTransport().getOutboundHandlingTimeBucketFrequencies(),
                        deserializedNodeStats.getTransport().getOutboundHandlingTimeBucketFrequencies()
                    );
                }
                if (nodeStats.getHttp() == null) {
                    assertNull(deserializedNodeStats.getHttp());
                } else {
                    assertEquals(nodeStats.getHttp().getServerOpen(), deserializedNodeStats.getHttp().getServerOpen());
                    assertEquals(nodeStats.getHttp().getTotalOpen(), deserializedNodeStats.getHttp().getTotalOpen());
                }
                if (nodeStats.getBreaker() == null) {
                    assertNull(deserializedNodeStats.getBreaker());
                } else {
                    assertEquals(nodeStats.getBreaker().getAllStats().length, deserializedNodeStats.getBreaker().getAllStats().length);
                    for (int i = 0; i < nodeStats.getBreaker().getAllStats().length; i++) {
                        CircuitBreakerStats circuitBreakerStats = nodeStats.getBreaker().getAllStats()[i];
                        CircuitBreakerStats deserializedCircuitBreakerStats = deserializedNodeStats.getBreaker().getAllStats()[i];
                        assertEquals(circuitBreakerStats.getEstimated(), deserializedCircuitBreakerStats.getEstimated());
                        assertEquals(circuitBreakerStats.getLimit(), deserializedCircuitBreakerStats.getLimit());
                        assertEquals(circuitBreakerStats.getName(), deserializedCircuitBreakerStats.getName());
                        assertEquals(circuitBreakerStats.getOverhead(), deserializedCircuitBreakerStats.getOverhead(), 0);
                        assertEquals(circuitBreakerStats.getTrippedCount(), deserializedCircuitBreakerStats.getTrippedCount(), 0);
                    }
                }
                ScriptStats scriptStats = nodeStats.getScriptStats();
                ScriptStats deserializedScriptStats = deserializedNodeStats.getScriptStats();
                if (scriptStats == null) {
                    assertNull(deserializedScriptStats);
                } else {
                    List<ScriptContextStats> deserialized = deserializedScriptStats.getContextStats();
                    long evictions = 0;
                    long limited = 0;
                    long compilations = 0;
                    List<ScriptContextStats> stats = scriptStats.getContextStats();
                    for (ScriptContextStats generatedStats : stats) {
                        List<ScriptContextStats> maybeDeserStats = deserialized.stream()
                            .filter(s -> s.getContext().equals(generatedStats.getContext()))
                            .toList();

                        assertEquals(1, maybeDeserStats.size());
                        ScriptContextStats deserStats = maybeDeserStats.get(0);

                        evictions += generatedStats.getCacheEvictions();
                        assertEquals(generatedStats.getCacheEvictions(), deserStats.getCacheEvictions());

                        limited += generatedStats.getCompilationLimitTriggered();
                        assertEquals(generatedStats.getCompilationLimitTriggered(), deserStats.getCompilationLimitTriggered());

                        compilations += generatedStats.getCompilations();
                        assertEquals(generatedStats.getCompilations(), deserStats.getCompilations());

                        assertEquals(generatedStats.getCacheEvictions(), deserStats.getCacheEvictions());
                        assertEquals(generatedStats.getCompilations(), deserStats.getCompilations());
                    }
                    assertEquals(evictions, scriptStats.getCacheEvictions());
                    assertEquals(limited, scriptStats.getCompilationLimitTriggered());
                    assertEquals(compilations, scriptStats.getCompilations());
                }
                DiscoveryStats discoveryStats = nodeStats.getDiscoveryStats();
                DiscoveryStats deserializedDiscoveryStats = deserializedNodeStats.getDiscoveryStats();
                if (discoveryStats == null) {
                    assertNull(deserializedDiscoveryStats);
                } else {
                    PendingClusterStateStats queueStats = discoveryStats.getQueueStats();
                    if (queueStats == null) {
                        assertNull(deserializedDiscoveryStats.getQueueStats());
                    } else {
                        assertEquals(queueStats.getCommitted(), deserializedDiscoveryStats.getQueueStats().getCommitted());
                        assertEquals(queueStats.getTotal(), deserializedDiscoveryStats.getQueueStats().getTotal());
                        assertEquals(queueStats.getPending(), deserializedDiscoveryStats.getQueueStats().getPending());
                    }

                    final PublishClusterStateStats publishStats = discoveryStats.getPublishStats();
                    if (publishStats == null) {
                        assertNull(deserializedDiscoveryStats.getPublishStats());
                    } else {
                        final PublishClusterStateStats deserializedPublishStats = deserializedDiscoveryStats.getPublishStats();
                        assertEquals(
                            publishStats.getFullClusterStateReceivedCount(),
                            deserializedPublishStats.getFullClusterStateReceivedCount()
                        );
                        assertEquals(
                            publishStats.getCompatibleClusterStateDiffReceivedCount(),
                            deserializedPublishStats.getCompatibleClusterStateDiffReceivedCount()
                        );
                        assertEquals(
                            publishStats.getIncompatibleClusterStateDiffReceivedCount(),
                            deserializedPublishStats.getIncompatibleClusterStateDiffReceivedCount()
                        );
                    }

                    final ClusterStateUpdateStats clusterStateUpdateStats = discoveryStats.getClusterStateUpdateStats();
                    if (clusterStateUpdateStats == null) {
                        assertNull(deserializedDiscoveryStats.getClusterStateUpdateStats());
                    } else {
                        final ClusterStateUpdateStats deserializedClusterStateUpdateStats = deserializedDiscoveryStats
                            .getClusterStateUpdateStats();
                        assertEquals(
                            clusterStateUpdateStats.getUnchangedTaskCount(),
                            deserializedClusterStateUpdateStats.getUnchangedTaskCount()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getPublicationSuccessCount(),
                            deserializedClusterStateUpdateStats.getPublicationSuccessCount()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getPublicationFailureCount(),
                            deserializedClusterStateUpdateStats.getPublicationFailureCount()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getUnchangedComputationElapsedMillis(),
                            deserializedClusterStateUpdateStats.getUnchangedComputationElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getUnchangedNotificationElapsedMillis(),
                            deserializedClusterStateUpdateStats.getUnchangedNotificationElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getSuccessfulComputationElapsedMillis(),
                            deserializedClusterStateUpdateStats.getSuccessfulComputationElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getSuccessfulPublicationElapsedMillis(),
                            deserializedClusterStateUpdateStats.getSuccessfulPublicationElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getSuccessfulContextConstructionElapsedMillis(),
                            deserializedClusterStateUpdateStats.getSuccessfulContextConstructionElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getSuccessfulCommitElapsedMillis(),
                            deserializedClusterStateUpdateStats.getSuccessfulCommitElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getSuccessfulCompletionElapsedMillis(),
                            deserializedClusterStateUpdateStats.getSuccessfulCompletionElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getSuccessfulMasterApplyElapsedMillis(),
                            deserializedClusterStateUpdateStats.getSuccessfulMasterApplyElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getSuccessfulNotificationElapsedMillis(),
                            deserializedClusterStateUpdateStats.getSuccessfulNotificationElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getFailedComputationElapsedMillis(),
                            deserializedClusterStateUpdateStats.getFailedComputationElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getFailedPublicationElapsedMillis(),
                            deserializedClusterStateUpdateStats.getFailedPublicationElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getFailedContextConstructionElapsedMillis(),
                            deserializedClusterStateUpdateStats.getFailedContextConstructionElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getFailedCommitElapsedMillis(),
                            deserializedClusterStateUpdateStats.getFailedCommitElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getFailedCompletionElapsedMillis(),
                            deserializedClusterStateUpdateStats.getFailedCompletionElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getFailedMasterApplyElapsedMillis(),
                            deserializedClusterStateUpdateStats.getFailedMasterApplyElapsedMillis()
                        );
                        assertEquals(
                            clusterStateUpdateStats.getFailedNotificationElapsedMillis(),
                            deserializedClusterStateUpdateStats.getFailedNotificationElapsedMillis()
                        );
                    }
                }
                IngestStats ingestStats = nodeStats.getIngestStats();
                IngestStats deserializedIngestStats = deserializedNodeStats.getIngestStats();
                if (ingestStats == null) {
                    assertNull(deserializedIngestStats);
                } else {
                    IngestStats.Stats totalStats = ingestStats.getTotalStats();
                    assertEquals(totalStats.getIngestCount(), deserializedIngestStats.getTotalStats().getIngestCount());
                    assertEquals(totalStats.getIngestCurrent(), deserializedIngestStats.getTotalStats().getIngestCurrent());
                    assertEquals(totalStats.getIngestFailedCount(), deserializedIngestStats.getTotalStats().getIngestFailedCount());
                    assertEquals(totalStats.getIngestTimeInMillis(), deserializedIngestStats.getTotalStats().getIngestTimeInMillis());
                    assertEquals(ingestStats.getPipelineStats().size(), deserializedIngestStats.getPipelineStats().size());
                    for (IngestStats.PipelineStat pipelineStat : ingestStats.getPipelineStats()) {
                        String pipelineId = pipelineStat.getPipelineId();
                        IngestStats.Stats deserializedPipelineStats = getPipelineStats(
                            deserializedIngestStats.getPipelineStats(),
                            pipelineId
                        );
                        assertEquals(pipelineStat.getStats().getIngestFailedCount(), deserializedPipelineStats.getIngestFailedCount());
                        assertEquals(pipelineStat.getStats().getIngestTimeInMillis(), deserializedPipelineStats.getIngestTimeInMillis());
                        assertEquals(pipelineStat.getStats().getIngestCurrent(), deserializedPipelineStats.getIngestCurrent());
                        assertEquals(pipelineStat.getStats().getIngestCount(), deserializedPipelineStats.getIngestCount());
                        List<IngestStats.ProcessorStat> processorStats = ingestStats.getProcessorStats().get(pipelineId);
                        // intentionally validating identical order
                        Iterator<IngestStats.ProcessorStat> it = deserializedIngestStats.getProcessorStats().get(pipelineId).iterator();
                        for (IngestStats.ProcessorStat processorStat : processorStats) {
                            IngestStats.ProcessorStat deserializedProcessorStat = it.next();
                            assertEquals(
                                processorStat.getStats().getIngestFailedCount(),
                                deserializedProcessorStat.getStats().getIngestFailedCount()
                            );
                            assertEquals(
                                processorStat.getStats().getIngestTimeInMillis(),
                                deserializedProcessorStat.getStats().getIngestTimeInMillis()
                            );
                            assertEquals(
                                processorStat.getStats().getIngestCurrent(),
                                deserializedProcessorStat.getStats().getIngestCurrent()
                            );
                            assertEquals(processorStat.getStats().getIngestCount(), deserializedProcessorStat.getStats().getIngestCount());
                        }
                        assertFalse(it.hasNext());
                    }
                }
                AdaptiveSelectionStats adaptiveStats = nodeStats.getAdaptiveSelectionStats();
                AdaptiveSelectionStats deserializedAdaptiveStats = deserializedNodeStats.getAdaptiveSelectionStats();
                if (adaptiveStats == null) {
                    assertNull(deserializedAdaptiveStats);
                } else {
                    assertEquals(adaptiveStats.getOutgoingConnections(), deserializedAdaptiveStats.getOutgoingConnections());
                    assertEquals(adaptiveStats.getRanks(), deserializedAdaptiveStats.getRanks());
                    adaptiveStats.getComputedStats().forEach((k, v) -> {
                        ResponseCollectorService.ComputedNodeStats aStats = adaptiveStats.getComputedStats().get(k);
                        ResponseCollectorService.ComputedNodeStats bStats = deserializedAdaptiveStats.getComputedStats().get(k);
                        assertEquals(aStats.nodeId, bStats.nodeId);
                        assertEquals(aStats.queueSize, bStats.queueSize, 0.01);
                        assertEquals(aStats.serviceTime, bStats.serviceTime, 0.01);
                        assertEquals(aStats.responseTime, bStats.responseTime, 0.01);
                    });
                }
                ScriptCacheStats scriptCacheStats = nodeStats.getScriptCacheStats();
                ScriptCacheStats deserializedScriptCacheStats = deserializedNodeStats.getScriptCacheStats();
                if (scriptCacheStats == null) {
                    assertNull(deserializedScriptCacheStats);
                } else if (deserializedScriptCacheStats.getContextStats() != null) {
                    Map<String, ScriptStats> deserialized = deserializedScriptCacheStats.getContextStats();
                    long evictions = 0;
                    long limited = 0;
                    long compilations = 0;
                    Map<String, ScriptStats> stats = scriptCacheStats.getContextStats();
                    for (String context : stats.keySet()) {
                        ScriptStats deserStats = deserialized.get(context);
                        ScriptStats generatedStats = stats.get(context);

                        evictions += generatedStats.getCacheEvictions();
                        assertEquals(generatedStats.getCacheEvictions(), deserStats.getCacheEvictions());

                        limited += generatedStats.getCompilationLimitTriggered();
                        assertEquals(generatedStats.getCompilationLimitTriggered(), deserStats.getCompilationLimitTriggered());

                        compilations += generatedStats.getCompilations();
                        assertEquals(generatedStats.getCompilations(), deserStats.getCompilations());
                    }
                    ScriptStats sum = deserializedScriptCacheStats.sum();
                    assertEquals(evictions, sum.getCacheEvictions());
                    assertEquals(limited, sum.getCompilationLimitTriggered());
                    assertEquals(compilations, sum.getCompilations());
                }
                if (nodeStats.getStatsRequestStats() == null) {
                    assertNull(deserializedNodeStats.getStatsRequestStats());
                } else {
                    Iterator<StatsRequestStats.Stats> statsRequestsStatsIterator = nodeStats.getStatsRequestStats().iterator();
                    Iterator<StatsRequestStats.Stats> deserializedStatsRequestsStatsIterator = deserializedNodeStats.getStatsRequestStats()
                        .iterator();
                    while (statsRequestsStatsIterator.hasNext()) {
                        StatsRequestStats.Stats stats = statsRequestsStatsIterator.next();
                        StatsRequestStats.Stats deserializedStats = deserializedStatsRequestsStatsIterator.next();
                        assertEquals(stats.getRequest(), deserializedStats.getRequest());
                        assertEquals(stats.getCurrent(), deserializedStats.getCurrent());
                        assertEquals(stats.getCompleted(), deserializedStats.getCompleted());
                        assertEquals(stats.getRejected(), deserializedStats.getRejected());
                    }
                }
            }
        }
    }",/server/src/test/java/org/elasticsearch/action/admin/cluster/node/stats/NodeStatsTests.java
2a00f25f573e1c1078c1f864eea52397a081c5c8,563,86,") {
        if (enabled) {
            ActionListener<XPackUsageFeatureResponse> preservingListener = ContextPreservingActionListener.wrapPreservingContext(
                listener,
                client.threadPool().getThreadContext()
            );
            try (ThreadContext.StoredContext ignore = client.threadPool().getThreadContext().stashWithOrigin(WATCHER_ORIGIN)) {
                WatcherStatsRequest statsRequest = new WatcherStatsRequest();
                statsRequest.includeStats(true);
                statsRequest.setParentTask(clusterService.localNode().getId(), task.getId());
                client.execute(WatcherStatsAction.INSTANCE, statsRequest, ActionListener.wrap(r -> {
                    List<Counters> countersPerNode = r.getNodes()
                        .stream()
                        .map(WatcherStatsResponse.Node::getStats)
                        .filter(Objects::nonNull)
                        .collect(Collectors.toList());
                    Counters mergedCounters = Counters.merge(countersPerNode);
                    WatcherFeatureSetUsage usage = new WatcherFeatureSetUsage(
                        WatcherField.WATCHER_FEATURE.checkWithoutTracking(licenseState),
                        true,
                        mergedCounters.toNestedMap()
                    );
                    preservingListener.onResponse(new XPackUsageFeatureResponse(usage));
                }, preservingListener::onFailure));
            }
        } else {
            WatcherFeatureSetUsage usage = new WatcherFeatureSetUsage(
                WatcherField.WATCHER_FEATURE.checkWithoutTracking(licenseState),
                false,
                Collections.emptyMap()
            );
            listener.onResponse(new XPackUsageFeatureResponse(usage));
        }
    }",") {
        if (enabled) {
            ActionListener<XPackUsageFeatureResponse> preservingListener = ContextPreservingActionListener.wrapPreservingContext(
                listener,
                client.threadPool().getThreadContext()
            );
            try (ThreadContext.StoredContext ignore = client.threadPool().getThreadContext().stashWithOrigin(WATCHER_ORIGIN)) {
                WatcherStatsRequest statsRequest = new WatcherStatsRequest();
                statsRequest.includeStats(true);
                statsRequest.setParentTask(clusterService.localNode().getId(), task.getId());
                client.execute(WatcherStatsAction.INSTANCE, statsRequest, ActionListener.wrap(r -> {
                    List<Counters> countersPerNode = r.getNodes()
                        .stream()
                        .map(WatcherStatsResponse.Node::getStats)
                        .filter(Objects::nonNull)
                        .toList();
                    Counters mergedCounters = Counters.merge(countersPerNode);
                    WatcherFeatureSetUsage usage = new WatcherFeatureSetUsage(
                        WatcherField.WATCHER_FEATURE.checkWithoutTracking(licenseState),
                        true,
                        mergedCounters.toNestedMap()
                    );
                    preservingListener.onResponse(new XPackUsageFeatureResponse(usage));
                }, preservingListener::onFailure));
            }
        } else {
            WatcherFeatureSetUsage usage = new WatcherFeatureSetUsage(
                WatcherField.WATCHER_FEATURE.checkWithoutTracking(licenseState),
                false,
                Collections.emptyMap()
            );
            listener.onResponse(new XPackUsageFeatureResponse(usage));
        }
    }",/x-pack/plugin/watcher/src/main/java/org/elasticsearch/xpack/watcher/WatcherUsageTransportAction.java
e5ed5b908f87f724150334c7ca2b277c85599372,563,361,"public MergeResult merge(Mapping mapping, boolean simulate, boolean updateAllTypes) {
        try (ReleasableLock lock = mappingWriteLock.acquire()) {
            final MergeResult mergeResult = new MergeResult(simulate, updateAllTypes);
            this.mapping.merge(mapping, mergeResult);
            if (simulate == false) {
                addMappers(mergeResult.getNewObjectMappers(), mergeResult.getNewFieldMappers(), updateAllTypes);
                refreshSource();
            }
            return mergeResult;
        }
    }","public MergeResult merge(Mapping mapping, boolean simulate, boolean updateAllTypes) {
        try (ReleasableLock lock = mappingWriteLock.acquire()) {
            mapperService.checkMappersCompatibility(type, mapping, updateAllTypes);
            final MergeResult mergeResult = new MergeResult(simulate, updateAllTypes);
            this.mapping.merge(mapping, mergeResult);
            if (simulate == false) {
                addMappers(mergeResult.getNewObjectMappers(), mergeResult.getNewFieldMappers(), updateAllTypes);
                refreshSource();
            }
            return mergeResult;
        }
    }",/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapper.java
e5ed5b908f87f724150334c7ca2b277c85599372,567,278,"private DocumentMapper merge(DocumentMapper mapper, boolean updateAllTypes) {
        try (ReleasableLock lock = mappingWriteLock.acquire()) {
            if (mapper.type().length() == 0) {
                throw new InvalidTypeNameException(""mapping type name is empty"");
            }
            if (indexSettings.getIndexVersionCreated().onOrAfter(Version.V_2_0_0_beta1) && mapper.type().length() > 255) {
                throw new InvalidTypeNameException(""mapping type name ["" + mapper.type() + ""] is too long; limit is length 255 but was ["" + mapper.type().length() + ""]"");
            }
            if (mapper.type().charAt(0) == '_') {
                throw new InvalidTypeNameException(""mapping type name ["" + mapper.type() + ""] can't start with '_'"");
            }
            if (mapper.type().contains(""#"")) {
                throw new InvalidTypeNameException(""mapping type name ["" + mapper.type() + ""] should not include '#' in it"");
            }
            if (mapper.type().contains("","")) {
                throw new InvalidTypeNameException(""mapping type name ["" + mapper.type() + ""] should not include ',' in it"");
            }
            if (mapper.type().equals(mapper.parentFieldMapper().type())) {
                throw new IllegalArgumentException(""The [_parent.type] option can't point to the same type"");
            }
            if (typeNameStartsWithIllegalDot(mapper)) {
                if (indexSettings.getIndexVersionCreated().onOrAfter(Version.V_2_0_0_beta1)) {
                    throw new IllegalArgumentException(""mapping type name ["" + mapper.type() + ""] must not start with a '.'"");
                } else {
                    logger.warn(""Type [{}] starts with a '.', it is recommended not to start a type name with a '.'"", mapper.type());
                }
            }
            // we can add new field/object mappers while the old ones are there
            // since we get new instances of those, and when we remove, we remove
            // by instance equality
            DocumentMapper oldMapper = mappers.get(mapper.type());

            if (oldMapper != null) {
                // simulate first
                MergeResult result = oldMapper.merge(mapper.mapping(), true, updateAllTypes);
                if (result.hasConflicts()) {
                    throw new IllegalArgumentException(""Merge failed with failures {"" + Arrays.toString(result.buildConflicts()) + ""}"");
                }
                // then apply for real
                result = oldMapper.merge(mapper.mapping(), false, updateAllTypes);
                assert result.hasConflicts() == false; // we already simulated
                return oldMapper;
            } else {
                List<ObjectMapper> newObjectMappers = new ArrayList<>();
                List<FieldMapper> newFieldMappers = new ArrayList<>();
                for (MetadataFieldMapper metadataMapper : mapper.mapping().metadataMappers) {
                    newFieldMappers.add(metadataMapper);
                }
                MapperUtils.collect(mapper.mapping().root, newObjectMappers, newFieldMappers);
                checkNewMappersCompatibility(newObjectMappers, newFieldMappers, updateAllTypes);
                addMappers(mapper.type(), newObjectMappers, newFieldMappers);

                for (DocumentTypeListener typeListener : typeListeners) {
                    typeListener.beforeCreate(mapper);
                }
                mappers = newMapBuilder(mappers).put(mapper.type(), mapper).map();
                if (mapper.parentFieldMapper().active()) {
                    Set<String> newParentTypes = new HashSet<>(parentTypes.size() + 1);
                    newParentTypes.addAll(parentTypes);
                    newParentTypes.add(mapper.parentFieldMapper().type());
                    parentTypes = unmodifiableSet(newParentTypes);
                }
                assert assertSerialization(mapper);
                return mapper;
            }
        }
    }","private DocumentMapper merge(DocumentMapper mapper, boolean updateAllTypes) {
        try (ReleasableLock lock = mappingWriteLock.acquire()) {
            if (mapper.type().length() == 0) {
                throw new InvalidTypeNameException(""mapping type name is empty"");
            }
            if (indexSettings.getIndexVersionCreated().onOrAfter(Version.V_2_0_0_beta1) && mapper.type().length() > 255) {
                throw new InvalidTypeNameException(""mapping type name ["" + mapper.type() + ""] is too long; limit is length 255 but was ["" + mapper.type().length() + ""]"");
            }
            if (mapper.type().charAt(0) == '_') {
                throw new InvalidTypeNameException(""mapping type name ["" + mapper.type() + ""] can't start with '_'"");
            }
            if (mapper.type().contains(""#"")) {
                throw new InvalidTypeNameException(""mapping type name ["" + mapper.type() + ""] should not include '#' in it"");
            }
            if (mapper.type().contains("","")) {
                throw new InvalidTypeNameException(""mapping type name ["" + mapper.type() + ""] should not include ',' in it"");
            }
            if (mapper.type().equals(mapper.parentFieldMapper().type())) {
                throw new IllegalArgumentException(""The [_parent.type] option can't point to the same type"");
            }
            if (typeNameStartsWithIllegalDot(mapper)) {
                if (indexSettings.getIndexVersionCreated().onOrAfter(Version.V_2_0_0_beta1)) {
                    throw new IllegalArgumentException(""mapping type name ["" + mapper.type() + ""] must not start with a '.'"");
                } else {
                    logger.warn(""Type [{}] starts with a '.', it is recommended not to start a type name with a '.'"", mapper.type());
                }
            }
            // we can add new field/object mappers while the old ones are there
            // since we get new instances of those, and when we remove, we remove
            // by instance equality
            DocumentMapper oldMapper = mappers.get(mapper.type());

            if (oldMapper != null) {
                // simulate first
                MergeResult result = oldMapper.merge(mapper.mapping(), true, updateAllTypes);
                if (result.hasConflicts()) {
                    throw new IllegalArgumentException(""Merge failed with failures {"" + Arrays.toString(result.buildConflicts()) + ""}"");
                }
                // then apply for real
                result = oldMapper.merge(mapper.mapping(), false, updateAllTypes);
                assert result.hasConflicts() == false; // we already simulated
                return oldMapper;
            } else {
                Tuple<Collection<ObjectMapper>, Collection<FieldMapper>> newMappers = checkMappersCompatibility(
                        mapper.type(), mapper.mapping(), updateAllTypes);
                Collection<ObjectMapper> newObjectMappers = newMappers.v1();
                Collection<FieldMapper> newFieldMappers = newMappers.v2();
                addMappers(mapper.type(), newObjectMappers, newFieldMappers);

                for (DocumentTypeListener typeListener : typeListeners) {
                    typeListener.beforeCreate(mapper);
                }
                mappers = newMapBuilder(mappers).put(mapper.type(), mapper).map();
                if (mapper.parentFieldMapper().active()) {
                    Set<String> newParentTypes = new HashSet<>(parentTypes.size() + 1);
                    newParentTypes.addAll(parentTypes);
                    newParentTypes.add(mapper.parentFieldMapper().type());
                    parentTypes = unmodifiableSet(newParentTypes);
                }
                assert assertSerialization(mapper);
                return mapper;
            }
        }
    }",/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java
e5ed5b908f87f724150334c7ca2b277c85599372,567,354,"private void addMappers(Collection<ObjectMapper> objectMappers, Collection<FieldMapper> fieldMappers, boolean updateAllTypes) {
        assert mappingLock.isWriteLockedByCurrentThread();
        // first ensure we don't have any incompatible new fields
        mapperService.checkNewMappersCompatibility(objectMappers, fieldMappers, updateAllTypes);

        // update mappers for this document type
        Map<String, ObjectMapper> builder = new HashMap<>(this.objectMappers);
        for (ObjectMapper objectMapper : objectMappers) {
            builder.put(objectMapper.fullPath(), objectMapper);
            if (objectMapper.nested().isNested()) {
                hasNestedObjects = true;
            }
        }
        this.objectMappers = Collections.unmodifiableMap(builder);
        this.fieldMappers = this.fieldMappers.copyAndAllAll(fieldMappers);

        // finally update for the entire index
        mapperService.addMappers(type, objectMappers, fieldMappers);
    }","private void addMappers(Collection<ObjectMapper> objectMappers, Collection<FieldMapper> fieldMappers, boolean updateAllTypes) {
        assert mappingLock.isWriteLockedByCurrentThread();

        // update mappers for this document type
        Map<String, ObjectMapper> builder = new HashMap<>(this.objectMappers);
        for (ObjectMapper objectMapper : objectMappers) {
            builder.put(objectMapper.fullPath(), objectMapper);
            if (objectMapper.nested().isNested()) {
                hasNestedObjects = true;
            }
        }
        this.objectMappers = Collections.unmodifiableMap(builder);
        this.fieldMappers = this.fieldMappers.copyAndAllAll(fieldMappers);

        // finally update for the entire index
        mapperService.addMappers(type, objectMappers, fieldMappers);
    }",/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapper.java
e5ed5b908f87f724150334c7ca2b277c85599372,690,82,"public FieldTypeLookup copyAndAddAll(String type, Collection<FieldMapper> newFieldMappers) {
        Objects.requireNonNull(type, ""type must not be null"");
        if (MapperService.DEFAULT_MAPPING.equals(type)) {
            throw new IllegalArgumentException(""Default mappings should not be added to the lookup"");
        }
        CopyOnWriteHashMap<String, MappedFieldTypeReference> fullName = this.fullNameToFieldType;
        CopyOnWriteHashMap<String, MappedFieldTypeReference> indexName = this.indexNameToFieldType;

        for (FieldMapper fieldMapper : newFieldMappers) {
            MappedFieldType fieldType = fieldMapper.fieldType();
            MappedFieldTypeReference fullNameRef = fullName.get(fieldType.names().fullName());
            MappedFieldTypeReference indexNameRef = indexName.get(fieldType.names().indexName());
            if (fullNameRef == null && indexNameRef == null) {
                // new field, just use the ref from this field mapper
                fullName = fullName.copyAndPut(fieldType.names().fullName(), fieldMapper.fieldTypeReference());
                indexName = indexName.copyAndPut(fieldType.names().indexName(), fieldMapper.fieldTypeReference());
            } else if (fullNameRef == null) {
                // this index name already exists, so copy over the reference
                fullName = fullName.copyAndPut(fieldType.names().fullName(), indexNameRef);
                indexNameRef.set(fieldMapper.fieldType()); // field type is updated, since modifiable settings may have changed
                fieldMapper.setFieldTypeReference(indexNameRef);
            } else if (indexNameRef == null) {
                // this full name already exists, so copy over the reference
                indexName = indexName.copyAndPut(fieldType.names().indexName(), fullNameRef);
                fullNameRef.set(fieldMapper.fieldType()); // field type is updated, since modifiable settings may have changed
                fieldMapper.setFieldTypeReference(fullNameRef);
            } else if (fullNameRef == indexNameRef) {
                // the field already exists, so replace the reference in this mapper with the pre-existing one
                fullNameRef.set(fieldMapper.fieldType()); // field type is updated, since modifiable settings may have changed
                fieldMapper.setFieldTypeReference(fullNameRef);
            } else {
                // this new field bridges between two existing field names (a full and index name), which we cannot support
                throw new IllegalStateException(""insane mappings found. field "" + fieldType.names().fullName() + "" maps across types to field "" + fieldType.names().indexName());
            }
        }
        return new FieldTypeLookup(fullName, indexName);
    }","private static CopyOnWriteHashMap<String, Set<String>> addType(CopyOnWriteHashMap<String, Set<String>> map, String key, String type) {
        Set<String> types = map.get(key);
        if (types == null) {
            return map.copyAndPut(key, Collections.singleton(type));
        } else if (types.contains(type)) {
            // noting to do
            return map;
        } else {
            Set<String> newTypes = new HashSet<>(types.size() + 1);
            newTypes.addAll(types);
            newTypes.add(type);
            assert newTypes.size() == types.size() + 1;
            newTypes = Collections.unmodifiableSet(newTypes);
            return map.copyAndPut(key, newTypes);
        }
    }",/core/src/main/java/org/elasticsearch/index/mapper/FieldTypeLookup.java
e35de2ea2c9a108d5aa60b72ac72f70ec8e8a398,662,169,"protected void respondIfPossible(Exception ex) {
            if (finishedAsyncActions && listener != null) {
                if (ex == null) {
                    super.respond(listener);
                } else {
                    listener.onFailure(ex);
                }
            }
        }","protected void respondIfPossible(Exception ex) {
            assert Thread.holdsLock(this);
            if (finishedAsyncActions && listener != null) {
                if (ex == null) {
                    super.respond(listener);
                } else {
                    listener.onFailure(ex);
                }
            }
        }",/server/src/main/java/org/elasticsearch/action/support/replication/TransportWriteAction.java
15987f49c0e366ab5de70406478801497b0584a4,563,195,"public void testCreateJobWithExistingIndex() {
        MockClientBuilder clientBuilder = new MockClientBuilder(CLUSTER_NAME);
        ArgumentCaptor<CreateIndexRequest> captor = ArgumentCaptor.forClass(CreateIndexRequest.class);
        clientBuilder.prepareAlias(AnomalyDetectorsIndex.jobResultsIndexName(""foo""), AnomalyDetectorsIndex.jobResultsIndexName(""foo123""));

        Job.Builder job = buildJobBuilder(""foo123"");
        job.setResultsIndexName(""foo"");
        JobProvider provider = createProvider(clientBuilder.build());

        Index index = mock(Index.class);
        when(index.getName()).thenReturn(AnomalyDetectorsIndex.jobResultsIndexName(""foo""));
        IndexMetaData indexMetaData = mock(IndexMetaData.class);
        when(indexMetaData.getIndex()).thenReturn(index);

        ImmutableOpenMap<String, AliasMetaData> aliases = ImmutableOpenMap.of();
        when(indexMetaData.getAliases()).thenReturn(aliases);

        ImmutableOpenMap<String, IndexMetaData> indexMap = ImmutableOpenMap.<String, IndexMetaData>builder()
                .fPut(AnomalyDetectorsIndex.jobResultsIndexName(""foo""), indexMetaData).build();

        ClusterState cs2 = ClusterState.builder(new ClusterName(""_name""))
                .metaData(MetaData.builder().putCustom(MlMetadata.TYPE, MlMetadata.EMPTY_METADATA).indices(indexMap)).build();

        ClusterService clusterService = mock(ClusterService.class);

        doAnswer(invocationOnMock -> {
            AckedClusterStateUpdateTask<Boolean> task = (AckedClusterStateUpdateTask<Boolean>) invocationOnMock.getArguments()[1];
            task.execute(cs2);
            return null;
        }).when(clusterService).submitStateUpdateTask(eq(""put-job-foo123""), any(AckedClusterStateUpdateTask.class));

        doAnswer(invocationOnMock -> {
            AckedClusterStateUpdateTask<Boolean> task = (AckedClusterStateUpdateTask<Boolean>) invocationOnMock.getArguments()[1];
            task.execute(cs2);
            return null;
        }).when(clusterService).submitStateUpdateTask(eq(""index-aliases""), any(AckedClusterStateUpdateTask.class));

        provider.createJobResultIndex(job.build(), cs2, new ActionListener<Boolean>() {
            @Override
            public void onResponse(Boolean aBoolean) {
                assertTrue(aBoolean);
            }

            @Override
            public void onFailure(Exception e) {
                fail(e.toString());
            }
        });
    }","public void testCreateJobResultsIndex() {
        MockClientBuilder clientBuilder = new MockClientBuilder(CLUSTER_NAME);
        ArgumentCaptor<CreateIndexRequest> captor = ArgumentCaptor.forClass(CreateIndexRequest.class);
        clientBuilder.createIndexRequest(AnomalyDetectorsIndex.jobResultsIndexName(""foo""), captor);

        Job.Builder job = buildJobBuilder(""foo"");
        JobProvider provider = createProvider(clientBuilder.build());

        ClusterState cs = ClusterState.builder(new ClusterName(""_name""))
                .metaData(MetaData.builder().putCustom(MlMetadata.TYPE, MlMetadata.EMPTY_METADATA).indices(ImmutableOpenMap.of())).build();

        ClusterService clusterService = mock(ClusterService.class);

        doAnswer(invocationOnMock -> {
            AckedClusterStateUpdateTask<Boolean> task = (AckedClusterStateUpdateTask<Boolean>) invocationOnMock.getArguments()[1];
            task.execute(cs);
            return null;
        }).when(clusterService).submitStateUpdateTask(eq(""put-job-foo""), any(AckedClusterStateUpdateTask.class));

        provider.createJobResultIndex(job.build(), cs, new ActionListener<Boolean>() {
            @Override
            public void onResponse(Boolean aBoolean) {
                CreateIndexRequest request = captor.getValue();
                assertNotNull(request);
                assertEquals(provider.mlResultsIndexSettings().build(), request.settings());
                assertTrue(request.mappings().containsKey(Result.TYPE.getPreferredName()));
                assertTrue(request.mappings().containsKey(CategoryDefinition.TYPE.getPreferredName()));
                assertTrue(request.mappings().containsKey(DataCounts.TYPE.getPreferredName()));
                assertTrue(request.mappings().containsKey(ModelSnapshot.TYPE.getPreferredName()));
                assertEquals(4, request.mappings().size());

                clientBuilder.verifyIndexCreated(AnomalyDetectorsIndex.jobResultsIndexName(""foo""));
            }

            @Override
            public void onFailure(Exception e) {
                fail(e.toString());
            }
        });
    }",/plugin/src/test/java/org/elasticsearch/xpack/ml/job/persistence/JobProviderTests.java
15987f49c0e366ab5de70406478801497b0584a4,563,398,"public void testCreateJobStateIndex() {
        MockClientBuilder clientBuilder = new MockClientBuilder(CLUSTER_NAME);
        ArgumentCaptor<CreateIndexRequest> captor = ArgumentCaptor.forClass(CreateIndexRequest.class);
        clientBuilder.createIndexRequest(AnomalyDetectorsIndex.jobStateIndexName(), captor);

        Job.Builder job = buildJobBuilder(""foo"");
        JobProvider provider = createProvider(clientBuilder.build());

        provider.createJobStateIndex((result, error) -> {
                assertTrue(result);
                CreateIndexRequest request = captor.getValue();
                assertNotNull(request);
                assertEquals(provider.mlStateIndexSettings().build(), request.settings());
                assertTrue(request.mappings().containsKey(CategorizerState.TYPE));
                assertTrue(request.mappings().containsKey(Quantiles.TYPE.getPreferredName()));
                assertTrue(request.mappings().containsKey(ModelState.TYPE.getPreferredName()));
                assertEquals(3, request.mappings().size());
            });
    }","public void testCreateMetaIndex() {
        MockClientBuilder clientBuilder = new MockClientBuilder(CLUSTER_NAME);
        ArgumentCaptor<CreateIndexRequest> captor = ArgumentCaptor.forClass(CreateIndexRequest.class);
        clientBuilder.createIndexRequest(JobProvider.ML_META_INDEX, captor);

        JobProvider provider = createProvider(clientBuilder.build());

        provider.createMetaIndex((result, error) -> {
            assertTrue(result);
            CreateIndexRequest request = captor.getValue();
            assertNotNull(request);
            assertEquals(provider.mlNotificationIndexSettings().build(), request.settings());
            assertEquals(0, request.mappings().size());

            clientBuilder.verifyIndexCreated(JobProvider.ML_META_INDEX);
        });
    }",/plugin/src/test/java/org/elasticsearch/xpack/ml/job/persistence/JobProviderTests.java
65e76b3f6f5ae73c91f4f66f9cd2458d13d8c994,563,555,"public void testRecoveryDifferentNodeOrderStartup() throws Exception {
        // we need different data paths so we make sure we start the second node fresh

        final Path pathNode1 = createTempDir();
        final String node_1 =
            internalCluster().startNode(Settings.builder().put(Environment.PATH_DATA_SETTING.getKey(), pathNode1).build());

        client().prepareIndex(""test"", ""type1"", ""1"").setSource(""field"", ""value"").execute().actionGet();

        final Path pathNode2 = createTempDir();
        final String node_2 =
            internalCluster().startNode(Settings.builder().put(Environment.PATH_DATA_SETTING.getKey(), pathNode2).build());

        ensureGreen();
        Map<String, long[]> primaryTerms = assertAndCapturePrimaryTerms(null);

        if (randomBoolean()) {
            internalCluster().stopRandomNode(InternalTestCluster.nameFilter(node_1));
            internalCluster().stopRandomNode(InternalTestCluster.nameFilter(node_2));
        } else {
            internalCluster().stopRandomNode(InternalTestCluster.nameFilter(node_2));
            internalCluster().stopRandomNode(InternalTestCluster.nameFilter(node_1));
        }
        // start the second node again
        internalCluster().startNode(Settings.builder().put(Environment.PATH_DATA_SETTING.getKey(), pathNode2).build());
        ensureYellow();
        primaryTerms = assertAndCapturePrimaryTerms(primaryTerms);
        assertThat(client().admin().indices().prepareExists(""test"").execute().actionGet().isExists(), equalTo(true));
        assertHitCount(client().prepareSearch(""test"").setSize(0).setQuery(QueryBuilders.matchAllQuery()).execute().actionGet(), 1);
    }","public void testStartedShardFoundIfStateNotYetProcessed() throws Exception {
        // nodes may need to report the shards they processed the initial recovered cluster state from the master
        final String nodeName = internalCluster().startNode();
        assertAcked(prepareCreate(""test"").setSettings(Settings.builder().put(SETTING_NUMBER_OF_SHARDS, 1)));
        final Index index = resolveIndex(""test"");
        final ShardId shardId = new ShardId(index, 0);
        index(""test"", ""type"", ""1"");
        flush(""test"");

        final boolean corrupt = randomBoolean();

        internalCluster().fullRestart(new RestartCallback() {
            @Override
            public Settings onNodeStopped(String nodeName) throws Exception {
                // make sure state is not recovered
                return Settings.builder().put(RECOVER_AFTER_NODES_SETTING.getKey(), 2).build();
            }
        });

        if (corrupt) {
            for (Path path : internalCluster().getInstance(NodeEnvironment.class, nodeName).availableShardPaths(shardId)) {
                final Path indexPath = path.resolve(ShardPath.INDEX_FOLDER_NAME);
                if (Files.exists(indexPath)) { // multi data path might only have one path in use
                    try (DirectoryStream<Path> stream = Files.newDirectoryStream(indexPath)) {
                        for (Path item : stream) {
                            if (item.getFileName().toString().startsWith(""segments_"")) {
                                logger.debug(""--> deleting [{}]"", item);
                                Files.delete(item);
                            }
                        }
                    }
                }

            }
        }

        DiscoveryNode node = internalCluster().getInstance(ClusterService.class, nodeName).localNode();

        TransportNodesListGatewayStartedShards.NodesGatewayStartedShards response;
        response = ActionTestUtils.executeBlocking(internalCluster().getInstance(TransportNodesListGatewayStartedShards.class),
            new TransportNodesListGatewayStartedShards.Request(shardId, new DiscoveryNode[]{node}));

        assertThat(response.getNodes(), hasSize(1));
        assertThat(response.getNodes().get(0).allocationId(), notNullValue());
        if (corrupt) {
            assertThat(response.getNodes().get(0).storeException(), notNullValue());
        } else {
            assertThat(response.getNodes().get(0).storeException(), nullValue());
        }

        // start another node so cluster consistency checks won't time out due to the lack of state
        internalCluster().startNode();
    }",/server/src/test/java/org/elasticsearch/gateway/RecoveryFromGatewayIT.java
65e76b3f6f5ae73c91f4f66f9cd2458d13d8c994,563,333,"public void testTwoNodeFirstNodeCleared() throws Exception {
        final String firstNode = internalCluster().startNode();
        internalCluster().startNode();

        client().prepareIndex(""test"", ""type1"", ""1"").setSource(jsonBuilder().startObject().field(""field"", ""value1"").endObject()).execute()
            .actionGet();
        flush();
        client().prepareIndex(""test"", ""type1"", ""2"").setSource(jsonBuilder().startObject().field(""field"", ""value2"").endObject()).execute()
            .actionGet();
        refresh();

        logger.info(""Running Cluster Health (wait for the shards to startup)"");
        ensureGreen();

        for (int i = 0; i < 10; i++) {
            assertHitCount(client().prepareSearch().setSize(0).setQuery(matchAllQuery()).execute().actionGet(), 2);
        }

        Map<String, long[]> primaryTerms = assertAndCapturePrimaryTerms(null);

        internalCluster().fullRestart(new RestartCallback() {
            @Override
            public Settings onNodeStopped(String nodeName) throws Exception {
                return Settings.builder().put(""gateway.recover_after_nodes"", 2).build();
            }

            @Override
            public boolean clearData(String nodeName) {
                return firstNode.equals(nodeName);
            }

        });

        logger.info(""Running Cluster Health (wait for the shards to startup)"");
        ensureGreen();
        primaryTerms = assertAndCapturePrimaryTerms(primaryTerms);

        for (int i = 0; i < 10; i++) {
            assertHitCount(client().prepareSearch().setSize(0).setQuery(matchAllQuery()).execute().actionGet(), 2);
        }
    }","public void testTwoNodeFirstNodeCleared() throws Exception {
        final String firstNode = internalCluster().startNode();
        internalCluster().startNode();

        client().prepareIndex(""test"", ""type1"", ""1"").setSource(jsonBuilder().startObject().field(""field"", ""value1"").endObject()).execute()
            .actionGet();
        flush();
        client().prepareIndex(""test"", ""type1"", ""2"").setSource(jsonBuilder().startObject().field(""field"", ""value2"").endObject()).execute()
            .actionGet();
        refresh();

        logger.info(""Running Cluster Health (wait for the shards to startup)"");
        ensureGreen();

        for (int i = 0; i < 10; i++) {
            assertHitCount(client().prepareSearch().setSize(0).setQuery(matchAllQuery()).execute().actionGet(), 2);
        }

        Map<String, long[]> primaryTerms = assertAndCapturePrimaryTerms(null);

        client().execute(AddVotingConfigExclusionsAction.INSTANCE, new AddVotingConfigExclusionsRequest(new String[]{firstNode})).get();

        internalCluster().fullRestart(new RestartCallback() {
            @Override
            public Settings onNodeStopped(String nodeName) {
                return Settings.builder()
                    .put(RECOVER_AFTER_NODES_SETTING.getKey(), 2)
                    .putList(INITIAL_MASTER_NODES_SETTING.getKey()) // disable bootstrapping
                    .build();
            }

            @Override
            public boolean clearData(String nodeName) {
                return firstNode.equals(nodeName);
            }

        });

        logger.info(""Running Cluster Health (wait for the shards to startup)"");
        ensureGreen();
        primaryTerms = assertAndCapturePrimaryTerms(primaryTerms);

        for (int i = 0; i < 10; i++) {
            assertHitCount(client().prepareSearch().setSize(0).setQuery(matchAllQuery()).execute().actionGet(), 2);
        }

        client().execute(ClearVotingConfigExclusionsAction.INSTANCE, new ClearVotingConfigExclusionsRequest()).get();
    }",/server/src/test/java/org/elasticsearch/gateway/RecoveryFromGatewayIT.java
256e01ca92c43f3ccdc87bfc95031cbcda82e04a,570,228,"protected void execute(Terminal terminal, OptionSet options, Environment env) throws Exception {

            String username = parseUsername(arguments.values(options), env.settings());
            char[] password = parsePassword(terminal, passwordOption.value(options));

            Path file = FileUserPasswdStore.resolveFile(env);
            FileAttributesChecker attributesChecker = new FileAttributesChecker(file);
            Map<String, char[]> users = new HashMap<>(FileUserPasswdStore.parseFile(file, null, env.settings()));
            if (users == null) {
                throw new UserException(ExitCodes.CONFIG, ""Configuration file ["" + file + ""] is missing"");
            }
            if (users.containsKey(username) == false) {
                throw new UserException(ExitCodes.NO_USER, ""User ["" + username + ""] doesn't exist"");
            }
            final Hasher hasher = Hasher.resolve(XPackSettings.PASSWORD_HASHING_ALGORITHM.get(env.settings()));
            users.put(username, hasher.hash(new SecureString(password)));
            FileUserPasswdStore.writeFile(users, file);

            attributesChecker.check(terminal);
        }","protected void execute(Terminal terminal, OptionSet options, Environment env) throws Exception {

            String username = parseUsername(arguments.values(options), env.settings());
            char[] password = parsePassword(terminal, passwordOption.value(options));

            Path file = FileUserPasswdStore.resolveFile(env);
            FileAttributesChecker attributesChecker = new FileAttributesChecker(file);
            Map<String, char[]> users = FileUserPasswdStore.parseFile(file, null, env.settings());
            if (users == null) {
                throw new UserException(ExitCodes.CONFIG, ""Configuration file ["" + file + ""] is missing"");
            }
            if (users.containsKey(username) == false) {
                throw new UserException(ExitCodes.NO_USER, ""User ["" + username + ""] doesn't exist"");
            }
            final Hasher hasher = Hasher.resolve(XPackSettings.PASSWORD_HASHING_ALGORITHM.get(env.settings()));
            users = new HashMap<>(users); // make modifiable
            users.put(username, hasher.hash(new SecureString(password)));
            FileUserPasswdStore.writeFile(users, file);

            attributesChecker.check(terminal);
        }",/x-pack/plugin/security/src/main/java/org/elasticsearch/xpack/security/authc/file/tool/UsersTool.java
c536a42c4e925ab2504aa58a2b2c73343d196b79,563,469,"public void testErrorRecordingOnRetention() throws Exception {
        // starting with a lifecycle without retention so we can rollover the data stream and manipulate the second generation index such
        // that its retention execution fails
        DataStreamLifecycle lifecycle = new DataStreamLifecycle();

        /*
         * We set index.auto_expand_replicas to 0-1 so that if we get a single-node cluster it is not yellow. The cluster being yellow
         * could result in data stream lifecycle's automatic forcemerge failing, which would result in an unexpected error in the error
         * store.
         */
        putComposableIndexTemplate(
            ""id1"",
            null,
            List.of(""metrics-foo*""),
            Settings.builder().put(IndexMetadata.SETTING_AUTO_EXPAND_REPLICAS, ""0-1"").build(),
            null,
            lifecycle
        );
        Iterable<DataStreamLifecycleService> dataLifecycleServices = internalCluster().getInstances(DataStreamLifecycleService.class);

        String dataStreamName = ""metrics-foo"";
        CreateDataStreamAction.Request createDataStreamRequest = new CreateDataStreamAction.Request(dataStreamName);
        client().execute(CreateDataStreamAction.INSTANCE, createDataStreamRequest).get();
        indexDocs(dataStreamName, 1);

        // let's allow one rollover to go through
        assertBusy(() -> {
            GetDataStreamAction.Request getDataStreamRequest = new GetDataStreamAction.Request(new String[] { dataStreamName });
            GetDataStreamAction.Response getDataStreamResponse = client().execute(GetDataStreamAction.INSTANCE, getDataStreamRequest)
                .actionGet();
            assertThat(getDataStreamResponse.getDataStreams().size(), equalTo(1));
            assertThat(getDataStreamResponse.getDataStreams().get(0).getDataStream().getName(), equalTo(dataStreamName));
            List<Index> backingIndices = getDataStreamResponse.getDataStreams().get(0).getDataStream().getIndices();
            assertThat(backingIndices.size(), equalTo(2));
            String backingIndex = backingIndices.get(0).getName();
            assertThat(backingIndex, backingIndexEqualTo(dataStreamName, 1));
            String writeIndex = backingIndices.get(1).getName();
            assertThat(writeIndex, backingIndexEqualTo(dataStreamName, 2));
        });

        String firstGenerationIndex = getBackingIndices(dataStreamName).get(0);

        // mark the first generation index as read-only so deletion fails when we enable the retention configuration
        updateIndexSettings(Settings.builder().put(READ_ONLY.settingName(), true), firstGenerationIndex);
        try {
            updateLifecycle(dataStreamName, TimeValue.timeValueSeconds(1));

            assertBusy(() -> {
                GetDataStreamAction.Request getDataStreamRequest = new GetDataStreamAction.Request(new String[] { dataStreamName });
                GetDataStreamAction.Response getDataStreamResponse = client().execute(GetDataStreamAction.INSTANCE, getDataStreamRequest)
                    .actionGet();
                assertThat(getDataStreamResponse.getDataStreams().size(), equalTo(1));
                assertThat(getDataStreamResponse.getDataStreams().get(0).getDataStream().getName(), equalTo(dataStreamName));
                List<Index> backingIndices = getDataStreamResponse.getDataStreams().get(0).getDataStream().getIndices();
                assertThat(backingIndices.size(), equalTo(2));
                String writeIndex = backingIndices.get(1).getName();
                assertThat(writeIndex, backingIndexEqualTo(dataStreamName, 2));

                String recordedRetentionExecutionError = null;
                Iterable<DataStreamLifecycleService> lifecycleServices = internalCluster().getInstances(DataStreamLifecycleService.class);

                for (DataStreamLifecycleService lifecycleService : lifecycleServices) {
                    recordedRetentionExecutionError = lifecycleService.getErrorStore().getError(firstGenerationIndex);
                    if (recordedRetentionExecutionError != null) {
                        break;
                    }
                }

                assertThat(recordedRetentionExecutionError, is(notNullValue()));
                assertThat(recordedRetentionExecutionError, containsString(""blocked by: [FORBIDDEN/5/index read-only (api)""));
            });

            // let's mark the index as writeable and make sure it's deleted and the error store is empty
            updateIndexSettings(Settings.builder().put(READ_ONLY.settingName(), false), firstGenerationIndex);

            assertBusy(() -> {
                GetDataStreamAction.Request getDataStreamRequest = new GetDataStreamAction.Request(new String[] { dataStreamName });
                GetDataStreamAction.Response getDataStreamResponse = client().execute(GetDataStreamAction.INSTANCE, getDataStreamRequest)
                    .actionGet();
                assertThat(getDataStreamResponse.getDataStreams().size(), equalTo(1));
                assertThat(getDataStreamResponse.getDataStreams().get(0).getDataStream().getName(), equalTo(dataStreamName));
                List<Index> backingIndices = getDataStreamResponse.getDataStreams().get(0).getDataStream().getIndices();
                // data stream only has one index now
                assertThat(backingIndices.size(), equalTo(1));

                // error stores don't contain anything for the first generation index anymore
                Iterable<DataStreamLifecycleService> lifecycleServices = internalCluster().getInstances(DataStreamLifecycleService.class);
                for (DataStreamLifecycleService lifecycleService : lifecycleServices) {
                    assertThat(lifecycleService.getErrorStore().getError(firstGenerationIndex), nullValue());
                }
            });
        } finally {
            // when the test executes successfully this will not be needed however, otherwise we need to make sure the index is
            // ""delete-able"" for test cleanup
            try {
                updateIndexSettings(Settings.builder().put(READ_ONLY.settingName(), false), firstGenerationIndex);
            } catch (Exception e) {
                // index would be deleted if the test is successful
            }
        }
    }","public void testErrorRecordingOnRetention() throws Exception {
        // starting with a lifecycle without retention so we can rollover the data stream and manipulate the second generation index such
        // that its retention execution fails
        DataStreamLifecycle lifecycle = new DataStreamLifecycle();

        /*
         * We set index.auto_expand_replicas to 0-1 so that if we get a single-node cluster it is not yellow. The cluster being yellow
         * could result in data stream lifecycle's automatic forcemerge failing, which would result in an unexpected error in the error
         * store.
         */
        putComposableIndexTemplate(
            ""id1"",
            null,
            List.of(""metrics-foo*""),
            Settings.builder().put(IndexMetadata.SETTING_AUTO_EXPAND_REPLICAS, ""0-1"").build(),
            null,
            lifecycle
        );

        String dataStreamName = ""metrics-foo"";
        CreateDataStreamAction.Request createDataStreamRequest = new CreateDataStreamAction.Request(dataStreamName);
        client().execute(CreateDataStreamAction.INSTANCE, createDataStreamRequest).get();
        indexDocs(dataStreamName, 1);

        // let's allow one rollover to go through
        assertBusy(() -> {
            GetDataStreamAction.Request getDataStreamRequest = new GetDataStreamAction.Request(new String[] { dataStreamName });
            GetDataStreamAction.Response getDataStreamResponse = client().execute(GetDataStreamAction.INSTANCE, getDataStreamRequest)
                .actionGet();
            assertThat(getDataStreamResponse.getDataStreams().size(), equalTo(1));
            assertThat(getDataStreamResponse.getDataStreams().get(0).getDataStream().getName(), equalTo(dataStreamName));
            List<Index> backingIndices = getDataStreamResponse.getDataStreams().get(0).getDataStream().getIndices();
            assertThat(backingIndices.size(), equalTo(2));
            String backingIndex = backingIndices.get(0).getName();
            assertThat(backingIndex, backingIndexEqualTo(dataStreamName, 1));
            String writeIndex = backingIndices.get(1).getName();
            assertThat(writeIndex, backingIndexEqualTo(dataStreamName, 2));
        });

        String firstGenerationIndex = getBackingIndices(dataStreamName).get(0);

        // mark the first generation index as read-only so deletion fails when we enable the retention configuration
        updateIndexSettings(Settings.builder().put(READ_ONLY.settingName(), true), firstGenerationIndex);
        try {
            updateLifecycle(dataStreamName, TimeValue.timeValueSeconds(1));

            assertBusy(() -> {
                GetDataStreamAction.Request getDataStreamRequest = new GetDataStreamAction.Request(new String[] { dataStreamName });
                GetDataStreamAction.Response getDataStreamResponse = client().execute(GetDataStreamAction.INSTANCE, getDataStreamRequest)
                    .actionGet();
                assertThat(getDataStreamResponse.getDataStreams().size(), equalTo(1));
                assertThat(getDataStreamResponse.getDataStreams().get(0).getDataStream().getName(), equalTo(dataStreamName));
                List<Index> backingIndices = getDataStreamResponse.getDataStreams().get(0).getDataStream().getIndices();
                assertThat(backingIndices.size(), equalTo(2));
                String writeIndex = backingIndices.get(1).getName();
                assertThat(writeIndex, backingIndexEqualTo(dataStreamName, 2));

                String recordedRetentionExecutionError = null;
                Iterable<DataStreamLifecycleService> lifecycleServices = internalCluster().getInstances(DataStreamLifecycleService.class);

                for (DataStreamLifecycleService lifecycleService : lifecycleServices) {
                    recordedRetentionExecutionError = lifecycleService.getErrorStore().getError(firstGenerationIndex);
                    if (recordedRetentionExecutionError != null) {
                        break;
                    }
                }

                assertThat(recordedRetentionExecutionError, is(notNullValue()));
                assertThat(recordedRetentionExecutionError, containsString(""blocked by: [FORBIDDEN/5/index read-only (api)""));
            });

            // let's mark the index as writeable and make sure it's deleted and the error store is empty
            updateIndexSettings(Settings.builder().put(READ_ONLY.settingName(), false), firstGenerationIndex);

            assertBusy(() -> {
                GetDataStreamAction.Request getDataStreamRequest = new GetDataStreamAction.Request(new String[] { dataStreamName });
                GetDataStreamAction.Response getDataStreamResponse = client().execute(GetDataStreamAction.INSTANCE, getDataStreamRequest)
                    .actionGet();
                assertThat(getDataStreamResponse.getDataStreams().size(), equalTo(1));
                assertThat(getDataStreamResponse.getDataStreams().get(0).getDataStream().getName(), equalTo(dataStreamName));
                List<Index> backingIndices = getDataStreamResponse.getDataStreams().get(0).getDataStream().getIndices();
                // data stream only has one index now
                assertThat(backingIndices.size(), equalTo(1));

                // error stores don't contain anything for the first generation index anymore
                Iterable<DataStreamLifecycleService> lifecycleServices = internalCluster().getInstances(DataStreamLifecycleService.class);
                for (DataStreamLifecycleService lifecycleService : lifecycleServices) {
                    assertThat(lifecycleService.getErrorStore().getError(firstGenerationIndex), nullValue());
                }
            });
        } finally {
            // when the test executes successfully this will not be needed however, otherwise we need to make sure the index is
            // ""delete-able"" for test cleanup
            try {
                updateIndexSettings(Settings.builder().put(READ_ONLY.settingName(), false), firstGenerationIndex);
            } catch (Exception e) {
                // index would be deleted if the test is successful
            }
        }
    }",/modules/data-streams/src/internalClusterTest/java/org/elasticsearch/datastreams/lifecycle/DataStreamLifecycleServiceIT.java
c536a42c4e925ab2504aa58a2b2c73343d196b79,563,386,"public void testErrorRecordingOnRollover() throws Exception {
        // empty lifecycle contains the default rollover
        DataStreamLifecycle lifecycle = new DataStreamLifecycle();
        /*
         * We set index.auto_expand_replicas to 0-1 so that if we get a single-node cluster it is not yellow. The cluster being yellow
         * could result in data stream lifecycle's automatic forcemerge failing, which would result in an unexpected error in the error
         * store.
         */
        putComposableIndexTemplate(
            ""id1"",
            null,
            List.of(""metrics-foo*""),
            Settings.builder().put(IndexMetadata.SETTING_AUTO_EXPAND_REPLICAS, ""0-1"").build(),
            null,
            lifecycle
        );
        Iterable<DataStreamLifecycleService> dataLifecycleServices = internalCluster().getInstances(DataStreamLifecycleService.class);

        String dataStreamName = ""metrics-foo"";
        CreateDataStreamAction.Request createDataStreamRequest = new CreateDataStreamAction.Request(dataStreamName);
        client().execute(CreateDataStreamAction.INSTANCE, createDataStreamRequest).get();

        indexDocs(dataStreamName, 1);

        // let's allow one rollover to go through
        assertBusy(() -> {
            GetDataStreamAction.Request getDataStreamRequest = new GetDataStreamAction.Request(new String[] { dataStreamName });
            GetDataStreamAction.Response getDataStreamResponse = client().execute(GetDataStreamAction.INSTANCE, getDataStreamRequest)
                .actionGet();
            assertThat(getDataStreamResponse.getDataStreams().size(), equalTo(1));
            assertThat(getDataStreamResponse.getDataStreams().get(0).getDataStream().getName(), equalTo(dataStreamName));
            List<Index> backingIndices = getDataStreamResponse.getDataStreams().get(0).getDataStream().getIndices();
            assertThat(backingIndices.size(), equalTo(2));
            String backingIndex = backingIndices.get(0).getName();
            assertThat(backingIndex, backingIndexEqualTo(dataStreamName, 1));
            String writeIndex = backingIndices.get(1).getName();
            assertThat(writeIndex, backingIndexEqualTo(dataStreamName, 2));
        });

        // prevent new indices from being created (ie. future rollovers)
        updateClusterSettings(Settings.builder().put(SETTING_CLUSTER_MAX_SHARDS_PER_NODE.getKey(), 1));

        indexDocs(dataStreamName, 1);

        assertBusy(() -> {
            String writeIndexName = getBackingIndices(dataStreamName).get(1);
            String writeIndexRolloverError = null;
            Iterable<DataStreamLifecycleService> lifecycleServices = internalCluster().getInstances(DataStreamLifecycleService.class);

            for (DataStreamLifecycleService lifecycleService : lifecycleServices) {
                writeIndexRolloverError = lifecycleService.getErrorStore().getError(writeIndexName);
                if (writeIndexRolloverError != null) {
                    break;
                }
            }

            assertThat(writeIndexRolloverError, is(notNullValue()));
            assertThat(writeIndexRolloverError, containsString(""maximum normal shards open""));
        });

        // let's reset the cluster max shards per node limit to allow rollover to proceed and check the error store is empty
        updateClusterSettings(Settings.builder().putNull(""*""));

        assertBusy(() -> {
            List<String> backingIndices = getBackingIndices(dataStreamName);
            assertThat(backingIndices.size(), equalTo(3));
            String writeIndex = backingIndices.get(2);
            // rollover was successful and we got to generation 3
            assertThat(writeIndex, backingIndexEqualTo(dataStreamName, 3));

            // we recorded the error against the previous write index (generation 2)
            // let's check there's no error recorded against it anymore
            String previousWriteInddex = backingIndices.get(1);
            Iterable<DataStreamLifecycleService> lifecycleServices = internalCluster().getInstances(DataStreamLifecycleService.class);

            for (DataStreamLifecycleService lifecycleService : lifecycleServices) {
                assertThat(lifecycleService.getErrorStore().getError(previousWriteInddex), nullValue());
            }
        });
    }","public void testErrorRecordingOnRollover() throws Exception {
        // empty lifecycle contains the default rollover
        DataStreamLifecycle lifecycle = new DataStreamLifecycle();
        /*
         * We set index.auto_expand_replicas to 0-1 so that if we get a single-node cluster it is not yellow. The cluster being yellow
         * could result in data stream lifecycle's automatic forcemerge failing, which would result in an unexpected error in the error
         * store.
         */
        putComposableIndexTemplate(
            ""id1"",
            null,
            List.of(""metrics-foo*""),
            Settings.builder().put(IndexMetadata.SETTING_AUTO_EXPAND_REPLICAS, ""0-1"").build(),
            null,
            lifecycle
        );

        String dataStreamName = ""metrics-foo"";
        CreateDataStreamAction.Request createDataStreamRequest = new CreateDataStreamAction.Request(dataStreamName);
        client().execute(CreateDataStreamAction.INSTANCE, createDataStreamRequest).get();

        indexDocs(dataStreamName, 1);

        // let's allow one rollover to go through
        assertBusy(() -> {
            GetDataStreamAction.Request getDataStreamRequest = new GetDataStreamAction.Request(new String[] { dataStreamName });
            GetDataStreamAction.Response getDataStreamResponse = client().execute(GetDataStreamAction.INSTANCE, getDataStreamRequest)
                .actionGet();
            assertThat(getDataStreamResponse.getDataStreams().size(), equalTo(1));
            assertThat(getDataStreamResponse.getDataStreams().get(0).getDataStream().getName(), equalTo(dataStreamName));
            List<Index> backingIndices = getDataStreamResponse.getDataStreams().get(0).getDataStream().getIndices();
            assertThat(backingIndices.size(), equalTo(2));
            String backingIndex = backingIndices.get(0).getName();
            assertThat(backingIndex, backingIndexEqualTo(dataStreamName, 1));
            String writeIndex = backingIndices.get(1).getName();
            assertThat(writeIndex, backingIndexEqualTo(dataStreamName, 2));
        });

        // prevent new indices from being created (ie. future rollovers)
        updateClusterSettings(Settings.builder().put(SETTING_CLUSTER_MAX_SHARDS_PER_NODE.getKey(), 1));

        indexDocs(dataStreamName, 1);

        assertBusy(() -> {
            String writeIndexName = getBackingIndices(dataStreamName).get(1);
            String writeIndexRolloverError = null;
            Iterable<DataStreamLifecycleService> lifecycleServices = internalCluster().getInstances(DataStreamLifecycleService.class);

            for (DataStreamLifecycleService lifecycleService : lifecycleServices) {
                writeIndexRolloverError = lifecycleService.getErrorStore().getError(writeIndexName);
                if (writeIndexRolloverError != null) {
                    break;
                }
            }

            assertThat(writeIndexRolloverError, is(notNullValue()));
            assertThat(writeIndexRolloverError, containsString(""maximum normal shards open""));
        });

        // let's reset the cluster max shards per node limit to allow rollover to proceed and check the error store is empty
        updateClusterSettings(Settings.builder().putNull(""*""));

        assertBusy(() -> {
            List<String> backingIndices = getBackingIndices(dataStreamName);
            assertThat(backingIndices.size(), equalTo(3));
            String writeIndex = backingIndices.get(2);
            // rollover was successful and we got to generation 3
            assertThat(writeIndex, backingIndexEqualTo(dataStreamName, 3));

            // we recorded the error against the previous write index (generation 2)
            // let's check there's no error recorded against it anymore
            String previousWriteInddex = backingIndices.get(1);
            Iterable<DataStreamLifecycleService> lifecycleServices = internalCluster().getInstances(DataStreamLifecycleService.class);

            for (DataStreamLifecycleService lifecycleService : lifecycleServices) {
                assertThat(lifecycleService.getErrorStore().getError(previousWriteInddex), nullValue());
            }
        });
    }",/modules/data-streams/src/internalClusterTest/java/org/elasticsearch/datastreams/lifecycle/DataStreamLifecycleServiceIT.java
5caec66ff87b85397c49bedd1bbf6d26e6ba3bdb,686,334,"public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {
        if (isMaster == false) {
            throw new IllegalArgumentException(""request for scaling information is only allowed on the master node"");
        }
        final Duration memoryTrackingStale;
        long previousTimeStamp = this.lastTimeToScale;
        this.lastTimeToScale = this.timeSupplier.get();
        if (previousTimeStamp == 0L) {
            memoryTrackingStale = DEFAULT_MEMORY_REFRESH_RATE;
        } else {
            memoryTrackingStale = Duration.ofMillis(TimeValue.timeValueMinutes(1).millis() + this.lastTimeToScale - previousTimeStamp);
        }

        final ClusterState clusterState = context.state();

        PersistentTasksCustomMetadata tasks = clusterState.getMetadata().custom(PersistentTasksCustomMetadata.TYPE);
        Collection<PersistentTask<?>> anomalyDetectionTasks = anomalyDetectionTasks(tasks);
        Collection<PersistentTask<?>> dataframeAnalyticsTasks = dataframeAnalyticsTasks(tasks);
        final List<DiscoveryNode> nodes = getNodes(clusterState);
        Optional<NativeMemoryCapacity> futureFreedCapacity = calculateFutureAvailableCapacity(
            tasks,
            memoryTrackingStale,
            nodes,
            clusterState
        );

        final List<String> waitingAnomalyJobs = anomalyDetectionTasks.stream()
            .filter(t -> AWAITING_LAZY_ASSIGNMENT.equals(t.getAssignment()))
            .map(t -> MlTasks.jobId(t.getId()))
            .collect(Collectors.toList());
        final List<String> waitingAnalyticsJobs = dataframeAnalyticsTasks.stream()
            .filter(t -> AWAITING_LAZY_ASSIGNMENT.equals(t.getAssignment()))
            .map(t -> MlTasks.dataFrameAnalyticsId(t.getId()))
            .collect(Collectors.toList());

        final NativeMemoryCapacity currentScale = currentScale(nodes);
        final MlScalingReason.Builder reasonBuilder = MlScalingReason.builder()
            .setWaitingAnomalyJobs(waitingAnomalyJobs)
            .setWaitingAnalyticsJobs(waitingAnalyticsJobs)
            .setCurrentMlCapacity(currentScale.autoscalingCapacity(maxMachineMemoryPercent, useAuto))
            .setPassedConfiguration(configuration);

        final Optional<AutoscalingDeciderResult> scaleUpDecision = checkForScaleUp(
            NUM_ANOMALY_JOBS_IN_QUEUE.get(configuration),
            NUM_ANALYTICS_JOBS_IN_QUEUE.get(configuration),
            waitingAnomalyJobs,
            waitingAnalyticsJobs,
            futureFreedCapacity.orElse(null),
            currentScale,
            reasonBuilder
        );

        if (scaleUpDecision.isPresent()) {
            resetScaleDownCoolDown();
            return scaleUpDecision.get();
        }
        if (waitingAnalyticsJobs.isEmpty() == false || waitingAnomalyJobs.isEmpty() == false) {
            // We don't want to continue to consider a scale down if there are now waiting jobs
            resetScaleDownCoolDown();
            return noScaleResultOrRefresh(reasonBuilder, memoryTrackingStale, new AutoscalingDeciderResult(
                context.currentCapacity(),
                reasonBuilder
                    .setSimpleReason(
                        String.format(
                            Locale.ROOT,
                            ""Passing currently perceived capacity as there are [%d] analytics and [%d] anomaly jobs in the queue, ""
                                + ""but the number in the queue is less than the configured maximum allowed. ""
                                + ""[%d] for analytics and [%d] for anomaly jobs"",
                            waitingAnalyticsJobs.size(),
                            waitingAnomalyJobs.size(),
                            NUM_ANALYTICS_JOBS_IN_QUEUE.get(configuration),
                            NUM_ANOMALY_JOBS_IN_QUEUE.get(configuration)
                        )
                    )
                    .build()));
        }
        if (mlMemoryTracker.isRecentlyRefreshed(memoryTrackingStale) == false) {
            logger.debug(() -> new ParameterizedMessage(
                ""view of job memory is stale given duration [{}]. Not attempting to scale down"",
                memoryTrackingStale));
            return buildDecisionAndRequestRefresh(reasonBuilder);
        }

        long largestJob = Math.max(
            anomalyDetectionTasks.stream()
                .filter(PersistentTask::isAssigned)
                // Memory SHOULD be recently refreshed, so in our current state, we should at least have an idea of the memory used
                .mapToLong(t -> {
                    Long mem = this.getAnomalyMemoryRequirement(t);
                    assert mem != null : ""unexpected null for anomaly memory requirement after recent stale check"";
                    return mem;
                })
                .max()
                .orElse(0L),
            dataframeAnalyticsTasks.stream()
                .filter(PersistentTask::isAssigned)
                // Memory SHOULD be recently refreshed, so in our current state, we should at least have an idea of the memory used
                .mapToLong(t -> {
                    Long mem = this.getAnalyticsMemoryRequirement(t);
                    assert mem != null : ""unexpected null for analytics memory requirement after recent stale check"";
                    return mem;
                })
                .max()
                .orElse(0L));

        // This is an exceptionally weird state
        // Our view of the memory is stale or we have tasks where the required job memory is 0, which should be impossible
        if (largestJob == 0L && ((dataframeAnalyticsTasks.isEmpty() || anomalyDetectionTasks.isEmpty()) == false)) {
            logger.warn(
                ""The calculated minimum required node size was unexpectedly [0] as there are ""
                    + ""[{}] anomaly job tasks and [{}] data frame analytics tasks"",
                anomalyDetectionTasks.size(),
                dataframeAnalyticsTasks.size()
            );
            return noScaleResultOrRefresh(reasonBuilder, memoryTrackingStale, new AutoscalingDeciderResult(
                context.currentCapacity(),
                reasonBuilder
                    .setSimpleReason(""Passing currently perceived capacity as there are running analytics and anomaly jobs, "" +
                        ""but their memory usage estimates are inaccurate."")
                    .build()));
        }

        final Optional<AutoscalingDeciderResult> scaleDownDecision =
            checkForScaleDown(nodes, clusterState, largestJob, currentScale, reasonBuilder);

        if (scaleDownDecision.isPresent()) {
            final long now = timeSupplier.get();
            if (newScaleDownCheck()) {
                scaleDownDetected = now;
            }
            TimeValue downScaleDelay = DOWN_SCALE_DELAY.get(configuration);
            long msLeftToScale = downScaleDelay.millis() - (now - scaleDownDetected);
            if (msLeftToScale <= 0) {
                return scaleDownDecision.get();
            }
            logger.debug(() -> new ParameterizedMessage(
                ""not scaling down as the current scale down delay [{}] is not satisfied."" +
                    "" The last time scale down was detected [{}]. Calculated scaled down capacity [{}] "",
                downScaleDelay.getStringRep(),
                XContentElasticsearchExtension.DEFAULT_DATE_PRINTER.print(scaleDownDetected),
                scaleDownDecision.get().requiredCapacity()));
            return new AutoscalingDeciderResult(
                context.currentCapacity(),
                reasonBuilder
                    .setSimpleReason(
                        String.format(
                            Locale.ROOT,
                            ""Passing currently perceived capacity as down scale delay has not be satisfied; configured delay [%s]""
                                + ""last detected scale down event [%s]. Will request scale down in approximately [%s]"",
                            downScaleDelay.getStringRep(),
                            XContentElasticsearchExtension.DEFAULT_DATE_PRINTER.print(scaleDownDetected),
                            TimeValue.timeValueMillis(msLeftToScale).getStringRep()
                        )
                    )
                    .build());
        }

        return noScaleResultOrRefresh(reasonBuilder, memoryTrackingStale, new AutoscalingDeciderResult(context.currentCapacity(),
            reasonBuilder
                .setSimpleReason(""Passing currently perceived capacity as no scaling changes were detected to be possible"")
                .build()));
    }","public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {
        if (isMaster == false) {
            throw new IllegalArgumentException(""request for scaling information is only allowed on the master node"");
        }
        final Duration memoryTrackingStale;
        long previousTimeStamp = this.lastTimeToScale;
        this.lastTimeToScale = this.timeSupplier.get();
        if (previousTimeStamp == 0L) {
            memoryTrackingStale = DEFAULT_MEMORY_REFRESH_RATE;
        } else {
            memoryTrackingStale = Duration.ofMillis(TimeValue.timeValueMinutes(1).millis() + this.lastTimeToScale - previousTimeStamp);
        }

        final ClusterState clusterState = context.state();

        PersistentTasksCustomMetadata tasks = clusterState.getMetadata().custom(PersistentTasksCustomMetadata.TYPE);
        Collection<PersistentTask<?>> anomalyDetectionTasks = anomalyDetectionTasks(tasks);
        Collection<PersistentTask<?>> dataframeAnalyticsTasks = dataframeAnalyticsTasks(tasks);
        final List<String> waitingAnomalyJobs = anomalyDetectionTasks.stream()
            .filter(t -> AWAITING_LAZY_ASSIGNMENT.equals(t.getAssignment()))
            .map(t -> MlTasks.jobId(t.getId()))
            .collect(Collectors.toList());
        final List<String> waitingAnalyticsJobs = dataframeAnalyticsTasks.stream()
            .filter(t -> AWAITING_LAZY_ASSIGNMENT.equals(t.getAssignment()))
            .map(t -> MlTasks.dataFrameAnalyticsId(t.getId()))
            .collect(Collectors.toList());

        final int numAnalyticsJobsInQueue = NUM_ANALYTICS_JOBS_IN_QUEUE.get(configuration);
        final int numAnomalyJobsInQueue = NUM_ANOMALY_JOBS_IN_QUEUE.get(configuration);

        final List<DiscoveryNode> nodes = getNodes(clusterState);
        final NativeMemoryCapacity currentScale = currentScale(nodes);
        final MlScalingReason.Builder reasonBuilder = MlScalingReason.builder()
            .setWaitingAnomalyJobs(waitingAnomalyJobs)
            .setWaitingAnalyticsJobs(waitingAnalyticsJobs)
            .setCurrentMlCapacity(currentScale.autoscalingCapacity(maxMachineMemoryPercent, useAuto))
            .setPassedConfiguration(configuration);

        // There are no ML nodes, scale up as quick as possible, no matter if memory is stale or not
        if (nodes.isEmpty()
            && (waitingAnomalyJobs.isEmpty() == false
            || waitingAnalyticsJobs.isEmpty() == false)) {
            return scaleUpFromZero(waitingAnomalyJobs, waitingAnalyticsJobs, reasonBuilder);
        }

        if (mlMemoryTracker.isRecentlyRefreshed(memoryTrackingStale) == false) {
            logger.debug(() -> new ParameterizedMessage(
                ""view of job memory is stale given duration [{}]. Not attempting to make scaling decision"",
                memoryTrackingStale));
            return buildDecisionAndRequestRefresh(reasonBuilder);
        }
        // We need the current node loads to determine if we need to scale up or down
        List<NodeLoad> nodeLoads = new ArrayList<>(nodes.size());
        boolean nodeIsMemoryAccurate = true;
        for (DiscoveryNode node : nodes) {
            NodeLoad nodeLoad = nodeLoadDetector.detectNodeLoad(clusterState,
                true,
                node,
                maxOpenJobs,
                maxMachineMemoryPercent,
                true,
                useAuto);
            if (nodeLoad.getError() != null) {
                logger.warn(""[{}] failed to gather node load limits, failure [{}]. Returning no scale"",
                    node.getId(),
                    nodeLoad.getError());
                return noScaleResultOrRefresh(reasonBuilder, true, new AutoscalingDeciderResult(context.currentCapacity(),
                    reasonBuilder
                        .setSimpleReason(
                            ""Passing currently perceived capacity as there was a failure gathering node limits [""
                                + nodeLoad.getError()
                                + ""]""
                        )
                        .build()));
            }
            nodeLoads.add(nodeLoad);
            nodeIsMemoryAccurate = nodeIsMemoryAccurate && nodeLoad.isUseMemory();
        }
        // This is an exceptional case, the memory tracking became stale between us checking previously and calculating the loads
        // We should return a no scale in this case
        if (nodeIsMemoryAccurate == false) {
            return noScaleResultOrRefresh(reasonBuilder, true, new AutoscalingDeciderResult(context.currentCapacity(),
                reasonBuilder
                    .setSimpleReason(
                        ""Passing currently perceived capacity as nodes were unable to provide an accurate view of their memory usage""
                    )
                    .build()));
        }

        Optional<NativeMemoryCapacity> futureFreedCapacity = calculateFutureAvailableCapacity(
            tasks,
            memoryTrackingStale,
            nodes,
            clusterState
        );

        final Optional<AutoscalingDeciderResult> scaleUpDecision = checkForScaleUp(
            numAnomalyJobsInQueue,
            numAnalyticsJobsInQueue,
            nodeLoads,
            waitingAnomalyJobs,
            waitingAnalyticsJobs,
            futureFreedCapacity.orElse(null),
            currentScale,
            reasonBuilder
        );

        if (scaleUpDecision.isPresent()) {
            resetScaleDownCoolDown();
            return scaleUpDecision.get();
        }
        if (waitingAnalyticsJobs.isEmpty() == false || waitingAnomalyJobs.isEmpty() == false) {
            // We don't want to continue to consider a scale down if there are now waiting jobs
            resetScaleDownCoolDown();
            return noScaleResultOrRefresh(reasonBuilder,
                mlMemoryTracker.isRecentlyRefreshed(memoryTrackingStale) == false,
                new AutoscalingDeciderResult(
                    context.currentCapacity(),
                    reasonBuilder
                        .setSimpleReason(
                            String.format(
                                Locale.ROOT,
                                ""Passing currently perceived capacity as there are [%d] analytics and [%d] anomaly jobs in the queue, ""
                                    + ""but the number in the queue is less than the configured maximum allowed ""
                                    + "" or the queued jobs will eventually be assignable at the current size. "",
                                waitingAnalyticsJobs.size(),
                                waitingAnomalyJobs.size()
                        )
                    )
                    .build()));
        }

        long largestJob = Math.max(
            anomalyDetectionTasks.stream()
                .filter(PersistentTask::isAssigned)
                // Memory SHOULD be recently refreshed, so in our current state, we should at least have an idea of the memory used
                .mapToLong(t -> {
                    Long mem = this.getAnomalyMemoryRequirement(t);
                    assert mem != null : ""unexpected null for anomaly memory requirement after recent stale check"";
                    return mem;
                })
                .max()
                .orElse(0L),
            dataframeAnalyticsTasks.stream()
                .filter(PersistentTask::isAssigned)
                // Memory SHOULD be recently refreshed, so in our current state, we should at least have an idea of the memory used
                .mapToLong(t -> {
                    Long mem = this.getAnalyticsMemoryRequirement(t);
                    assert mem != null : ""unexpected null for analytics memory requirement after recent stale check"";
                    return mem;
                })
                .max()
                .orElse(0L));

        // This is an exceptionally weird state
        // Our view of the memory is stale or we have tasks where the required job memory is 0, which should be impossible
        if (largestJob == 0L && ((dataframeAnalyticsTasks.isEmpty() || anomalyDetectionTasks.isEmpty()) == false)) {
            logger.warn(
                ""The calculated minimum required node size was unexpectedly [0] as there are ""
                    + ""[{}] anomaly job tasks and [{}] data frame analytics tasks"",
                anomalyDetectionTasks.size(),
                dataframeAnalyticsTasks.size()
            );
            return noScaleResultOrRefresh(reasonBuilder, true, new AutoscalingDeciderResult(
                context.currentCapacity(),
                reasonBuilder
                    .setSimpleReason(""Passing currently perceived capacity as there are running analytics and anomaly jobs, "" +
                        ""but their memory usage estimates are inaccurate."")
                    .build()));
        }

        final Optional<AutoscalingDeciderResult> scaleDownDecision = checkForScaleDown(nodeLoads, largestJob, currentScale, reasonBuilder);

        if (scaleDownDecision.isPresent()) {
            // Given maxOpenJobs, could we scale down to just one node?
            // We have no way of saying ""we need X nodes""
            if (nodeLoads.size() > 1) {
                long totalAssignedJobs = nodeLoads.stream().mapToLong(NodeLoad::getNumAssignedJobs).sum();
                // one volatile read
                long maxOpenJobs = this.maxOpenJobs;
                if (totalAssignedJobs > maxOpenJobs) {
                    String msg = String.format(Locale.ROOT,
                        ""not scaling down as the total number of jobs [%d] exceeds the setting [%s (%d)]. ""
                            + "" To allow a scale down [%s] must be increased."",
                        totalAssignedJobs,
                        MAX_OPEN_JOBS_PER_NODE.getKey(),
                        maxOpenJobs,
                        MAX_OPEN_JOBS_PER_NODE.getKey());
                    logger.info(() -> new ParameterizedMessage(""{} Calculated potential scaled down capacity [{}] "",
                        msg,
                        scaleDownDecision.get().requiredCapacity()));
                    return new AutoscalingDeciderResult(context.currentCapacity(), reasonBuilder.setSimpleReason(msg).build());
                }
            }

            final long now = timeSupplier.get();
            if (newScaleDownCheck()) {
                scaleDownDetected = now;
            }
            TimeValue downScaleDelay = DOWN_SCALE_DELAY.get(configuration);
            long msLeftToScale = downScaleDelay.millis() - (now - scaleDownDetected);
            if (msLeftToScale <= 0) {
                return scaleDownDecision.get();
            }
            logger.debug(() -> new ParameterizedMessage(
                ""not scaling down as the current scale down delay [{}] is not satisfied."" +
                    "" The last time scale down was detected [{}]. Calculated scaled down capacity [{}] "",
                downScaleDelay.getStringRep(),
                XContentElasticsearchExtension.DEFAULT_DATE_PRINTER.print(scaleDownDetected),
                scaleDownDecision.get().requiredCapacity()));
            return new AutoscalingDeciderResult(
                context.currentCapacity(),
                reasonBuilder
                    .setSimpleReason(
                        String.format(
                            Locale.ROOT,
                            ""Passing currently perceived capacity as down scale delay has not be satisfied; configured delay [%s]""
                                + ""last detected scale down event [%s]. Will request scale down in approximately [%s]"",
                            downScaleDelay.getStringRep(),
                            XContentElasticsearchExtension.DEFAULT_DATE_PRINTER.print(scaleDownDetected),
                            TimeValue.timeValueMillis(msLeftToScale).getStringRep()
                        )
                    )
                    .build());
        }

        return noScaleResultOrRefresh(reasonBuilder,
            mlMemoryTracker.isRecentlyRefreshed(memoryTrackingStale) == false,
            new AutoscalingDeciderResult(context.currentCapacity(),
                reasonBuilder
                    .setSimpleReason(""Passing currently perceived capacity as no scaling changes were detected to be possible"")
                    .build()));
    }",/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/autoscaling/MlAutoscalingDeciderService.java
1f906804ffee9ca910467fa091154e6945703649,690,250,"public void ping(final PingListener listener, final TimeValue timeout) {
        if (!pingEnabled) {
            threadPool.generic().execute(new Runnable() {
                @Override
                public void run() {
                    listener.onPing(new PingResponse[0]);
                }
            });
            return;
        }
        final int id = pingIdGenerator.incrementAndGet();
        receivedResponses.put(id, ConcurrentCollections.<DiscoveryNode, PingResponse>newConcurrentMap());
        sendPingRequest(id);
        // try and send another ping request halfway through (just in case someone woke up during it...)
        // this can be a good trade-off to nailing the initial lookup or un-delivered messages
        threadPool.schedule(TimeValue.timeValueMillis(timeout.millis() / 2), ThreadPool.Names.GENERIC, new Runnable() {
            @Override
            public void run() {
                try {
                    sendPingRequest(id);
                } catch (Exception e) {
                    logger.warn(""[{}] failed to send second ping request"", e, id);
                }
            }
        });
        threadPool.schedule(timeout, ThreadPool.Names.GENERIC, new Runnable() {
            @Override
            public void run() {
                ConcurrentMap<DiscoveryNode, PingResponse> responses = receivedResponses.remove(id);
                listener.onPing(responses.values().toArray(new PingResponse[responses.size()]));
            }
        });
    }","public void ping(final PingListener listener, final TimeValue timeout) {
        if (!pingEnabled) {
            threadPool.generic().execute(new Runnable() {
                @Override
                public void run() {
                    listener.onPing(PingResponse.EMPTY);
                }
            });
            return;
        }
        final int id = pingIdGenerator.incrementAndGet();
        receivedResponses.put(id, ConcurrentCollections.<DiscoveryNode, PingResponse>newConcurrentMap());
        sendPingRequest(id);
        // try and send another ping request halfway through (just in case someone woke up during it...)
        // this can be a good trade-off to nailing the initial lookup or un-delivered messages
        threadPool.schedule(TimeValue.timeValueMillis(timeout.millis() / 2), ThreadPool.Names.GENERIC, new Runnable() {
            @Override
            public void run() {
                try {
                    sendPingRequest(id);
                } catch (Exception e) {
                    logger.warn(""[{}] failed to send second ping request"", e, id);
                }
            }
        });
        threadPool.schedule(timeout, ThreadPool.Names.GENERIC, new Runnable() {
            @Override
            public void run() {
                ConcurrentMap<DiscoveryNode, PingResponse> responses = receivedResponses.remove(id);
                listener.onPing(responses.values().toArray(new PingResponse[responses.size()]));
            }
        });
    }",/src/main/java/org/elasticsearch/discovery/zen/ping/multicast/MulticastZenPing.java
1f906804ffee9ca910467fa091154e6945703649,391,215,"public PingResponse[] pingAndWait(TimeValue timeout) {
        final AtomicReference<PingResponse[]> response = new AtomicReference<PingResponse[]>();
        final CountDownLatch latch = new CountDownLatch(1);
        ping(new PingListener() {
            @Override
            public void onPing(PingResponse[] pings) {
                response.set(pings);
                latch.countDown();
            }
        }, timeout);
        try {
            latch.await();
            return response.get();
        } catch (InterruptedException e) {
            return null;
        }
    }","public PingResponse[] pingAndWait(TimeValue timeout) {
        final AtomicReference<PingResponse[]> response = new AtomicReference<PingResponse[]>();
        final CountDownLatch latch = new CountDownLatch(1);
        try {
            ping(new PingListener() {
                @Override
                public void onPing(PingResponse[] pings) {
                    response.set(pings);
                    latch.countDown();
                }
            }, timeout);
        } catch (EsRejectedExecutionException ex) {
            logger.debug(""Ping execution rejected"", ex);
            return PingResponse.EMPTY;
        }
        try {
            latch.await();
            return response.get();
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            return PingResponse.EMPTY;
        }
    }",/src/main/java/org/elasticsearch/discovery/zen/ping/multicast/MulticastZenPing.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,321,"int numberOfReplicas) {
        MetaData.Builder metaDataBuilder = MetaData.builder();
        RoutingTable.Builder routingTableBuilder = RoutingTable.builder();

        for (int i = 0; i < numberOfIndices; i++) {
            IndexMetaData.Builder index = IndexMetaData.builder(""test"" + i).settings(settings(Version.CURRENT)).numberOfShards(numberOfShards).numberOfReplicas(
                    numberOfReplicas);
            metaDataBuilder = metaDataBuilder.put(index);
        }

        MetaData metaData = metaDataBuilder.build();

        for (ObjectCursor<IndexMetaData> cursor : metaData.indices().values()) {
            routingTableBuilder.addAsNew(cursor.value);
        }

        RoutingTable routingTable = routingTableBuilder.build();

        logger.info(""start {} nodes"", numberOfNodes);
        DiscoveryNodes.Builder nodes = DiscoveryNodes.builder();
        for (int i = 0; i < numberOfNodes; i++) {
            nodes.add(newNode(""node"" + i));
        }
        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).nodes(nodes).metaData(metaData).routingTable(routingTable).build();
        routingTable = service.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        RoutingNodes routingNodes = clusterState.getRoutingNodes();

        logger.info(""restart all the primary shards, replicas will start initializing"");
        routingNodes = clusterState.getRoutingNodes();
        routingTable = service.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        logger.info(""start the replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        routingTable = service.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        logger.info(""complete rebalancing"");
        RoutingTable prev = routingTable;
        while (true) {
            logger.debug(""ClusterState: {}"", clusterState.getRoutingNodes().prettyPrint());
            routingTable = service.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
            clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
            routingNodes = clusterState.getRoutingNodes();
            if (routingTable == prev)
                break;
            prev = routingTable;
        }

        return clusterState;
    }","int numberOfReplicas) {
        MetaData.Builder metaDataBuilder = MetaData.builder(clusterState.getMetaData());
        RoutingTable.Builder routingTableBuilder = RoutingTable.builder(clusterState.routingTable());

        IndexMetaData.Builder index = IndexMetaData.builder(""test"" + indexOrdinal).settings(settings(Version.CURRENT)).numberOfShards(numberOfShards).numberOfReplicas(
                numberOfReplicas);
        IndexMetaData imd = index.build();
        metaDataBuilder = metaDataBuilder.put(imd, true);
        routingTableBuilder.addAsNew(imd);

        MetaData metaData = metaDataBuilder.build();
        clusterState = ClusterState.builder(clusterState).metaData(metaData).routingTable(routingTableBuilder.build()).build();
        RoutingAllocation.Result routingResult = service.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""restart all the primary shards, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = service.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""start the replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = service.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""complete rebalancing"");
        return applyStartedShardsUntilNoChange(clusterState, service);
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AddIncrementallyTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,552,"public void testClusterAllActive3() {
        AllocationService strategy = createAllocationService(Settings.builder().put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(),
                ClusterRebalanceAllocationDecider.ClusterRebalanceType.INDICES_ALL_ACTIVE.toString()).build());

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .put(IndexMetaData.builder(""test2"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test1""))
                .addAsNew(metaData.index(""test2""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info(""start two nodes"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards for test1, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start the test1 replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards for test2, replicas will start initializing"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test2"", INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        logger.info(""now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode(""node3"")))
                .build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(routingNodes.node(""node3"").isEmpty(), equalTo(true));
    }","public void testClusterAllActive3() {
        AllocationService strategy = createAllocationService(Settings.builder().put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(),
                ClusterRebalanceAllocationDecider.ClusterRebalanceType.INDICES_ALL_ACTIVE.toString()).build());

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .put(IndexMetaData.builder(""test2"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test1""))
                .addAsNew(metaData.index(""test2""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        logger.info(""start two nodes"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards for test1, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start the test1 replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards for test2, replicas will start initializing"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test2"", INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        logger.info(""now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode(""node3"")))
                .build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(routingNodes.node(""node3"").isEmpty(), equalTo(true));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/ClusterRebalanceRoutingTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,121,"public void testRebalanceOnlyAfterAllShardsAreActive() {
        final long[] sizes = new long[5];
        for (int i =0; i < sizes.length; i++) {
            sizes[i] = randomIntBetween(0, Integer.MAX_VALUE);
        }

        AllocationService strategy = createAllocationService(Settings.builder()
                        .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                        .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                        .put(""cluster.routing.allocation.cluster_concurrent_rebalance"", -1)
                        .build(),
                new ClusterInfoService() {
                    @Override
                    public ClusterInfo getClusterInfo() {
                        return new ClusterInfo() {
                            @Override
                            public Long getShardSize(ShardRouting shardRouting) {
                                if (shardRouting.getIndexName().equals(""test"")) {
                                    return sizes[shardRouting.getId()];
                                }
                                return null;                    }
                        };
                    }

                    @Override
                    public void addListener(Listener listener) {
                    }
                });
        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(5).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        assertThat(routingTable.index(""test"").shards().size(), equalTo(5));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).shards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(routingTable.index(""test"").shard(i).shards().get(1).state(), equalTo(UNASSIGNED));
            assertThat(routingTable.index(""test"").shard(i).shards().get(0).currentNodeId(), nullValue());
            assertThat(routingTable.index(""test"").shard(i).shards().get(1).currentNodeId(), nullValue());
        }

        logger.info(""start two nodes and fully start the shards"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
            assertEquals(routingTable.index(""test"").shard(i).replicaShards().get(0).getExpectedShardSize(), sizes[i]);
        }

        logger.info(""now, start 8 more nodes, and check that no rebalancing/relocation have happened"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode(""node3"")).add(newNode(""node4"")).add(newNode(""node5"")).add(newNode(""node6"")).add(newNode(""node7"")).add(newNode(""node8"")).add(newNode(""node9"")).add(newNode(""node10"")))
                .build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
            assertEquals(routingTable.index(""test"").shard(i).replicaShards().get(0).getExpectedShardSize(), sizes[i]);

        }

        logger.info(""start the replica shards, rebalancing should start"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        // we only allow one relocation at a time
        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(5));
        assertThat(routingTable.shardsWithState(RELOCATING).size(), equalTo(5));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            int num = 0;
            for (ShardRouting routing : routingTable.index(""test"").shard(i).shards()) {
                if (routing.state() == RELOCATING || routing.state() == INITIALIZING) {
                    assertEquals(routing.getExpectedShardSize(), sizes[i]);
                    num++;
                }
            }
            assertTrue(num > 0);
        }

        logger.info(""complete relocation, other half of relocation should happen"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        // we now only relocate 3, since 2 remain where they are!
        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(7));
        assertThat(routingTable.shardsWithState(RELOCATING).size(), equalTo(3));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            for (ShardRouting routing : routingTable.index(""test"").shard(i).shards()) {
                if (routing.state() == RELOCATING || routing.state() == INITIALIZING) {
                    assertEquals(routing.getExpectedShardSize(), sizes[i]);
                }
            }
        }


        logger.info(""complete relocation, that's it!"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(10));
        // make sure we have an even relocation
        for (RoutingNode routingNode : routingNodes) {
            assertThat(routingNode.size(), equalTo(1));
        }
    }","public void testRebalanceOnlyAfterAllShardsAreActive() {
        final long[] sizes = new long[5];
        for (int i =0; i < sizes.length; i++) {
            sizes[i] = randomIntBetween(0, Integer.MAX_VALUE);
        }

        AllocationService strategy = createAllocationService(Settings.builder()
                        .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                        .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                        .put(""cluster.routing.allocation.cluster_concurrent_rebalance"", -1)
                        .build(),
                new ClusterInfoService() {
                    @Override
                    public ClusterInfo getClusterInfo() {
                        return new ClusterInfo() {
                            @Override
                            public Long getShardSize(ShardRouting shardRouting) {
                                if (shardRouting.getIndexName().equals(""test"")) {
                                    return sizes[shardRouting.getId()];
                                }
                                return null;                    }
                        };
                    }

                    @Override
                    public void addListener(Listener listener) {
                    }
                });
        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(5).numberOfReplicas(1))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(5));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(1).state(), equalTo(UNASSIGNED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(0).currentNodeId(), nullValue());
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(1).currentNodeId(), nullValue());
        }

        logger.info(""start two nodes and fully start the shards"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
            assertEquals(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).getExpectedShardSize(), sizes[i]);
        }

        logger.info(""now, start 8 more nodes, and check that no rebalancing/relocation have happened"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode(""node3"")).add(newNode(""node4"")).add(newNode(""node5"")).add(newNode(""node6"")).add(newNode(""node7"")).add(newNode(""node8"")).add(newNode(""node9"")).add(newNode(""node10"")))
                .build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
            assertEquals(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).getExpectedShardSize(), sizes[i]);

        }

        logger.info(""start the replica shards, rebalancing should start"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        // we only allow one relocation at a time
        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(5));
        assertThat(clusterState.routingTable().shardsWithState(RELOCATING).size(), equalTo(5));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            int num = 0;
            for (ShardRouting routing : clusterState.routingTable().index(""test"").shard(i).shards()) {
                if (routing.state() == RELOCATING || routing.state() == INITIALIZING) {
                    assertEquals(routing.getExpectedShardSize(), sizes[i]);
                    num++;
                }
            }
            assertTrue(num > 0);
        }

        logger.info(""complete relocation, other half of relocation should happen"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        // we now only relocate 3, since 2 remain where they are!
        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(7));
        assertThat(clusterState.routingTable().shardsWithState(RELOCATING).size(), equalTo(3));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            for (ShardRouting routing : clusterState.routingTable().index(""test"").shard(i).shards()) {
                if (routing.state() == RELOCATING || routing.state() == INITIALIZING) {
                    assertEquals(routing.getExpectedShardSize(), sizes[i]);
                }
            }
        }


        logger.info(""complete relocation, that's it!"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(10));
        // make sure we have an even relocation
        for (RoutingNode routingNode : routingNodes) {
            assertThat(routingNode.size(), equalTo(1));
        }
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/RebalanceAfterActiveTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,216,"public void testClusterPrimariesActive1() {
        AllocationService strategy = createAllocationService(Settings.builder().put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(),
                ClusterRebalanceAllocationDecider.ClusterRebalanceType.INDICES_PRIMARIES_ACTIVE.toString()).build());

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .put(IndexMetaData.builder(""test2"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test1""))
                .addAsNew(metaData.index(""test2""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info(""start two nodes"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards for test1, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start the test1 replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards for test2, replicas will start initializing"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test2"", INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        logger.info(""now, start 1 more node, check that rebalancing happen (for test1) because we set it to primaries_active"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode(""node3"")))
                .build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(routingNodes.node(""node3"").size(), equalTo(1));
        assertThat(routingNodes.node(""node3"").iterator().next().shardId().getIndex().getName(), equalTo(""test1""));
    }","public void testClusterPrimariesActive1() {
        AllocationService strategy = createAllocationService(Settings.builder().put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(),
                ClusterRebalanceAllocationDecider.ClusterRebalanceType.INDICES_PRIMARIES_ACTIVE.toString()).build());

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .put(IndexMetaData.builder(""test2"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test1""))
                .addAsNew(metaData.index(""test2""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        logger.info(""start two nodes"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards for test1, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start the test1 replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards for test2, replicas will start initializing"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test2"", INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        logger.info(""now, start 1 more node, check that rebalancing happen (for test1) because we set it to primaries_active"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode(""node3"")))
                .build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(routingNodes.node(""node3"").size(), equalTo(1));
        assertThat(routingNodes.node(""node3"").iterator().next().shardId().getIndex().getName(), equalTo(""test1""));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/ClusterRebalanceRoutingTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,118,"public void testBalanceAllNodesStarted() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(""cluster.routing.allocation.node_initial_primaries_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .put(""cluster.routing.allocation.cluster_concurrent_rebalance"", -1).build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder().put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(3).numberOfReplicas(1))
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)).numberOfShards(3).numberOfReplicas(1)).build();

        RoutingTable routingTable = RoutingTable.builder().addAsNew(metaData.index(""test"")).addAsNew(metaData.index(""test1"")).build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();
        RoutingNodes routingNodes = clusterState.getRoutingNodes();

        logger.info(""Adding three node and performing rerouting"");
        clusterState = ClusterState.builder(clusterState)
                .nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2"")).add(newNode(""node3""))).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        // all shards are unassigned. so no inactive shards or primaries.
        assertThat(routingNodes.hasInactiveShards(), equalTo(false));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(false));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(true));

        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(true));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(true));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(false));

        logger.info(""Another round of rebalancing"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())).build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        logger.info(""Reroute, nothing should change"");
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();

        logger.info(""Start the more shards"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(false));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(false));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(false));

        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

    }","public void testBalanceIncrementallyStartNodes() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(""cluster.routing.allocation.node_initial_primaries_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .put(""cluster.routing.allocation.cluster_concurrent_rebalance"", -1).build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder().put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(3).numberOfReplicas(1))
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)).numberOfShards(3).numberOfReplicas(1)).build();

        RoutingTable initialRoutingTable = RoutingTable.builder().addAsNew(metaData.index(""test"")).addAsNew(metaData.index(""test1"")).build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        logger.info(""Adding one node and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1""))).build();

        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""Add another node and perform rerouting, nothing will happen since primary not started"");
        clusterState = ClusterState.builder(clusterState)
                .nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node2""))).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""Start the primary shard"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""Reroute, nothing should change"");
        routingResult = strategy.reroute(clusterState, ""reroute"");

        logger.info(""Start the backup shard"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        logger.info(""Add another node and perform rerouting, nothing will happen since primary not started"");
        clusterState = ClusterState.builder(clusterState)
                .nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node3""))).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""Reroute, nothing should change"");
        routingResult = strategy.reroute(clusterState, ""reroute"");
        assertFalse(routingResult.changed());

        logger.info(""Start the backup shard"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(3));

        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test1"").shards().size(), equalTo(3));

        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), equalTo(4));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), equalTo(4));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(STARTED), equalTo(4));

        assertThat(routingNodes.node(""node1"").shardsWithState(""test"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node2"").shardsWithState(""test"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node3"").shardsWithState(""test"", STARTED).size(), equalTo(2));

        assertThat(routingNodes.node(""node1"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node2"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node3"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/RoutingNodesIntegrityTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,106,"public void testPrimaryRecoveryThrottling() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 3)
                .put(""cluster.routing.allocation.node_initial_primaries_recoveries"", 3)
                .build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(10).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = createRecoveryRoutingTable(metaData.index(""test""));

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info(""start one node, do reroute, only 3 should initialize"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1""))).build();
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(0));
        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(3));
        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(17));

        logger.info(""start initializing, another 3 should initialize"");
        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(3));
        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(3));
        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(14));

        logger.info(""start initializing, another 3 should initialize"");
        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(6));
        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(3));
        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(11));

        logger.info(""start initializing, another 1 should initialize"");
        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(9));
        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(1));
        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(10));

        logger.info(""start initializing, all primaries should be started"");
        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(10));
        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(0));
        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(10));
    }","public void testPrimaryRecoveryThrottling() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 3)
                .put(""cluster.routing.allocation.node_initial_primaries_recoveries"", 3)
                .build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(10).numberOfReplicas(1))
                .build();

        RoutingTable initialRoutingTable = createRecoveryRoutingTable(metaData.index(""test""));

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        logger.info(""start one node, do reroute, only 3 should initialize"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1""))).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(0));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(3));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(17));

        logger.info(""start initializing, another 3 should initialize"");
        routingResult = strategy.applyStartedShards(clusterState, clusterState.routingTable().shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(3));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(3));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(14));

        logger.info(""start initializing, another 3 should initialize"");
        routingResult = strategy.applyStartedShards(clusterState, clusterState.routingTable().shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(6));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(3));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(11));

        logger.info(""start initializing, another 1 should initialize"");
        routingResult = strategy.applyStartedShards(clusterState, clusterState.routingTable().shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(9));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(1));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(10));

        logger.info(""start initializing, all primaries should be started"");
        routingResult = strategy.applyStartedShards(clusterState, clusterState.routingTable().shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(10));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(0));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(10));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/ThrottlingAllocationTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,298,"public void testClusterPrimariesActive2() {
        AllocationService strategy = createAllocationService(Settings.builder().put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(),
                ClusterRebalanceAllocationDecider.ClusterRebalanceType.INDICES_PRIMARIES_ACTIVE.toString()).build());

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .put(IndexMetaData.builder(""test2"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test1""))
                .addAsNew(metaData.index(""test2""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info(""start two nodes"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards for test1, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start the test1 replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to primaries_active"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode(""node3"")))
                .build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(routingNodes.node(""node3"").isEmpty(), equalTo(true));
    }","public void testClusterPrimariesActive2() {
        AllocationService strategy = createAllocationService(Settings.builder().put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(),
                ClusterRebalanceAllocationDecider.ClusterRebalanceType.INDICES_PRIMARIES_ACTIVE.toString()).build());

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .put(IndexMetaData.builder(""test2"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test1""))
                .addAsNew(metaData.index(""test2""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        logger.info(""start two nodes"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards for test1, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start the test1 replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to primaries_active"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode(""node3"")))
                .build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(routingNodes.node(""node3"").isEmpty(), equalTo(true));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/ClusterRebalanceRoutingTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,64,"public void testSimpleFailedNodeTest() {
        AllocationService strategy = createAllocationService(Settings.builder().put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(),
                ClusterRebalanceAllocationDecider.ClusterRebalanceType.ALWAYS.toString()).build());

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .put(IndexMetaData.builder(""test2"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test1""))
                .addAsNew(metaData.index(""test2""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info(""start 4 nodes"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2"")).add(newNode(""node3"")).add(newNode(""node4""))).build();
        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        logger.info(""start all the primary shards, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        logger.info(""start the replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), equalTo(1));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), equalTo(1));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(STARTED), equalTo(1));
        assertThat(routingNodes.node(""node4"").numberOfShardsWithState(STARTED), equalTo(1));


        logger.info(""remove 2 nodes where primaries are allocated, reroute"");

        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .remove(routingTable.index(""test1"").shard(0).primaryShard().currentNodeId())
                .remove(routingTable.index(""test2"").shard(0).primaryShard().currentNodeId())
        )
                .build();
        prevRoutingTable = routingTable;
        routingTable = strategy.deassociateDeadNodes(clusterState, true, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (RoutingNode routingNode : routingNodes) {
            assertThat(routingNode.numberOfShardsWithState(STARTED), equalTo(1));
            assertThat(routingNode.numberOfShardsWithState(INITIALIZING), equalTo(1));
        }
    }","public void testSimpleFailedNodeTest() {
        AllocationService strategy = createAllocationService(Settings.builder().put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(),
                ClusterRebalanceAllocationDecider.ClusterRebalanceType.ALWAYS.toString()).build());

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .put(IndexMetaData.builder(""test2"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test1""))
                .addAsNew(metaData.index(""test2""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        logger.info(""start 4 nodes"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2"")).add(newNode(""node3"")).add(newNode(""node4""))).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""start all the primary shards, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        logger.info(""start the replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), equalTo(1));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), equalTo(1));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(STARTED), equalTo(1));
        assertThat(routingNodes.node(""node4"").numberOfShardsWithState(STARTED), equalTo(1));


        logger.info(""remove 2 nodes where primaries are allocated, reroute"");

        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .remove(clusterState.routingTable().index(""test1"").shard(0).primaryShard().currentNodeId())
                .remove(clusterState.routingTable().index(""test2"").shard(0).primaryShard().currentNodeId())
        )
                .build();
        routingResult = strategy.deassociateDeadNodes(clusterState, true, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (RoutingNode routingNode : routingNodes) {
            assertThat(routingNode.numberOfShardsWithState(STARTED), equalTo(1));
            assertThat(routingNode.numberOfShardsWithState(INITIALIZING), equalTo(1));
        }
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/FailedNodeRoutingTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,300,"public void testMultiIndexEvenDistribution() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .put(""cluster.routing.allocation.cluster_concurrent_rebalance"", -1)
                .build());

        final int numberOfIndices = 50;
        logger.info(""Building initial routing table with "" + numberOfIndices + "" indices"");

        MetaData.Builder metaDataBuilder = MetaData.builder();
        for (int i = 0; i < numberOfIndices; i++) {
            metaDataBuilder.put(IndexMetaData.builder(""test"" + i).settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(0));
        }
        MetaData metaData = metaDataBuilder.build();

        RoutingTable.Builder routingTableBuilder = RoutingTable.builder();
        for (int i = 0; i < numberOfIndices; i++) {
            routingTableBuilder.addAsNew(metaData.index(""test"" + i));
        }
        RoutingTable routingTable = routingTableBuilder.build();
        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        assertThat(routingTable.indicesRouting().size(), equalTo(numberOfIndices));
        for (int i = 0; i < numberOfIndices; i++) {
            assertThat(routingTable.index(""test"" + i).shards().size(), equalTo(1));
            assertThat(routingTable.index(""test"" + i).shard(0).size(), equalTo(1));
            assertThat(routingTable.index(""test"" + i).shard(0).shards().size(), equalTo(1));
            assertThat(routingTable.index(""test"" + i).shard(0).shards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(routingTable.index(""test"" + i).shard(0).shards().get(0).currentNodeId(), nullValue());
        }

        logger.info(""Adding "" + (numberOfIndices / 2) + "" nodes"");
        DiscoveryNodes.Builder nodesBuilder = DiscoveryNodes.builder();
        List<DiscoveryNode> nodes = new ArrayList<>();
        for (int i = 0; i < (numberOfIndices / 2); i++) {
            nodesBuilder.add(newNode(""node"" + i));
        }
        RoutingTable prevRoutingTable = routingTable;
        clusterState = ClusterState.builder(clusterState).nodes(nodesBuilder).build();
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        for (int i = 0; i < numberOfIndices; i++) {
            assertThat(routingTable.index(""test"" + i).shards().size(), equalTo(1));
            assertThat(routingTable.index(""test"" + i).shard(0).size(), equalTo(1));
            assertThat(routingTable.index(""test"" + i).shard(0).shards().size(), equalTo(1));
            assertThat(routingTable.index(""test"" + i).shard(0).shards().get(0).unassigned(), equalTo(false));
            assertThat(routingTable.index(""test"" + i).shard(0).shards().get(0).state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test"" + i).shard(0).shards().get(0).primary(), equalTo(true));
            // make sure we still have 2 shards initializing per node on the first 25 nodes
            String nodeId = routingTable.index(""test"" + i).shard(0).shards().get(0).currentNodeId();
            int nodeIndex = Integer.parseInt(nodeId.substring(""node"".length()));
            assertThat(nodeIndex, lessThan(25));
        }
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        Set<String> encounteredIndices = new HashSet<>();
        for (RoutingNode routingNode : routingNodes) {
            assertThat(routingNode.numberOfShardsWithState(STARTED), equalTo(0));
            assertThat(routingNode.size(), equalTo(2));
            // make sure we still have 2 shards initializing per node on the only 25 nodes
            int nodeIndex = Integer.parseInt(routingNode.nodeId().substring(""node"".length()));
            assertThat(nodeIndex, lessThan(25));
            // check that we don't have a shard associated with a node with the same index name (we have a single shard)
            for (ShardRouting shardRoutingEntry : routingNode) {
                assertThat(encounteredIndices, not(hasItem(shardRoutingEntry.getIndexName())));
                encounteredIndices.add(shardRoutingEntry.getIndexName());
            }
        }

        logger.info(""Adding additional "" + (numberOfIndices / 2) + "" nodes, nothing should change"");
        nodesBuilder = DiscoveryNodes.builder(clusterState.nodes());
        for (int i = (numberOfIndices / 2); i < numberOfIndices; i++) {
            nodesBuilder.add(newNode(""node"" + i));
        }
        prevRoutingTable = routingTable;
        clusterState = ClusterState.builder(clusterState).nodes(nodesBuilder).build();
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(false));

        logger.info(""Marking the shard as started"");
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        int numberOfRelocatingShards = 0;
        int numberOfStartedShards = 0;
        for (int i = 0; i < numberOfIndices; i++) {
            assertThat(routingTable.index(""test"" + i).shards().size(), equalTo(1));
            assertThat(routingTable.index(""test"" + i).shard(0).size(), equalTo(1));
            assertThat(routingTable.index(""test"" + i).shard(0).shards().size(), equalTo(1));
            assertThat(routingTable.index(""test"" + i).shard(0).shards().get(0).unassigned(), equalTo(false));
            assertThat(routingTable.index(""test"" + i).shard(0).shards().get(0).state(), anyOf(equalTo(STARTED), equalTo(RELOCATING)));
            if (routingTable.index(""test"" + i).shard(0).shards().get(0).state() == STARTED) {
                numberOfStartedShards++;
            } else if (routingTable.index(""test"" + i).shard(0).shards().get(0).state() == RELOCATING) {
                numberOfRelocatingShards++;
            }
            assertThat(routingTable.index(""test"" + i).shard(0).shards().get(0).primary(), equalTo(true));
            // make sure we still have 2 shards either relocating or started on the first 25 nodes (still)
            String nodeId = routingTable.index(""test"" + i).shard(0).shards().get(0).currentNodeId();
            int nodeIndex = Integer.parseInt(nodeId.substring(""node"".length()));
            assertThat(nodeIndex, lessThan(25));
        }
        assertThat(numberOfRelocatingShards, equalTo(25));
        assertThat(numberOfStartedShards, equalTo(25));
    }","public void testMultiIndexEvenDistribution() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .put(""cluster.routing.allocation.cluster_concurrent_rebalance"", -1)
                .build());

        final int numberOfIndices = 50;
        logger.info(""Building initial routing table with "" + numberOfIndices + "" indices"");

        MetaData.Builder metaDataBuilder = MetaData.builder();
        for (int i = 0; i < numberOfIndices; i++) {
            metaDataBuilder.put(IndexMetaData.builder(""test"" + i).settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(0));
        }
        MetaData metaData = metaDataBuilder.build();

        RoutingTable.Builder routingTableBuilder = RoutingTable.builder();
        for (int i = 0; i < numberOfIndices; i++) {
            routingTableBuilder.addAsNew(metaData.index(""test"" + i));
        }
        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTableBuilder.build()).build();

        assertThat(clusterState.routingTable().indicesRouting().size(), equalTo(numberOfIndices));
        for (int i = 0; i < numberOfIndices; i++) {
            assertThat(clusterState.routingTable().index(""test"" + i).shards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).currentNodeId(), nullValue());
        }

        logger.info(""Adding "" + (numberOfIndices / 2) + "" nodes"");
        DiscoveryNodes.Builder nodesBuilder = DiscoveryNodes.builder();
        List<DiscoveryNode> nodes = new ArrayList<>();
        for (int i = 0; i < (numberOfIndices / 2); i++) {
            nodesBuilder.add(newNode(""node"" + i));
        }
        clusterState = ClusterState.builder(clusterState).nodes(nodesBuilder).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(routingResult.changed(), equalTo(true));
        for (int i = 0; i < numberOfIndices; i++) {
            assertThat(clusterState.routingTable().index(""test"" + i).shards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).unassigned(), equalTo(false));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).primary(), equalTo(true));
            // make sure we still have 2 shards initializing per node on the first 25 nodes
            String nodeId = clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).currentNodeId();
            int nodeIndex = Integer.parseInt(nodeId.substring(""node"".length()));
            assertThat(nodeIndex, lessThan(25));
        }
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        Set<String> encounteredIndices = new HashSet<>();
        for (RoutingNode routingNode : routingNodes) {
            assertThat(routingNode.numberOfShardsWithState(STARTED), equalTo(0));
            assertThat(routingNode.size(), equalTo(2));
            // make sure we still have 2 shards initializing per node on the only 25 nodes
            int nodeIndex = Integer.parseInt(routingNode.nodeId().substring(""node"".length()));
            assertThat(nodeIndex, lessThan(25));
            // check that we don't have a shard associated with a node with the same index name (we have a single shard)
            for (ShardRouting shardRoutingEntry : routingNode) {
                assertThat(encounteredIndices, not(hasItem(shardRoutingEntry.getIndexName())));
                encounteredIndices.add(shardRoutingEntry.getIndexName());
            }
        }

        logger.info(""Adding additional "" + (numberOfIndices / 2) + "" nodes, nothing should change"");
        nodesBuilder = DiscoveryNodes.builder(clusterState.nodes());
        for (int i = (numberOfIndices / 2); i < numberOfIndices; i++) {
            nodesBuilder.add(newNode(""node"" + i));
        }
        clusterState = ClusterState.builder(clusterState).nodes(nodesBuilder).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(routingResult.changed(), equalTo(false));

        logger.info(""Marking the shard as started"");
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(routingResult.changed(), equalTo(true));
        int numberOfRelocatingShards = 0;
        int numberOfStartedShards = 0;
        for (int i = 0; i < numberOfIndices; i++) {
            assertThat(clusterState.routingTable().index(""test"" + i).shards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).unassigned(), equalTo(false));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).state(), anyOf(equalTo(STARTED), equalTo(RELOCATING)));
            if (clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).state() == STARTED) {
                numberOfStartedShards++;
            } else if (clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).state() == RELOCATING) {
                numberOfRelocatingShards++;
            }
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).primary(), equalTo(true));
            // make sure we still have 2 shards either relocating or started on the first 25 nodes (still)
            String nodeId = clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).currentNodeId();
            int nodeIndex = Integer.parseInt(nodeId.substring(""node"".length()));
            assertThat(nodeIndex, lessThan(25));
        }
        assertThat(numberOfRelocatingShards, equalTo(25));
        assertThat(numberOfStartedShards, equalTo(25));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/SingleShardNoReplicasRoutingTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,65,"public void testElectReplicaAsPrimaryDuringRelocation() {
        AllocationService strategy = createAllocationService(Settings.builder().put(""cluster.routing.allocation.node_concurrent_recoveries"", 10).build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(2).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info(""Adding two nodes and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        logger.info(""Start the primary shards"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        logger.info(""Start the replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(2));
        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), equalTo(2));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), equalTo(2));

        logger.info(""Start another node and perform rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node3""))).build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        logger.info(""find the replica shard that gets relocated"");
        IndexShardRoutingTable indexShardRoutingTable = null;
        if (routingTable.index(""test"").shard(0).replicaShards().get(0).relocating()) {
            indexShardRoutingTable = routingTable.index(""test"").shard(0);
        } else if (routingTable.index(""test"").shard(1).replicaShards().get(0).relocating()) {
            indexShardRoutingTable = routingTable.index(""test"").shard(1);
        }

        // we might have primary relocating, and the test is only for replicas, so only test in the case of replica allocation
        if (indexShardRoutingTable != null) {
            logger.info(""kill the node [{}] of the primary shard for the relocating replica"", indexShardRoutingTable.primaryShard().currentNodeId());
            clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).remove(indexShardRoutingTable.primaryShard().currentNodeId())).build();
            prevRoutingTable = routingTable;
            routingTable = strategy.deassociateDeadNodes(clusterState, true, ""reroute"").routingTable();
            clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

            logger.info(""make sure all the primary shards are active"");
            assertThat(routingTable.index(""test"").shard(0).primaryShard().active(), equalTo(true));
            assertThat(routingTable.index(""test"").shard(1).primaryShard().active(), equalTo(true));
        }
    }","public void testElectReplicaAsPrimaryDuringRelocation() {
        AllocationService strategy = createAllocationService(Settings.builder().put(""cluster.routing.allocation.node_concurrent_recoveries"", 10).build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(2).numberOfReplicas(1))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        logger.info(""Adding two nodes and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""Start the primary shards"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""Start the replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(2));
        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), equalTo(2));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), equalTo(2));

        logger.info(""Start another node and perform rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node3""))).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""find the replica shard that gets relocated"");
        IndexShardRoutingTable indexShardRoutingTable = null;
        if (clusterState.routingTable().index(""test"").shard(0).replicaShards().get(0).relocating()) {
            indexShardRoutingTable = clusterState.routingTable().index(""test"").shard(0);
        } else if (clusterState.routingTable().index(""test"").shard(1).replicaShards().get(0).relocating()) {
            indexShardRoutingTable = clusterState.routingTable().index(""test"").shard(1);
        }

        // we might have primary relocating, and the test is only for replicas, so only test in the case of replica allocation
        if (indexShardRoutingTable != null) {
            logger.info(""kill the node [{}] of the primary shard for the relocating replica"", indexShardRoutingTable.primaryShard().currentNodeId());
            clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).remove(indexShardRoutingTable.primaryShard().currentNodeId())).build();
            routingResult = strategy.deassociateDeadNodes(clusterState, true, ""reroute"");
            clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

            logger.info(""make sure all the primary shards are active"");
            assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().active(), equalTo(true));
            assertThat(clusterState.routingTable().index(""test"").shard(1).primaryShard().active(), equalTo(true));
        }
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/ElectReplicaAsPrimaryDuringRelocationTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,508,"public void testClusterAllActive2() {
        AllocationService strategy = createAllocationService(Settings.builder().put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(),
                ClusterRebalanceAllocationDecider.ClusterRebalanceType.INDICES_ALL_ACTIVE.toString()).build());

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .put(IndexMetaData.builder(""test2"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test1""))
                .addAsNew(metaData.index(""test2""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info(""start two nodes"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards for test1, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start the test1 replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode(""node3"")))
                .build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(routingNodes.node(""node3"").isEmpty(), equalTo(true));
    }","public void testClusterAllActive2() {
        AllocationService strategy = createAllocationService(Settings.builder().put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(),
                ClusterRebalanceAllocationDecider.ClusterRebalanceType.INDICES_ALL_ACTIVE.toString()).build());

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .put(IndexMetaData.builder(""test2"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test1""))
                .addAsNew(metaData.index(""test2""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        logger.info(""start two nodes"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards for test1, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start the test1 replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode(""node3"")))
                .build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(routingNodes.node(""node3"").isEmpty(), equalTo(true));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/ClusterRebalanceRoutingTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,141,"private ClusterState initCluster(AllocationService strategy) {
        MetaData.Builder metaDataBuilder = MetaData.builder();
        RoutingTable.Builder routingTableBuilder = RoutingTable.builder();

        for (int i = 0; i < numberOfIndices; i++) {
            IndexMetaData.Builder index = IndexMetaData.builder(""test"" + i).settings(settings(Version.CURRENT)).numberOfShards(numberOfShards).numberOfReplicas(numberOfReplicas);
            metaDataBuilder = metaDataBuilder.put(index);
        }

        MetaData metaData = metaDataBuilder.build();

        for (ObjectCursor<IndexMetaData> cursor : metaData.indices().values()) {
            routingTableBuilder.addAsNew(cursor.value);
        }

        RoutingTable routingTable = routingTableBuilder.build();


        logger.info(""start "" + numberOfNodes + "" nodes"");
        DiscoveryNodes.Builder nodes = DiscoveryNodes.builder();
        for (int i = 0; i < numberOfNodes; i++) {
            nodes.add(newNode(""node"" + i));
        }
        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).nodes(nodes).metaData(metaData).routingTable(routingTable).build();
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        RoutingNodes routingNodes = clusterState.getRoutingNodes();

        logger.info(""restart all the primary shards, replicas will start initializing"");
        routingNodes = clusterState.getRoutingNodes();
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        logger.info(""start the replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        logger.info(""complete rebalancing"");
        RoutingTable prev = routingTable;
        while (true) {
            routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
            clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
            routingNodes = clusterState.getRoutingNodes();
            if (routingTable == prev)
                break;
            prev = routingTable;
        }

        return clusterState;
    }","private ClusterState initCluster(AllocationService strategy) {
        MetaData.Builder metaDataBuilder = MetaData.builder();
        RoutingTable.Builder routingTableBuilder = RoutingTable.builder();

        for (int i = 0; i < numberOfIndices; i++) {
            IndexMetaData.Builder index = IndexMetaData.builder(""test"" + i).settings(settings(Version.CURRENT)).numberOfShards(numberOfShards).numberOfReplicas(numberOfReplicas);
            metaDataBuilder = metaDataBuilder.put(index);
        }

        MetaData metaData = metaDataBuilder.build();

        for (ObjectCursor<IndexMetaData> cursor : metaData.indices().values()) {
            routingTableBuilder.addAsNew(cursor.value);
        }

        RoutingTable initialRoutingTable = routingTableBuilder.build();


        logger.info(""start "" + numberOfNodes + "" nodes"");
        DiscoveryNodes.Builder nodes = DiscoveryNodes.builder();
        for (int i = 0; i < numberOfNodes; i++) {
            nodes.add(newNode(""node"" + i));
        }
        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).nodes(nodes).metaData(metaData).routingTable(initialRoutingTable).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""restart all the primary shards, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""start the replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""complete rebalancing"");
        return applyStartedShardsUntilNoChange(clusterState, strategy);
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/BalanceConfigurationTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,401,"public void testClusterAllActive1() {
        AllocationService strategy = createAllocationService(Settings.builder().put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(),
                ClusterRebalanceAllocationDecider.ClusterRebalanceType.INDICES_ALL_ACTIVE.toString()).build());

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .put(IndexMetaData.builder(""test2"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test1""))
                .addAsNew(metaData.index(""test2""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info(""start two nodes"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards for test1, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start the test1 replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards for test2, replicas will start initializing"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test2"", INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        logger.info(""start the test2 replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test2"", INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        logger.info(""now, start 1 more node, check that rebalancing happen (for test1) because we set it to all_active"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode(""node3"")))
                .build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(routingNodes.node(""node3"").size(), equalTo(1));
        assertThat(routingNodes.node(""node3"").iterator().next().shardId().getIndex().getName(), anyOf(equalTo(""test1""), equalTo(""test2"")));
    }","public void testClusterAllActive1() {
        AllocationService strategy = createAllocationService(Settings.builder().put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(),
                ClusterRebalanceAllocationDecider.ClusterRebalanceType.INDICES_ALL_ACTIVE.toString()).build());

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .put(IndexMetaData.builder(""test2"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test1""))
                .addAsNew(metaData.index(""test2""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        logger.info(""start two nodes"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards for test1, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start the test1 replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards for test2, replicas will start initializing"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test2"", INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        logger.info(""start the test2 replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test2"", INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        logger.info(""now, start 1 more node, check that rebalancing happen (for test1) because we set it to all_active"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode(""node3"")))
                .build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(routingNodes.node(""node3"").size(), equalTo(1));
        assertThat(routingNodes.node(""node3"").iterator().next().shardId().getIndex().getName(), anyOf(equalTo(""test1""), equalTo(""test2"")));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/ClusterRebalanceRoutingTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,174,"public void testDoNotAllocateFromPrimary() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .put(""cluster.routing.allocation.cluster_concurrent_rebalance"", -1)
                .build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(5).numberOfReplicas(2))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        assertThat(routingTable.index(""test"").shards().size(), equalTo(5));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(3));
            assertThat(routingTable.index(""test"").shard(i).shards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(routingTable.index(""test"").shard(i).shards().get(1).state(), equalTo(UNASSIGNED));
            assertThat(routingTable.index(""test"").shard(i).shards().get(2).state(), equalTo(UNASSIGNED));
            assertThat(routingTable.index(""test"").shard(i).shards().get(0).currentNodeId(), nullValue());
            assertThat(routingTable.index(""test"").shard(i).shards().get(1).currentNodeId(), nullValue());
            assertThat(routingTable.index(""test"").shard(i).shards().get(2).currentNodeId(), nullValue());
        }

        logger.info(""start two nodes and fully start the shards"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(3));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test"").shard(i).replicaShardsWithState(UNASSIGNED).size(), equalTo(2));

        }

        logger.info(""start all the primary shards, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(3));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test"").shard(i).replicaShardsWithState(INITIALIZING).size(), equalTo(1));
            assertThat(routingTable.index(""test"").shard(i).replicaShardsWithState(UNASSIGNED).size(), equalTo(1));
        }

        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(3));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test"").shard(i).replicaShardsWithState(STARTED).size(), equalTo(1));
            assertThat(routingTable.index(""test"").shard(i).replicaShardsWithState(UNASSIGNED).size(), equalTo(1));
        }

        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode(""node3"", VersionUtils.getPreviousVersion())))
                .build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(3));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test"").shard(i).replicaShardsWithState(STARTED).size(), equalTo(1));
            assertThat(routingTable.index(""test"").shard(i).replicaShardsWithState(UNASSIGNED).size(), equalTo(1));
        }


        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode(""node4"")))
                .build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(3));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test"").shard(i).replicaShardsWithState(STARTED).size(), equalTo(1));
            assertThat(routingTable.index(""test"").shard(i).replicaShardsWithState(INITIALIZING).size(), equalTo(1));
        }

        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(3));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test"").shard(i).replicaShardsWithState(STARTED).size(), equalTo(2));
        }
    }","public void testDoNotAllocateFromPrimary() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .put(""cluster.routing.allocation.cluster_concurrent_rebalance"", -1)
                .build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(5).numberOfReplicas(2))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(5));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(3));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(1).state(), equalTo(UNASSIGNED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(2).state(), equalTo(UNASSIGNED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(0).currentNodeId(), nullValue());
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(1).currentNodeId(), nullValue());
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(2).currentNodeId(), nullValue());
        }

        logger.info(""start two nodes and fully start the shards"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(3));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShardsWithState(UNASSIGNED).size(), equalTo(2));

        }

        logger.info(""start all the primary shards, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(3));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShardsWithState(INITIALIZING).size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShardsWithState(UNASSIGNED).size(), equalTo(1));
        }

        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(3));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShardsWithState(STARTED).size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShardsWithState(UNASSIGNED).size(), equalTo(1));
        }

        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode(""node3"", VersionUtils.getPreviousVersion())))
                .build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(3));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShardsWithState(STARTED).size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShardsWithState(UNASSIGNED).size(), equalTo(1));
        }


        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode(""node4"")))
                .build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(3));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShardsWithState(STARTED).size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShardsWithState(INITIALIZING).size(), equalTo(1));
        }

        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(3));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShardsWithState(STARTED).size(), equalTo(2));
        }
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/NodeVersionAllocationDeciderTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,303,"public void testBalanceAllNodesStartedAddIndex() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 1)
                .put(""cluster.routing.allocation.node_initial_primaries_recoveries"", 3)
                .put(ThrottlingAllocationDecider.CLUSTER_ROUTING_ALLOCATION_NODE_CONCURRENT_OUTGOING_RECOVERIES_SETTING.getKey(), 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .put(""cluster.routing.allocation.cluster_concurrent_rebalance"", -1).build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder().put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(3).numberOfReplicas(1)).build();

        RoutingTable routingTable = RoutingTable.builder().addAsNew(metaData.index(""test"")).build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info(""Adding three node and performing rerouting"");
        clusterState = ClusterState.builder(clusterState)
                .nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2"")).add(newNode(""node3""))).build();

        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(false));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(false));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(true));

        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(true));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(true));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(false));

        logger.info(""Another round of rebalancing"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())).build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable == routingTable, equalTo(true));

        routingNodes = clusterState.getRoutingNodes();
        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(INITIALIZING), equalTo(1));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(INITIALIZING), equalTo(1));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(INITIALIZING), equalTo(1));

        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(true));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(false));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(false));
        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), equalTo(1));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), equalTo(1));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(STARTED), equalTo(1));

        logger.info(""Reroute, nothing should change"");
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        assertThat(prevRoutingTable == routingTable, equalTo(true));

        logger.info(""Start the more shards"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(false));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(false));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(false));

        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), equalTo(2));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), equalTo(2));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(STARTED), equalTo(2));

        assertThat(routingNodes.node(""node1"").shardsWithState(""test"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node2"").shardsWithState(""test"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node3"").shardsWithState(""test"", STARTED).size(), equalTo(2));

        logger.info(""Add new index 3 shards 1 replica"");

        prevRoutingTable = routingTable;
        metaData = MetaData.builder(metaData)
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)
                        .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 3)
                        .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 1)
                ))
                .build();
        routingTable = RoutingTable.builder(routingTable)
                .addAsNew(metaData.index(""test1""))
                .build();
        clusterState = ClusterState.builder(clusterState).metaData(metaData).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(false));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(false));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(true));

        assertThat(routingTable.index(""test1"").shards().size(), equalTo(3));

        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        logger.info(""Reroute, assign"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())).build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(true));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(true));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(false));

        assertThat(prevRoutingTable == routingTable, equalTo(true));

        logger.info(""Reroute, start the primaries"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(true));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(false));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(false));

        logger.info(""Reroute, start the replicas"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(false));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(false));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(false));


        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), equalTo(4));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), equalTo(4));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(STARTED), equalTo(4));

        assertThat(routingNodes.node(""node1"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node2"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node3"").shardsWithState(""test1"", STARTED).size(), equalTo(2));

        logger.info(""kill one node"");
        IndexShardRoutingTable indexShardRoutingTable = routingTable.index(""test"").shard(0);
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).remove(indexShardRoutingTable.primaryShard().currentNodeId())).build();
        routingTable = strategy.deassociateDeadNodes(clusterState, true, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(true));
        // replica got promoted to primary
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(false));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(false));

        logger.info(""Start Recovering shards round 1"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(true));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(false));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(false));

        logger.info(""Start Recovering shards round 2"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(false));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(false));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(false));

    }","public void testBalanceAllNodesStartedAddIndex() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 1)
                .put(""cluster.routing.allocation.node_initial_primaries_recoveries"", 3)
                .put(ThrottlingAllocationDecider.CLUSTER_ROUTING_ALLOCATION_NODE_CONCURRENT_OUTGOING_RECOVERIES_SETTING.getKey(), 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .put(""cluster.routing.allocation.cluster_concurrent_rebalance"", -1).build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder().put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(3).numberOfReplicas(1)).build();

        RoutingTable initialRoutingTable = RoutingTable.builder().addAsNew(metaData.index(""test"")).build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        logger.info(""Adding three node and performing rerouting"");
        clusterState = ClusterState.builder(clusterState)
                .nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2"")).add(newNode(""node3""))).build();

        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(false));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(false));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(true));

        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(true));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(true));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(false));

        logger.info(""Another round of rebalancing"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertFalse(routingResult.changed());

        routingNodes = clusterState.getRoutingNodes();
        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(INITIALIZING), equalTo(1));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(INITIALIZING), equalTo(1));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(INITIALIZING), equalTo(1));

        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(true));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(false));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(false));
        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), equalTo(1));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), equalTo(1));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(STARTED), equalTo(1));

        logger.info(""Reroute, nothing should change"");
        routingResult = strategy.reroute(clusterState, ""reroute"");
        assertFalse(routingResult.changed());

        logger.info(""Start the more shards"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(false));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(false));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(false));

        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), equalTo(2));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), equalTo(2));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(STARTED), equalTo(2));

        assertThat(routingNodes.node(""node1"").shardsWithState(""test"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node2"").shardsWithState(""test"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node3"").shardsWithState(""test"", STARTED).size(), equalTo(2));

        logger.info(""Add new index 3 shards 1 replica"");

        metaData = MetaData.builder(clusterState.metaData())
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)
                        .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 3)
                        .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 1)
                ))
                .build();
        RoutingTable updatedRoutingTable = RoutingTable.builder(clusterState.routingTable())
            .addAsNew(metaData.index(""test1""))
            .build();
        clusterState = ClusterState.builder(clusterState).metaData(metaData).routingTable(updatedRoutingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(false));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(false));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(true));

        assertThat(clusterState.routingTable().index(""test1"").shards().size(), equalTo(3));

        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""Reroute, assign"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(true));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(true));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(false));

        assertFalse(routingResult.changed());

        logger.info(""Reroute, start the primaries"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(true));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(false));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(false));

        logger.info(""Reroute, start the replicas"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(false));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(false));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(false));


        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), equalTo(4));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), equalTo(4));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(STARTED), equalTo(4));

        assertThat(routingNodes.node(""node1"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node2"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node3"").shardsWithState(""test1"", STARTED).size(), equalTo(2));

        logger.info(""kill one node"");
        IndexShardRoutingTable indexShardRoutingTable = clusterState.routingTable().index(""test"").shard(0);
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).remove(indexShardRoutingTable.primaryShard().currentNodeId())).build();
        routingResult = strategy.deassociateDeadNodes(clusterState, true, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(true));
        // replica got promoted to primary
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(false));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(false));

        logger.info(""Start Recovering shards round 1"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(true));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(false));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(false));

        logger.info(""Start Recovering shards round 2"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(assertShardStats(routingNodes), equalTo(true));
        assertThat(routingNodes.hasInactiveShards(), equalTo(false));
        assertThat(routingNodes.hasInactivePrimaries(), equalTo(false));
        assertThat(routingNodes.hasUnassignedPrimaries(), equalTo(false));

    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/RoutingNodesIntegrityTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,78,"public void testUpdateNumberOfReplicas() {
        AllocationService strategy = createAllocationService(Settings.builder().put(""cluster.routing.allocation.node_concurrent_recoveries"", 10).build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).shards().size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).state(), equalTo(UNASSIGNED));
        assertThat(routingTable.index(""test"").shard(0).shards().get(1).state(), equalTo(UNASSIGNED));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).currentNodeId(), nullValue());
        assertThat(routingTable.index(""test"").shard(0).shards().get(1).currentNodeId(), nullValue());


        logger.info(""Adding two nodes and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();

        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        logger.info(""Start all the primary shards"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        logger.info(""Start all the replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        final String nodeHoldingPrimary = routingTable.index(""test"").shard(0).primaryShard().currentNodeId();
        final String nodeHoldingReplica = routingTable.index(""test"").shard(0).replicaShards().get(0).currentNodeId();
        assertThat(nodeHoldingPrimary, not(equalTo(nodeHoldingReplica)));
        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).shards().size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().state(), equalTo(STARTED));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().currentNodeId(), equalTo(nodeHoldingPrimary));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().get(0).state(), equalTo(STARTED));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().get(0).currentNodeId(), equalTo(nodeHoldingReplica));


        logger.info(""add another replica"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = RoutingTable.builder(routingTable).updateNumberOfReplicas(2).build();
        metaData = MetaData.builder(clusterState.metaData()).updateNumberOfReplicas(2).build();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).metaData(metaData).build();

        assertThat(clusterState.metaData().index(""test"").getNumberOfReplicas(), equalTo(2));

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(3));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().state(), equalTo(STARTED));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().currentNodeId(), equalTo(nodeHoldingPrimary));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().get(0).state(), equalTo(STARTED));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().get(0).currentNodeId(), equalTo(nodeHoldingReplica));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().get(1).state(), equalTo(UNASSIGNED));

        logger.info(""Add another node and start the added replica"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node3""))).build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(3));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().state(), equalTo(STARTED));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().currentNodeId(), equalTo(nodeHoldingPrimary));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).replicaShardsWithState(STARTED).size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).replicaShardsWithState(STARTED).get(0).currentNodeId(), equalTo(nodeHoldingReplica));
        assertThat(routingTable.index(""test"").shard(0).replicaShardsWithState(INITIALIZING).size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).replicaShardsWithState(INITIALIZING).get(0).currentNodeId(), equalTo(""node3""));

        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(3));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().state(), equalTo(STARTED));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().currentNodeId(), equalTo(nodeHoldingPrimary));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).replicaShardsWithState(STARTED).size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).replicaShardsWithState(STARTED).get(0).currentNodeId(), anyOf(equalTo(nodeHoldingReplica), equalTo(""node3"")));
        assertThat(routingTable.index(""test"").shard(0).replicaShardsWithState(STARTED).get(1).currentNodeId(), anyOf(equalTo(nodeHoldingReplica), equalTo(""node3"")));

        logger.info(""now remove a replica"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = RoutingTable.builder(routingTable).updateNumberOfReplicas(1).build();
        metaData = MetaData.builder(clusterState.metaData()).updateNumberOfReplicas(1).build();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).metaData(metaData).build();

        assertThat(clusterState.metaData().index(""test"").getNumberOfReplicas(), equalTo(1));

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().state(), equalTo(STARTED));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().currentNodeId(), equalTo(nodeHoldingPrimary));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().get(0).state(), equalTo(STARTED));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().get(0).currentNodeId(), anyOf(equalTo(nodeHoldingReplica), equalTo(""node3"")));

        logger.info(""do a reroute, should remain the same"");
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(false));
    }","public void testUpdateNumberOfReplicas() {
        AllocationService strategy = createAllocationService(Settings.builder().put(""cluster.routing.allocation.node_concurrent_recoveries"", 10).build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        assertThat(initialRoutingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(initialRoutingTable.index(""test"").shard(0).size(), equalTo(2));
        assertThat(initialRoutingTable.index(""test"").shard(0).shards().size(), equalTo(2));
        assertThat(initialRoutingTable.index(""test"").shard(0).shards().get(0).state(), equalTo(UNASSIGNED));
        assertThat(initialRoutingTable.index(""test"").shard(0).shards().get(1).state(), equalTo(UNASSIGNED));
        assertThat(initialRoutingTable.index(""test"").shard(0).shards().get(0).currentNodeId(), nullValue());
        assertThat(initialRoutingTable.index(""test"").shard(0).shards().get(1).currentNodeId(), nullValue());


        logger.info(""Adding two nodes and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();

        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""Start all the primary shards"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""Start all the replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        final String nodeHoldingPrimary = clusterState.routingTable().index(""test"").shard(0).primaryShard().currentNodeId();
        final String nodeHoldingReplica = clusterState.routingTable().index(""test"").shard(0).replicaShards().get(0).currentNodeId();
        assertThat(nodeHoldingPrimary, not(equalTo(nodeHoldingReplica)));
        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().state(), equalTo(STARTED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().currentNodeId(), equalTo(nodeHoldingPrimary));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().get(0).state(), equalTo(STARTED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().get(0).currentNodeId(), equalTo(nodeHoldingReplica));


        logger.info(""add another replica"");
        routingNodes = clusterState.getRoutingNodes();
        RoutingTable updatedRoutingTable = RoutingTable.builder(clusterState.routingTable()).updateNumberOfReplicas(2).build();
        metaData = MetaData.builder(clusterState.metaData()).updateNumberOfReplicas(2).build();
        clusterState = ClusterState.builder(clusterState).routingTable(updatedRoutingTable).metaData(metaData).build();

        assertThat(clusterState.metaData().index(""test"").getNumberOfReplicas(), equalTo(2));

        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).size(), equalTo(3));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().state(), equalTo(STARTED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().currentNodeId(), equalTo(nodeHoldingPrimary));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().get(0).state(), equalTo(STARTED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().get(0).currentNodeId(), equalTo(nodeHoldingReplica));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().get(1).state(), equalTo(UNASSIGNED));

        logger.info(""Add another node and start the added replica"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node3""))).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).size(), equalTo(3));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().state(), equalTo(STARTED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().currentNodeId(), equalTo(nodeHoldingPrimary));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShardsWithState(STARTED).size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShardsWithState(STARTED).get(0).currentNodeId(), equalTo(nodeHoldingReplica));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShardsWithState(INITIALIZING).size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShardsWithState(INITIALIZING).get(0).currentNodeId(), equalTo(""node3""));

        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).size(), equalTo(3));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().state(), equalTo(STARTED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().currentNodeId(), equalTo(nodeHoldingPrimary));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShardsWithState(STARTED).size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShardsWithState(STARTED).get(0).currentNodeId(), anyOf(equalTo(nodeHoldingReplica), equalTo(""node3"")));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShardsWithState(STARTED).get(1).currentNodeId(), anyOf(equalTo(nodeHoldingReplica), equalTo(""node3"")));

        logger.info(""now remove a replica"");
        routingNodes = clusterState.getRoutingNodes();
        updatedRoutingTable = RoutingTable.builder(clusterState.routingTable()).updateNumberOfReplicas(1).build();
        metaData = MetaData.builder(clusterState.metaData()).updateNumberOfReplicas(1).build();
        clusterState = ClusterState.builder(clusterState).routingTable(updatedRoutingTable).metaData(metaData).build();

        assertThat(clusterState.metaData().index(""test"").getNumberOfReplicas(), equalTo(1));

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().state(), equalTo(STARTED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().currentNodeId(), equalTo(nodeHoldingPrimary));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().get(0).state(), equalTo(STARTED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().get(0).currentNodeId(), anyOf(equalTo(nodeHoldingReplica), equalTo(""node3"")));

        logger.info(""do a reroute, should remain the same"");
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertFalse(routingResult.changed());
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/UpdateNumberOfReplicasTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,92,"public void testAlways() {
        AllocationService strategy = createAllocationService(Settings.builder().put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(),
                ClusterRebalanceAllocationDecider.ClusterRebalanceType.ALWAYS.toString()).build());

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .put(IndexMetaData.builder(""test2"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test1""))
                .addAsNew(metaData.index(""test2""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info(""start two nodes"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards for test1, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
//            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start the test1 replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        for (int i = 0; i < routingTable.index(""test2"").shards().size(); i++) {
            assertThat(routingTable.index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""now, start 1 more node, check that rebalancing will happen (for test1) because we set it to always"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode(""node3"")))
                .build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(routingNodes.node(""node3"").size(), equalTo(1));
        assertThat(routingNodes.node(""node3"").iterator().next().shardId().getIndex().getName(), equalTo(""test1""));
    }","public void testAlways() {
        AllocationService strategy = createAllocationService(Settings.builder().put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(),
                ClusterRebalanceAllocationDecider.ClusterRebalanceType.ALWAYS.toString()).build());

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .put(IndexMetaData.builder(""test2"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test1""))
                .addAsNew(metaData.index(""test2""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        logger.info(""start two nodes"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards for test1, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
//            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start the test1 replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(""test1"", INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        for (int i = 0; i < clusterState.routingTable().index(""test2"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test2"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test2"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""now, start 1 more node, check that rebalancing will happen (for test1) because we set it to always"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode(""node3"")))
                .build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(routingNodes.node(""node3"").size(), equalTo(1));
        assertThat(routingNodes.node(""node3"").iterator().next().shardId().getIndex().getName(), equalTo(""test1""));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/ClusterRebalanceRoutingTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,204,"public void testSingleIndexShardFailed() {
        AllocationService strategy = createAllocationService(Settings.builder().put(""cluster.routing.allocation.node_concurrent_recoveries"", 10).build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(0))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).state(), equalTo(UNASSIGNED));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).currentNodeId(), nullValue());

        logger.info(""Adding one node and rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1""))).build();
        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).unassigned(), equalTo(false));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).state(), equalTo(INITIALIZING));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).currentNodeId(), equalTo(""node1""));

        logger.info(""Marking the shard as failed"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyFailedShard(clusterState, routingNodes.node(""node1"").shardsWithState(INITIALIZING).get(0)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).state(), equalTo(UNASSIGNED));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).currentNodeId(), nullValue());
    }","public void testMultiIndexEvenDistribution() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .put(""cluster.routing.allocation.cluster_concurrent_rebalance"", -1)
                .build());

        final int numberOfIndices = 50;
        logger.info(""Building initial routing table with "" + numberOfIndices + "" indices"");

        MetaData.Builder metaDataBuilder = MetaData.builder();
        for (int i = 0; i < numberOfIndices; i++) {
            metaDataBuilder.put(IndexMetaData.builder(""test"" + i).settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(0));
        }
        MetaData metaData = metaDataBuilder.build();

        RoutingTable.Builder routingTableBuilder = RoutingTable.builder();
        for (int i = 0; i < numberOfIndices; i++) {
            routingTableBuilder.addAsNew(metaData.index(""test"" + i));
        }
        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTableBuilder.build()).build();

        assertThat(clusterState.routingTable().indicesRouting().size(), equalTo(numberOfIndices));
        for (int i = 0; i < numberOfIndices; i++) {
            assertThat(clusterState.routingTable().index(""test"" + i).shards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).currentNodeId(), nullValue());
        }

        logger.info(""Adding "" + (numberOfIndices / 2) + "" nodes"");
        DiscoveryNodes.Builder nodesBuilder = DiscoveryNodes.builder();
        List<DiscoveryNode> nodes = new ArrayList<>();
        for (int i = 0; i < (numberOfIndices / 2); i++) {
            nodesBuilder.add(newNode(""node"" + i));
        }
        clusterState = ClusterState.builder(clusterState).nodes(nodesBuilder).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(routingResult.changed(), equalTo(true));
        for (int i = 0; i < numberOfIndices; i++) {
            assertThat(clusterState.routingTable().index(""test"" + i).shards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).unassigned(), equalTo(false));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).primary(), equalTo(true));
            // make sure we still have 2 shards initializing per node on the first 25 nodes
            String nodeId = clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).currentNodeId();
            int nodeIndex = Integer.parseInt(nodeId.substring(""node"".length()));
            assertThat(nodeIndex, lessThan(25));
        }
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        Set<String> encounteredIndices = new HashSet<>();
        for (RoutingNode routingNode : routingNodes) {
            assertThat(routingNode.numberOfShardsWithState(STARTED), equalTo(0));
            assertThat(routingNode.size(), equalTo(2));
            // make sure we still have 2 shards initializing per node on the only 25 nodes
            int nodeIndex = Integer.parseInt(routingNode.nodeId().substring(""node"".length()));
            assertThat(nodeIndex, lessThan(25));
            // check that we don't have a shard associated with a node with the same index name (we have a single shard)
            for (ShardRouting shardRoutingEntry : routingNode) {
                assertThat(encounteredIndices, not(hasItem(shardRoutingEntry.getIndexName())));
                encounteredIndices.add(shardRoutingEntry.getIndexName());
            }
        }

        logger.info(""Adding additional "" + (numberOfIndices / 2) + "" nodes, nothing should change"");
        nodesBuilder = DiscoveryNodes.builder(clusterState.nodes());
        for (int i = (numberOfIndices / 2); i < numberOfIndices; i++) {
            nodesBuilder.add(newNode(""node"" + i));
        }
        clusterState = ClusterState.builder(clusterState).nodes(nodesBuilder).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(routingResult.changed(), equalTo(false));

        logger.info(""Marking the shard as started"");
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(routingResult.changed(), equalTo(true));
        int numberOfRelocatingShards = 0;
        int numberOfStartedShards = 0;
        for (int i = 0; i < numberOfIndices; i++) {
            assertThat(clusterState.routingTable().index(""test"" + i).shards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).unassigned(), equalTo(false));
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).state(), anyOf(equalTo(STARTED), equalTo(RELOCATING)));
            if (clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).state() == STARTED) {
                numberOfStartedShards++;
            } else if (clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).state() == RELOCATING) {
                numberOfRelocatingShards++;
            }
            assertThat(clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).primary(), equalTo(true));
            // make sure we still have 2 shards either relocating or started on the first 25 nodes (still)
            String nodeId = clusterState.routingTable().index(""test"" + i).shard(0).shards().get(0).currentNodeId();
            int nodeIndex = Integer.parseInt(nodeId.substring(""node"".length()));
            assertThat(nodeIndex, lessThan(25));
        }
        assertThat(numberOfRelocatingShards, equalTo(25));
        assertThat(numberOfStartedShards, equalTo(25));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/SingleShardNoReplicasRoutingTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,484,"public void testRebalanceFailure() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(2).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info(""Adding two nodes and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        logger.info(""Start the shards (primaries)"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(2));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().currentNodeId(), anyOf(equalTo(""node1""), equalTo(""node2"")));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).currentNodeId(), anyOf(equalTo(""node2""), equalTo(""node1"")));
        }

        logger.info(""Start the shards (backups)"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(2));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().currentNodeId(), anyOf(equalTo(""node1""), equalTo(""node2"")));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).currentNodeId(), anyOf(equalTo(""node2""), equalTo(""node1"")));
        }

        logger.info(""Adding third node and reroute"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node3""))).build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(2));
        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED, RELOCATING), equalTo(2));
        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), lessThan(3));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED, RELOCATING), equalTo(2));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), lessThan(3));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(INITIALIZING), equalTo(1));


        logger.info(""Fail the shards on node 3"");
        ShardRouting shardToFail = routingNodes.node(""node3"").iterator().next();
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyFailedShard(clusterState, shardToFail).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(2));
        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED, RELOCATING), equalTo(2));
        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), lessThan(3));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED, RELOCATING), equalTo(2));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), lessThan(3));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(INITIALIZING), equalTo(1));
        // make sure the failedShard is not INITIALIZING again on node3
        assertThat(routingNodes.node(""node3"").iterator().next().shardId(), not(equalTo(shardToFail.shardId())));
    }","public void testRebalanceFailure() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(2).numberOfReplicas(1))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        logger.info(""Adding two nodes and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""Start the shards (primaries)"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(2));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().currentNodeId(), anyOf(equalTo(""node1""), equalTo(""node2"")));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).currentNodeId(), anyOf(equalTo(""node2""), equalTo(""node1"")));
        }

        logger.info(""Start the shards (backups)"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(2));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().currentNodeId(), anyOf(equalTo(""node1""), equalTo(""node2"")));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).currentNodeId(), anyOf(equalTo(""node2""), equalTo(""node1"")));
        }

        logger.info(""Adding third node and reroute"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node3""))).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(2));
        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED, RELOCATING), equalTo(2));
        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), lessThan(3));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED, RELOCATING), equalTo(2));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), lessThan(3));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(INITIALIZING), equalTo(1));


        logger.info(""Fail the shards on node 3"");
        ShardRouting shardToFail = routingNodes.node(""node3"").iterator().next();
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyFailedShard(clusterState, shardToFail);
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(2));
        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED, RELOCATING), equalTo(2));
        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), lessThan(3));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED, RELOCATING), equalTo(2));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), lessThan(3));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(INITIALIZING), equalTo(1));
        // make sure the failedShard is not INITIALIZING again on node3
        assertThat(routingNodes.node(""node3"").iterator().next().shardId(), not(equalTo(shardToFail.shardId())));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/FailedShardsRoutingTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,303,"public void testEnableClusterBalanceNoReplicas() {
        final boolean useClusterSetting = randomBoolean();
        Settings build = Settings.builder()
                .put(CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), useClusterSetting ? Rebalance.NONE: RandomPicks.randomFrom(random(), Rebalance.values())) // index settings override cluster settings
                .put(ConcurrentRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_CLUSTER_CONCURRENT_REBALANCE_SETTING.getKey(), 3)
                .build();
        ClusterSettings clusterSettings = new ClusterSettings(build, ClusterSettings.BUILT_IN_CLUSTER_SETTINGS);
        AllocationService strategy = createAllocationService(build, clusterSettings, random());
        Settings indexSettings = useClusterSetting ? Settings.EMPTY : Settings.builder().put(EnableAllocationDecider.INDEX_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), Rebalance.NONE).build();

        logger.info(""Building initial routing table"");
        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT).put(indexSettings)).numberOfShards(6).numberOfReplicas(0))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info(""--> adding one nodes and do rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
                .add(newNode(""node1""))
                .add(newNode(""node2""))
        ).build();
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        assertThat(clusterState.getRoutingNodes().shardsWithState(INITIALIZING).size(), equalTo(6));
        logger.info(""--> start the shards (primaries)"");
        routingTable = strategy.applyStartedShards(clusterState, clusterState.getRoutingNodes().shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        assertThat(clusterState.getRoutingNodes().shardsWithState(STARTED).size(), equalTo(6));
        assertThat(clusterState.getRoutingNodes().shardsWithState(INITIALIZING).size(), equalTo(0));

        logger.info(""--> adding one nodes and do rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
                .add(newNode(""node1""))
                .add(newNode(""node2""))
                .add(newNode(""node3""))
        ).build();
        ClusterState prevState = clusterState;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        assertThat(clusterState.getRoutingNodes().shardsWithState(STARTED).size(), equalTo(6));
        assertThat(clusterState.getRoutingNodes().shardsWithState(RELOCATING).size(), equalTo(0));
        if (useClusterSetting) {
            prevState = clusterState;
            clusterState = ClusterState.builder(clusterState).metaData(MetaData.builder(metaData).transientSettings(Settings.builder()
                    .put(CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), randomBoolean() ? Rebalance.PRIMARIES : Rebalance.ALL)
                    .build())).build();
        } else {
            prevState = clusterState;
            IndexMetaData meta = clusterState.getMetaData().index(""test"");
            clusterState = ClusterState.builder(clusterState).metaData(MetaData.builder(metaData).removeAllIndices()
                    .put(IndexMetaData.builder(meta).settings(Settings.builder().put(meta.getSettings()).put(EnableAllocationDecider.INDEX_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), randomBoolean() ? Rebalance.PRIMARIES : Rebalance.ALL).build()))).build();
        }
        clusterSettings.applySettings(clusterState.metaData().settings());
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        assertThat(""expected 4 primaries to be started and 2 to relocate useClusterSettings: "" + useClusterSetting, clusterState.getRoutingNodes().shardsWithState(STARTED).size(), equalTo(4));
        assertThat(""expected 2 primaries to relocate useClusterSettings: "" + useClusterSetting, clusterState.getRoutingNodes().shardsWithState(RELOCATING).size(), equalTo(2));

    }","public void testEnableClusterBalanceNoReplicas() {
        final boolean useClusterSetting = randomBoolean();
        Settings build = Settings.builder()
                .put(CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), useClusterSetting ? Rebalance.NONE: RandomPicks.randomFrom(random(), Rebalance.values())) // index settings override cluster settings
                .put(ConcurrentRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_CLUSTER_CONCURRENT_REBALANCE_SETTING.getKey(), 3)
                .build();
        ClusterSettings clusterSettings = new ClusterSettings(build, ClusterSettings.BUILT_IN_CLUSTER_SETTINGS);
        AllocationService strategy = createAllocationService(build, clusterSettings, random());
        Settings indexSettings = useClusterSetting ? Settings.EMPTY : Settings.builder().put(EnableAllocationDecider.INDEX_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), Rebalance.NONE).build();

        logger.info(""Building initial routing table"");
        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT).put(indexSettings)).numberOfShards(6).numberOfReplicas(0))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        logger.info(""--> adding one nodes and do rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
                .add(newNode(""node1""))
                .add(newNode(""node2""))
        ).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        assertThat(clusterState.getRoutingNodes().shardsWithState(INITIALIZING).size(), equalTo(6));
        logger.info(""--> start the shards (primaries)"");
        routingResult = strategy.applyStartedShards(clusterState, clusterState.getRoutingNodes().shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        assertThat(clusterState.getRoutingNodes().shardsWithState(STARTED).size(), equalTo(6));
        assertThat(clusterState.getRoutingNodes().shardsWithState(INITIALIZING).size(), equalTo(0));

        logger.info(""--> adding one nodes and do rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
                .add(newNode(""node1""))
                .add(newNode(""node2""))
                .add(newNode(""node3""))
        ).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        assertThat(clusterState.getRoutingNodes().shardsWithState(STARTED).size(), equalTo(6));
        assertThat(clusterState.getRoutingNodes().shardsWithState(RELOCATING).size(), equalTo(0));
        metaData = clusterState.metaData();
        if (useClusterSetting) {
            clusterState = ClusterState.builder(clusterState).metaData(MetaData.builder(metaData).transientSettings(Settings.builder()
                    .put(CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), randomBoolean() ? Rebalance.PRIMARIES : Rebalance.ALL)
                    .build())).build();
        } else {
            IndexMetaData meta = clusterState.getMetaData().index(""test"");
            clusterState = ClusterState.builder(clusterState).metaData(MetaData.builder(metaData).removeAllIndices()
                    .put(IndexMetaData.builder(meta).settings(Settings.builder().put(meta.getSettings()).put(EnableAllocationDecider.INDEX_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), randomBoolean() ? Rebalance.PRIMARIES : Rebalance.ALL).build()))).build();
        }
        clusterSettings.applySettings(clusterState.metaData().settings());
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        assertThat(""expected 4 primaries to be started and 2 to relocate useClusterSettings: "" + useClusterSetting, clusterState.getRoutingNodes().shardsWithState(STARTED).size(), equalTo(4));
        assertThat(""expected 2 primaries to relocate useClusterSettings: "" + useClusterSetting, clusterState.getRoutingNodes().shardsWithState(RELOCATING).size(), equalTo(2));

    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/EnableAllocationTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,174,"public void testReplicaAndPrimaryRecoveryThrottling() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 3)
                .put(""cluster.routing.allocation.concurrent_source_recoveries"", 3)
                .put(""cluster.routing.allocation.node_initial_primaries_recoveries"", 3)
                .build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(5).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = createRecoveryRoutingTable(metaData.index(""test""));

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info(""start one node, do reroute, only 3 should initialize"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1""))).build();
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(0));
        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(3));
        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(7));

        logger.info(""start initializing, another 2 should initialize"");
        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(3));
        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(2));
        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(5));

        logger.info(""start initializing, all primaries should be started"");
        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(5));
        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(0));
        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(5));

        logger.info(""start another node, replicas should start being allocated"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node2""))).build();
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(5));
        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(3));
        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(2));

        logger.info(""start initializing replicas"");
        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(8));
        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(2));
        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(0));

        logger.info(""start initializing replicas, all should be started"");
        routingTable = strategy.applyStartedShards(clusterState, routingTable.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(10));
        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(0));
        assertThat(routingTable.shardsWithState(UNASSIGNED).size(), equalTo(0));
    }","public void testReplicaAndPrimaryRecoveryThrottling() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 3)
                .put(""cluster.routing.allocation.concurrent_source_recoveries"", 3)
                .put(""cluster.routing.allocation.node_initial_primaries_recoveries"", 3)
                .build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(5).numberOfReplicas(1))
                .build();

        RoutingTable initialRoutingTable = createRecoveryRoutingTable(metaData.index(""test""));

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        logger.info(""start one node, do reroute, only 3 should initialize"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1""))).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(0));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(3));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(7));

        logger.info(""start initializing, another 2 should initialize"");
        routingResult = strategy.applyStartedShards(clusterState, clusterState.routingTable().shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(3));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(2));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(5));

        logger.info(""start initializing, all primaries should be started"");
        routingResult = strategy.applyStartedShards(clusterState, clusterState.routingTable().shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(5));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(0));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(5));

        logger.info(""start another node, replicas should start being allocated"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node2""))).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(5));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(3));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(2));

        logger.info(""start initializing replicas"");
        routingResult = strategy.applyStartedShards(clusterState, clusterState.routingTable().shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(8));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(2));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(0));

        logger.info(""start initializing replicas, all should be started"");
        routingResult = strategy.applyStartedShards(clusterState, clusterState.routingTable().shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(10));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(0));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(0));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/ThrottlingAllocationTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,267,"public void testFirstAllocationFailureSingleNode() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info(""Adding single node and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1""))).build();
        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().currentNodeId(), equalTo(""node1""));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""fail the first shard, will have no place to be rerouted to (single node), so stays unassigned"");
        prevRoutingTable = routingTable;
        ShardRouting firstShard = clusterState.getRoutingNodes().node(""node1"").iterator().next();
        routingTable = strategy.applyFailedShard(clusterState, firstShard).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(UNASSIGNED));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().currentNodeId(), nullValue());
            assertThat(routingTable.index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }
    }","public void testFirstAllocationFailureSingleNode() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        logger.info(""Adding single node and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1""))).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().currentNodeId(), equalTo(""node1""));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""fail the first shard, will have no place to be rerouted to (single node), so stays unassigned"");
        ShardRouting firstShard = clusterState.getRoutingNodes().node(""node1"").iterator().next();
        routingResult = strategy.applyFailedShard(clusterState, firstShard);
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(UNASSIGNED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().currentNodeId(), nullValue());
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/FailedShardsRoutingTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,89,"public void testPrimaryNotRelocatedWhileBeingRecoveredFrom() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(""cluster.routing.allocation.concurrent_source_recoveries"", 10)
                .put(""cluster.routing.allocation.node_initial_primaries_recoveries"", 10)
                .build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(5).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info(""Adding two nodes and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1""))).build();
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        logger.info(""Start the primary shard (on node1)"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.node(""node1"").shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(5));

        logger.info(""start another node, replica will start recovering form primary"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node2""))).build();
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(5));
        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(5));

        logger.info(""start another node, make sure the primary is not relocated"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node3""))).build();
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(5));
        assertThat(routingTable.shardsWithState(INITIALIZING).size(), equalTo(5));
    }","public void testPrimaryNotRelocatedWhileBeingRecoveredFrom() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(""cluster.routing.allocation.concurrent_source_recoveries"", 10)
                .put(""cluster.routing.allocation.node_initial_primaries_recoveries"", 10)
                .build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(5).numberOfReplicas(1))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        logger.info(""Adding two nodes and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1""))).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""Start the primary shard (on node1)"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.node(""node1"").shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(5));

        logger.info(""start another node, replica will start recovering form primary"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node2""))).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(5));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(5));

        logger.info(""start another node, make sure the primary is not relocated"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node3""))).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(5));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(5));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/PrimaryNotRelocatedWhileBeingRecoveredTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,286,"public void testBalanceIncrementallyStartNodes() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(""cluster.routing.allocation.node_initial_primaries_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .put(""cluster.routing.allocation.cluster_concurrent_rebalance"", -1).build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder().put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(3).numberOfReplicas(1))
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)).numberOfShards(3).numberOfReplicas(1)).build();

        RoutingTable routingTable = RoutingTable.builder().addAsNew(metaData.index(""test"")).addAsNew(metaData.index(""test1"")).build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        assertThat(routingTable.index(""test"").shards().size(), equalTo(3));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).shards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(routingTable.index(""test"").shard(i).shards().get(1).state(), equalTo(UNASSIGNED));
            assertThat(routingTable.index(""test"").shard(i).shards().get(0).currentNodeId(), nullValue());
            assertThat(routingTable.index(""test"").shard(i).shards().get(1).currentNodeId(), nullValue());
        }

        assertThat(routingTable.index(""test1"").shards().size(), equalTo(3));
        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).shards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(routingTable.index(""test1"").shard(i).shards().get(1).state(), equalTo(UNASSIGNED));
            assertThat(routingTable.index(""test1"").shard(i).shards().get(0).currentNodeId(), nullValue());
            assertThat(routingTable.index(""test1"").shard(i).shards().get(1).currentNodeId(), nullValue());
        }

        logger.info(""Adding one node and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1""))).build();

        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(3));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).currentNodeId(), nullValue());
        }

        logger.info(""Add another node and perform rerouting, nothing will happen since primary not started"");
        clusterState = ClusterState.builder(clusterState)
                .nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node2""))).build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable == routingTable, equalTo(true));

        logger.info(""Start the primary shard"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(3));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().size(), equalTo(1));
            // backup shards are initializing as well, we make sure that they
            // recover from primary *started* shards in the
            // IndicesClusterStateService
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        logger.info(""Reroute, nothing should change"");
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        assertThat(prevRoutingTable == routingTable, equalTo(true));

        logger.info(""Start the backup shard"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(3));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test1"").shards().size(), equalTo(3));
        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        logger.info(""Add another node and perform rerouting, nothing will happen since primary not started"");
        clusterState = ClusterState.builder(clusterState)
                .nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node3""))).build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));

        logger.info(""Reroute, nothing should change"");
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        assertThat(prevRoutingTable == routingTable, equalTo(true));

        logger.info(""Start the backup shard"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(3));

        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test1"").shards().size(), equalTo(3));

        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), equalTo(4));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), equalTo(4));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(STARTED), equalTo(4));

        assertThat(routingNodes.node(""node1"").shardsWithState(""test"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node2"").shardsWithState(""test"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node3"").shardsWithState(""test"", STARTED).size(), equalTo(2));

        assertThat(routingNodes.node(""node1"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node2"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node3"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
    }","public void testBalanceIncrementallyStartNodes() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(""cluster.routing.allocation.node_initial_primaries_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .put(""cluster.routing.allocation.cluster_concurrent_rebalance"", -1).build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder().put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(3).numberOfReplicas(1))
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)).numberOfShards(3).numberOfReplicas(1)).build();

        RoutingTable initialRoutingTable = RoutingTable.builder().addAsNew(metaData.index(""test"")).addAsNew(metaData.index(""test1"")).build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(3));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(1).state(), equalTo(UNASSIGNED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(0).currentNodeId(), nullValue());
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(1).currentNodeId(), nullValue());
        }

        assertThat(clusterState.routingTable().index(""test1"").shards().size(), equalTo(3));
        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().get(1).state(), equalTo(UNASSIGNED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().get(0).currentNodeId(), nullValue());
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().get(1).currentNodeId(), nullValue());
        }

        logger.info(""Adding one node and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1""))).build();

        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(3));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).currentNodeId(), nullValue());
        }

        logger.info(""Add another node and perform rerouting, nothing will happen since primary not started"");
        clusterState = ClusterState.builder(clusterState)
                .nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node2""))).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertFalse(routingResult.changed());

        logger.info(""Start the primary shard"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(3));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().size(), equalTo(1));
            // backup shards are initializing as well, we make sure that they
            // recover from primary *started* shards in the
            // IndicesClusterStateService
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        logger.info(""Reroute, nothing should change"");
        routingResult = strategy.reroute(clusterState, ""reroute"");
        assertFalse(routingResult.changed());

        logger.info(""Start the backup shard"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(3));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }
        assertThat(clusterState.routingTable().index(""test1"").shards().size(), equalTo(3));
        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
        }

        logger.info(""Add another node and perform rerouting, nothing will happen since primary not started"");
        clusterState = ClusterState.builder(clusterState)
                .nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node3""))).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertTrue(routingResult.changed());

        logger.info(""Reroute, nothing should change"");
        routingResult = strategy.reroute(clusterState, ""reroute"");
        assertFalse(routingResult.changed());

        logger.info(""Start the backup shard"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(3));

        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test1"").shards().size(), equalTo(3));

        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), equalTo(4));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), equalTo(4));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(STARTED), equalTo(4));

        assertThat(routingNodes.node(""node1"").shardsWithState(""test"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node2"").shardsWithState(""test"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node3"").shardsWithState(""test"", STARTED).size(), equalTo(2));

        assertThat(routingNodes.node(""node1"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node2"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node3"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/IndexBalanceTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,87,"public void testSingleIndexStartedShard() {
        AllocationService strategy = createAllocationService(Settings.builder().put(""cluster.routing.allocation.node_concurrent_recoveries"", 10).build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(0))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).state(), equalTo(UNASSIGNED));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).currentNodeId(), nullValue());

        logger.info(""Adding one node and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1""))).build();
        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).state(), equalTo(INITIALIZING));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).currentNodeId(), equalTo(""node1""));

        logger.info(""Rerouting again, nothing should change"");
        prevRoutingTable = routingTable;
        clusterState = ClusterState.builder(clusterState).build();
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        assertThat(routingTable == prevRoutingTable, equalTo(true));
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        logger.info(""Marking the shard as started"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.node(""node1"").shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(routingTable != prevRoutingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).state(), equalTo(STARTED));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).currentNodeId(), equalTo(""node1""));

        logger.info(""Starting another node and making sure nothing changed"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node2""))).build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(routingTable == prevRoutingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).state(), equalTo(STARTED));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).currentNodeId(), equalTo(""node1""));

        logger.info(""Killing node1 where the shard is, checking the shard is relocated"");

        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).remove(""node1"")).build();
        prevRoutingTable = routingTable;
        routingTable = strategy.deassociateDeadNodes(clusterState, true, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(routingTable != prevRoutingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).state(), equalTo(INITIALIZING));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).currentNodeId(), equalTo(""node2""));

        logger.info(""Start another node, make sure that things remain the same (shard is in node2 and initializing)"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node3""))).build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        assertThat(routingTable == prevRoutingTable, equalTo(true));

        logger.info(""Start the shard on node 2"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.node(""node2"").shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(routingTable != prevRoutingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).state(), equalTo(STARTED));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).currentNodeId(), equalTo(""node2""));
    }","public void testSingleIndexStartedShard() {
        AllocationService strategy = createAllocationService(Settings.builder().put(""cluster.routing.allocation.node_concurrent_recoveries"", 10).build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(0))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder().addAsNew(metaData.index(""test"")).build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().get(0).state(), equalTo(UNASSIGNED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().get(0).currentNodeId(), nullValue());

        logger.info(""Adding one node and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1""))).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().get(0).state(), equalTo(INITIALIZING));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().get(0).currentNodeId(), equalTo(""node1""));

        logger.info(""Rerouting again, nothing should change"");
        clusterState = ClusterState.builder(clusterState).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        assertThat(routingResult.changed(), equalTo(false));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""Marking the shard as started"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.node(""node1"").shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(routingResult.changed(), equalTo(true));
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().get(0).state(), equalTo(STARTED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().get(0).currentNodeId(), equalTo(""node1""));

        logger.info(""Starting another node and making sure nothing changed"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node2""))).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(routingResult.changed(), equalTo(false));
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().get(0).state(), equalTo(STARTED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().get(0).currentNodeId(), equalTo(""node1""));

        logger.info(""Killing node1 where the shard is, checking the shard is relocated"");

        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).remove(""node1"")).build();
        routingResult = strategy.deassociateDeadNodes(clusterState, true, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(routingResult.changed(), equalTo(true));
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().get(0).state(), equalTo(INITIALIZING));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().get(0).currentNodeId(), equalTo(""node2""));

        logger.info(""Start another node, make sure that things remain the same (shard is in node2 and initializing)"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node3""))).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        assertThat(routingResult.changed(), equalTo(false));

        logger.info(""Start the shard on node 2"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.node(""node2"").shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertThat(routingResult.changed(), equalTo(true));
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().get(0).state(), equalTo(STARTED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().get(0).currentNodeId(), equalTo(""node2""));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/SingleShardNoReplicasRoutingTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,366,"int numberOfReplicas) {
        MetaData.Builder metaDataBuilder = MetaData.builder(clusterState.getMetaData());
        RoutingTable.Builder routingTableBuilder = RoutingTable.builder(clusterState.routingTable());

        IndexMetaData.Builder index = IndexMetaData.builder(""test"" + indexOrdinal).settings(settings(Version.CURRENT)).numberOfShards(numberOfShards).numberOfReplicas(
                numberOfReplicas);
        IndexMetaData imd = index.build();
        metaDataBuilder = metaDataBuilder.put(imd, true);
        routingTableBuilder.addAsNew(imd);

        MetaData metaData = metaDataBuilder.build();
        RoutingTable routingTable = routingTableBuilder.build();
        clusterState = ClusterState.builder(clusterState).metaData(metaData).routingTable(routingTable).build();
        routingTable = service.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        RoutingNodes routingNodes = clusterState.getRoutingNodes();

        logger.info(""restart all the primary shards, replicas will start initializing"");
        routingNodes = clusterState.getRoutingNodes();
        routingTable = service.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        logger.info(""start the replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        routingTable = service.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        logger.info(""complete rebalancing"");
        RoutingTable prev = routingTable;
        while (true) {
            logger.debug(""ClusterState: {}"", clusterState.getRoutingNodes().prettyPrint());
            routingTable = service.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
            clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
            routingNodes = clusterState.getRoutingNodes();
            if (routingTable == prev)
                break;
            prev = routingTable;
        }

        return clusterState;
    }","private ClusterState removeNodes(ClusterState clusterState, AllocationService service, int numNodes) {
        logger.info(""Removing [{}] nodes"", numNodes);
        DiscoveryNodes.Builder nodes = DiscoveryNodes.builder(clusterState.nodes());
        ArrayList<DiscoveryNode> discoveryNodes = CollectionUtils.iterableAsArrayList(clusterState.nodes());
        Collections.shuffle(discoveryNodes, random());
        for (DiscoveryNode node : discoveryNodes) {
            nodes.remove(node.getId());
            numNodes--;
            if (numNodes <= 0) {
                break;
            }
        }

        clusterState = ClusterState.builder(clusterState).nodes(nodes.build()).build();
        clusterState = ClusterState.builder(clusterState)
            .routingResult(service.deassociateDeadNodes(clusterState, true, ""reroute"")).build();

        logger.info(""start all the primary shards, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        RoutingAllocation.Result routingResult = service.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""start the replica shards"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = service.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""rebalancing"");
        routingResult = service.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""complete rebalancing"");
        clusterState = applyStartedShardsUntilNoChange(clusterState, service);

        return clusterState;
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AddIncrementallyTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,154,"public void testBalanceIncrementallyStartNodes() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(""cluster.routing.allocation.node_initial_primaries_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .put(""cluster.routing.allocation.cluster_concurrent_rebalance"", -1).build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder().put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(3).numberOfReplicas(1))
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)).numberOfShards(3).numberOfReplicas(1)).build();

        RoutingTable routingTable = RoutingTable.builder().addAsNew(metaData.index(""test"")).addAsNew(metaData.index(""test1"")).build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info(""Adding one node and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1""))).build();

        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        logger.info(""Add another node and perform rerouting, nothing will happen since primary not started"");
        clusterState = ClusterState.builder(clusterState)
                .nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node2""))).build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        logger.info(""Start the primary shard"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        logger.info(""Reroute, nothing should change"");
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();

        logger.info(""Start the backup shard"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        logger.info(""Add another node and perform rerouting, nothing will happen since primary not started"");
        clusterState = ClusterState.builder(clusterState)
                .nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node3""))).build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        logger.info(""Reroute, nothing should change"");
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();

        logger.info(""Start the backup shard"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(3));

        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test1"").shards().size(), equalTo(3));

        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), equalTo(4));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), equalTo(4));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(STARTED), equalTo(4));

        assertThat(routingNodes.node(""node1"").shardsWithState(""test"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node2"").shardsWithState(""test"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node3"").shardsWithState(""test"", STARTED).size(), equalTo(2));

        assertThat(routingNodes.node(""node1"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node2"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node3"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
    }","public void testBalanceIncrementallyStartNodes() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(""cluster.routing.allocation.node_initial_primaries_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .put(""cluster.routing.allocation.cluster_concurrent_rebalance"", -1).build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder().put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(3).numberOfReplicas(1))
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)).numberOfShards(3).numberOfReplicas(1)).build();

        RoutingTable initialRoutingTable = RoutingTable.builder().addAsNew(metaData.index(""test"")).addAsNew(metaData.index(""test1"")).build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        logger.info(""Adding one node and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1""))).build();

        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""Add another node and perform rerouting, nothing will happen since primary not started"");
        clusterState = ClusterState.builder(clusterState)
                .nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node2""))).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""Start the primary shard"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""Reroute, nothing should change"");
        routingResult = strategy.reroute(clusterState, ""reroute"");

        logger.info(""Start the backup shard"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        logger.info(""Add another node and perform rerouting, nothing will happen since primary not started"");
        clusterState = ClusterState.builder(clusterState)
                .nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node3""))).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""Reroute, nothing should change"");
        routingResult = strategy.reroute(clusterState, ""reroute"");
        assertFalse(routingResult.changed());

        logger.info(""Start the backup shard"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(3));

        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test1"").shards().size(), equalTo(3));

        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), equalTo(4));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), equalTo(4));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(STARTED), equalTo(4));

        assertThat(routingNodes.node(""node1"").shardsWithState(""test"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node2"").shardsWithState(""test"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node3"").shardsWithState(""test"", STARTED).size(), equalTo(2));

        assertThat(routingNodes.node(""node1"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node2"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node3"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/RoutingNodesIntegrityTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,220,"private ClusterState removeNodes(ClusterState clusterState, AllocationService strategy) {
        logger.info(""Removing half the nodes ("" + (numberOfNodes + 1) / 2 + "")"");
        DiscoveryNodes.Builder nodes = DiscoveryNodes.builder(clusterState.nodes());

        boolean removed = false;
        for (int i = (numberOfNodes + 1) / 2; i <= numberOfNodes; i++) {
            nodes.remove(""node"" + i);
            removed = true;
        }

        clusterState = ClusterState.builder(clusterState).nodes(nodes.build()).build();
        if (removed) {
            clusterState = ClusterState.builder(clusterState).routingResult(
                strategy.deassociateDeadNodes(clusterState, randomBoolean(), ""removed nodes"")
            ).build();
        }
        RoutingNodes routingNodes = clusterState.getRoutingNodes();

        logger.info(""start all the primary shards, replicas will start initializing"");
        RoutingTable routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        logger.info(""start the replica shards"");
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        logger.info(""rebalancing"");
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        logger.info(""complete rebalancing"");
        RoutingTable prev = routingTable;
        while (true) {
            routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
            clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
            routingNodes = clusterState.getRoutingNodes();
            if (routingTable == prev)
                break;
            prev = routingTable;
        }

        return clusterState;
    }","private void assertIndexBalance(RoutingTable routingTable, RoutingNodes nodes, int numberOfNodes, int numberOfIndices, int numberOfReplicas, int numberOfShards, float treshold) {

        final int numShards = numberOfShards * (numberOfReplicas + 1);
        final float avgNumShards = (float) (numShards) / (float) (numberOfNodes);
        final int minAvgNumberOfShards = Math.round(Math.round(Math.floor(avgNumShards - treshold)));
        final int maxAvgNumberOfShards = Math.round(Math.round(Math.ceil(avgNumShards + treshold)));

        for (ObjectCursor<String> index : routingTable.indicesRouting().keys()) {
            for (RoutingNode node : nodes) {
//              logger.info(node.nodeId() +"":""+index+ "": "" + node.shardsWithState(index, INITIALIZING, STARTED).size() + "" shards (""+minAvgNumberOfShards+"" to ""+maxAvgNumberOfShards+"")"");
                assertThat(node.shardsWithState(index.value, STARTED).size(), Matchers.greaterThanOrEqualTo(minAvgNumberOfShards));
                assertThat(node.shardsWithState(index.value, STARTED).size(), Matchers.lessThanOrEqualTo(maxAvgNumberOfShards));
            }
        }
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/BalanceConfigurationTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,216,"public void testFailPrimaryStartedCheckReplicaElected() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info(""Adding two nodes and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        logger.info(""Start the shards (primaries)"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();

        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().currentNodeId(), anyOf(equalTo(""node1""), equalTo(""node2"")));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).currentNodeId(), anyOf(equalTo(""node2""), equalTo(""node1"")));
        }

        logger.info(""Start the shards (backups)"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().currentNodeId(), anyOf(equalTo(""node1""), equalTo(""node2"")));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).currentNodeId(), anyOf(equalTo(""node2""), equalTo(""node1"")));
        }

        logger.info(""fail the primary shard, will have no place to be rerouted to (single node), so stays unassigned"");
        ShardRouting shardToFail = routingTable.index(""test"").shard(0).primaryShard();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyFailedShard(clusterState, shardToFail).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().currentNodeId(), not(equalTo(shardToFail.currentNodeId())));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().state(), equalTo(STARTED));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().currentNodeId(), anyOf(equalTo(""node1""), equalTo(""node2"")));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().get(0).state(), equalTo(UNASSIGNED));
    }","public void testFailPrimaryStartedCheckReplicaElected() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        logger.info(""Adding two nodes and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        logger.info(""Start the shards (primaries)"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();

        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().currentNodeId(), anyOf(equalTo(""node1""), equalTo(""node2"")));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).currentNodeId(), anyOf(equalTo(""node2""), equalTo(""node1"")));
        }

        logger.info(""Start the shards (backups)"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().currentNodeId(), anyOf(equalTo(""node1""), equalTo(""node2"")));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).currentNodeId(), anyOf(equalTo(""node2""), equalTo(""node1"")));
        }

        logger.info(""fail the primary shard, will have no place to be rerouted to (single node), so stays unassigned"");
        ShardRouting shardToFail = clusterState.routingTable().index(""test"").shard(0).primaryShard();
        routingResult = strategy.applyFailedShard(clusterState, shardToFail);
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shard(0).size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().currentNodeId(), not(equalTo(shardToFail.currentNodeId())));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().state(), equalTo(STARTED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().currentNodeId(), anyOf(equalTo(""node1""), equalTo(""node2"")));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().get(0).state(), equalTo(UNASSIGNED));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/FailedShardsRoutingTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,115,"public void testClusterConcurrentRebalance() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(""cluster.routing.allocation.cluster_concurrent_rebalance"", 3)
                .build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(5).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        assertThat(routingTable.index(""test"").shards().size(), equalTo(5));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).shards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(routingTable.index(""test"").shard(i).shards().get(1).state(), equalTo(UNASSIGNED));
            assertThat(routingTable.index(""test"").shard(i).shards().get(0).currentNodeId(), nullValue());
            assertThat(routingTable.index(""test"").shard(i).shards().get(1).currentNodeId(), nullValue());
        }

        logger.info(""start two nodes and fully start the shards"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        logger.info(""now, start 8 more nodes, and check that no rebalancing/relocation have happened"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode(""node3"")).add(newNode(""node4"")).add(newNode(""node5"")).add(newNode(""node6"")).add(newNode(""node7"")).add(newNode(""node8"")).add(newNode(""node9"")).add(newNode(""node10"")))
                .build();
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        logger.info(""start the replica shards, rebalancing should start, but, only 3 should be rebalancing"");
        routingNodes = clusterState.getRoutingNodes();
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        // we only allow one relocation at a time
        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(7));
        assertThat(routingTable.shardsWithState(RELOCATING).size(), equalTo(3));

        logger.info(""finalize this session relocation, 3 more should relocate now"");
        routingNodes = clusterState.getRoutingNodes();
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        // we only allow one relocation at a time
        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(7));
        assertThat(routingTable.shardsWithState(RELOCATING).size(), equalTo(3));

        logger.info(""finalize this session relocation, 2 more should relocate now"");
        routingNodes = clusterState.getRoutingNodes();
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        // we only allow one relocation at a time
        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(8));
        assertThat(routingTable.shardsWithState(RELOCATING).size(), equalTo(2));

        logger.info(""finalize this session relocation, no more relocation"");
        routingNodes = clusterState.getRoutingNodes();
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        // we only allow one relocation at a time
        assertThat(routingTable.shardsWithState(STARTED).size(), equalTo(10));
        assertThat(routingTable.shardsWithState(RELOCATING).size(), equalTo(0));
    }","public void testClusterConcurrentRebalance() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(""cluster.routing.allocation.cluster_concurrent_rebalance"", 3)
                .build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(5).numberOfReplicas(1))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(5));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(1).state(), equalTo(UNASSIGNED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(0).currentNodeId(), nullValue());
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(1).currentNodeId(), nullValue());
        }

        logger.info(""start two nodes and fully start the shards"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""start all the primary shards, replicas will start initializing"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        logger.info(""now, start 8 more nodes, and check that no rebalancing/relocation have happened"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode(""node3"")).add(newNode(""node4"")).add(newNode(""node5"")).add(newNode(""node6"")).add(newNode(""node7"")).add(newNode(""node8"")).add(newNode(""node9"")).add(newNode(""node10"")))
                .build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        logger.info(""start the replica shards, rebalancing should start, but, only 3 should be rebalancing"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        // we only allow one relocation at a time
        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(7));
        assertThat(clusterState.routingTable().shardsWithState(RELOCATING).size(), equalTo(3));

        logger.info(""finalize this session relocation, 3 more should relocate now"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        // we only allow one relocation at a time
        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(7));
        assertThat(clusterState.routingTable().shardsWithState(RELOCATING).size(), equalTo(3));

        logger.info(""finalize this session relocation, 2 more should relocate now"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        // we only allow one relocation at a time
        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(8));
        assertThat(clusterState.routingTable().shardsWithState(RELOCATING).size(), equalTo(2));

        logger.info(""finalize this session relocation, no more relocation"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        // we only allow one relocation at a time
        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(10));
        assertThat(clusterState.routingTable().shardsWithState(RELOCATING).size(), equalTo(0));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/ConcurrentRebalanceRoutingTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,448,"public void testBalanceAllNodesStartedAddIndex() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(""cluster.routing.allocation.node_initial_primaries_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .put(""cluster.routing.allocation.cluster_concurrent_rebalance"", -1).build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder().put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(3).numberOfReplicas(1)).build();

        RoutingTable routingTable = RoutingTable.builder().addAsNew(metaData.index(""test"")).build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        assertThat(routingTable.index(""test"").shards().size(), equalTo(3));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).shards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(routingTable.index(""test"").shard(i).shards().get(1).state(), equalTo(UNASSIGNED));
            assertThat(routingTable.index(""test"").shard(i).shards().get(0).currentNodeId(), nullValue());
            assertThat(routingTable.index(""test"").shard(i).shards().get(1).currentNodeId(), nullValue());
        }

        logger.info(""Adding three node and performing rerouting"");
        clusterState = ClusterState.builder(clusterState)
                .nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2"")).add(newNode(""node3""))).build();

        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(3));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).currentNodeId(), nullValue());
        }

        logger.info(""Another round of rebalancing"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())).build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable == routingTable, equalTo(true));

        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(3));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().size(), equalTo(1));
            // backup shards are initializing as well, we make sure that they
            // recover from primary *started* shards in the
            // IndicesClusterStateService
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        logger.info(""Reroute, nothing should change"");
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        assertThat(prevRoutingTable == routingTable, equalTo(true));

        logger.info(""Start the more shards"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();
        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(3));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().size(), equalTo(1));
        }

        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(prevRoutingTable != routingTable, equalTo(true));

        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), equalTo(2));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), equalTo(2));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(STARTED), equalTo(2));

        assertThat(routingNodes.node(""node1"").shardsWithState(""test"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node2"").shardsWithState(""test"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node3"").shardsWithState(""test"", STARTED).size(), equalTo(2));

        logger.info(""Add new index 3 shards 1 replica"");

        prevRoutingTable = routingTable;
        metaData = MetaData.builder(metaData)
                .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)
                        .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 3)
                        .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 1)
                ))
                .build();
        routingTable = RoutingTable.builder(routingTable)
                .addAsNew(metaData.index(""test1""))
                .build();
        clusterState = ClusterState.builder(clusterState).metaData(metaData).routingTable(routingTable).build();


        assertThat(routingTable.index(""test1"").shards().size(), equalTo(3));

        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test1"").shards().size(), equalTo(3));
        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).currentNodeId(), nullValue());
        }

        logger.info(""Another round of rebalancing"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())).build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable == routingTable, equalTo(true));

        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test1"").shards().size(), equalTo(3));
        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().size(), equalTo(1));
            // backup shards are initializing as well, we make sure that they
            // recover from primary *started* shards in the
            // IndicesClusterStateService
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        logger.info(""Reroute, nothing should change"");
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        assertThat(prevRoutingTable == routingTable, equalTo(true));

        logger.info(""Start the more shards"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();
        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test1"").shards().size(), equalTo(3));
        for (int i = 0; i < routingTable.index(""test1"").shards().size(); i++) {
            assertThat(routingTable.index(""test1"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(routingTable.index(""test1"").shard(i).replicaShards().size(), equalTo(1));
        }

        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.getRoutingNodes();

        assertThat(prevRoutingTable != routingTable, equalTo(true));

        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), equalTo(4));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), equalTo(4));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(STARTED), equalTo(4));

        assertThat(routingNodes.node(""node1"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node2"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node3"").shardsWithState(""test1"", STARTED).size(), equalTo(2));

    }","public void testBalanceAllNodesStartedAddIndex() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(""cluster.routing.allocation.node_initial_primaries_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .put(""cluster.routing.allocation.cluster_concurrent_rebalance"", -1).build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder().put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(3).numberOfReplicas(1)).build();

        RoutingTable initialRoutingTable = RoutingTable.builder().addAsNew(metaData.index(""test"")).build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(3));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(1).state(), equalTo(UNASSIGNED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(0).currentNodeId(), nullValue());
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().get(1).currentNodeId(), nullValue());
        }

        logger.info(""Adding three node and performing rerouting"");
        clusterState = ClusterState.builder(clusterState)
                .nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2"")).add(newNode(""node3""))).build();

        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(3));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).currentNodeId(), nullValue());
        }

        logger.info(""Another round of rebalancing"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertFalse(routingResult.changed());

        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(3));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().size(), equalTo(1));
            // backup shards are initializing as well, we make sure that they
            // recover from primary *started* shards in the
            // IndicesClusterStateService
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        logger.info(""Reroute, nothing should change"");
        routingResult = strategy.reroute(clusterState, ""reroute"");
        assertFalse(routingResult.changed());

        logger.info(""Start the more shards"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();
        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(3));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().size(), equalTo(1));
        }
        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), equalTo(2));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), equalTo(2));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(STARTED), equalTo(2));

        assertThat(routingNodes.node(""node1"").shardsWithState(""test"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node2"").shardsWithState(""test"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node3"").shardsWithState(""test"", STARTED).size(), equalTo(2));

        logger.info(""Add new index 3 shards 1 replica"");

        MetaData updatedMetaData = MetaData.builder(clusterState.metaData())
            .put(IndexMetaData.builder(""test1"").settings(settings(Version.CURRENT)
                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 3)
                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 1)
            ))
            .build();
        RoutingTable updatedRoutingTable = RoutingTable.builder(clusterState.routingTable())
            .addAsNew(updatedMetaData.index(""test1""))
            .build();
        clusterState = ClusterState.builder(clusterState).metaData(updatedMetaData).routingTable(updatedRoutingTable).build();


        assertThat(clusterState.routingTable().index(""test1"").shards().size(), equalTo(3));

        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test1"").shards().size(), equalTo(3));
        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).currentNodeId(), nullValue());
        }

        logger.info(""Another round of rebalancing"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertFalse(routingResult.changed());

        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test1"").shards().size(), equalTo(3));
        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().size(), equalTo(1));
            // backup shards are initializing as well, we make sure that they
            // recover from primary *started* shards in the
            // IndicesClusterStateService
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().get(0).state(), equalTo(INITIALIZING));
        }

        logger.info(""Reroute, nothing should change"");
        routingResult = strategy.reroute(clusterState, ""reroute"");
        assertFalse(routingResult.changed());

        logger.info(""Start the more shards"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        routingNodes = clusterState.getRoutingNodes();
        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test1"").shards().size(), equalTo(3));
        for (int i = 0; i < clusterState.routingTable().index(""test1"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test1"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).primaryShard().state(), equalTo(STARTED));
            assertThat(clusterState.routingTable().index(""test1"").shard(i).replicaShards().size(), equalTo(1));
        }
        assertThat(routingNodes.node(""node1"").numberOfShardsWithState(STARTED), equalTo(4));
        assertThat(routingNodes.node(""node2"").numberOfShardsWithState(STARTED), equalTo(4));
        assertThat(routingNodes.node(""node3"").numberOfShardsWithState(STARTED), equalTo(4));

        assertThat(routingNodes.node(""node1"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node2"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
        assertThat(routingNodes.node(""node3"").shardsWithState(""test1"", STARTED).size(), equalTo(2));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/IndexBalanceTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,220,"public void testEnableClusterBalance() {
        final boolean useClusterSetting = randomBoolean();
        final Rebalance allowedOnes = RandomPicks.randomFrom(random(), EnumSet.of(Rebalance.PRIMARIES, Rebalance.REPLICAS, Rebalance.ALL));
        Settings build = Settings.builder()
                .put(CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), useClusterSetting ? Rebalance.NONE: RandomPicks.randomFrom(random(), Rebalance.values())) // index settings override cluster settings
                .put(ConcurrentRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_CLUSTER_CONCURRENT_REBALANCE_SETTING.getKey(), 3)
                .put(ThrottlingAllocationDecider.CLUSTER_ROUTING_ALLOCATION_NODE_CONCURRENT_OUTGOING_RECOVERIES_SETTING.getKey(), 10)
                .build();
        ClusterSettings clusterSettings = new ClusterSettings(build, ClusterSettings.BUILT_IN_CLUSTER_SETTINGS);
        AllocationService strategy = createAllocationService(build, clusterSettings, random());
        Settings indexSettings = useClusterSetting ? Settings.EMPTY : Settings.builder().put(EnableAllocationDecider.INDEX_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), Rebalance.NONE).build();

        logger.info(""Building initial routing table"");
        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT).put(indexSettings)).numberOfShards(3).numberOfReplicas(1))
                .put(IndexMetaData.builder(""always_disabled"").settings(settings(Version.CURRENT).put(EnableAllocationDecider.INDEX_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), Rebalance.NONE)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .addAsNew(metaData.index(""always_disabled""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info(""--> adding one nodes and do rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
                .add(newNode(""node1""))
                .add(newNode(""node2""))
        ).build();
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        assertThat(clusterState.getRoutingNodes().shardsWithState(INITIALIZING).size(), equalTo(4));
        logger.info(""--> start the shards (primaries)"");
        routingTable = strategy.applyStartedShards(clusterState, clusterState.getRoutingNodes().shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        assertThat(clusterState.getRoutingNodes().shardsWithState(STARTED).size(), equalTo(4));
        assertThat(clusterState.getRoutingNodes().shardsWithState(INITIALIZING).size(), equalTo(4));

        routingTable = strategy.applyStartedShards(clusterState, clusterState.getRoutingNodes().shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        assertThat(clusterState.getRoutingNodes().shardsWithState(STARTED).size(), equalTo(8));
        assertThat(clusterState.getRoutingNodes().shardsWithState(INITIALIZING).size(), equalTo(0));

        logger.info(""--> adding one nodes and do rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
                .add(newNode(""node1""))
                .add(newNode(""node2""))
                .add(newNode(""node3""))
        ).build();
        ClusterState prevState = clusterState;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        assertThat(clusterState.getRoutingNodes().shardsWithState(STARTED).size(), equalTo(8));
        assertThat(clusterState.getRoutingNodes().shardsWithState(RELOCATING).size(), equalTo(0));

        if (useClusterSetting) {
            prevState = clusterState;
            clusterState = ClusterState.builder(clusterState).metaData(MetaData.builder(metaData).transientSettings(Settings.builder()
                .put(CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), allowedOnes)
                .build())).build();
        } else {
            prevState = clusterState;
            IndexMetaData meta = clusterState.getMetaData().index(""test"");
            IndexMetaData meta1 = clusterState.getMetaData().index(""always_disabled"");
            clusterState = ClusterState.builder(clusterState).metaData(MetaData.builder(metaData).removeAllIndices().put(IndexMetaData.builder(meta1))
                    .put(IndexMetaData.builder(meta).settings(Settings.builder().put(meta.getSettings()).put(EnableAllocationDecider.INDEX_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), allowedOnes).build())))
                    .build();

        }
        clusterSettings.applySettings(clusterState.metaData().settings());
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        assertThat(""expected 6 shards to be started 2 to relocate useClusterSettings: "" + useClusterSetting, clusterState.getRoutingNodes().shardsWithState(STARTED).size(), equalTo(6));
        assertThat(""expected 2 shards to relocate useClusterSettings: "" + useClusterSetting, clusterState.getRoutingNodes().shardsWithState(RELOCATING).size(), equalTo(2));
        List<ShardRouting> mutableShardRoutings = clusterState.getRoutingNodes().shardsWithState(RELOCATING);
        switch (allowedOnes) {
            case PRIMARIES:
                for (ShardRouting routing : mutableShardRoutings) {
                    assertTrue(""only primaries are allowed to relocate"", routing.primary());
                    assertThat(""only test index can rebalance"", routing.getIndexName(), equalTo(""test""));
                }
                break;
            case REPLICAS:
                for (ShardRouting routing : mutableShardRoutings) {
                    assertFalse(""only replicas are allowed to relocate"", routing.primary());
                    assertThat(""only test index can rebalance"", routing.getIndexName(), equalTo(""test""));
                }
                break;
            case ALL:
                for (ShardRouting routing : mutableShardRoutings) {
                    assertThat(""only test index can rebalance"", routing.getIndexName(), equalTo(""test""));
                }
                break;
            default:
                fail(""only replicas, primaries or all are allowed"");
        }
        routingTable = strategy.applyStartedShards(clusterState, clusterState.getRoutingNodes().shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        assertThat(clusterState.getRoutingNodes().shardsWithState(STARTED).size(), equalTo(8));
        assertThat(clusterState.getRoutingNodes().shardsWithState(INITIALIZING).size(), equalTo(0));

    }","public void testEnableClusterBalance() {
        final boolean useClusterSetting = randomBoolean();
        final Rebalance allowedOnes = RandomPicks.randomFrom(random(), EnumSet.of(Rebalance.PRIMARIES, Rebalance.REPLICAS, Rebalance.ALL));
        Settings build = Settings.builder()
                .put(CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), useClusterSetting ? Rebalance.NONE: RandomPicks.randomFrom(random(), Rebalance.values())) // index settings override cluster settings
                .put(ConcurrentRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_CLUSTER_CONCURRENT_REBALANCE_SETTING.getKey(), 3)
                .put(ThrottlingAllocationDecider.CLUSTER_ROUTING_ALLOCATION_NODE_CONCURRENT_OUTGOING_RECOVERIES_SETTING.getKey(), 10)
                .build();
        ClusterSettings clusterSettings = new ClusterSettings(build, ClusterSettings.BUILT_IN_CLUSTER_SETTINGS);
        AllocationService strategy = createAllocationService(build, clusterSettings, random());
        Settings indexSettings = useClusterSetting ? Settings.EMPTY : Settings.builder().put(EnableAllocationDecider.INDEX_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), Rebalance.NONE).build();

        logger.info(""Building initial routing table"");
        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT).put(indexSettings)).numberOfShards(3).numberOfReplicas(1))
                .put(IndexMetaData.builder(""always_disabled"").settings(settings(Version.CURRENT).put(EnableAllocationDecider.INDEX_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), Rebalance.NONE)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .addAsNew(metaData.index(""always_disabled""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        logger.info(""--> adding one nodes and do rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
                .add(newNode(""node1""))
                .add(newNode(""node2""))
        ).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        assertThat(clusterState.getRoutingNodes().shardsWithState(INITIALIZING).size(), equalTo(4));
        logger.info(""--> start the shards (primaries)"");
        routingResult = strategy.applyStartedShards(clusterState, clusterState.getRoutingNodes().shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        assertThat(clusterState.getRoutingNodes().shardsWithState(STARTED).size(), equalTo(4));
        assertThat(clusterState.getRoutingNodes().shardsWithState(INITIALIZING).size(), equalTo(4));

        routingResult = strategy.applyStartedShards(clusterState, clusterState.getRoutingNodes().shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        assertThat(clusterState.getRoutingNodes().shardsWithState(STARTED).size(), equalTo(8));
        assertThat(clusterState.getRoutingNodes().shardsWithState(INITIALIZING).size(), equalTo(0));

        logger.info(""--> adding one nodes and do rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
                .add(newNode(""node1""))
                .add(newNode(""node2""))
                .add(newNode(""node3""))
        ).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        assertThat(clusterState.getRoutingNodes().shardsWithState(STARTED).size(), equalTo(8));
        assertThat(clusterState.getRoutingNodes().shardsWithState(RELOCATING).size(), equalTo(0));

        if (useClusterSetting) {
            clusterState = ClusterState.builder(clusterState).metaData(MetaData.builder(clusterState.metaData()).transientSettings(Settings.builder()
                .put(CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), allowedOnes)
                .build())).build();
        } else {
            IndexMetaData meta = clusterState.getMetaData().index(""test"");
            IndexMetaData meta1 = clusterState.getMetaData().index(""always_disabled"");
            clusterState = ClusterState.builder(clusterState).metaData(MetaData.builder(clusterState.metaData()).removeAllIndices().put(IndexMetaData.builder(meta1))
                    .put(IndexMetaData.builder(meta).settings(Settings.builder().put(meta.getSettings()).put(EnableAllocationDecider.INDEX_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), allowedOnes).build())))
                    .build();

        }
        clusterSettings.applySettings(clusterState.metaData().settings());
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        assertThat(""expected 6 shards to be started 2 to relocate useClusterSettings: "" + useClusterSetting, clusterState.getRoutingNodes().shardsWithState(STARTED).size(), equalTo(6));
        assertThat(""expected 2 shards to relocate useClusterSettings: "" + useClusterSetting, clusterState.getRoutingNodes().shardsWithState(RELOCATING).size(), equalTo(2));
        List<ShardRouting> mutableShardRoutings = clusterState.getRoutingNodes().shardsWithState(RELOCATING);
        switch (allowedOnes) {
            case PRIMARIES:
                for (ShardRouting routing : mutableShardRoutings) {
                    assertTrue(""only primaries are allowed to relocate"", routing.primary());
                    assertThat(""only test index can rebalance"", routing.getIndexName(), equalTo(""test""));
                }
                break;
            case REPLICAS:
                for (ShardRouting routing : mutableShardRoutings) {
                    assertFalse(""only replicas are allowed to relocate"", routing.primary());
                    assertThat(""only test index can rebalance"", routing.getIndexName(), equalTo(""test""));
                }
                break;
            case ALL:
                for (ShardRouting routing : mutableShardRoutings) {
                    assertThat(""only test index can rebalance"", routing.getIndexName(), equalTo(""test""));
                }
                break;
            default:
                fail(""only replicas, primaries or all are allowed"");
        }
        routingResult = strategy.applyStartedShards(clusterState, clusterState.getRoutingNodes().shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        assertThat(clusterState.getRoutingNodes().shardsWithState(STARTED).size(), equalTo(8));
        assertThat(clusterState.getRoutingNodes().shardsWithState(INITIALIZING).size(), equalTo(0));

    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/EnableAllocationTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,349,"public void testRebalanceDoesNotAllocatePrimaryAndReplicasOnDifferentVersionNodes() {
        ShardId shard1 = new ShardId(""test1"", ""_na_"", 0);
        ShardId shard2 = new ShardId(""test2"", ""_na_"", 0);
        final DiscoveryNode newNode = new DiscoveryNode(""newNode"", LocalTransportAddress.buildUnique(), emptyMap(),
                MASTER_DATA_ROLES, Version.CURRENT);
        final DiscoveryNode oldNode1 = new DiscoveryNode(""oldNode1"", LocalTransportAddress.buildUnique(), emptyMap(),
                MASTER_DATA_ROLES, VersionUtils.getPreviousVersion());
        final DiscoveryNode oldNode2 = new DiscoveryNode(""oldNode2"", LocalTransportAddress.buildUnique(), emptyMap(),
                MASTER_DATA_ROLES, VersionUtils.getPreviousVersion());
        MetaData metaData = MetaData.builder()
            .put(IndexMetaData.builder(shard1.getIndexName()).settings(settings(Version.CURRENT).put(Settings.EMPTY)).numberOfShards(1).numberOfReplicas(1))
            .put(IndexMetaData.builder(shard2.getIndexName()).settings(settings(Version.CURRENT).put(Settings.EMPTY)).numberOfShards(1).numberOfReplicas(1))
            .build();
        RoutingTable routingTable = RoutingTable.builder()
            .add(IndexRoutingTable.builder(shard1.getIndex())
                .addIndexShard(new IndexShardRoutingTable.Builder(shard1)
                    .addShard(TestShardRouting.newShardRouting(shard1.getIndexName(), shard1.getId(), newNode.getId(), true, ShardRoutingState.STARTED))
                    .addShard(TestShardRouting.newShardRouting(shard1.getIndexName(), shard1.getId(), oldNode1.getId(), false, ShardRoutingState.STARTED))
                    .build())
            )
            .add(IndexRoutingTable.builder(shard2.getIndex())
                .addIndexShard(new IndexShardRoutingTable.Builder(shard2)
                    .addShard(TestShardRouting.newShardRouting(shard2.getIndexName(), shard2.getId(), newNode.getId(), true, ShardRoutingState.STARTED))
                    .addShard(TestShardRouting.newShardRouting(shard2.getIndexName(), shard2.getId(), oldNode1.getId(), false, ShardRoutingState.STARTED))
                    .build())
            )
            .build();
        ClusterState state = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY))
            .metaData(metaData)
            .routingTable(routingTable)
            .nodes(DiscoveryNodes.builder().add(newNode).add(oldNode1).add(oldNode2)).build();
        AllocationDeciders allocationDeciders = new AllocationDeciders(Settings.EMPTY, Collections.singleton(new NodeVersionAllocationDecider(Settings.EMPTY)));
        AllocationService strategy = new MockAllocationService(Settings.EMPTY,
            allocationDeciders,
            NoopGatewayAllocator.INSTANCE, new BalancedShardsAllocator(Settings.EMPTY), EmptyClusterInfoService.INSTANCE);
        RoutingAllocation.Result result = strategy.reroute(state, new AllocationCommands(), true, false);
        // the two indices must stay as is, the replicas cannot move to oldNode2 because versions don't match
        state = ClusterState.builder(state).routingResult(result).build();
        assertThat(result.routingTable().index(shard2.getIndex()).shardsWithState(ShardRoutingState.RELOCATING).size(), equalTo(0));
        assertThat(result.routingTable().index(shard1.getIndex()).shardsWithState(ShardRoutingState.RELOCATING).size(), equalTo(0));
    }","public void testRebalanceDoesNotAllocatePrimaryAndReplicasOnDifferentVersionNodes() {
        ShardId shard1 = new ShardId(""test1"", ""_na_"", 0);
        ShardId shard2 = new ShardId(""test2"", ""_na_"", 0);
        final DiscoveryNode newNode = new DiscoveryNode(""newNode"", LocalTransportAddress.buildUnique(), emptyMap(),
                MASTER_DATA_ROLES, Version.CURRENT);
        final DiscoveryNode oldNode1 = new DiscoveryNode(""oldNode1"", LocalTransportAddress.buildUnique(), emptyMap(),
                MASTER_DATA_ROLES, VersionUtils.getPreviousVersion());
        final DiscoveryNode oldNode2 = new DiscoveryNode(""oldNode2"", LocalTransportAddress.buildUnique(), emptyMap(),
                MASTER_DATA_ROLES, VersionUtils.getPreviousVersion());
        AllocationId allocationId1P = AllocationId.newInitializing();
        AllocationId allocationId1R = AllocationId.newInitializing();
        AllocationId allocationId2P = AllocationId.newInitializing();
        AllocationId allocationId2R = AllocationId.newInitializing();
        MetaData metaData = MetaData.builder()
            .put(IndexMetaData.builder(shard1.getIndexName()).settings(settings(Version.CURRENT).put(Settings.EMPTY)).numberOfShards(1).numberOfReplicas(1).putActiveAllocationIds(0, Sets.newHashSet(allocationId1P.getId(), allocationId1R.getId())))
            .put(IndexMetaData.builder(shard2.getIndexName()).settings(settings(Version.CURRENT).put(Settings.EMPTY)).numberOfShards(1).numberOfReplicas(1).putActiveAllocationIds(0, Sets.newHashSet(allocationId2P.getId(), allocationId2R.getId())))
            .build();
        RoutingTable routingTable = RoutingTable.builder()
            .add(IndexRoutingTable.builder(shard1.getIndex())
                .addIndexShard(new IndexShardRoutingTable.Builder(shard1)
                    .addShard(TestShardRouting.newShardRouting(shard1.getIndexName(), shard1.getId(), newNode.getId(), null, true, ShardRoutingState.STARTED, allocationId1P))
                    .addShard(TestShardRouting.newShardRouting(shard1.getIndexName(), shard1.getId(), oldNode1.getId(), null, false, ShardRoutingState.STARTED, allocationId1R))
                    .build())
            )
            .add(IndexRoutingTable.builder(shard2.getIndex())
                .addIndexShard(new IndexShardRoutingTable.Builder(shard2)
                    .addShard(TestShardRouting.newShardRouting(shard2.getIndexName(), shard2.getId(), newNode.getId(), null, true, ShardRoutingState.STARTED, allocationId2P))
                    .addShard(TestShardRouting.newShardRouting(shard2.getIndexName(), shard2.getId(), oldNode1.getId(), null, false, ShardRoutingState.STARTED, allocationId2R))
                    .build())
            )
            .build();
        ClusterState state = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY))
            .metaData(metaData)
            .routingTable(routingTable)
            .nodes(DiscoveryNodes.builder().add(newNode).add(oldNode1).add(oldNode2)).build();
        AllocationDeciders allocationDeciders = new AllocationDeciders(Settings.EMPTY, Collections.singleton(new NodeVersionAllocationDecider(Settings.EMPTY)));
        AllocationService strategy = new MockAllocationService(Settings.EMPTY,
            allocationDeciders,
            NoopGatewayAllocator.INSTANCE, new BalancedShardsAllocator(Settings.EMPTY), EmptyClusterInfoService.INSTANCE);
        RoutingAllocation.Result result = strategy.reroute(state, new AllocationCommands(), true, false);
        // the two indices must stay as is, the replicas cannot move to oldNode2 because versions don't match
        state = ClusterState.builder(state).routingResult(result).build();
        assertThat(result.routingTable().index(shard2.getIndex()).shardsWithState(ShardRoutingState.RELOCATING).size(), equalTo(0));
        assertThat(result.routingTable().index(shard1.getIndex()).shardsWithState(ShardRoutingState.RELOCATING).size(), equalTo(0));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/NodeVersionAllocationDeciderTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,133,"public void testRun() throws IOException {
        Set<String> nodes = new HashSet<>();
        Map<String, Idx> indices = new HashMap<>();
        try (BufferedReader reader = Files.newBufferedReader(getCatPath(), StandardCharsets.UTF_8)) {
            String line = null;
            // regexp FTW
            Pattern pattern = Pattern.compile(""^(.+)\\s+(\\d)\\s+([rp])\\s+(STARTED|RELOCATING|INITIALIZING|UNASSIGNED)"" +
                ""\\s+\\d+\\s+[0-9.a-z]+\\s+(\\d+\\.\\d+\\.\\d+\\.\\d+).*$"");
            while((line = reader.readLine()) != null) {
                final Matcher matcher;
                if ((matcher = pattern.matcher(line)).matches()) {
                    final String index = matcher.group(1);
                    Idx idx = indices.get(index);
                    if (idx == null) {
                        idx = new Idx(index);
                        indices.put(index, idx);
                    }
                    final int shard = Integer.parseInt(matcher.group(2));
                    final boolean primary = matcher.group(3).equals(""p"");
                    ShardRoutingState state = ShardRoutingState.valueOf(matcher.group(4));
                    String ip = matcher.group(5);
                    nodes.add(ip);
                    ShardRouting routing = TestShardRouting.newShardRouting(index, shard, ip, null, null, primary, state);
                    idx.add(routing);
                    logger.debug(""Add routing {}"", routing);
                } else {
                    fail(""can't read line: "" + line);
                }
            }

        }

        logger.info(""Building initial routing table"");
        MetaData.Builder builder = MetaData.builder();
        RoutingTable.Builder routingTableBuilder = RoutingTable.builder();
        for(Idx idx : indices.values()) {
            IndexMetaData idxMeta = IndexMetaData.builder(idx.name).settings(settings(Version.CURRENT))
                .numberOfShards(idx.numShards()).numberOfReplicas(idx.numReplicas()).build();
            builder.put(idxMeta, false);
            IndexRoutingTable.Builder tableBuilder = new IndexRoutingTable.Builder(idxMeta.getIndex()).initializeAsRecovery(idxMeta);
            Map<Integer, IndexShardRoutingTable> shardIdToRouting = new HashMap<>();
            for (ShardRouting r : idx.routing) {
                IndexShardRoutingTable refData = new IndexShardRoutingTable.Builder(r.shardId()).addShard(r).build();
                if (shardIdToRouting.containsKey(r.getId())) {
                    refData = new IndexShardRoutingTable.Builder(shardIdToRouting.get(r.getId())).addShard(r).build();
                }
                shardIdToRouting.put(r.getId(), refData);

            }
            for (IndexShardRoutingTable t: shardIdToRouting.values()) {
                tableBuilder.addIndexShard(t);
            }
            IndexRoutingTable table = tableBuilder.build();
            routingTableBuilder.add(table);
        }
        MetaData metaData = builder.build();

        RoutingTable routingTable = routingTableBuilder.build();
        DiscoveryNodes.Builder builderDiscoNodes = DiscoveryNodes.builder();
        for (String node : nodes) {
            builderDiscoNodes.add(newNode(node));
        }
        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING
            .getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).nodes(builderDiscoNodes.build()).build();
        if (balanceFirst()) {
            clusterState = rebalance(clusterState);
        }
        clusterState = allocateNew(clusterState);
    }","public void testRun() throws IOException {
        Set<String> nodes = new HashSet<>();
        Map<String, Idx> indices = new HashMap<>();
        try (BufferedReader reader = Files.newBufferedReader(getCatPath(), StandardCharsets.UTF_8)) {
            String line = null;
            // regexp FTW
            Pattern pattern = Pattern.compile(""^(.+)\\s+(\\d)\\s+([rp])\\s+(STARTED|RELOCATING|INITIALIZING|UNASSIGNED)"" +
                ""\\s+\\d+\\s+[0-9.a-z]+\\s+(\\d+\\.\\d+\\.\\d+\\.\\d+).*$"");
            while((line = reader.readLine()) != null) {
                final Matcher matcher;
                if ((matcher = pattern.matcher(line)).matches()) {
                    final String index = matcher.group(1);
                    Idx idx = indices.get(index);
                    if (idx == null) {
                        idx = new Idx(index);
                        indices.put(index, idx);
                    }
                    final int shard = Integer.parseInt(matcher.group(2));
                    final boolean primary = matcher.group(3).equals(""p"");
                    ShardRoutingState state = ShardRoutingState.valueOf(matcher.group(4));
                    String ip = matcher.group(5);
                    nodes.add(ip);
                    ShardRouting routing = TestShardRouting.newShardRouting(index, shard, ip, null, null, primary, state);
                    idx.add(routing);
                    logger.debug(""Add routing {}"", routing);
                } else {
                    fail(""can't read line: "" + line);
                }
            }

        }

        logger.info(""Building initial routing table"");
        MetaData.Builder builder = MetaData.builder();
        RoutingTable.Builder routingTableBuilder = RoutingTable.builder();
        for(Idx idx : indices.values()) {
            IndexMetaData.Builder idxMetaBuilder = IndexMetaData.builder(idx.name).settings(settings(Version.CURRENT))
                .numberOfShards(idx.numShards()).numberOfReplicas(idx.numReplicas());
            for (ShardRouting shardRouting : idx.routing) {
                if (shardRouting.active()) {
                    Set<String> allocationIds = idxMetaBuilder.getActiveAllocationIds(shardRouting.id());
                    if (allocationIds == null) {
                        allocationIds = new HashSet<>();
                    } else {
                        allocationIds = new HashSet<>(allocationIds);
                    }
                    allocationIds.add(shardRouting.allocationId().getId());
                    idxMetaBuilder.putActiveAllocationIds(shardRouting.id(), allocationIds);
                }
            }
            IndexMetaData idxMeta = idxMetaBuilder.build();
            builder.put(idxMeta, false);
            IndexRoutingTable.Builder tableBuilder = new IndexRoutingTable.Builder(idxMeta.getIndex()).initializeAsRecovery(idxMeta);
            Map<Integer, IndexShardRoutingTable> shardIdToRouting = new HashMap<>();
            for (ShardRouting r : idx.routing) {
                IndexShardRoutingTable refData = new IndexShardRoutingTable.Builder(r.shardId()).addShard(r).build();
                if (shardIdToRouting.containsKey(r.getId())) {
                    refData = new IndexShardRoutingTable.Builder(shardIdToRouting.get(r.getId())).addShard(r).build();
                }
                shardIdToRouting.put(r.getId(), refData);
            }
            for (IndexShardRoutingTable t: shardIdToRouting.values()) {
                tableBuilder.addIndexShard(t);
            }
            IndexRoutingTable table = tableBuilder.build();
            routingTableBuilder.add(table);
        }
        MetaData metaData = builder.build();

        RoutingTable routingTable = routingTableBuilder.build();
        DiscoveryNodes.Builder builderDiscoNodes = DiscoveryNodes.builder();
        for (String node : nodes) {
            builderDiscoNodes.add(newNode(node));
        }
        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING
            .getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).nodes(builderDiscoNodes.build()).build();
        if (balanceFirst()) {
            clusterState = rebalance(clusterState);
        }
        clusterState = allocateNew(clusterState);
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/CatAllocationTestCase.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,159,"public void testSingleIndexFirstStartPrimaryThenBackups() {
        AllocationService strategy = createAllocationService(Settings.builder().put(""cluster.routing.allocation.node_concurrent_recoveries"", 10).build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).shards().size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).state(), equalTo(UNASSIGNED));
        assertThat(routingTable.index(""test"").shard(0).shards().get(1).state(), equalTo(UNASSIGNED));
        assertThat(routingTable.index(""test"").shard(0).shards().get(0).currentNodeId(), nullValue());
        assertThat(routingTable.index(""test"").shard(0).shards().get(1).currentNodeId(), nullValue());

        logger.info(""Adding one node and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1""))).build();

        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).shards().size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().state(), equalTo(INITIALIZING));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().currentNodeId(), equalTo(""node1""));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().get(0).currentNodeId(), nullValue());

        logger.info(""Add another node and perform rerouting, nothing will happen since primary shards not started"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node2""))).build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable == routingTable, equalTo(true));

        logger.info(""Start the primary shard (on node1)"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.node(""node1"").shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).shards().size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().state(), equalTo(STARTED));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().currentNodeId(), equalTo(""node1""));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().size(), equalTo(1));
        // backup shards are initializing as well, we make sure that they recover from primary *started* shards in the IndicesClusterStateService
        assertThat(routingTable.index(""test"").shard(0).replicaShards().get(0).state(), equalTo(INITIALIZING));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().get(0).currentNodeId(), equalTo(""node2""));


        logger.info(""Reroute, nothing should change"");
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        assertThat(prevRoutingTable == routingTable, equalTo(true));

        logger.info(""Start the backup shard"");
        routingNodes = clusterState.getRoutingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.node(""node2"").shardsWithState(INITIALIZING)).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).shards().size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().state(), equalTo(STARTED));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().currentNodeId(), equalTo(""node1""));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().get(0).state(), equalTo(STARTED));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().get(0).currentNodeId(), equalTo(""node2""));

        logger.info(""Kill node1, backup shard should become primary"");

        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).remove(""node1"")).build();
        prevRoutingTable = routingTable;
        routingTable = strategy.deassociateDeadNodes(clusterState, true, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).shards().size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().state(), equalTo(STARTED));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().currentNodeId(), equalTo(""node2""));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().size(), equalTo(1));
        // backup shards are initializing as well, we make sure that they recover from primary *started* shards in the IndicesClusterStateService
        assertThat(routingTable.index(""test"").shard(0).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().get(0).currentNodeId(), nullValue());

        logger.info(""Start another node, backup shard should start initializing"");

        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node3""))).build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        assertThat(routingTable.index(""test"").shard(0).size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).shards().size(), equalTo(2));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().state(), equalTo(STARTED));
        assertThat(routingTable.index(""test"").shard(0).primaryShard().currentNodeId(), equalTo(""node2""));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().size(), equalTo(1));
        // backup shards are initializing as well, we make sure that they recover from primary *started* shards in the IndicesClusterStateService
        assertThat(routingTable.index(""test"").shard(0).replicaShards().get(0).state(), equalTo(INITIALIZING));
        assertThat(routingTable.index(""test"").shard(0).replicaShards().get(0).currentNodeId(), equalTo(""node3""));
    }","public void testSingleIndexFirstStartPrimaryThenBackups() {
        AllocationService strategy = createAllocationService(Settings.builder().put(""cluster.routing.allocation.node_concurrent_recoveries"", 10).build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().get(0).state(), equalTo(UNASSIGNED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().get(1).state(), equalTo(UNASSIGNED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().get(0).currentNodeId(), nullValue());
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().get(1).currentNodeId(), nullValue());

        logger.info(""Adding one node and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1""))).build();

        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().state(), equalTo(INITIALIZING));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().currentNodeId(), equalTo(""node1""));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().get(0).currentNodeId(), nullValue());

        logger.info(""Add another node and perform rerouting, nothing will happen since primary shards not started"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node2""))).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertFalse(routingResult.changed());

        logger.info(""Start the primary shard (on node1)"");
        RoutingNodes routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.node(""node1"").shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().state(), equalTo(STARTED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().currentNodeId(), equalTo(""node1""));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().size(), equalTo(1));
        // backup shards are initializing as well, we make sure that they recover from primary *started* shards in the IndicesClusterStateService
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().get(0).state(), equalTo(INITIALIZING));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().get(0).currentNodeId(), equalTo(""node2""));


        logger.info(""Reroute, nothing should change"");
        routingResult = strategy.reroute(clusterState, ""reroute"");
        assertFalse(routingResult.changed());

        logger.info(""Start the backup shard"");
        routingNodes = clusterState.getRoutingNodes();
        routingResult = strategy.applyStartedShards(clusterState, routingNodes.node(""node2"").shardsWithState(INITIALIZING));
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().state(), equalTo(STARTED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().currentNodeId(), equalTo(""node1""));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().get(0).state(), equalTo(STARTED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().get(0).currentNodeId(), equalTo(""node2""));

        logger.info(""Kill node1, backup shard should become primary"");

        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).remove(""node1"")).build();
        routingResult = strategy.deassociateDeadNodes(clusterState, true, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().state(), equalTo(STARTED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().currentNodeId(), equalTo(""node2""));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().size(), equalTo(1));
        // backup shards are initializing as well, we make sure that they recover from primary *started* shards in the IndicesClusterStateService
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().get(0).currentNodeId(), nullValue());

        logger.info(""Start another node, backup shard should start initializing"");

        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode(""node3""))).build();
        routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        assertThat(clusterState.routingTable().index(""test"").shard(0).size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).shards().size(), equalTo(2));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().state(), equalTo(STARTED));
        assertThat(clusterState.routingTable().index(""test"").shard(0).primaryShard().currentNodeId(), equalTo(""node2""));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().size(), equalTo(1));
        // backup shards are initializing as well, we make sure that they recover from primary *started* shards in the IndicesClusterStateService
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().get(0).state(), equalTo(INITIALIZING));
        assertThat(clusterState.routingTable().index(""test"").shard(0).replicaShards().get(0).currentNodeId(), equalTo(""node3""));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/SingleShardOneReplicaRoutingTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,563,389,"public void testFirstAllocationFailureTwoNodes() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info(""Adding two nodes and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        final String nodeHoldingPrimary = routingTable.index(""test"").shard(0).primaryShard().currentNodeId();

        assertThat(prevRoutingTable != routingTable, equalTo(true));
        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().currentNodeId(), equalTo(nodeHoldingPrimary));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""fail the first shard, will start INITIALIZING on the second node"");
        prevRoutingTable = routingTable;
        final ShardRouting firstShard = clusterState.getRoutingNodes().node(nodeHoldingPrimary).iterator().next();
        routingTable = strategy.applyFailedShard(clusterState, firstShard).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        assertThat(prevRoutingTable != routingTable, equalTo(true));

        final String nodeHoldingPrimary2 = routingTable.index(""test"").shard(0).primaryShard().currentNodeId();
        assertThat(nodeHoldingPrimary2, not(equalTo(nodeHoldingPrimary)));

        assertThat(routingTable.index(""test"").shards().size(), equalTo(1));
        for (int i = 0; i < routingTable.index(""test"").shards().size(); i++) {
            assertThat(routingTable.index(""test"").shard(i).size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(routingTable.index(""test"").shard(i).primaryShard().currentNodeId(), not(equalTo(nodeHoldingPrimary)));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(routingTable.index(""test"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }
    }","public void testFirstAllocationFailureTwoNodes() {
        AllocationService strategy = createAllocationService(Settings.builder()
                .put(""cluster.routing.allocation.node_concurrent_recoveries"", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), ""always"")
                .build());

        logger.info(""Building initial routing table"");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder(""test"").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable initialRoutingTable = RoutingTable.builder()
                .addAsNew(metaData.index(""test""))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();

        logger.info(""Adding two nodes and performing rerouting"");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode(""node1"")).add(newNode(""node2""))).build();
        RoutingAllocation.Result routingResult = strategy.reroute(clusterState, ""reroute"");
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        final String nodeHoldingPrimary = clusterState.routingTable().index(""test"").shard(0).primaryShard().currentNodeId();

        assertTrue(routingResult.changed());
        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().currentNodeId(), equalTo(nodeHoldingPrimary));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }

        logger.info(""fail the first shard, will start INITIALIZING on the second node"");
        final ShardRouting firstShard = clusterState.getRoutingNodes().node(nodeHoldingPrimary).iterator().next();
        routingResult = strategy.applyFailedShard(clusterState, firstShard);
        clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
        assertTrue(routingResult.changed());

        final String nodeHoldingPrimary2 = clusterState.routingTable().index(""test"").shard(0).primaryShard().currentNodeId();
        assertThat(nodeHoldingPrimary2, not(equalTo(nodeHoldingPrimary)));

        assertThat(clusterState.routingTable().index(""test"").shards().size(), equalTo(1));
        for (int i = 0; i < clusterState.routingTable().index(""test"").shards().size(); i++) {
            assertThat(clusterState.routingTable().index(""test"").shard(i).size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).shards().size(), equalTo(2));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().state(), equalTo(INITIALIZING));
            assertThat(clusterState.routingTable().index(""test"").shard(i).primaryShard().currentNodeId(), not(equalTo(nodeHoldingPrimary)));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().size(), equalTo(1));
            assertThat(clusterState.routingTable().index(""test"").shard(i).replicaShards().get(0).state(), equalTo(UNASSIGNED));
        }
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/FailedShardsRoutingTests.java
57c3dcb7d714bf08e92e174987dbd0ceabd0cefb,682,162,"public void testRandomDecisions() {
        RandomAllocationDecider randomAllocationDecider = new RandomAllocationDecider(random());
        AllocationService strategy = new AllocationService(Settings.builder().build(), new AllocationDeciders(Settings.EMPTY,
                new HashSet<>(Arrays.asList(new SameShardAllocationDecider(Settings.EMPTY), new ReplicaAfterPrimaryActiveAllocationDecider(Settings.EMPTY),
                        randomAllocationDecider))), NoopGatewayAllocator.INSTANCE, new BalancedShardsAllocator(Settings.EMPTY), EmptyClusterInfoService.INSTANCE);
        int indices = scaledRandomIntBetween(1, 20);
        Builder metaBuilder = MetaData.builder();
        int maxNumReplicas = 1;
        int totalNumShards = 0;
        for (int i = 0; i < indices; i++) {
            int replicas = scaledRandomIntBetween(0, 6);
            maxNumReplicas = Math.max(maxNumReplicas, replicas + 1);
            int numShards = scaledRandomIntBetween(1, 20);
            totalNumShards += numShards * (replicas + 1);
            metaBuilder.put(IndexMetaData.builder(""INDEX_"" + i).settings(settings(Version.CURRENT)).numberOfShards(numShards).numberOfReplicas(replicas));

        }
        MetaData metaData = metaBuilder.build();
        RoutingTable.Builder routingTableBuilder = RoutingTable.builder();
        for (int i = 0; i < indices; i++) {
            routingTableBuilder.addAsNew(metaData.index(""INDEX_"" + i));
        }

        RoutingTable routingTable = routingTableBuilder.build();
        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();
        int numIters = scaledRandomIntBetween(5, 15);
        int nodeIdCounter = 0;
        int atMostNodes = scaledRandomIntBetween(Math.max(1, maxNumReplicas), 15);
        final boolean frequentNodes = randomBoolean();
        for (int i = 0; i < numIters; i++) {
            logger.info(""Start iteration [{}]"", i);
            ClusterState.Builder stateBuilder = ClusterState.builder(clusterState);
            DiscoveryNodes.Builder newNodesBuilder = DiscoveryNodes.builder(clusterState.nodes());

            if (clusterState.nodes().getSize() <= atMostNodes &&
                    (nodeIdCounter == 0 || (frequentNodes ? frequently() : rarely()))) {
                int numNodes = scaledRandomIntBetween(1, 3);
                for (int j = 0; j < numNodes; j++) {
                    logger.info(""adding node [{}]"", nodeIdCounter);
                    newNodesBuilder.add(newNode(""NODE_"" + (nodeIdCounter++)));
                }
            }

            boolean nodesRemoved = false;
            if (nodeIdCounter > 1 && rarely()) {
                int nodeId = scaledRandomIntBetween(0, nodeIdCounter - 2);
                logger.info(""removing node [{}]"", nodeId);
                newNodesBuilder.remove(""NODE_"" + nodeId);
                nodesRemoved = true;
            }

            stateBuilder.nodes(newNodesBuilder.build());
            clusterState = stateBuilder.build();
            if (nodesRemoved) {
                routingTable = strategy.deassociateDeadNodes(clusterState, true, ""reroute"").routingTable();
            } else {
                routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
            }
            clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
            if (clusterState.getRoutingNodes().shardsWithState(INITIALIZING).size() > 0) {
                routingTable = strategy.applyStartedShards(clusterState, clusterState.getRoutingNodes().shardsWithState(INITIALIZING))
                        .routingTable();
                clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
            }
        }
        logger.info(""Fill up nodes such that every shard can be allocated"");
        if (clusterState.nodes().getSize() < maxNumReplicas) {
            ClusterState.Builder stateBuilder = ClusterState.builder(clusterState);
            DiscoveryNodes.Builder newNodesBuilder = DiscoveryNodes.builder(clusterState.nodes());
            for (int j = 0; j < (maxNumReplicas - clusterState.nodes().getSize()); j++) {
                logger.info(""adding node [{}]"", nodeIdCounter);
                newNodesBuilder.add(newNode(""NODE_"" + (nodeIdCounter++)));
            }
            stateBuilder.nodes(newNodesBuilder.build());
            clusterState = stateBuilder.build();
        }


        randomAllocationDecider.alwaysSayYes = true;
        logger.info(""now say YES to everything"");
        int iterations = 0;
        do {
            iterations++;
            routingTable = strategy.reroute(clusterState, ""reroute"").routingTable();
            clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
            if (clusterState.getRoutingNodes().shardsWithState(INITIALIZING).size() > 0) {
                routingTable = strategy.applyStartedShards(clusterState, clusterState.getRoutingNodes().shardsWithState(INITIALIZING))
                        .routingTable();
                clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
            }

        } while (clusterState.getRoutingNodes().shardsWithState(ShardRoutingState.INITIALIZING).size() != 0 ||
                clusterState.getRoutingNodes().shardsWithState(ShardRoutingState.UNASSIGNED).size() != 0 && iterations < 200);
        logger.info(""Done Balancing after [{}] iterations"", iterations);
        // we stop after 200 iterations if it didn't stabelize by then something is likely to be wrong
        assertThat(""max num iteration exceeded"", iterations, Matchers.lessThan(200));
        assertThat(clusterState.getRoutingNodes().shardsWithState(ShardRoutingState.INITIALIZING).size(), equalTo(0));
        assertThat(clusterState.getRoutingNodes().shardsWithState(ShardRoutingState.UNASSIGNED).size(), equalTo(0));
        int shards = clusterState.getRoutingNodes().shardsWithState(ShardRoutingState.STARTED).size();
        assertThat(shards, equalTo(totalNumShards));
        final int numNodes = clusterState.nodes().getSize();
        final int upperBound = (int) Math.round(((shards / numNodes) * 1.10));
        final int lowerBound = (int) Math.round(((shards / numNodes) * 0.90));
        for (int i = 0; i < nodeIdCounter; i++) {
            if (clusterState.getRoutingNodes().node(""NODE_"" + i) == null) {
                continue;
            }
            assertThat(clusterState.getRoutingNodes().node(""NODE_"" + i).size(), Matchers.anyOf(
                    Matchers.anyOf(equalTo((shards / numNodes) + 1), equalTo((shards / numNodes) - 1), equalTo((shards / numNodes))),
                    Matchers.allOf(Matchers.greaterThanOrEqualTo(lowerBound), Matchers.lessThanOrEqualTo(upperBound))));
        }
    }","public void testRandomDecisions() {
        RandomAllocationDecider randomAllocationDecider = new RandomAllocationDecider(random());
        AllocationService strategy = new AllocationService(Settings.builder().build(), new AllocationDeciders(Settings.EMPTY,
                new HashSet<>(Arrays.asList(new SameShardAllocationDecider(Settings.EMPTY), new ReplicaAfterPrimaryActiveAllocationDecider(Settings.EMPTY),
                        randomAllocationDecider))), NoopGatewayAllocator.INSTANCE, new BalancedShardsAllocator(Settings.EMPTY), EmptyClusterInfoService.INSTANCE);
        int indices = scaledRandomIntBetween(1, 20);
        Builder metaBuilder = MetaData.builder();
        int maxNumReplicas = 1;
        int totalNumShards = 0;
        for (int i = 0; i < indices; i++) {
            int replicas = scaledRandomIntBetween(0, 6);
            maxNumReplicas = Math.max(maxNumReplicas, replicas + 1);
            int numShards = scaledRandomIntBetween(1, 20);
            totalNumShards += numShards * (replicas + 1);
            metaBuilder.put(IndexMetaData.builder(""INDEX_"" + i).settings(settings(Version.CURRENT)).numberOfShards(numShards).numberOfReplicas(replicas));

        }
        MetaData metaData = metaBuilder.build();
        RoutingTable.Builder routingTableBuilder = RoutingTable.builder();
        for (int i = 0; i < indices; i++) {
            routingTableBuilder.addAsNew(metaData.index(""INDEX_"" + i));
        }

        RoutingTable initialRoutingTable = routingTableBuilder.build();
        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(initialRoutingTable).build();
        int numIters = scaledRandomIntBetween(5, 15);
        int nodeIdCounter = 0;
        int atMostNodes = scaledRandomIntBetween(Math.max(1, maxNumReplicas), 15);
        final boolean frequentNodes = randomBoolean();
        RoutingAllocation.Result routingResult;
        for (int i = 0; i < numIters; i++) {
            logger.info(""Start iteration [{}]"", i);
            ClusterState.Builder stateBuilder = ClusterState.builder(clusterState);
            DiscoveryNodes.Builder newNodesBuilder = DiscoveryNodes.builder(clusterState.nodes());

            if (clusterState.nodes().getSize() <= atMostNodes &&
                    (nodeIdCounter == 0 || (frequentNodes ? frequently() : rarely()))) {
                int numNodes = scaledRandomIntBetween(1, 3);
                for (int j = 0; j < numNodes; j++) {
                    logger.info(""adding node [{}]"", nodeIdCounter);
                    newNodesBuilder.add(newNode(""NODE_"" + (nodeIdCounter++)));
                }
            }

            boolean nodesRemoved = false;
            if (nodeIdCounter > 1 && rarely()) {
                int nodeId = scaledRandomIntBetween(0, nodeIdCounter - 2);
                logger.info(""removing node [{}]"", nodeId);
                newNodesBuilder.remove(""NODE_"" + nodeId);
                nodesRemoved = true;
            }

            stateBuilder.nodes(newNodesBuilder.build());
            clusterState = stateBuilder.build();
            if (nodesRemoved) {
                routingResult = strategy.deassociateDeadNodes(clusterState, true, ""reroute"");
            } else {
                routingResult = strategy.reroute(clusterState, ""reroute"");
            }
            clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
            if (clusterState.getRoutingNodes().shardsWithState(INITIALIZING).size() > 0) {
                routingResult = strategy.applyStartedShards(clusterState, clusterState.getRoutingNodes().shardsWithState(INITIALIZING));
                clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
            }
        }
        logger.info(""Fill up nodes such that every shard can be allocated"");
        if (clusterState.nodes().getSize() < maxNumReplicas) {
            ClusterState.Builder stateBuilder = ClusterState.builder(clusterState);
            DiscoveryNodes.Builder newNodesBuilder = DiscoveryNodes.builder(clusterState.nodes());
            for (int j = 0; j < (maxNumReplicas - clusterState.nodes().getSize()); j++) {
                logger.info(""adding node [{}]"", nodeIdCounter);
                newNodesBuilder.add(newNode(""NODE_"" + (nodeIdCounter++)));
            }
            stateBuilder.nodes(newNodesBuilder.build());
            clusterState = stateBuilder.build();
        }


        randomAllocationDecider.alwaysSayYes = true;
        logger.info(""now say YES to everything"");
        int iterations = 0;
        do {
            iterations++;
            routingResult = strategy.reroute(clusterState, ""reroute"");
            clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
            if (clusterState.getRoutingNodes().shardsWithState(INITIALIZING).size() > 0) {
                routingResult = strategy.applyStartedShards(clusterState, clusterState.getRoutingNodes().shardsWithState(INITIALIZING));
                clusterState = ClusterState.builder(clusterState).routingResult(routingResult).build();
            }

        } while (clusterState.getRoutingNodes().shardsWithState(ShardRoutingState.INITIALIZING).size() != 0 ||
                clusterState.getRoutingNodes().shardsWithState(ShardRoutingState.UNASSIGNED).size() != 0 && iterations < 200);
        logger.info(""Done Balancing after [{}] iterations"", iterations);
        // we stop after 200 iterations if it didn't stabelize by then something is likely to be wrong
        assertThat(""max num iteration exceeded"", iterations, Matchers.lessThan(200));
        assertThat(clusterState.getRoutingNodes().shardsWithState(ShardRoutingState.INITIALIZING).size(), equalTo(0));
        assertThat(clusterState.getRoutingNodes().shardsWithState(ShardRoutingState.UNASSIGNED).size(), equalTo(0));
        int shards = clusterState.getRoutingNodes().shardsWithState(ShardRoutingState.STARTED).size();
        assertThat(shards, equalTo(totalNumShards));
        final int numNodes = clusterState.nodes().getSize();
        final int upperBound = (int) Math.round(((shards / numNodes) * 1.10));
        final int lowerBound = (int) Math.round(((shards / numNodes) * 0.90));
        for (int i = 0; i < nodeIdCounter; i++) {
            if (clusterState.getRoutingNodes().node(""NODE_"" + i) == null) {
                continue;
            }
            assertThat(clusterState.getRoutingNodes().node(""NODE_"" + i).size(), Matchers.anyOf(
                    Matchers.anyOf(equalTo((shards / numNodes) + 1), equalTo((shards / numNodes) - 1), equalTo((shards / numNodes))),
                    Matchers.allOf(Matchers.greaterThanOrEqualTo(lowerBound), Matchers.lessThanOrEqualTo(upperBound))));
        }
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/RandomAllocationDeciderTests.java
3cae2696bebc699299ecf180c51070f2b4ea3029,563,409,"public void testTrustStoreReloadException() throws Exception {
        Path tempDir = createTempDir();
        Path trustStorePath = tempDir.resolve(""testnode.jks"");
        Files.copy(getDataPath(""/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode.jks""), trustStorePath);
        MockSecureSettings secureSettings = new MockSecureSettings();
        secureSettings.setString(""xpack.security.transport.ssl.truststore.secure_password"", ""testnode"");
        Settings settings = Settings.builder()
            .put(""xpack.security.transport.ssl.truststore.path"", trustStorePath)
            .put(""xpack.security.transport.ssl.supported_protocols"", ""TLSv1.2"")
            .put(""path.home"", createTempDir())
            .setSecureSettings(secureSettings)
            .build();
        Environment env = randomBoolean() ? null : TestEnvironment.newEnvironment(settings);
        final SSLService sslService = new SSLService(settings, env);
        final SSLConfiguration config = sslService.getSSLConfiguration(""xpack.security.transport.ssl."");
        new SSLConfigurationReloader(env, sslService, resourceWatcherService) {
            @Override
            void reloadSSLContext(SSLConfiguration configuration) {
                fail(""reload should not be called! [truststore reload exception]"");
            }
        };

        final SSLContext context = sslService.sslContextHolder(config).sslContext();

        // truncate the truststore
        try (OutputStream os = Files.newOutputStream(trustStorePath, StandardOpenOption.TRUNCATE_EXISTING)) {
        }

        // we intentionally don't wait here as we rely on concurrency to catch a failure
        assertThat(sslService.sslContextHolder(config).sslContext(), sameInstance(context));
    }","public void testTrustStoreReloadException() throws Exception {
        Path tempDir = createTempDir();
        Path trustStorePath = tempDir.resolve(""testnode.jks"");
        Files.copy(getDataPath(""/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode.jks""), trustStorePath);
        MockSecureSettings secureSettings = new MockSecureSettings();
        secureSettings.setString(""xpack.security.transport.ssl.truststore.secure_password"", ""testnode"");
        Settings settings = Settings.builder()
            .put(""xpack.security.transport.ssl.truststore.path"", trustStorePath)
            .put(""path.home"", createTempDir())
            .setSecureSettings(secureSettings)
            .build();
        Environment env = randomBoolean() ? null : TestEnvironment.newEnvironment(settings);
        final SSLService sslService = new SSLService(settings, env);
        final SSLConfiguration config = sslService.getSSLConfiguration(""xpack.security.transport.ssl."");
        new SSLConfigurationReloader(env, sslService, resourceWatcherService) {
            @Override
            void reloadSSLContext(SSLConfiguration configuration) {
                fail(""reload should not be called! [truststore reload exception]"");
            }
        };

        final SSLContext context = sslService.sslContextHolder(config).sslContext();

        // truncate the truststore
        try (OutputStream os = Files.newOutputStream(trustStorePath, StandardOpenOption.TRUNCATE_EXISTING)) {
        }

        // we intentionally don't wait here as we rely on concurrency to catch a failure
        assertThat(sslService.sslContextHolder(config).sslContext(), sameInstance(context));
    }",/x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/core/ssl/SSLConfigurationReloaderTests.java
3cae2696bebc699299ecf180c51070f2b4ea3029,563,331,"public void testReloadingKeyStoreException() throws Exception {
        assumeFalse(""Can't run in a FIPS JVM"", inFipsJvm());
        Path tempDir = createTempDir();
        Path keystorePath = tempDir.resolve(""testnode.jks"");
        Files.copy(getDataPath(""/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode.jks""), keystorePath);
        MockSecureSettings secureSettings = new MockSecureSettings();
        secureSettings.setString(""xpack.security.transport.ssl.keystore.secure_password"", ""testnode"");
        Settings settings = Settings.builder()
            .put(""xpack.security.transport.ssl.keystore.path"", keystorePath)
            .put(""xpack.security.transport.ssl.supported_protocols"", ""TLSv1.2"")
            .setSecureSettings(secureSettings)
            .put(""path.home"", createTempDir())
            .build();
        Environment env = randomBoolean() ? null : TestEnvironment.newEnvironment(settings);
        final SSLService sslService = new SSLService(settings, env);
        final SSLConfiguration config = sslService.getSSLConfiguration(""xpack.security.transport.ssl."");
        new SSLConfigurationReloader(env, sslService, resourceWatcherService) {
            @Override
            void reloadSSLContext(SSLConfiguration configuration) {
                fail(""reload should not be called! [keystore reload exception]"");
            }
        };

        final SSLContext context = sslService.sslContextHolder(config).sslContext();

        // truncate the keystore
        try (OutputStream out = Files.newOutputStream(keystorePath, StandardOpenOption.TRUNCATE_EXISTING)) {
        }

        // we intentionally don't wait here as we rely on concurrency to catch a failure
        assertThat(sslService.sslContextHolder(config).sslContext(), sameInstance(context));
    }","public void testReloadingKeyStoreException() throws Exception {
        assumeFalse(""Can't run in a FIPS JVM"", inFipsJvm());
        Path tempDir = createTempDir();
        Path keystorePath = tempDir.resolve(""testnode.jks"");
        Files.copy(getDataPath(""/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode.jks""), keystorePath);
        MockSecureSettings secureSettings = new MockSecureSettings();
        secureSettings.setString(""xpack.security.transport.ssl.keystore.secure_password"", ""testnode"");
        Settings settings = Settings.builder()
            .put(""xpack.security.transport.ssl.keystore.path"", keystorePath)
            .setSecureSettings(secureSettings)
            .put(""path.home"", createTempDir())
            .build();
        Environment env = randomBoolean() ? null : TestEnvironment.newEnvironment(settings);
        final SSLService sslService = new SSLService(settings, env);
        final SSLConfiguration config = sslService.getSSLConfiguration(""xpack.security.transport.ssl."");
        new SSLConfigurationReloader(env, sslService, resourceWatcherService) {
            @Override
            void reloadSSLContext(SSLConfiguration configuration) {
                fail(""reload should not be called! [keystore reload exception]"");
            }
        };

        final SSLContext context = sslService.sslContextHolder(config).sslContext();

        // truncate the keystore
        try (OutputStream out = Files.newOutputStream(keystorePath, StandardOpenOption.TRUNCATE_EXISTING)) {
        }

        // we intentionally don't wait here as we rely on concurrency to catch a failure
        assertThat(sslService.sslContextHolder(config).sslContext(), sameInstance(context));
    }",/x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/core/ssl/SSLConfigurationReloaderTests.java
3cae2696bebc699299ecf180c51070f2b4ea3029,563,373,"public void testReloadingPEMKeyConfigException() throws Exception {
        Path tempDir = createTempDir();
        Path keyPath = tempDir.resolve(""testnode.pem"");
        Path certPath = tempDir.resolve(""testnode.crt"");
        Path clientCertPath = tempDir.resolve(""testclient.crt"");
        Files.copy(getDataPath(""/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode.pem""), keyPath);
        Files.copy(getDataPath(""/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode.crt""), certPath);
        Files.copy(getDataPath(""/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testclient.crt""), clientCertPath);
        MockSecureSettings secureSettings = new MockSecureSettings();
        secureSettings.setString(""xpack.security.transport.ssl.secure_key_passphrase"", ""testnode"");
        Settings settings = Settings.builder()
            .put(""xpack.security.transport.ssl.key"", keyPath)
            .put(""xpack.security.transport.ssl.certificate"", certPath)
            .putList(""xpack.security.transport.ssl.certificate_authorities"", certPath.toString(), clientCertPath.toString())
            .put(""xpack.security.transport.ssl.supported_protocols"", ""TLSv1.2"")
            .put(""path.home"", createTempDir())
            .setSecureSettings(secureSettings)
            .build();
        Environment env = randomBoolean() ? null : TestEnvironment.newEnvironment(settings);
        final SSLService sslService = new SSLService(settings, env);
        final SSLConfiguration config = sslService.getSSLConfiguration(""xpack.security.transport.ssl."");
        new SSLConfigurationReloader(env, sslService, resourceWatcherService) {
            @Override
            void reloadSSLContext(SSLConfiguration configuration) {
                fail(""reload should not be called! [pem key reload exception]"");
            }
        };

        final SSLContext context = sslService.sslContextHolder(config).sslContext();

        // truncate the file
        try (OutputStream os = Files.newOutputStream(keyPath, StandardOpenOption.TRUNCATE_EXISTING)) {
        }

        // we intentionally don't wait here as we rely on concurrency to catch a failure
        assertThat(sslService.sslContextHolder(config).sslContext(), sameInstance(context));
    }","public void testReloadingPEMKeyConfigException() throws Exception {
        Path tempDir = createTempDir();
        Path keyPath = tempDir.resolve(""testnode.pem"");
        Path certPath = tempDir.resolve(""testnode.crt"");
        Path clientCertPath = tempDir.resolve(""testclient.crt"");
        Files.copy(getDataPath(""/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode.pem""), keyPath);
        Files.copy(getDataPath(""/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode.crt""), certPath);
        Files.copy(getDataPath(""/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testclient.crt""), clientCertPath);
        MockSecureSettings secureSettings = new MockSecureSettings();
        secureSettings.setString(""xpack.security.transport.ssl.secure_key_passphrase"", ""testnode"");
        Settings settings = Settings.builder()
            .put(""xpack.security.transport.ssl.key"", keyPath)
            .put(""xpack.security.transport.ssl.certificate"", certPath)
            .putList(""xpack.security.transport.ssl.certificate_authorities"", certPath.toString(), clientCertPath.toString())
            .put(""path.home"", createTempDir())
            .setSecureSettings(secureSettings)
            .build();
        Environment env = randomBoolean() ? null : TestEnvironment.newEnvironment(settings);
        final SSLService sslService = new SSLService(settings, env);
        final SSLConfiguration config = sslService.getSSLConfiguration(""xpack.security.transport.ssl."");
        new SSLConfigurationReloader(env, sslService, resourceWatcherService) {
            @Override
            void reloadSSLContext(SSLConfiguration configuration) {
                fail(""reload should not be called! [pem key reload exception]"");
            }
        };

        final SSLContext context = sslService.sslContextHolder(config).sslContext();

        // truncate the file
        try (OutputStream os = Files.newOutputStream(keyPath, StandardOpenOption.TRUNCATE_EXISTING)) {
        }

        // we intentionally don't wait here as we rely on concurrency to catch a failure
        assertThat(sslService.sslContextHolder(config).sslContext(), sameInstance(context));
    }",/x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/core/ssl/SSLConfigurationReloaderTests.java
9630b1a6e7dbed72ec5eaf8ea91c0c91e48a541c,570,978,"public static boolean assertShardStats(RoutingNodes routingNodes) {
        boolean run = false;
        assert (run = true); // only run if assertions are enabled!
        if (!run) {
            return true;
        }
        int unassignedPrimaryCount = 0;
        int unassignedIgnoredPrimaryCount = 0;
        int inactivePrimaryCount = 0;
        int inactiveShardCount = 0;
        int relocating = 0;
        Map<Index, Integer> indicesAndShards = new HashMap<>();
        for (RoutingNode node : routingNodes) {
            for (ShardRouting shard : node) {
                if (shard.initializing() && shard.relocatingNodeId() == null) {
                    inactiveShardCount++;
                    if (shard.primary()) {
                        inactivePrimaryCount++;
                    }
                }
                if (shard.relocating()) {
                    relocating++;
                }
                Integer i = indicesAndShards.get(shard.index());
                if (i == null) {
                    i = shard.id();
                }
                indicesAndShards.put(shard.index(), Math.max(i, shard.id()));
            }
        }
        // Assert that the active shard routing are identical.
        Set<Map.Entry<Index, Integer>> entries = indicesAndShards.entrySet();
        final List<ShardRouting> shards = new ArrayList<>();
        for (Map.Entry<Index, Integer> e : entries) {
            Index index = e.getKey();
            for (int i = 0; i < e.getValue(); i++) {
                for (RoutingNode routingNode : routingNodes) {
                    for (ShardRouting shardRouting : routingNode) {
                        if (shardRouting.index().equals(index) && shardRouting.id() == i) {
                            shards.add(shardRouting);
                        }
                    }
                }
                List<ShardRouting> mutableShardRoutings = routingNodes.assignedShards(new ShardId(index, i));
                assert mutableShardRoutings.size() == shards.size();
                for (ShardRouting r : mutableShardRoutings) {
                    assert shards.contains(r);
                    shards.remove(r);
                }
                assert shards.isEmpty();
            }
        }

        for (ShardRouting shard : routingNodes.unassigned()) {
            if (shard.primary()) {
                unassignedPrimaryCount++;
            }
        }

        for (ShardRouting shard : routingNodes.unassigned().ignored()) {
            if (shard.primary()) {
                unassignedIgnoredPrimaryCount++;
            }
        }

        for (Map.Entry<String, Recoveries> recoveries : routingNodes.recoveriesPerNode.entrySet()) {
            String node = recoveries.getKey();
            final Recoveries value = recoveries.getValue();
            int incoming = 0;
            int outgoing = 0;
            RoutingNode routingNode = routingNodes.nodesToShards.get(node);
            if (routingNode != null) { // node might have dropped out of the cluster
                for (ShardRouting routing : routingNode) {
                    if (routing.initializing()) {
                        incoming++;
                    }
                    if (routing.primary() && routing.isRelocationTarget() == false) {
                        for (ShardRouting assigned : routingNodes.assignedShards.get(routing.shardId())) {
                            if (assigned.initializing() && assigned.recoverySource().getType() == RecoverySource.Type.PEER) {
                                outgoing++;
                            }
                        }
                    }
                }
            }
            assert incoming == value.incoming : incoming + "" != "" + value.incoming + "" node: "" + routingNode;
            assert outgoing == value.outgoing : outgoing + "" != "" + value.outgoing + "" node: "" + routingNode;
        }


        assert unassignedPrimaryCount == routingNodes.unassignedShards.getNumPrimaries() :
                ""Unassigned primaries is ["" + unassignedPrimaryCount + ""] but RoutingNodes returned unassigned primaries ["" + routingNodes.unassigned().getNumPrimaries() + ""]"";
        assert unassignedIgnoredPrimaryCount == routingNodes.unassignedShards.getNumIgnoredPrimaries() :
                ""Unassigned ignored primaries is ["" + unassignedIgnoredPrimaryCount + ""] but RoutingNodes returned unassigned ignored primaries ["" + routingNodes.unassigned().getNumIgnoredPrimaries() + ""]"";
        assert inactivePrimaryCount == routingNodes.inactivePrimaryCount :
                ""Inactive Primary count ["" + inactivePrimaryCount + ""] but RoutingNodes returned inactive primaries ["" + routingNodes.inactivePrimaryCount + ""]"";
        assert inactiveShardCount == routingNodes.inactiveShardCount :
                ""Inactive Shard count ["" + inactiveShardCount + ""] but RoutingNodes returned inactive shards ["" + routingNodes.inactiveShardCount + ""]"";
        assert routingNodes.getRelocatingShardCount() == relocating : ""Relocating shards mismatch ["" + routingNodes.getRelocatingShardCount() + ""] but expected ["" + relocating + ""]"";

        return true;
    }","public ShardRouting[] drain() {
            nodes.ensureMutable();
            ShardRouting[] mutableShardRoutings = unassigned.toArray(new ShardRouting[unassigned.size()]);
            unassigned.clear();
            primaries = 0;
            return mutableShardRoutings;
        }",/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java
85a7721185739ad8cedac3065424c42e29ea0418,662,63,"void markDead() {
        synchronized (this) {
            int failedAttempts = Math.max(this.failedAttempts, 0);
            long timeoutMillis = (long)Math.min(DEFAULT_CONNECTION_TIMEOUT_MILLIS * 2 * Math.pow(2, failedAttempts * 0.5 - 1),
                    MAX_CONNECTION_TIMEOUT_MILLIS);
            this.deadUntil = System.nanoTime() + TimeUnit.MILLISECONDS.toNanos(timeoutMillis);
            this.failedAttempts = ++failedAttempts;
            this.state = State.DEAD;
        }
    }","void markDead() {
        synchronized (this) {
            int failedAttempts = Math.max(this.failedAttempts, 0);
            long timeoutMillis = (long)Math.min(DEFAULT_CONNECTION_TIMEOUT_MILLIS * 2 * Math.pow(2, failedAttempts * 0.5 - 1),
                    MAX_CONNECTION_TIMEOUT_MILLIS);
            this.deadUntil = System.nanoTime() + TimeUnit.MILLISECONDS.toNanos(timeoutMillis);
            this.failedAttempts = ++failedAttempts;
        }
    }",/client/src/main/java/org/elasticsearch/client/Connection.java
85a7721185739ad8cedac3065424c42e29ea0418,662,80,"void markAlive() {
        if (this.state != State.ALIVE) {
            synchronized (this) {
                this.deadUntil = -1;
                this.failedAttempts = 0;
                this.state = State.ALIVE;
            }
        }
    }","void markAlive() {
        if (this.failedAttempts > 0) {
            synchronized (this) {
                this.deadUntil = -1;
                this.failedAttempts = 0;
            }
        }
    }",/client/src/main/java/org/elasticsearch/client/Connection.java
85a7721185739ad8cedac3065424c42e29ea0418,662,96,"void markResurrected() {
        if (this.state == State.DEAD) {
            synchronized (this) {
                this.state = State.UNKNOWN;
            }
        }
    }","public boolean isBlacklisted() {
        return failedAttempts > 0 && System.nanoTime() - deadUntil < 0;
    }",/client/src/main/java/org/elasticsearch/client/Connection.java
51111a81063977c2ac89df79be4aff83bc3bf92f,690,170,"protected void doExecute(Request request, ActionListener<Response> listener) {
            client.admin().cluster().state(new ClusterStateRequest(), new ActionListener<ClusterStateResponse>() {
                @Override
                public void onResponse(ClusterStateResponse clusterStateResponse) {
                    IndexMetaData leaderIndexMetadata = clusterStateResponse.getState().getMetaData()
                            .index(request.leaderIndex);
                    if (leaderIndexMetadata == null) {
                        listener.onFailure(new IllegalArgumentException(""leader index ["" + request.leaderIndex + ""] does not exist""));
                    }

                    IndexMetaData followIndexMetadata = clusterStateResponse.getState().getMetaData()
                            .index(request.followIndex);
                    if (followIndexMetadata == null) {
                        listener.onFailure(new IllegalArgumentException(""follow index ["" + request.followIndex + ""] does not exist""));
                    }

                    if (leaderIndexMetadata.getNumberOfShards() != followIndexMetadata.getNumberOfShards()) {
                        listener.onFailure(new IllegalArgumentException(""leader index primary shards ["" +
                                leaderIndexMetadata.getNumberOfShards() +  ""] does not match with the number of "" +
                                ""shards of the follow index ["" + followIndexMetadata.getNumberOfShards() + ""]""));
                        return;
                    }

                    // TODO: other validation checks

                    final int numShards = followIndexMetadata.getNumberOfShards();
                    final AtomicInteger counter = new AtomicInteger(numShards);
                    final AtomicReferenceArray<Object> responses = new AtomicReferenceArray<>(followIndexMetadata.getNumberOfShards());
                    for (int i = 0; i < numShards; i++) {
                        final int shardId = i;
                        String taskId = followIndexMetadata.getIndexUUID() + ""-"" + shardId;
                        ShardFollowTask shardFollowTask =  new ShardFollowTask(new ShardId(followIndexMetadata.getIndex(), shardId),
                                new ShardId(leaderIndexMetadata.getIndex(), shardId), request.batchSize, request.concurrentProcessors);
                        persistentTasksService.startPersistentTask(taskId, ShardFollowTask.NAME, shardFollowTask,
                                new ActionListener<PersistentTasksCustomMetaData.PersistentTask<ShardFollowTask>>() {
                            @Override
                            public void onResponse(PersistentTasksCustomMetaData.PersistentTask<ShardFollowTask> task) {
                                responses.set(shardId, task);
                                finalizeResponse();
                            }

                            @Override
                            public void onFailure(Exception e) {
                                responses.set(shardId, e);
                                finalizeResponse();
                            }

                            void finalizeResponse() {
                                Exception error = null;
                                if (counter.decrementAndGet() == 0) {
                                    for (int j = 0; j < responses.length(); j++) {
                                        Object response = responses.get(j);
                                        if (response instanceof Exception) {
                                            if (error == null) {
                                                error = (Exception) response;
                                            } else {
                                                error.addSuppressed((Throwable) response);
                                            }
                                        }
                                    }

                                    if (error == null) {
                                        // include task ids?
                                        listener.onResponse(new Response());
                                    } else {
                                        // TODO: cancel all started tasks
                                        listener.onFailure(error);
                                    }
                                }
                            }

                        });
                    }
                }

                @Override
                public void onFailure(Exception e) {
                    listener.onFailure(e);
                }
            });
        }","protected void doExecute(Request request, ActionListener<Response> listener) {
            client.admin().cluster().state(new ClusterStateRequest(), new ActionListener<ClusterStateResponse>() {
                @Override
                public void onResponse(ClusterStateResponse clusterStateResponse) {
                    IndexMetaData leaderIndexMetadata = clusterStateResponse.getState().getMetaData()
                            .index(request.leaderIndex);
                    if (leaderIndexMetadata == null) {
                        listener.onFailure(new IllegalArgumentException(""leader index ["" + request.leaderIndex + ""] does not exist""));
                        return;
                    }

                    IndexMetaData followIndexMetadata = clusterStateResponse.getState().getMetaData()
                            .index(request.followIndex);
                    if (followIndexMetadata == null) {
                        listener.onFailure(new IllegalArgumentException(""follow index ["" + request.followIndex + ""] does not exist""));
                        return;
                    }

                    if (leaderIndexMetadata.getNumberOfShards() != followIndexMetadata.getNumberOfShards()) {
                        listener.onFailure(new IllegalArgumentException(""leader index primary shards ["" +
                                leaderIndexMetadata.getNumberOfShards() +  ""] does not match with the number of "" +
                                ""shards of the follow index ["" + followIndexMetadata.getNumberOfShards() + ""]""));
                        return;
                    }

                    // TODO: other validation checks

                    final int numShards = followIndexMetadata.getNumberOfShards();
                    final AtomicInteger counter = new AtomicInteger(numShards);
                    final AtomicReferenceArray<Object> responses = new AtomicReferenceArray<>(followIndexMetadata.getNumberOfShards());
                    for (int i = 0; i < numShards; i++) {
                        final int shardId = i;
                        String taskId = followIndexMetadata.getIndexUUID() + ""-"" + shardId;
                        ShardFollowTask shardFollowTask =  new ShardFollowTask(new ShardId(followIndexMetadata.getIndex(), shardId),
                                new ShardId(leaderIndexMetadata.getIndex(), shardId), request.batchSize, request.concurrentProcessors);
                        persistentTasksService.startPersistentTask(taskId, ShardFollowTask.NAME, shardFollowTask,
                                new ActionListener<PersistentTasksCustomMetaData.PersistentTask<ShardFollowTask>>() {
                            @Override
                            public void onResponse(PersistentTasksCustomMetaData.PersistentTask<ShardFollowTask> task) {
                                responses.set(shardId, task);
                                finalizeResponse();
                            }

                            @Override
                            public void onFailure(Exception e) {
                                responses.set(shardId, e);
                                finalizeResponse();
                            }

                            void finalizeResponse() {
                                Exception error = null;
                                if (counter.decrementAndGet() == 0) {
                                    for (int j = 0; j < responses.length(); j++) {
                                        Object response = responses.get(j);
                                        if (response instanceof Exception) {
                                            if (error == null) {
                                                error = (Exception) response;
                                            } else {
                                                error.addSuppressed((Throwable) response);
                                            }
                                        }
                                    }

                                    if (error == null) {
                                        // include task ids?
                                        listener.onResponse(new Response());
                                    } else {
                                        // TODO: cancel all started tasks
                                        listener.onFailure(error);
                                    }
                                }
                            }

                        });
                    }
                }

                @Override
                public void onFailure(Exception e) {
                    listener.onFailure(e);
                }
            });
        }",/x-pack/plugin/ccr/src/main/java/org/elasticsearch/xpack/ccr/action/FollowExistingIndexAction.java
cd4634bdc653fcb4e9bb10aeee9307ecdcee50db,563,290,"public long nextRoundingValue(long time) {
            long timeLocal = time;
            timeLocal = timeZone.convertUTCToLocal(time);
            long next = timeLocal + interval;
            return timeZone.convertLocalToUTC(next, false);
        }","private boolean isInDSTGap(long instantLocal) {
            if (timeZone.isFixed()) {
                return false;
            }
            // get the offset at instantLocal (first estimate)
            int offsetLocal = timeZone.getOffset(instantLocal);
            // adjust instantLocal using the estimate and recalc the offset
            int offset = timeZone.getOffset(instantLocal - offsetLocal);
            // if the offsets differ, we must be near a DST boundary
            if (offsetLocal != offset) {
                // determine if we are in the DST gap
                long nextLocal = timeZone.nextTransition(instantLocal - offsetLocal);
                if (nextLocal == (instantLocal - offsetLocal)) {
                    nextLocal = Long.MAX_VALUE;
                }
                long nextAdjusted = timeZone.nextTransition(instantLocal - offset);
                if (nextAdjusted == (instantLocal - offset)) {
                    nextAdjusted = Long.MAX_VALUE;
                }
                if (nextLocal != nextAdjusted) {
                    // we are in the DST gap
                    return true;
                }
            }
            return false;
        }",/core/src/main/java/org/elasticsearch/common/rounding/Rounding.java
ae1d4021c0ac13454097f3f84d273a6f806c9ef6,567,77,"public void add(Job job) {
        assert job.trigger() instanceof ScheduleTrigger;
        ScheduleTrigger trigger = (ScheduleTrigger) job.trigger();
        ActiveSchedule schedule = new ActiveSchedule(job.name(), trigger.schedule(), clock.millis());
        schedules = schedules.add(schedule);
    }","public void add(Job job) {
        assert job.trigger() instanceof ScheduleTrigger;
        ScheduleTrigger trigger = (ScheduleTrigger) job.trigger();
        ActiveSchedule schedule = new ActiveSchedule(job.id(), trigger.getSchedule(), clock.millis());
        schedules = schedules.add(schedule);
    }",/src/main/java/org/elasticsearch/watcher/trigger/schedule/engine/SchedulerScheduleTriggerEngine.java
dc7cf28be4ec56fb9ddd52fac923ccde1b1af855,690,629,"Consumer<Exception> errorHandler) {
        String hitId = hit.getId();
        if (DataCounts.documentId(jobId).equals(hitId)) {
            paramsBuilder.setDataCounts(parseSearchHit(hit, DataCounts.PARSER, errorHandler));
        } else if (TimingStats.documentId(jobId).equals(hitId)) {
            paramsBuilder.setTimingStats(parseSearchHit(hit, TimingStats.PARSER, errorHandler));
        } else if (hitId.startsWith(ModelSizeStats.documentIdPrefix(jobId))) {
            ModelSizeStats.Builder modelSizeStats = parseSearchHit(hit, ModelSizeStats.LENIENT_PARSER, errorHandler);
            paramsBuilder.setModelSizeStats(modelSizeStats == null ? null : modelSizeStats.build());
        } else if (hitId.startsWith(ModelSnapshot.documentIdPrefix(jobId))) {
            ModelSnapshot.Builder modelSnapshot = parseSearchHit(hit, ModelSnapshot.LENIENT_PARSER, errorHandler);
            paramsBuilder.setModelSnapshot(modelSnapshot == null ? null : modelSnapshot.build());
        } else if (Quantiles.documentId(jobId).equals(hit.getId())) {
            paramsBuilder.setQuantiles(parseSearchHit(hit, Quantiles.LENIENT_PARSER, errorHandler));
        } else if (hitId.startsWith(MlFilter.DOCUMENT_ID_PREFIX)) {
            paramsBuilder.addFilter(parseSearchHit(hit, MlFilter.LENIENT_PARSER, errorHandler).build());
        } else {
            errorHandler.accept(new IllegalStateException(""Unexpected Id ["" + hitId + ""]""));
        }
    }","SearchHit hit) {
        String hitId = hit.getId();
        if (DataCounts.documentId(jobId).equals(hitId)) {
            paramsBuilder.setDataCounts(parseSearchHit(hit, DataCounts.PARSER));
        } else if (TimingStats.documentId(jobId).equals(hitId)) {
            paramsBuilder.setTimingStats(parseSearchHit(hit, TimingStats.PARSER));
        } else if (hitId.startsWith(ModelSizeStats.documentIdPrefix(jobId))) {
            ModelSizeStats.Builder modelSizeStats = parseSearchHit(hit, ModelSizeStats.LENIENT_PARSER);
            paramsBuilder.setModelSizeStats(modelSizeStats == null ? null : modelSizeStats.build());
        } else if (hitId.startsWith(ModelSnapshot.documentIdPrefix(jobId))) {
            ModelSnapshot.Builder modelSnapshot = parseSearchHit(hit, ModelSnapshot.LENIENT_PARSER);
            paramsBuilder.setModelSnapshot(modelSnapshot == null ? null : modelSnapshot.build());
        } else if (Quantiles.documentId(jobId).equals(hit.getId())) {
            paramsBuilder.setQuantiles(parseSearchHit(hit, Quantiles.LENIENT_PARSER));
        } else if (hitId.startsWith(MlFilter.DOCUMENT_ID_PREFIX)) {
            paramsBuilder.addFilter(parseSearchHit(hit, MlFilter.LENIENT_PARSER).build());
        } else {
            throw new IllegalStateException(""Unexpected Id ["" + hitId + ""]"");
        }
    }",/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/persistence/JobResultsProvider.java
dc7cf28be4ec56fb9ddd52fac923ccde1b1af855,563,1042,"public QueryPage<ModelPlot> modelPlot(String jobId, int from, int size) {
        SearchResponse searchResponse;
        String indexName = AnomalyDetectorsIndex.jobResultsAliasedName(jobId);
        LOGGER.trace(""ES API CALL: search model plots from index {} from {} size {}"", indexName, from, size);

        try (ThreadContext.StoredContext ignore = client.threadPool().getThreadContext().stashWithOrigin(ML_ORIGIN)) {
            searchResponse = client.prepareSearch(indexName)
                    .setIndicesOptions(MlIndicesUtils.addIgnoreUnavailable(SearchRequest.DEFAULT_INDICES_OPTIONS))
                    .setQuery(new TermsQueryBuilder(Result.RESULT_TYPE.getPreferredName(), ModelPlot.RESULT_TYPE_VALUE))
                    .setFrom(from).setSize(size)
                    .setTrackTotalHits(true)
                    .get();
        }

        List<ModelPlot> results = new ArrayList<>();

        for (SearchHit hit : searchResponse.getHits().getHits()) {
            BytesReference source = hit.getSourceRef();
            try (InputStream stream = source.streamInput();
                 XContentParser parser = XContentFactory.xContent(XContentType.JSON)
                         .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, stream)) {
                ModelPlot modelPlot = ModelPlot.LENIENT_PARSER.apply(parser, null);
                results.add(modelPlot);
            } catch (IOException e) {
                throw new ElasticsearchParseException(""failed to parse modelPlot"", e);
            }
        }

        return new QueryPage<>(results, searchResponse.getHits().getTotalHits().value, ModelPlot.RESULTS_FIELD);
    }","Consumer<Exception> errorHandler) {
        if (Strings.isEmpty(sortField)) {
            sortField = ModelSnapshot.TIMESTAMP.getPreferredName();
        }

        QueryBuilder finalQuery = QueryBuilders.boolQuery()
                .filter(QueryBuilders.existsQuery(ModelSnapshot.SNAPSHOT_DOC_COUNT.getPreferredName()))
                .must(qb);

        FieldSortBuilder sb = new FieldSortBuilder(sortField)
                .order(sortDescending ? SortOrder.DESC : SortOrder.ASC);

        String indexName = AnomalyDetectorsIndex.jobResultsAliasedName(jobId);
        LOGGER.trace(""ES API CALL: search all model snapshots from index {} sort ascending {} with filter after sort from {} size {}"",
                indexName, sortField, from, size);

        SearchRequest searchRequest = new SearchRequest(indexName);
        searchRequest.indicesOptions(MlIndicesUtils.addIgnoreUnavailable(searchRequest.indicesOptions()));
        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();
        sourceBuilder.sort(sb);
        sourceBuilder.query(finalQuery);
        sourceBuilder.from(from);
        sourceBuilder.size(size);
        sourceBuilder.trackTotalHits(true);
        searchRequest.source(sourceBuilder);
        executeAsyncWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN, searchRequest,
                ActionListener.<SearchResponse>wrap(searchResponse -> {
                    List<ModelSnapshot> results = new ArrayList<>();
                    for (SearchHit hit : searchResponse.getHits().getHits()) {
                        results.add(ModelSnapshot.fromJson(hit.getSourceRef()));
                    }

                    QueryPage<ModelSnapshot> result =
                            new QueryPage<>(results, searchResponse.getHits().getTotalHits().value, ModelSnapshot.RESULTS_FIELD);
                    handler.accept(result);
                }, errorHandler), client::search);
    }",/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/persistence/JobResultsProvider.java
b0a637d78acc0bf0e13d8063b12704adb5a37774,561,245,"private <T extends TransportRequest> void handleRequest(TcpChannel channel, Header header, InboundMessage message) throws IOException {
        final String action = header.getActionName();
        final long requestId = header.getRequestId();
        final TransportVersion version = header.getVersion();
        if (header.isHandshake()) {
            messageListener.onRequestReceived(requestId, action);
            // Cannot short circuit handshakes
            assert message.isShortCircuit() == false;
            final StreamInput stream = namedWriteableStream(message.openOrGetStreamInput());
            assertRemoteVersion(stream, header.getVersion());
            final TransportChannel transportChannel = new TcpTransportChannel(
                outboundHandler,
                channel,
                action,
                requestId,
                version,
                header.getCompressionScheme(),
                ResponseStatsConsumer.NONE,
                header.isHandshake(),
                message.takeBreakerReleaseControl()
            );
            try {
                handshaker.handleHandshake(transportChannel, requestId, stream);
            } catch (Exception e) {
                logger.warn(() -> ""error processing handshake version ["" + version + ""] received on ["" + channel + ""], closing channel"", e);
                channel.close();
            }
        } else {
            final TransportChannel transportChannel;
            final RequestHandlerRegistry<T> reg;
            try {
                reg = requestHandlers.getHandler(action);
                assert message.isShortCircuit() || reg != null : action;
                transportChannel = new TcpTransportChannel(
                    outboundHandler,
                    channel,
                    action,
                    requestId,
                    version,
                    header.getCompressionScheme(),
                    reg == null ? ResponseStatsConsumer.NONE : reg,
                    header.isHandshake(),
                    message.takeBreakerReleaseControl()
                );
            } catch (Exception e) {
                assert false : e;
                sendErrorResponse(
                    action,
                    new TcpTransportChannel(
                        outboundHandler,
                        channel,
                        action,
                        requestId,
                        version,
                        header.getCompressionScheme(),
                        ResponseStatsConsumer.NONE,
                        header.isHandshake(),
                        message.takeBreakerReleaseControl()
                    ),
                    e
                );
                return;
            }

            try {
                messageListener.onRequestReceived(requestId, action);
                if (reg != null) {
                    reg.addRequestStats(header.getNetworkMessageSize() + TcpHeader.BYTES_REQUIRED_FOR_MESSAGE_SIZE);
                }

                if (message.isShortCircuit()) {
                    sendErrorResponse(action, transportChannel, message.getException());
                } else {
                    assert reg != null;
                    final StreamInput stream = namedWriteableStream(message.openOrGetStreamInput());
                    assertRemoteVersion(stream, header.getVersion());
                    final T request;
                    try {
                        request = reg.newRequest(stream);
                    } catch (Exception e) {
                        assert ignoreDeserializationErrors : e;
                        throw e;
                    }
                    try {
                        request.remoteAddress(channel.getRemoteAddress());
                        assert requestId > 0;
                        request.setRequestId(requestId);
                        // in case we throw an exception, i.e. when the limit is hit, we don't want to verify
                        final int nextByte = stream.read();
                        // calling read() is useful to make sure the message is fully read, even if there some kind of EOS marker
                        if (nextByte != -1) {
                            final IllegalStateException exception = new IllegalStateException(
                                ""Message not fully read (request) for requestId [""
                                    + requestId
                                    + ""], action [""
                                    + action
                                    + ""], available [""
                                    + stream.available()
                                    + ""]; resetting""
                            );
                            assert ignoreDeserializationErrors : exception;
                            throw exception;
                        }
                        final String executor = reg.getExecutor();
                        if (ThreadPool.Names.SAME.equals(executor)) {
                            try (var ignored = threadPool.getThreadContext().newTraceContext()) {
                                try {
                                    reg.processMessageReceived(request, transportChannel);
                                } catch (Exception e) {
                                    sendErrorResponse(reg.getAction(), transportChannel, e);
                                }
                            }
                        } else {
                            boolean success = false;
                            request.incRef();
                            try {
                                threadPool.executor(executor)
                                    .execute(threadPool.getThreadContext().preserveContextWithTracing(new AbstractRunnable() {
                                        @Override
                                        protected void doRun() throws Exception {
                                            reg.processMessageReceived(request, transportChannel);
                                        }

                                        @Override
                                        public boolean isForceExecution() {
                                            return reg.isForceExecution();
                                        }

                                        @Override
                                        public void onFailure(Exception e) {
                                            sendErrorResponse(reg.getAction(), transportChannel, e);
                                        }

                                        @Override
                                        public void onAfter() {
                                            request.decRef();
                                        }
                                    }));
                                success = true;
                            } finally {
                                if (success == false) {
                                    request.decRef();
                                }
                            }
                        }
                    } finally {
                        request.decRef();
                    }
                }
            } catch (Exception e) {
                sendErrorResponse(action, transportChannel, e);
            }
        }
    }","private <T extends TransportRequest> void handleRequest(TcpChannel channel, Header header, InboundMessage message) throws IOException {
        final String action = header.getActionName();
        final long requestId = header.getRequestId();
        final TransportVersion version = header.getVersion();
        if (header.isHandshake()) {
            messageListener.onRequestReceived(requestId, action);
            // Cannot short circuit handshakes
            assert message.isShortCircuit() == false;
            final StreamInput stream = namedWriteableStream(message.openOrGetStreamInput());
            assertRemoteVersion(stream, header.getVersion());
            final TransportChannel transportChannel = new TcpTransportChannel(
                outboundHandler,
                channel,
                action,
                requestId,
                version,
                header.getCompressionScheme(),
                ResponseStatsConsumer.NONE,
                header.isHandshake(),
                message.takeBreakerReleaseControl()
            );
            try {
                handshaker.handleHandshake(transportChannel, requestId, stream);
            } catch (Exception e) {
                logger.warn(() -> ""error processing handshake version ["" + version + ""] received on ["" + channel + ""], closing channel"", e);
                channel.close();
            }
        } else {
            final RequestHandlerRegistry<T> reg = requestHandlers.getHandler(action);
            assert message.isShortCircuit() || reg != null : action;
            final TransportChannel transportChannel = new TcpTransportChannel(
                outboundHandler,
                channel,
                action,
                requestId,
                version,
                header.getCompressionScheme(),
                reg == null ? ResponseStatsConsumer.NONE : reg,
                header.isHandshake(),
                message.takeBreakerReleaseControl()
            );

            try {
                messageListener.onRequestReceived(requestId, action);
                if (reg != null) {
                    reg.addRequestStats(header.getNetworkMessageSize() + TcpHeader.BYTES_REQUIRED_FOR_MESSAGE_SIZE);
                }

                if (message.isShortCircuit()) {
                    sendErrorResponse(action, transportChannel, message.getException());
                } else {
                    assert reg != null;
                    final StreamInput stream = namedWriteableStream(message.openOrGetStreamInput());
                    assertRemoteVersion(stream, header.getVersion());
                    final T request;
                    try {
                        request = reg.newRequest(stream);
                    } catch (Exception e) {
                        assert ignoreDeserializationErrors : e;
                        throw e;
                    }
                    try {
                        request.remoteAddress(channel.getRemoteAddress());
                        assert requestId > 0;
                        request.setRequestId(requestId);
                        // in case we throw an exception, i.e. when the limit is hit, we don't want to verify
                        final int nextByte = stream.read();
                        // calling read() is useful to make sure the message is fully read, even if there some kind of EOS marker
                        if (nextByte != -1) {
                            final IllegalStateException exception = new IllegalStateException(
                                ""Message not fully read (request) for requestId [""
                                    + requestId
                                    + ""], action [""
                                    + action
                                    + ""], available [""
                                    + stream.available()
                                    + ""]; resetting""
                            );
                            assert ignoreDeserializationErrors : exception;
                            throw exception;
                        }
                        final String executor = reg.getExecutor();
                        if (ThreadPool.Names.SAME.equals(executor)) {
                            try (var ignored = threadPool.getThreadContext().newTraceContext()) {
                                try {
                                    reg.processMessageReceived(request, transportChannel);
                                } catch (Exception e) {
                                    sendErrorResponse(reg.getAction(), transportChannel, e);
                                }
                            }
                        } else {
                            boolean success = false;
                            request.incRef();
                            try {
                                threadPool.executor(executor)
                                    .execute(threadPool.getThreadContext().preserveContextWithTracing(new AbstractRunnable() {
                                        @Override
                                        protected void doRun() throws Exception {
                                            reg.processMessageReceived(request, transportChannel);
                                        }

                                        @Override
                                        public boolean isForceExecution() {
                                            return reg.isForceExecution();
                                        }

                                        @Override
                                        public void onFailure(Exception e) {
                                            sendErrorResponse(reg.getAction(), transportChannel, e);
                                        }

                                        @Override
                                        public void onAfter() {
                                            request.decRef();
                                        }
                                    }));
                                success = true;
                            } finally {
                                if (success == false) {
                                    request.decRef();
                                }
                            }
                        }
                    } finally {
                        request.decRef();
                    }
                }
            } catch (Exception e) {
                sendErrorResponse(action, transportChannel, e);
            }
        }
    }",/server/src/main/java/org/elasticsearch/transport/InboundHandler.java
d410ec77e2e690c0b874a04a4766aab051ba0f50,690,380,"throws IOException {
        // Also if highlighting is requested on nested documents we need to fetch the _source from the root document,
        // otherwise highlighting will attempt to fetch the _source from the nested doc, which will fail,
        // because the entire _source is only stored with the root document.
        boolean needSource = sourceRequired(context) || context.highlight() != null;

        String rootId;
        Map<String, Object> rootSourceAsMap = null;
        XContentType rootSourceContentType = null;

        SearchExecutionContext searchExecutionContext = context.getSearchExecutionContext();
        if (context instanceof InnerHitsContext.InnerHitSubContext) {
            InnerHitsContext.InnerHitSubContext innerHitsContext = (InnerHitsContext.InnerHitSubContext) context;
            rootId = innerHitsContext.getRootId();

            if (needSource) {
                SourceLookup rootLookup = innerHitsContext.getRootLookup();
                rootSourceAsMap = rootLookup.source();
                rootSourceContentType = rootLookup.sourceContentType();
            }
        } else {
            FieldsVisitor rootFieldsVisitor = new FieldsVisitor(needSource);
            loadStoredFields(searchExecutionContext::getFieldType, storedFieldReader, rootFieldsVisitor, nestedInfo.rootDoc());
            rootId = rootFieldsVisitor.id();

            if (needSource) {
                if (rootFieldsVisitor.source() != null) {
                    Tuple<XContentType, Map<String, Object>> tuple = XContentHelper.convertToMap(rootFieldsVisitor.source(), false);
                    rootSourceAsMap = tuple.v2();
                    rootSourceContentType = tuple.v1();
                } else {
                    rootSourceAsMap = Collections.emptyMap();
                }
            }
        }

        Map<String, DocumentField> docFields = emptyMap();
        Map<String, DocumentField> metaFields = emptyMap();
        if (context.hasStoredFields() && context.storedFieldsContext().fieldNames().isEmpty() == false) {
            FieldsVisitor nestedFieldsVisitor = new CustomFieldsVisitor(storedToRequestedFields.keySet(), false);
            loadStoredFields(searchExecutionContext::getFieldType, storedFieldReader, nestedFieldsVisitor, nestedInfo.doc());
            if (nestedFieldsVisitor.fields().isEmpty() == false) {
                docFields = new HashMap<>();
                metaFields = new HashMap<>();
                fillDocAndMetaFields(context, nestedFieldsVisitor, storedToRequestedFields, docFields, metaFields);
            }
        }

        SearchHit.NestedIdentity nestedIdentity = nestedInfo.nestedIdentity();

        SearchHit hit = new SearchHit(topDocId, rootId, nestedIdentity, docFields, metaFields);
        HitContext hitContext = new HitContext(hit, subReaderContext, nestedInfo.doc());

        if (rootSourceAsMap != null && rootSourceAsMap.isEmpty() == false) {
            // Isolate the nested json array object that matches with nested hit and wrap it back into the same json
            // structure with the nested json array object being the actual content. The latter is important, so that
            // features like source filtering and highlighting work consistent regardless of whether the field points
            // to a json object array for consistency reasons on how we refer to fields
            Map<String, Object> nestedSourceAsMap = new HashMap<>();
            Map<String, Object> current = nestedSourceAsMap;
            for (SearchHit.NestedIdentity nested = nestedIdentity; nested != null; nested = nested.getChild()) {
                String nestedPath = nested.getField().string();
                current.put(nestedPath, new HashMap<>());
                List<?> nestedParsedSource = XContentMapValues.extractNestedValue(nestedPath, rootSourceAsMap);
                if ((nestedParsedSource.get(0) instanceof Map) == false && hasNonNestedParent.test(nestedPath)) {
                    // When one of the parent objects are not nested then XContentMapValues.extractValue(...) extracts the values
                    // from two or more layers resulting in a list of list being returned. This is because nestedPath
                    // encapsulates two or more object layers in the _source.
                    //
                    // This is why only the first element of nestedParsedSource needs to be checked.
                    throw new IllegalArgumentException(""Cannot execute inner hits. One or more parent object fields of nested field ["" +
                        nestedPath + ""] are not nested. All parent fields need to be nested fields too"");
                }
                rootSourceAsMap = (Map<String, Object>) nestedParsedSource.get(nested.getOffset());
                if (nested.getChild() == null) {
                    current.put(nestedPath, rootSourceAsMap);
                } else {
                    Map<String, Object> next = new HashMap<>();
                    current.put(nestedPath, next);
                    current = next;
                }
            }

            hitContext.sourceLookup().setSource(nestedSourceAsMap);
            hitContext.sourceLookup().setSourceContentType(rootSourceContentType);
        }
        return hitContext;
    }","throws IOException {
        // Also if highlighting is requested on nested documents we need to fetch the _source from the root document,
        // otherwise highlighting will attempt to fetch the _source from the nested doc, which will fail,
        // because the entire _source is only stored with the root document.
        boolean needSource = sourceRequired(context) || context.highlight() != null;

        String rootId;
        Map<String, Object> rootSourceAsMap = null;
        XContentType rootSourceContentType = null;

        SearchExecutionContext searchExecutionContext = context.getSearchExecutionContext();
        if (context instanceof InnerHitsContext.InnerHitSubContext) {
            InnerHitsContext.InnerHitSubContext innerHitsContext = (InnerHitsContext.InnerHitSubContext) context;
            rootId = innerHitsContext.getRootId();

            if (needSource) {
                SourceLookup rootLookup = innerHitsContext.getRootLookup();
                rootSourceAsMap = rootLookup.source();
                rootSourceContentType = rootLookup.sourceContentType();
            }
        } else {
            FieldsVisitor rootFieldsVisitor = new FieldsVisitor(needSource);
            loadStoredFields(searchExecutionContext::getFieldType, storedFieldReader, rootFieldsVisitor, nestedInfo.rootDoc());
            rootId = rootFieldsVisitor.id();

            if (needSource) {
                if (rootFieldsVisitor.source() != null) {
                    Tuple<XContentType, Map<String, Object>> tuple = XContentHelper.convertToMap(rootFieldsVisitor.source(), false);
                    rootSourceAsMap = tuple.v2();
                    rootSourceContentType = tuple.v1();
                } else {
                    rootSourceAsMap = Collections.emptyMap();
                }
            }
        }

        Map<String, DocumentField> docFields = emptyMap();
        Map<String, DocumentField> metaFields = emptyMap();
        if (context.hasStoredFields() && context.storedFieldsContext().fieldNames().isEmpty() == false) {
            FieldsVisitor nestedFieldsVisitor = new CustomFieldsVisitor(storedToRequestedFields.keySet(), false);
            loadStoredFields(searchExecutionContext::getFieldType, storedFieldReader, nestedFieldsVisitor, nestedInfo.doc());
            if (nestedFieldsVisitor.fields().isEmpty() == false) {
                docFields = new HashMap<>();
                metaFields = new HashMap<>();
                fillDocAndMetaFields(context, nestedFieldsVisitor, storedToRequestedFields, docFields, metaFields);
            }
        }

        SearchHit.NestedIdentity nestedIdentity = nestedInfo.nestedIdentity();

        SearchHit hit = new SearchHit(topDocId, rootId, nestedIdentity, docFields, metaFields);
        HitContext hitContext = new HitContext(hit, subReaderContext, nestedInfo.doc());

        if (rootSourceAsMap != null && rootSourceAsMap.isEmpty() == false) {
            // Isolate the nested json array object that matches with nested hit and wrap it back into the same json
            // structure with the nested json array object being the actual content. The latter is important, so that
            // features like source filtering and highlighting work consistent regardless of whether the field points
            // to a json object array for consistency reasons on how we refer to fields
            Map<String, Object> nestedSourceAsMap = new HashMap<>();
            Map<String, Object> current = nestedSourceAsMap;
            for (SearchHit.NestedIdentity nested = nestedIdentity; nested != null; nested = nested.getChild()) {
                String nestedPath = nested.getField().string();
                current.put(nestedPath, new HashMap<>());
                List<Map<?, ?>> nestedParsedSource = XContentMapValues.extractNestedSources(nestedPath, rootSourceAsMap);
                if (nestedParsedSource == null) {
                    throw new IllegalStateException(""Couldn't find nested source for path "" + nestedPath);
                }
                rootSourceAsMap = (Map<String, Object>) nestedParsedSource.get(nested.getOffset());
                if (nested.getChild() == null) {
                    current.put(nestedPath, rootSourceAsMap);
                } else {
                    Map<String, Object> next = new HashMap<>();
                    current.put(nestedPath, next);
                    current = next;
                }
            }

            hitContext.sourceLookup().setSource(nestedSourceAsMap);
            hitContext.sourceLookup().setSourceContentType(rootSourceContentType);
        }
        return hitContext;
    }",/server/src/main/java/org/elasticsearch/search/fetch/FetchPhase.java
9121003c47ce768ea45c6deb2a8054cad822a50d,476,59,"public User authenticate(RestRequest request) throws AuthenticationException {
        AuthenticationToken token = token(request);
        if (token == null) {
            auditTrail.anonymousAccessDenied(request);
            throw new AuthenticationException(""missing authentication token for REST request ["" + request.uri() + ""]"");
        }
        User user = authenticate(request, token);
        if (user == null) {
            throw new AuthenticationException(""unable to authenticate user ["" + user.principal() + ""] for REST request ["" + request.uri() + ""]"");
        }
        request.putInContext(USER_KEY, user);
        return user;
    }","public User authenticate(RestRequest request) throws AuthenticationException {
        AuthenticationToken token = token(request);
        if (token == null) {
            auditTrail.anonymousAccessDenied(request);
            throw new AuthenticationException(""missing authentication token for REST request ["" + request.uri() + ""]"");
        }
        User user = authenticate(request, token);
        if (user == null) {
            throw new AuthenticationException(""unable to authenticate user ["" + token.principal() + ""] for REST request ["" + request.uri() + ""]"");
        }
        request.putInContext(USER_KEY, user);
        return user;
    }",/src/main/java/org/elasticsearch/shield/authc/InternalAuthenticationService.java
4b4594e30cb5206f9e7a0ba08813a87965696a3a,563,602,"public void testEvalNull() throws Exception {
        var optimized = optimizedPlan(physicalPlan(""""""
            from test
            | eval nullsum = emp_no + null
            | project *
            | sort nullsum
            | limit 1
            """"""));
        var topN = as(optimized, TopNExec.class);
        var exchange = as(topN.child(), ExchangeExec.class);
        var topNLocal = as(exchange.child(), TopNExec.class);
        var project = as(topNLocal.child(), ProjectExec.class);
        var extract = as(project.child(), FieldExtractExec.class);
        var eval = as(extract.child(), EvalExec.class);
    }","public void testExtractorForEvalWithoutProject() throws Exception {
        var optimized = optimizedPlan(physicalPlan(""""""
            from test
            | eval nullsum = emp_no + null
            | sort nullsum
            | limit 1
            """"""));
        var topN = as(optimized, TopNExec.class);
        var exchange = as(topN.child(), ExchangeExec.class);
        var project = as(exchange.child(), ProjectExec.class);
        var extract = as(project.child(), FieldExtractExec.class);
        var topNLocal = as(extract.child(), TopNExec.class);
        var eval = as(topNLocal.child(), EvalExec.class);
    }",/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/PhysicalPlanOptimizerTests.java
139128856a5f63deb41243756e2b3b3a843fa57c,563,182,"public Collection<TriggeredWatch> findTriggeredWatches(Collection<Watch> watches, ClusterState clusterState) {
        if (watches.isEmpty()) {
            return Collections.emptyList();
        }

        // non existing index, return immediately
        IndexMetaData indexMetaData = WatchStoreUtils.getConcreteIndex(TriggeredWatchStoreField.INDEX_NAME, clusterState.metaData());
        if (indexMetaData == null) {
            return Collections.emptyList();
        }

        try (ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), WATCHER_ORIGIN)) {
            client.admin().indices().refresh(new RefreshRequest(TriggeredWatchStoreField.INDEX_NAME))
                .actionGet(TimeValue.timeValueSeconds(5));
        } catch (IndexNotFoundException e) {
            return Collections.emptyList();
        }

        Set<String> ids = watches.stream().map(Watch::id).collect(Collectors.toSet());
        Collection<TriggeredWatch> triggeredWatches = new ArrayList<>(ids.size());

        SearchRequest searchRequest = new SearchRequest(TriggeredWatchStoreField.INDEX_NAME)
            .scroll(scrollTimeout)
            .preference(Preference.LOCAL.toString())
            .source(new SearchSourceBuilder()
                .size(scrollSize)
                .sort(SortBuilders.fieldSort(""_doc""))
                .version(true));

        SearchResponse response = null;
        try (ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), WATCHER_ORIGIN)) {
            response = client.search(searchRequest).actionGet(defaultSearchTimeout);
            logger.debug(""trying to find triggered watches for ids {}: found [{}] docs"", ids, response.getHits().getTotalHits());
            while (response.getHits().getHits().length != 0) {
                for (SearchHit hit : response.getHits()) {
                    Wid wid = new Wid(hit.getId());
                    if (ids.contains(wid.watchId())) {
                        TriggeredWatch triggeredWatch = triggeredWatchParser.parse(hit.getId(), hit.getVersion(), hit.getSourceRef());
                        triggeredWatches.add(triggeredWatch);
                    }
                }
                SearchScrollRequest request = new SearchScrollRequest(response.getScrollId());
                request.scroll(scrollTimeout);
                response = client.searchScroll(request).actionGet(defaultSearchTimeout);
            }
        } finally {
            if (response != null) {
                try (ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), WATCHER_ORIGIN)) {
                    ClearScrollRequest clearScrollRequest = new ClearScrollRequest();
                    clearScrollRequest.addScrollId(response.getScrollId());
                    client.clearScroll(clearScrollRequest).actionGet(scrollTimeout);
                }
            }
        }

        return triggeredWatches;
    }","public Collection<TriggeredWatch> findTriggeredWatches(Collection<Watch> watches, ClusterState clusterState) {
        if (watches.isEmpty()) {
            return Collections.emptyList();
        }

        // non existing index, return immediately
        IndexMetaData indexMetaData = WatchStoreUtils.getConcreteIndex(TriggeredWatchStoreField.INDEX_NAME, clusterState.metaData());
        if (indexMetaData == null) {
            return Collections.emptyList();
        }

        try {
            RefreshRequest request = new RefreshRequest(TriggeredWatchStoreField.INDEX_NAME);
            client.admin().indices().refresh(request).actionGet(TimeValue.timeValueSeconds(5));
        } catch (IndexNotFoundException e) {
            return Collections.emptyList();
        }

        Set<String> ids = watches.stream().map(Watch::id).collect(Collectors.toSet());
        Collection<TriggeredWatch> triggeredWatches = new ArrayList<>(ids.size());

        SearchRequest searchRequest = new SearchRequest(TriggeredWatchStoreField.INDEX_NAME)
            .scroll(scrollTimeout)
            .preference(Preference.LOCAL.toString())
            .source(new SearchSourceBuilder()
                .size(scrollSize)
                .sort(SortBuilders.fieldSort(""_doc""))
                .version(true));

        SearchResponse response = null;
        try {
            response = client.search(searchRequest).actionGet(defaultSearchTimeout);
            logger.debug(""trying to find triggered watches for ids {}: found [{}] docs"", ids, response.getHits().getTotalHits());
            while (response.getHits().getHits().length != 0) {
                for (SearchHit hit : response.getHits()) {
                    Wid wid = new Wid(hit.getId());
                    if (ids.contains(wid.watchId())) {
                        TriggeredWatch triggeredWatch = triggeredWatchParser.parse(hit.getId(), hit.getVersion(), hit.getSourceRef());
                        triggeredWatches.add(triggeredWatch);
                    }
                }
                SearchScrollRequest request = new SearchScrollRequest(response.getScrollId());
                request.scroll(scrollTimeout);
                response = client.searchScroll(request).actionGet(defaultSearchTimeout);
            }
        } finally {
            if (response != null) {
                ClearScrollRequest clearScrollRequest = new ClearScrollRequest();
                clearScrollRequest.addScrollId(response.getScrollId());
                client.clearScroll(clearScrollRequest).actionGet(scrollTimeout);
            }
        }

        return triggeredWatches;
    }",/x-pack/plugin/watcher/src/main/java/org/elasticsearch/xpack/watcher/execution/TriggeredWatchStore.java
139128856a5f63deb41243756e2b3b3a843fa57c,563,120,"public void delete(Wid wid) {
        DeleteRequest request = new DeleteRequest(TriggeredWatchStoreField.INDEX_NAME, TriggeredWatchStoreField.DOC_TYPE, wid.value());
        try (ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), WATCHER_ORIGIN)) {
            client.delete(request); // FIXME shouldn't we wait before saying the delete was successful
        }
        logger.trace(""successfully deleted triggered watch with id [{}]"", wid);
    }","public void delete(Wid wid) {
        DeleteRequest request = new DeleteRequest(TriggeredWatchStoreField.INDEX_NAME, TriggeredWatchStoreField.DOC_TYPE, wid.value());
        bulkProcessor.add(request);
    }",/x-pack/plugin/watcher/src/main/java/org/elasticsearch/xpack/watcher/execution/TriggeredWatchStore.java
139128856a5f63deb41243756e2b3b3a843fa57c,563,511,"private GetResponse getWatch(String id) {
        try (ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), WATCHER_ORIGIN)) {
            GetRequest getRequest = new GetRequest(Watch.INDEX, Watch.DOC_TYPE, id).preference(Preference.LOCAL.type()).realtime(true);
            PlainActionFuture<GetResponse> future = PlainActionFuture.newFuture();
            client.get(getRequest, future);
            return future.actionGet();
        }
    }","public Counters executionTimes() {
        Counters counters = new Counters();
        counters.inc(""execution.actions._all.total"", totalExecutionsTime.count());
        counters.inc(""execution.actions._all.total_time_in_ms"", totalExecutionsTime.sum());

        for (Map.Entry<String, MeanMetric> entry : actionByTypeExecutionTime.entrySet()) {
            counters.inc(""execution.actions."" + entry.getKey() + "".total"", entry.getValue().count());
            counters.inc(""execution.actions."" + entry.getKey() + "".total_time_in_ms"", entry.getValue().sum());
        }

        return counters;
    }",/x-pack/plugin/watcher/src/main/java/org/elasticsearch/xpack/watcher/execution/ExecutionService.java
139128856a5f63deb41243756e2b3b3a843fa57c,563,73,"public void put(WatchRecord watchRecord) throws Exception {
        String index = HistoryStoreField.getHistoryIndexNameForTime(watchRecord.triggerEvent().triggeredTime());
        putUpdateLock.lock();
        try (XContentBuilder builder = XContentFactory.jsonBuilder();
             ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), WATCHER_ORIGIN)) {
            watchRecord.toXContent(builder, WatcherParams.HIDE_SECRETS);

            IndexRequest request = new IndexRequest(index, DOC_TYPE, watchRecord.id().value())
                .source(builder)
                .opType(IndexRequest.OpType.CREATE);
            client.index(request).actionGet(30, TimeUnit.SECONDS);
            logger.debug(""indexed watch history record [{}]"", watchRecord.id().value());
        } catch (IOException ioe) {
            throw ioException(""failed to persist watch record [{}]"", ioe, watchRecord);
        } finally {
            putUpdateLock.unlock();
        }
    }","public void forcePut(WatchRecord watchRecord) {
        String index = HistoryStoreField.getHistoryIndexNameForTime(watchRecord.triggerEvent().triggeredTime());
            try (XContentBuilder builder = XContentFactory.jsonBuilder()) {
                watchRecord.toXContent(builder, WatcherParams.HIDE_SECRETS);

                IndexRequest request = new IndexRequest(index, DOC_TYPE, watchRecord.id().value()).source(builder);
                bulkProcessor.add(request);
        } catch (IOException ioe) {
            final WatchRecord wr = watchRecord;
            logger.error((Supplier<?>) () -> new ParameterizedMessage(""failed to persist watch record [{}]"", wr), ioe);
        }
    }",/x-pack/plugin/watcher/src/main/java/org/elasticsearch/xpack/watcher/history/HistoryStore.java
7bb676ad4f94a1b92c1968012534cf5c925dabcd,563,527,"public void testHalfDeletedIndexImport() throws Exception {
        // It's possible for a 6.x node to add a tombstone for an index but not actually delete the index metadata from disk since that
        // deletion is slightly deferred and may race against the node being shut down; if you upgrade to 7.x when in this state then the
        // node won't start.

        internalCluster().startNode();
        createIndex(""test"", Settings.builder()
            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)
            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)
            .build());
        ensureGreen(""test"");

        final Metadata metadata = internalCluster().getInstance(ClusterService.class).state().metadata();
        final Path[] paths = internalCluster().getInstance(NodeEnvironment.class).nodeDataPaths();
//        writeBrokenMeta(metaStateService -> {
//            metaStateService.writeGlobalState(""test"", Metadata.builder(metadata)
//                // we remove the manifest file, resetting the term and making this look like an upgrade from 6.x, so must also reset the
//                // term in the coordination metadata
//                .coordinationMetadata(CoordinationMetadata.builder(metadata.coordinationMetadata()).term(0L).build())
//                // add a tombstone but do not delete the index metadata from disk
//               .putCustom(IndexGraveyard.TYPE, IndexGraveyard.builder().addTombstone(metadata.index(""test"").getIndex()).build()).build());
//            for (final Path path : paths) {
//                try (Stream<Path> stateFiles = Files.list(path.resolve(MetadataStateFormat.STATE_DIR_NAME))) {
//                    for (final Path manifestPath : stateFiles
//                        .filter(p -> p.getFileName().toString().startsWith(Manifest.FORMAT.getPrefix())).collect(Collectors.toList())) {
//                        IOUtils.rm(manifestPath);
//                    }
//                }
//            }
//        });

        ensureGreen();

        assertBusy(() -> assertThat(internalCluster().getInstance(NodeEnvironment.class).availableIndexFolders(), empty()));
    }","public void testHalfDeletedIndexImport() throws Exception {
        // It's possible for a 6.x node to add a tombstone for an index but not actually delete the index metadata from disk since that
        // deletion is slightly deferred and may race against the node being shut down; if you upgrade to 7.x when in this state then the
        // node won't start.

        final String nodeName = internalCluster().startNode();
        createIndex(""test"", Settings.builder()
            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)
            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)
            .build());
        ensureGreen(""test"");

        final Metadata metadata = internalCluster().getInstance(ClusterService.class).state().metadata();
        final Path[] paths = internalCluster().getInstance(NodeEnvironment.class).nodeDataPaths();
        final String nodeId = client().admin().cluster().prepareNodesInfo(nodeName).clear().get().getNodes().get(0).getNode().getId();

        writeBrokenMeta(metaStateService -> {
            for (final Path path : paths) {
                IOUtils.rm(path.resolve(PersistedClusterStateService.METADATA_DIRECTORY_NAME));
            }
            metaStateService.writeGlobalState(""test"", Metadata.builder(metadata)
                // we remove the manifest file, resetting the term and making this look like an upgrade from 6.x, so must also reset the
                // term in the coordination metadata
                .coordinationMetadata(CoordinationMetadata.builder(metadata.coordinationMetadata()).term(0L).build())
                // add a tombstone but do not delete the index metadata from disk
               .putCustom(IndexGraveyard.TYPE, IndexGraveyard.builder().addTombstone(metadata.index(""test"").getIndex()).build()).build());
            NodeMetadata.FORMAT.writeAndCleanup(new NodeMetadata(nodeId, Version.CURRENT), paths);
        });

        ensureGreen();

        assertBusy(() -> assertThat(internalCluster().getInstance(NodeEnvironment.class).availableIndexFolders(), empty()));
    }",/server/src/internalClusterTest/java/org/elasticsearch/gateway/GatewayIndexStateIT.java
7c6d745523ca6b5f1357bdacdc4ab61dcac1d2b9,391,520,"public void run() {
            while (running) {
                estimatedTimeInMillis = System.currentTimeMillis();
                try {
                    Thread.sleep(interval);
                } catch (InterruptedException e) {
                    running = false;
                    return;
                }
                try {
                    FileSystemUtils.checkMkdirsStall(estimatedTimeInMillis);
                } catch (Exception e) {
                    // ignore
                }
            }
        }","public void run() {
            while (running) {
                estimatedTimeInMillis = System.currentTimeMillis();
                try {
                    Thread.sleep(interval);
                } catch (InterruptedException e) {
                    running = false;
                    return;
                }
            }
        }",/src/main/java/org/elasticsearch/threadpool/ThreadPool.java
4620dd6853e9da167325b5993370bbada696fa2d,563,84,"void handleHandshake(TransportChannel channel, long requestId, StreamInput stream) throws IOException {
        // Must read the handshake request to exhaust the stream
        HandshakeRequest handshakeRequest = new HandshakeRequest(stream);
        final int nextByte = stream.read();
        if (nextByte != -1) {
            throw new IllegalStateException(
                ""Handshake request not fully read for requestId [""
                    + requestId
                    + ""], action [""
                    + TransportHandshaker.HANDSHAKE_ACTION_NAME
                    + ""], available [""
                    + stream.available()
                    + ""]; resetting""
            );
        }
        channel.sendResponse(new HandshakeResponse(this.version));
    }","void sendHandshake(long requestId, DiscoveryNode node, TcpChannel channel, TimeValue timeout, ActionListener<Version> listener) {
        numHandshakes.inc();
        final HandshakeResponseHandler handler = new HandshakeResponseHandler(requestId, version, listener);
        pendingHandshakes.put(requestId, handler);
        channel.addCloseListener(
            ActionListener.wrap(() -> handler.handleLocalException(new TransportException(""handshake failed because connection reset"")))
        );
        boolean success = false;
        try {
            // for the request we use the minCompatVersion since we don't know what's the version of the node we talk to
            // we also have no payload on the request but the response will contain the actual version of the node we talk
            // to as the payload.
            final Version minCompatVersion = version.minimumCompatibilityVersion();
            handshakeRequestSender.sendRequest(node, channel, requestId, minCompatVersion);

            threadPool.schedule(
                () -> handler.handleLocalException(new ConnectTransportException(node, ""handshake_timeout["" + timeout + ""]"")),
                timeout,
                ThreadPool.Names.GENERIC
            );
            success = true;
        } catch (Exception e) {
            handler.handleLocalException(new ConnectTransportException(node, ""failure to send "" + HANDSHAKE_ACTION_NAME, e));
        } finally {
            if (success == false) {
                TransportResponseHandler<?> removed = pendingHandshakes.remove(requestId);
                assert removed == null : ""Handshake should not be pending if exception was thrown"";
            }
        }
    }",/server/src/main/java/org/elasticsearch/transport/TransportHandshaker.java
4620dd6853e9da167325b5993370bbada696fa2d,563,110,"private void messageReceived(TcpChannel channel, InboundMessage message, long startTime) throws IOException {
        final InetSocketAddress remoteAddress = channel.getRemoteAddress();
        final Header header = message.getHeader();
        assert header.needsToReadVariableHeader() == false;

        TransportResponseHandler<?> responseHandler = null;
        final boolean isRequest = message.getHeader().isRequest();

        ThreadContext threadContext = threadPool.getThreadContext();
        try (ThreadContext.StoredContext existing = threadContext.stashContext()) {
            // Place the context with the headers from the message
            threadContext.setHeaders(header.getHeaders());
            threadContext.putTransient(""_remote_address"", remoteAddress);
            if (isRequest) {
                handleRequest(channel, header, message);
            } else {
                // Responses do not support short circuiting currently
                assert message.isShortCircuit() == false;
                long requestId = header.getRequestId();
                if (header.isHandshake()) {
                    responseHandler = handshaker.removeHandlerForHandshake(requestId);
                } else {
                    final TransportResponseHandler<? extends TransportResponse> theHandler = responseHandlers.onResponseReceived(
                        requestId,
                        messageListener
                    );
                    if (theHandler == null && header.isError()) {
                        responseHandler = handshaker.removeHandlerForHandshake(requestId);
                    } else {
                        responseHandler = theHandler;
                    }
                }
                // ignore if its null, the service logs it
                if (responseHandler != null) {
                    final StreamInput streamInput;
                    if (message.getContentLength() > 0 || header.getVersion().equals(Version.CURRENT) == false) {
                        streamInput = namedWriteableStream(message.openOrGetStreamInput());
                        assertRemoteVersion(streamInput, header.getVersion());
                        if (header.isError()) {
                            handlerResponseError(streamInput, responseHandler);
                        } else {
                            handleResponse(remoteAddress, streamInput, responseHandler);
                        }
                        // Check the entire message has been read
                        final int nextByte = streamInput.read();
                        // calling read() is useful to make sure the message is fully read, even if there is an EOS marker
                        if (nextByte != -1) {
                            throw new IllegalStateException(
                                ""Message not fully read (response) for requestId [""
                                    + requestId
                                    + ""], handler [""
                                    + responseHandler
                                    + ""], error [""
                                    + header.isError()
                                    + ""]; resetting""
                            );
                        }
                    } else {
                        assert header.isError() == false;
                        handleResponse(remoteAddress, EMPTY_STREAM_INPUT, responseHandler);
                    }
                }
            }
        } finally {
            final long took = threadPool.rawRelativeTimeInMillis() - startTime;
            handlingTimeTracker.addHandlingTime(took);
            final long logThreshold = slowLogThresholdMs;
            if (logThreshold > 0 && took > logThreshold) {
                if (isRequest) {
                    logger.warn(
                        ""handling request [{}] took [{}ms] which is above the warn threshold of [{}ms]"",
                        message,
                        took,
                        logThreshold
                    );
                } else {
                    logger.warn(
                        ""handling response [{}] on handler [{}] took [{}ms] which is above the warn threshold of [{}ms]"",
                        message,
                        responseHandler,
                        took,
                        logThreshold
                    );
                }
            }
        }
    }","private void messageReceived(TcpChannel channel, InboundMessage message, long startTime) throws IOException {
        final InetSocketAddress remoteAddress = channel.getRemoteAddress();
        final Header header = message.getHeader();
        assert header.needsToReadVariableHeader() == false;

        TransportResponseHandler<?> responseHandler = null;
        final boolean isRequest = message.getHeader().isRequest();

        ThreadContext threadContext = threadPool.getThreadContext();
        try (ThreadContext.StoredContext existing = threadContext.stashContext()) {
            // Place the context with the headers from the message
            threadContext.setHeaders(header.getHeaders());
            threadContext.putTransient(""_remote_address"", remoteAddress);
            if (isRequest) {
                handleRequest(channel, header, message);
            } else {
                // Responses do not support short circuiting currently
                assert message.isShortCircuit() == false;
                long requestId = header.getRequestId();
                if (header.isHandshake()) {
                    responseHandler = handshaker.removeHandlerForHandshake(requestId);
                } else {
                    final TransportResponseHandler<? extends TransportResponse> theHandler = responseHandlers.onResponseReceived(
                        requestId,
                        messageListener
                    );
                    if (theHandler == null && header.isError()) {
                        responseHandler = handshaker.removeHandlerForHandshake(requestId);
                    } else {
                        responseHandler = theHandler;
                    }
                }
                // ignore if its null, the service logs it
                if (responseHandler != null) {
                    final StreamInput streamInput;
                    if (message.getContentLength() > 0 || header.getVersion().equals(Version.CURRENT) == false) {
                        streamInput = namedWriteableStream(message.openOrGetStreamInput());
                        assertRemoteVersion(streamInput, header.getVersion());
                        if (header.isError()) {
                            handlerResponseError(streamInput, responseHandler);
                        } else {
                            handleResponse(remoteAddress, streamInput, responseHandler);
                        }
                        // Check the entire message has been read
                        final int nextByte = streamInput.read();
                        // calling read() is useful to make sure the message is fully read, even if there is an EOS marker
                        if (nextByte != -1) {
                            final IllegalStateException exception = new IllegalStateException(
                                ""Message not fully read (response) for requestId [""
                                    + requestId
                                    + ""], handler [""
                                    + responseHandler
                                    + ""], error [""
                                    + header.isError()
                                    + ""]; resetting""
                            );
                            assert ignoreDeserializationErrors : exception;
                            throw exception;
                        }
                    } else {
                        assert header.isError() == false;
                        handleResponse(remoteAddress, EMPTY_STREAM_INPUT, responseHandler);
                    }
                }
            }
        } finally {
            final long took = threadPool.rawRelativeTimeInMillis() - startTime;
            handlingTimeTracker.addHandlingTime(took);
            final long logThreshold = slowLogThresholdMs;
            if (logThreshold > 0 && took > logThreshold) {
                if (isRequest) {
                    logger.warn(
                        ""handling request [{}] took [{}ms] which is above the warn threshold of [{}ms]"",
                        message,
                        took,
                        logThreshold
                    );
                } else {
                    logger.warn(
                        ""handling response [{}] on handler [{}] took [{}ms] which is above the warn threshold of [{}ms]"",
                        message,
                        responseHandler,
                        took,
                        logThreshold
                    );
                }
            }
        }
    }",/server/src/main/java/org/elasticsearch/transport/InboundHandler.java
143cd9bbaa082fa9535990bba32c47739411cb4d,595,467,"DocumentMapper mapper, MergeReason reason) {
        boolean hasNested = this.hasNested;
        Map<String, ObjectMapper> fullPathObjectMappers = this.fullPathObjectMappers;
        FieldTypeLookup fieldTypes = this.fieldTypes;

        Map<String, DocumentMapper> results = new LinkedHashMap<>(2);

        if (defaultMapper != null) {
            if (indexSettings.getIndexVersionCreated().onOrAfter(Version.V_7_0_0_alpha1)) {
                throw new IllegalArgumentException(""The [default] mapping cannot be updated on index ["" + index().getName() +
                        ""]: defaults mappings are not useful anymore now that indices can have at most one type."");
            } else if (reason == MergeReason.MAPPING_UPDATE) { // only log in case of explicit mapping updates
                DEPRECATION_LOGGER.deprecated(""[_default_] mapping is deprecated since it is not useful anymore now that indexes "" +
                        ""cannot have more than one type"");
            }
            assert defaultMapper.type().equals(DEFAULT_MAPPING);
            results.put(DEFAULT_MAPPING, defaultMapper);
        }

        {
            if (mapper != null && this.mapper != null && Objects.equals(this.mapper.type(), mapper.type()) == false) {
                throw new IllegalArgumentException(
                        ""Rejecting mapping update to ["" + index().getName() + ""] as the final mapping would have more than 1 type: "" + Arrays.asList(this.mapper.type(), mapper.type()));
            }
        }

        DocumentMapper newMapper = null;
        if (mapper != null) {
            // check naming
            validateTypeName(mapper.type());

            // compute the merged DocumentMapper
            DocumentMapper oldMapper = this.mapper;
            if (oldMapper != null) {
                newMapper = oldMapper.merge(mapper.mapping());
            } else {
                newMapper = mapper;
            }

            // check basic sanity of the new mapping
            List<ObjectMapper> objectMappers = new ArrayList<>();
            List<FieldMapper> fieldMappers = new ArrayList<>();
            List<FieldAliasMapper> fieldAliasMappers = new ArrayList<>();
            Collections.addAll(fieldMappers, newMapper.mapping().metadataMappers);
            MapperUtils.collect(newMapper.mapping().root(), objectMappers, fieldMappers, fieldAliasMappers);

            MapperMergeValidator.validateMapperStructure(newMapper.type(), objectMappers, fieldMappers,
                fieldAliasMappers, fullPathObjectMappers, fieldTypes);
            checkPartitionedIndexConstraints(newMapper);

            // update lookup data-structures
            // this will in particular make sure that the merged fields are compatible with other types
            fieldTypes = fieldTypes.copyAndAddAll(newMapper.type(), fieldMappers, fieldAliasMappers);

            for (ObjectMapper objectMapper : objectMappers) {
                if (fullPathObjectMappers == this.fullPathObjectMappers) {
                    // first time through the loops
                    fullPathObjectMappers = new HashMap<>(this.fullPathObjectMappers);
                }
                fullPathObjectMappers.put(objectMapper.fullPath(), objectMapper);

                if (objectMapper.nested().isNested()) {
                    hasNested = true;
                }
            }

            MapperMergeValidator.validateFieldReferences(fieldMappers, fieldAliasMappers,
                fullPathObjectMappers, fieldTypes);

            ContextMapping.validateContextPaths(indexSettings.getIndexVersionCreated(), fieldMappers, fieldTypes::get);

            if (reason == MergeReason.MAPPING_UPDATE) {
                // this check will only be performed on the master node when there is
                // a call to the update mapping API. For all other cases like
                // the master node restoring mappings from disk or data nodes
                // deserializing cluster state that was sent by the master node,
                // this check will be skipped.
                checkTotalFieldsLimit(objectMappers.size() + fieldMappers.size() + fieldAliasMappers.size());
            }

            results.put(newMapper.type(), newMapper);
        }

        if (reason == MergeReason.MAPPING_UPDATE) {
            // this check will only be performed on the master node when there is
            // a call to the update mapping API. For all other cases like
            // the master node restoring mappings from disk or data nodes
            // deserializing cluster state that was sent by the master node,
            // this check will be skipped.
            checkNestedFieldsLimit(fullPathObjectMappers);
            checkDepthLimit(fullPathObjectMappers.keySet());
        }
        checkIndexSortCompatibility(indexSettings.getIndexSortConfig(), hasNested);

        if (newMapper != null) {
            DocumentMapper updatedDocumentMapper = newMapper.updateFieldType(fieldTypes.fullNameToFieldType);
            if (updatedDocumentMapper != newMapper) {
                // update both mappers and result
                newMapper = updatedDocumentMapper;
                results.put(updatedDocumentMapper.type(), updatedDocumentMapper);
            }
        }

        // make structures immutable
        results = Collections.unmodifiableMap(results);

        // only need to immutably rewrap these if the previous reference was changed.
        // if not then they are already implicitly immutable.
        if (fullPathObjectMappers != this.fullPathObjectMappers) {
            fullPathObjectMappers = Collections.unmodifiableMap(fullPathObjectMappers);
        }

        // commit the change
        if (defaultMappingSource != null) {
            this.defaultMappingSource = defaultMappingSource;
        }
        if (newMapper != null) {
            this.mapper = newMapper;
        }
        this.defaultMapper = defaultMapper;
        this.fieldTypes = fieldTypes;
        this.hasNested = hasNested;
        this.fullPathObjectMappers = fullPathObjectMappers;

        assert assertMappersShareSameFieldType();
        assert results.values().stream().allMatch(this::assertSerialization);

        return results;
    }","DocumentMapper mapper, MergeReason reason) {
        boolean hasNested = this.hasNested;
        Map<String, ObjectMapper> fullPathObjectMappers = this.fullPathObjectMappers;
        FieldTypeLookup fieldTypes = this.fieldTypes;

        Map<String, DocumentMapper> results = new LinkedHashMap<>(2);

        if (defaultMapper != null) {
            if (indexSettings.getIndexVersionCreated().onOrAfter(Version.V_7_0_0_alpha1)) {
                throw new IllegalArgumentException(""The [default] mapping cannot be updated on index ["" + index().getName() +
                        ""]: defaults mappings are not useful anymore now that indices can have at most one type."");
            } else if (reason == MergeReason.MAPPING_UPDATE) { // only log in case of explicit mapping updates
                DEPRECATION_LOGGER.deprecated(""[_default_] mapping is deprecated since it is not useful anymore now that indexes "" +
                        ""cannot have more than one type"");
            }
            assert defaultMapper.type().equals(DEFAULT_MAPPING);
            results.put(DEFAULT_MAPPING, defaultMapper);
        }

        {
            if (mapper != null && this.mapper != null && Objects.equals(this.mapper.type(), mapper.type()) == false) {
                throw new IllegalArgumentException(
                        ""Rejecting mapping update to ["" + index().getName() + ""] as the final mapping would have more than 1 type: "" + Arrays.asList(this.mapper.type(), mapper.type()));
            }
        }

        DocumentMapper newMapper = null;
        if (mapper != null) {
            // check naming
            validateTypeName(mapper.type());

            // compute the merged DocumentMapper
            DocumentMapper oldMapper = this.mapper;
            if (oldMapper != null) {
                newMapper = oldMapper.merge(mapper.mapping());
            } else {
                newMapper = mapper;
            }

            // check basic sanity of the new mapping
            List<ObjectMapper> objectMappers = new ArrayList<>();
            List<FieldMapper> fieldMappers = new ArrayList<>();
            List<FieldAliasMapper> fieldAliasMappers = new ArrayList<>();
            Collections.addAll(fieldMappers, newMapper.mapping().metadataMappers);
            MapperUtils.collect(newMapper.mapping().root(), objectMappers, fieldMappers, fieldAliasMappers);

            MapperMergeValidator.validateMapperStructure(newMapper.type(), objectMappers, fieldMappers,
                fieldAliasMappers, fullPathObjectMappers, fieldTypes);
            checkPartitionedIndexConstraints(newMapper);

            // update lookup data-structures
            // this will in particular make sure that the merged fields are compatible with other types
            fieldTypes = fieldTypes.copyAndAddAll(newMapper.type(), fieldMappers, fieldAliasMappers);

            for (ObjectMapper objectMapper : objectMappers) {
                if (fullPathObjectMappers == this.fullPathObjectMappers) {
                    // first time through the loops
                    fullPathObjectMappers = new HashMap<>(this.fullPathObjectMappers);
                }
                fullPathObjectMappers.put(objectMapper.fullPath(), objectMapper);

                if (objectMapper.nested().isNested()) {
                    hasNested = true;
                }
            }

            MapperMergeValidator.validateFieldReferences(fieldMappers, fieldAliasMappers,
                fullPathObjectMappers, fieldTypes);

            ContextMapping.validateContextPaths(indexSettings.getIndexVersionCreated(), fieldMappers, fieldTypes::get);

            if (reason == MergeReason.MAPPING_UPDATE) {
                // this check will only be performed on the master node when there is
                // a call to the update mapping API. For all other cases like
                // the master node restoring mappings from disk or data nodes
                // deserializing cluster state that was sent by the master node,
                // this check will be skipped.
                checkTotalFieldsLimit(objectMappers.size() + fieldMappers.size() + fieldAliasMappers.size());
            }

            results.put(newMapper.type(), newMapper);
        }

        if (reason == MergeReason.MAPPING_UPDATE) {
            // this check will only be performed on the master node when there is
            // a call to the update mapping API. For all other cases like
            // the master node restoring mappings from disk or data nodes
            // deserializing cluster state that was sent by the master node,
            // this check will be skipped.
            checkNestedFieldsLimit(fullPathObjectMappers);
            checkDepthLimit(fullPathObjectMappers.keySet());
        }
        checkIndexSortCompatibility(indexSettings.getIndexSortConfig(), hasNested);

        if (newMapper != null) {
            DocumentMapper updatedDocumentMapper = newMapper.updateFieldType(fieldTypes.fullNameToFieldType);
            if (updatedDocumentMapper != newMapper) {
                // update both mappers and result
                newMapper = updatedDocumentMapper;
                results.put(updatedDocumentMapper.type(), updatedDocumentMapper);
            }
        }

        // make structures immutable
        results = Collections.unmodifiableMap(results);

        // only need to immutably rewrap these if the previous reference was changed.
        // if not then they are already implicitly immutable.
        if (fullPathObjectMappers != this.fullPathObjectMappers) {
            fullPathObjectMappers = Collections.unmodifiableMap(fullPathObjectMappers);
        }

        // commit the change
        if (defaultMappingSource != null) {
            this.defaultMappingSource = defaultMappingSource;
            this.defaultMapper = defaultMapper;
        }
        if (newMapper != null) {
            this.mapper = newMapper;
        }
        this.fieldTypes = fieldTypes;
        this.hasNested = hasNested;
        this.fullPathObjectMappers = fullPathObjectMappers;

        assert assertMappersShareSameFieldType();
        assert results.values().stream().allMatch(this::assertSerialization);

        return results;
    }",/server/src/main/java/org/elasticsearch/index/mapper/MapperService.java
8bbc312fdd2442ce5c9ad431ab0c61930069df2f,561,301,"private void deleteIndices(final ClusterChangedEvent event) {
        final ClusterState previousState = event.previousState();
        final ClusterState state = event.state();
        final String localNodeId = state.nodes().getLocalNodeId();
        assert localNodeId != null;

        for (Index index : event.indicesDeleted()) {
            if (logger.isDebugEnabled()) {
                logger.debug(""[{}] cleaning index, no longer part of the metadata"", index);
            }
            AllocatedIndex<? extends Shard> indexService = indicesService.indexService(index);
            final IndexSettings indexSettings;
            if (indexService != null) {
                indexSettings = indexService.getIndexSettings();
                indicesService.deleteIndex(index, ""index no longer part of the metadata"");
            } else if (previousState.metaData().hasIndex(index.getName())) {
                // The deleted index was part of the previous cluster state, but not loaded on the local node
                final IndexMetaData metaData = previousState.metaData().index(index);
                indexSettings = new IndexSettings(metaData, settings);
                indicesService.deleteUnassignedIndex(""deleted index was not assigned to local node"", metaData, state);
            } else {
                // The previous cluster state's metadata also does not contain the index,
                // which is what happens on node startup when an index was deleted while the
                // node was not part of the cluster.  In this case, try reading the index
                // metadata from disk.  If its not there, there is nothing to delete.
                // First, though, verify the precondition for applying this case by
                // asserting that the previous cluster state is not initialized/recovered.
                assert previousState.blocks().hasGlobalBlock(GatewayService.STATE_NOT_RECOVERED_BLOCK);
                final IndexMetaData metaData = indicesService.verifyIndexIsDeleted(index, event.state());
                if (metaData != null) {
                    indexSettings = new IndexSettings(metaData, settings);
                } else {
                    indexSettings = null;
                }
            }
            if (indexSettings != null) {
                threadPool.generic().execute(new AbstractRunnable() {
                    @Override
                    public void onFailure(Exception e) {
                        logger.warn(""[{}] failed to complete pending deletion for index"", e, index);
                    }

                    @Override
                    protected void doRun() throws Exception {
                        try {
                            // we are waiting until we can lock the index / all shards on the node and then we ack the delete of the store
                            // to the master. If we can't acquire the locks here immediately there might be a shard of this index still
                            // holding on to the lock due to a ""currently canceled recovery"" or so. The shard will delete itself BEFORE the
                            // lock is released so it's guaranteed to be deleted by the time we get the lock
                            indicesService.processPendingDeletes(index, indexSettings, new TimeValue(30, TimeUnit.MINUTES));
                        } catch (LockObtainFailedException exc) {
                            logger.warn(""[{}] failed to lock all shards for index - timed out after 30 seconds"", index);
                        } catch (InterruptedException e) {
                            logger.warn(""[{}] failed to lock all shards for index - interrupted"", index);
                        }
                    }
                });
            }
        }

        // delete local indices that do neither exist in previous cluster state nor part of tombstones
        for (AllocatedIndex<? extends Shard> indexService : indicesService) {
            Index index = indexService.index();
            IndexMetaData indexMetaData = event.state().metaData().index(index);
            if (indexMetaData == null) {
                assert false : ""index"" + index + "" exists locally, doesn't have a metadata but is not part""
                    + "" of the delete index list. \nprevious state: "" + event.previousState().prettyPrint()
                    + ""\n current state:\n"" + event.state().prettyPrint();
                logger.warn(""[{}] isn't part of metadata but is part of in memory structures. removing"", index);
                indicesService.deleteIndex(index, ""isn't part of metadata (explicit check)"");
            }
        }
    }","private void removeUnallocatedIndices(final ClusterChangedEvent event) {
        final ClusterState state = event.state();
        final String localNodeId = state.nodes().getLocalNodeId();
        assert localNodeId != null;

        Set<Index> indicesWithShards = new HashSet<>();
        RoutingNode localRoutingNode = state.getRoutingNodes().node(localNodeId);
        if (localRoutingNode != null) { // null e.g. if we are not a data node
            for (ShardRouting shardRouting : localRoutingNode) {
                indicesWithShards.add(shardRouting.index());
            }
        }

        for (AllocatedIndex<? extends Shard> indexService : indicesService) {
            Index index = indexService.index();
            if (indicesWithShards.contains(index) == false) {
                // if the cluster change indicates a brand new cluster, we only want
                // to remove the in-memory structures for the index and not delete the
                // contents on disk because the index will later be re-imported as a
                // dangling index
                assert state.metaData().index(index) != null || event.isNewCluster() :
                    ""index "" + index + "" does not exist in the cluster state, it should either "" +
                    ""have been deleted or the cluster must be new"";
                logger.debug(""{} removing index, no shards allocated"", index);
                indicesService.removeIndex(index, ""removing index (no shards allocated)"");
            }
        }
    }",/core/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java
bca4edcd56fa984b9e712f9298e6f91a19983710,690,768,"public void testCustomOverrideNotMatchingBuiltInFormat() {

        String overrideFormat = ""MM/dd HH.mm.ss,SSSSSS 'in' yyyy"";
        String text = ""05/15 17.14.56,374946 in 2018"";
        String expectedSimpleRegex = ""\\b\\d{2}/\\d{2} \\d{2}\\.\\d{2}\\.\\d{2},\\d{6} in \\d{4}\\b"";
        String expectedGrokPatternName = ""CUSTOM_TIMESTAMP"";
        Map<String, String> expectedCustomGrokPatternDefinitions =
            Collections.singletonMap(TimestampFormatFinder.CUSTOM_TIMESTAMP_GROK_NAME,
                ""%{MONTHNUM2}/%{MONTHDAY} %{HOUR}\\.%{MINUTE}\\.%{SECOND} in %{YEAR}"");

        TimestampFormatFinder strictTimestampFormatFinder = new TimestampFormatFinder(explanation, overrideFormat, true, true, true,
            NOOP_TIMEOUT_CHECKER);
        strictTimestampFormatFinder.addSample(text);
        assertEquals(expectedGrokPatternName, strictTimestampFormatFinder.getGrokPatternName());
        assertEquals(expectedCustomGrokPatternDefinitions, strictTimestampFormatFinder.getCustomGrokPatternDefinitions());
        assertEquals(expectedSimpleRegex, strictTimestampFormatFinder.getSimplePattern().pattern());
        assertEquals(Collections.singletonList(overrideFormat), strictTimestampFormatFinder.getJavaTimestampFormats());
        assertEquals(1, strictTimestampFormatFinder.getNumMatchedFormats());

        TimestampFormatFinder lenientTimestampFormatFinder = new TimestampFormatFinder(explanation, overrideFormat, false, false, false,
            NOOP_TIMEOUT_CHECKER);
        lenientTimestampFormatFinder.addSample(text);
        lenientTimestampFormatFinder.selectBestMatch();
        assertEquals(expectedGrokPatternName, lenientTimestampFormatFinder.getGrokPatternName());
        assertEquals(expectedCustomGrokPatternDefinitions, lenientTimestampFormatFinder.getCustomGrokPatternDefinitions());
        assertEquals(expectedSimpleRegex, lenientTimestampFormatFinder.getSimplePattern().pattern());
        assertEquals(Collections.singletonList(overrideFormat), lenientTimestampFormatFinder.getJavaTimestampFormats());
        assertEquals(1, lenientTimestampFormatFinder.getNumMatchedFormats());
    }","Map<String, String> expectedCustomGrokPatternDefinitions) {
        TimestampFormatFinder strictTimestampFormatFinder = new TimestampFormatFinder(explanation, overrideFormat, true, true, true,
            NOOP_TIMEOUT_CHECKER);
        strictTimestampFormatFinder.addSample(text);
        assertEquals(expectedGrokPatternName, strictTimestampFormatFinder.getGrokPatternName());
        assertEquals(expectedCustomGrokPatternDefinitions, strictTimestampFormatFinder.getCustomGrokPatternDefinitions());
        assertEquals(expectedSimpleRegex, strictTimestampFormatFinder.getSimplePattern().pattern());
        assertEquals(Collections.singletonList(overrideFormat), strictTimestampFormatFinder.getJavaTimestampFormats());
        assertEquals(1, strictTimestampFormatFinder.getNumMatchedFormats());

        TimestampFormatFinder lenientTimestampFormatFinder = new TimestampFormatFinder(explanation, overrideFormat, false, false, false,
            NOOP_TIMEOUT_CHECKER);
        lenientTimestampFormatFinder.addSample(text);
        lenientTimestampFormatFinder.selectBestMatch();
        assertEquals(expectedGrokPatternName, lenientTimestampFormatFinder.getGrokPatternName());
        assertEquals(expectedCustomGrokPatternDefinitions, lenientTimestampFormatFinder.getCustomGrokPatternDefinitions());
        assertEquals(expectedSimpleRegex, lenientTimestampFormatFinder.getSimplePattern().pattern());
        assertEquals(Collections.singletonList(overrideFormat), lenientTimestampFormatFinder.getJavaTimestampFormats());
        assertEquals(1, lenientTimestampFormatFinder.getNumMatchedFormats());
    }",/x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/filestructurefinder/TimestampFormatFinderTests.java
bca4edcd56fa984b9e712f9298e6f91a19983710,787,287,"static Tuple<String, String> overrideFormatToGrokAndRegex(String overrideFormat) {

        if (overrideFormat.indexOf('\n') >= 0 || overrideFormat.indexOf('\r') >= 0) {
            throw new IllegalArgumentException(""Multi-line timestamp formats ["" + overrideFormat + ""] not supported"");
        }

        if (overrideFormat.indexOf(INDETERMINATE_FIELD_PLACEHOLDER) >= 0) {
            throw new IllegalArgumentException(""Timestamp format ["" + overrideFormat + ""] not supported because it contains [""
                + INDETERMINATE_FIELD_PLACEHOLDER + ""]"");
        }

        StringBuilder grokPatternBuilder = new StringBuilder();
        StringBuilder regexBuilder = new StringBuilder();

        boolean notQuoted = true;
        char prevChar = '\0';
        String prevLetterGroup = null;
        int pos = 0;
        while (pos < overrideFormat.length()) {
            char curChar = overrideFormat.charAt(pos);

            if (curChar == '\'') {
                notQuoted = !notQuoted;
            } else if (notQuoted && Character.isLetter(curChar)) {
                int startPos = pos;
                int endPos = startPos + 1;
                while (endPos < overrideFormat.length() && overrideFormat.charAt(endPos) == curChar) {
                    ++endPos;
                    ++pos;
                }
                String letterGroup = overrideFormat.substring(startPos, endPos);
                Tuple<String, String> grokPatternAndRegexForGroup = VALID_LETTER_GROUPS.get(letterGroup);
                if (grokPatternAndRegexForGroup == null) {
                    // Special case of fractional seconds
                    if (curChar != 'S' || FRACTIONAL_SECOND_SEPARATORS.indexOf(prevChar) == -1 ||
                        ""ss"".equals(prevLetterGroup) == false || endPos - startPos > 9) {
                        String msg = ""Letter group ["" + letterGroup + ""] in ["" + overrideFormat + ""] is not supported"";
                        if (curChar == 'S') {
                            msg += "" because it is not preceded by [ss] and a separator from ["" + FRACTIONAL_SECOND_SEPARATORS + ""]"";
                        }
                        throw new IllegalArgumentException(msg);
                    }
                    // No need to append to the Grok pattern as %{SECOND} already allows for an optional
                    // fraction, but we need to remove the separator that's included in %{SECOND}
                    grokPatternBuilder.deleteCharAt(grokPatternBuilder.length() - 1);
                    regexBuilder.append(""\\d{"").append(endPos - startPos).append('}');
                } else {
                    grokPatternBuilder.append(grokPatternAndRegexForGroup.v1());
                    if (regexBuilder.length() == 0) {
                        regexBuilder.append(""\\b"");
                    }
                    regexBuilder.append(grokPatternAndRegexForGroup.v2());
                }
                if (pos + 1 == overrideFormat.length()) {
                    regexBuilder.append(""\\b"");
                }
                prevLetterGroup = letterGroup;
            } else {
                if (PUNCTUATION_THAT_NEEDS_ESCAPING_IN_REGEX.indexOf(curChar) >= 0) {
                    grokPatternBuilder.append('\\');
                    regexBuilder.append('\\');
                }
                grokPatternBuilder.append(curChar);
                regexBuilder.append(curChar);
            }

            prevChar = curChar;
            ++pos;
        }

        if (prevLetterGroup == null) {
            throw new IllegalArgumentException(""No time format letter groups in override format ["" + overrideFormat + ""]"");
        }

        return new Tuple<>(grokPatternBuilder.toString(), regexBuilder.toString());
    }","static Tuple<String, String> overrideFormatToGrokAndRegex(String overrideFormat) {

        if (overrideFormat.indexOf('\n') >= 0 || overrideFormat.indexOf('\r') >= 0) {
            throw new IllegalArgumentException(""Multi-line timestamp formats ["" + overrideFormat + ""] not supported"");
        }

        if (overrideFormat.indexOf(INDETERMINATE_FIELD_PLACEHOLDER) >= 0) {
            throw new IllegalArgumentException(""Timestamp format ["" + overrideFormat + ""] not supported because it contains [""
                + INDETERMINATE_FIELD_PLACEHOLDER + ""]"");
        }

        StringBuilder grokPatternBuilder = new StringBuilder();
        StringBuilder regexBuilder = new StringBuilder();

        boolean notQuoted = true;
        char prevChar = '\0';
        String prevLetterGroup = null;
        int pos = 0;
        while (pos < overrideFormat.length()) {
            char curChar = overrideFormat.charAt(pos);

            if (curChar == '\'') {
                notQuoted = !notQuoted;
            } else if (notQuoted && Character.isLetter(curChar)) {
                int startPos = pos;
                int endPos = startPos + 1;
                while (endPos < overrideFormat.length() && overrideFormat.charAt(endPos) == curChar) {
                    ++endPos;
                    ++pos;
                }
                String letterGroup = overrideFormat.substring(startPos, endPos);
                Tuple<String, String> grokPatternAndRegexForGroup = VALID_LETTER_GROUPS.get(letterGroup);
                if (grokPatternAndRegexForGroup == null) {
                    // Special case of fractional seconds
                    if (curChar != 'S' || FRACTIONAL_SECOND_SEPARATORS.indexOf(prevChar) == -1 ||
                        ""ss"".equals(prevLetterGroup) == false || endPos - startPos > 9) {
                        String msg = ""Letter group ["" + letterGroup + ""] in ["" + overrideFormat + ""] is not supported"";
                        if (curChar == 'S') {
                            msg += "" because it is not preceded by [ss] and a separator from ["" + FRACTIONAL_SECOND_SEPARATORS + ""]"";
                        }
                        throw new IllegalArgumentException(msg);
                    }
                    // No need to append to the Grok pattern as %{SECOND} already allows for an optional fraction,
                    // but we need to remove the separator that's included in %{SECOND} (and that might be escaped)
                    int numCharsToDelete = (PUNCTUATION_THAT_NEEDS_ESCAPING_IN_REGEX.indexOf(prevChar) >= 0) ? 2 : 1;
                    grokPatternBuilder.delete(grokPatternBuilder.length() - numCharsToDelete, grokPatternBuilder.length());
                    regexBuilder.append(""\\d{"").append(endPos - startPos).append('}');
                } else {
                    grokPatternBuilder.append(grokPatternAndRegexForGroup.v1());
                    if (regexBuilder.length() == 0) {
                        regexBuilder.append(""\\b"");
                    }
                    regexBuilder.append(grokPatternAndRegexForGroup.v2());
                }
                if (pos + 1 == overrideFormat.length()) {
                    regexBuilder.append(""\\b"");
                }
                prevLetterGroup = letterGroup;
            } else {
                if (PUNCTUATION_THAT_NEEDS_ESCAPING_IN_REGEX.indexOf(curChar) >= 0) {
                    grokPatternBuilder.append('\\');
                    regexBuilder.append('\\');
                }
                grokPatternBuilder.append(curChar);
                regexBuilder.append(curChar);
            }

            prevChar = curChar;
            ++pos;
        }

        if (prevLetterGroup == null) {
            throw new IllegalArgumentException(""No time format letter groups in override format ["" + overrideFormat + ""]"");
        }

        return new Tuple<>(grokPatternBuilder.toString(), regexBuilder.toString());
    }",/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/filestructurefinder/TimestampFormatFinder.java
bca4edcd56fa984b9e712f9298e6f91a19983710,563,905,"public void testSelectBestMatchGivenExceptionTraceAndTimestampFormatOverride() {

        FileStructureOverrides overrides = FileStructureOverrides.builder().setTimestampFormat(""yyyy-MM-dd HH:mm:ss"").build();

        TimestampFormatFinder timestampFormatFinder = TextLogFileStructureFinder.populateTimestampFormatFinder(explanation,
            EXCEPTION_TRACE_SAMPLE.split(""\n""), overrides, NOOP_TIMEOUT_CHECKER);

        // The override should force the seemingly inferior choice of timestamp
        // TODO - this won't work any more :-(
    }","public void testSelectBestMatchGivenExceptionTrace() {

        TimestampFormatFinder timestampFormatFinder = TextLogFileStructureFinder.populateTimestampFormatFinder(explanation,
            EXCEPTION_TRACE_SAMPLE.split(""\n""), FileStructureOverrides.EMPTY_OVERRIDES, NOOP_TIMEOUT_CHECKER);

        // Even though many lines have a timestamp near the end (in the Lucene version information),
        // these are so far along the lines that the weight of the timestamp near the beginning of the
        // first line should take precedence
        timestampFormatFinder.selectBestMatch();
        assertEquals(Collections.singletonList(""ISO8601""), timestampFormatFinder.getJavaTimestampFormats());
        assertEquals(""TIMESTAMP_ISO8601"", timestampFormatFinder.getGrokPatternName());
        assertEquals(""\\b\\d{4}-\\d{2}-\\d{2}[T ]\\d{2}:\\d{2}"", timestampFormatFinder.getSimplePattern().pattern());
        for (String preface : timestampFormatFinder.getPrefaces()) {
            assertEquals(""["", preface);
        }
        assertEquals(2, timestampFormatFinder.getNumMatchedFormats());
    }",/x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/filestructurefinder/TimestampFormatFinderTests.java
b29f7a9ddb254e6b5ab44fc6fc6b71702a9a2420,391,95,"public void testTimeoutDuringExecution() throws InterruptedException {
        final CountDownLatch listenerCalledLatch = new CountDownLatch(1);
        final CountDownLatch timeoutCalledLatch = new CountDownLatch(1);
        final CountDownLatch runningLatch = new CountDownLatch(1);
        final ActionListener<User> listener = ActionListener.wrap(user -> {
            listenerCalledLatch.countDown();
        }, e -> {
            throw new AssertionError(""onFailure should not be executed"");
        });
        final CancellableLdapRunnable runnable = new CancellableLdapRunnable(listener, () -> {
            runningLatch.countDown();
            try {
                timeoutCalledLatch.await();
                listener.onResponse(null);
            } catch (InterruptedException e) {
                throw new AssertionError(""don't interrupt me"", e);
            }
        }, logger);

        Thread t = new Thread(runnable);
        t.start();
        runningLatch.await();
        runnable.maybeTimeout();
        timeoutCalledLatch.countDown();
        listenerCalledLatch.await();
        t.join();
    }","public void testTimeoutDuringExecution() throws InterruptedException {
        final CountDownLatch listenerCalledLatch = new CountDownLatch(1);
        final CountDownLatch timeoutCalledLatch = new CountDownLatch(1);
        final CountDownLatch runningLatch = new CountDownLatch(1);
        final ActionListener<User> listener = ActionListener.wrap(user -> {
            listenerCalledLatch.countDown();
        }, e -> {
            throw new AssertionError(""onFailure should not be executed"");
        });
        final CancellableLdapRunnable runnable = new CancellableLdapRunnable(listener, e -> null, () -> {
            runningLatch.countDown();
            try {
                timeoutCalledLatch.await();
                listener.onResponse(null);
            } catch (InterruptedException e) {
                throw new AssertionError(""don't interrupt me"", e);
            }
        }, logger);

        Thread t = new Thread(runnable);
        t.start();
        runningLatch.await();
        runnable.maybeTimeout();
        timeoutCalledLatch.countDown();
        listenerCalledLatch.await();
        t.join();
    }",/plugin/src/test/java/org/elasticsearch/xpack/security/authc/ldap/CancellableLdapRunnableTests.java
a00da6e95398df533d67a0ec5faaa3011c2ffc4b,563,1112,"public void testSimpleMapper() throws Exception {
        IndexService indexService = createIndex(""test"");
        DocumentMapper docMapper = new DocumentMapper.Builder(
                new RootObjectMapper.Builder(""person"")
                        .add(new ObjectMapper.Builder(""name"")
                            .add(new TextFieldMapper.Builder(""first"").store(true).index(false))),
            indexService.mapperService()).build(indexService.mapperService());

        BytesReference json = new BytesArray(copyToBytesFromClasspath(""/org/elasticsearch/index/mapper/simple/test1.json""));
        Document doc = docMapper.parse(new SourceToParse(""test"", ""person"", ""1"", json, XContentType.JSON)).rootDoc();

        assertThat(doc.get(docMapper.mappers().getMapper(""name.first"").name()), equalTo(""shay""));
        doc = docMapper.parse(new SourceToParse(""test"", ""person"", ""1"", json, XContentType.JSON)).rootDoc();
    }","public void testDynamicDottedFieldNameObjectWithExistingParentWrongType() throws Exception {
        DocumentMapperParser mapperParser = createIndex(""test"").mapperService().documentMapperParser();
        String mapping = Strings.toString(XContentFactory.jsonBuilder().startObject().startObject(""type"")
            .startObject(""properties"") .startObject(""foo"")
            .field(""type"", ""long"")
            .endObject().endObject().endObject().endObject());
        DocumentMapper mapper = mapperParser.parse(""type"", new CompressedXContent(mapping));

        BytesReference bytes = BytesReference.bytes(XContentFactory.jsonBuilder().startObject().startObject(""foo.bar.baz"")
            .field(""a"", 0).endObject().endObject());
        MapperParsingException exception = expectThrows(MapperParsingException.class,
                () -> mapper.parse(new SourceToParse(""test"", ""type"", ""1"", bytes, XContentType.JSON)));

        assertEquals(""Could not dynamically add mapping for field [foo.bar.baz]. ""
                + ""Existing mapping for [foo] must be of type object but found [long]."", exception.getMessage());
    }",/server/src/test/java/org/elasticsearch/index/mapper/DocumentParserTests.java
72463768f506f854f0a9706de0a553d49f4b3e5d,628,517,"public void testEqualsAndHashcode() throws IOException {
        for (int runs = 0; runs < NUMBER_OF_TESTQUERIES; runs++) {
            QB firstQuery = createTestQueryBuilder();
            assertFalse(""query is equal to null"", firstQuery.equals(null));
            assertFalse(""query is equal to incompatible type"", firstQuery.equals(""""));
            assertTrue(""query is not equal to self"", firstQuery.equals(firstQuery));
            assertThat(""same query's hashcode returns different values if called multiple times"", firstQuery.hashCode(),
                    equalTo(firstQuery.hashCode()));

            QB secondQuery = copyQuery(firstQuery);
            assertTrue(""query is not equal to self"", secondQuery.equals(secondQuery));
            assertTrue(""query is not equal to its copy"", firstQuery.equals(secondQuery));
            assertTrue(""equals is not symmetric"", secondQuery.equals(firstQuery));
            assertThat(""query copy's hashcode is different from original hashcode"", secondQuery.hashCode(), equalTo(firstQuery.hashCode()));

            QB thirdQuery = copyQuery(secondQuery);
            assertTrue(""query is not equal to self"", thirdQuery.equals(thirdQuery));
            assertTrue(""query is not equal to its copy"", secondQuery.equals(thirdQuery));
            assertThat(""query copy's hashcode is different from original hashcode"", secondQuery.hashCode(), equalTo(thirdQuery.hashCode()));
            assertTrue(""equals is not transitive"", firstQuery.equals(thirdQuery));
            assertThat(""query copy's hashcode is different from original hashcode"", firstQuery.hashCode(), equalTo(thirdQuery.hashCode()));
            assertTrue(""equals is not symmetric"", thirdQuery.equals(secondQuery));
            assertTrue(""equals is not symmetric"", thirdQuery.equals(firstQuery));

            if (randomBoolean()) {
                secondQuery.queryName(secondQuery.queryName() == null ? randomAsciiOfLengthBetween(1, 30) : secondQuery.queryName()
                        + randomAsciiOfLengthBetween(1, 10));
            } else {
                secondQuery.boost(firstQuery.boost() + 1f + randomFloat());
            }
            assertThat(""different queries should not be equal"", secondQuery, not(equalTo(firstQuery)));
            assertThat(""different queries should have different hashcode"", secondQuery.hashCode(), not(equalTo(firstQuery.hashCode())));
        }
    }","public void testSerialization() throws IOException {
        for (int runs = 0; runs < NUMBER_OF_TESTQUERIES; runs++) {
            QB testQuery = createTestQueryBuilder();
            assertSerialization(testQuery);
        }
    }",/core/src/test/java/org/elasticsearch/index/query/AbstractQueryTestCase.java
014b3236dcb6f2942945c360b343dccac605b466,563,752,"public IndexResult index(Index index) throws IOException {
        assert Objects.equals(index.uid().field(), IdFieldMapper.NAME) : index.uid().field();
        final boolean doThrottle = index.origin().isRecovery() == false;
        try (ReleasableLock releasableLock = readLock.acquire()) {
            ensureOpen();
            assert assertIncomingSequenceNumber(index.origin(), index.seqNo());
            try (Releasable ignored = versionMap.acquireLock(index.uid().bytes());
                Releasable indexThrottle = doThrottle ? () -> {} : throttle.acquireThrottle()) {
                lastWriteNanos = index.startTime();
                /* A NOTE ABOUT APPEND ONLY OPTIMIZATIONS:
                 * if we have an autoGeneratedID that comes into the engine we can potentially optimize
                 * and just use addDocument instead of updateDocument and skip the entire version and index lookupVersion across the board.
                 * Yet, we have to deal with multiple document delivery, for this we use a property of the document that is added
                 * to detect if it has potentially been added before. We use the documents timestamp for this since it's something
                 * that:
                 *  - doesn't change per document
                 *  - is preserved in the transaction log
                 *  - and is assigned before we start to index / replicate
                 * NOTE: it's not important for this timestamp to be consistent across nodes etc. it's just a number that is in the common
                 * case increasing and can be used in the failure case when we retry and resent documents to establish a happens before relationship.
                 * for instance:
                 *  - doc A has autoGeneratedIdTimestamp = 10, isRetry = false
                 *  - doc B has autoGeneratedIdTimestamp = 9, isRetry = false
                 *
                 *  while both docs are in in flight, we disconnect on one node, reconnect and send doc A again
                 *  - now doc A' has autoGeneratedIdTimestamp = 10, isRetry = true
                 *
                 *  if A' arrives on the shard first we update maxUnsafeAutoIdTimestamp to 10 and use update document. All subsequent
                 *  documents that arrive (A and B) will also use updateDocument since their timestamps are less than maxUnsafeAutoIdTimestamp.
                 *  While this is not strictly needed for doc B it is just much simpler to implement since it will just de-optimize some doc in the worst case.
                 *
                 *  if A arrives on the shard first we use addDocument since maxUnsafeAutoIdTimestamp is < 10. A` will then just be skipped or calls
                 *  updateDocument.
                 */
                final IndexingStrategy plan;

                if (index.origin() == Operation.Origin.PRIMARY) {
                    plan = planIndexingAsPrimary(index);
                } else {
                    // non-primary mode (i.e., replica or recovery)
                    plan = planIndexingAsNonPrimary(index);
                }

                final IndexResult indexResult;
                if (plan.earlyResultOnPreFlightError.isPresent()) {
                    indexResult = plan.earlyResultOnPreFlightError.get();
                    assert indexResult.getResultType() == Result.Type.FAILURE : indexResult.getResultType();
                } else if (plan.indexIntoLucene) {
                    indexResult = indexIntoLucene(index, plan);
                } else {
                    indexResult = new IndexResult(
                            plan.versionForIndexing, getPrimaryTerm(), plan.seqNoForIndexing, plan.currentNotFoundOrDeleted);
                }
                if (index.origin() != Operation.Origin.LOCAL_TRANSLOG_RECOVERY) {
                    final Translog.Location location;
                    if (indexResult.getResultType() == Result.Type.SUCCESS) {
                        location = translog.add(new Translog.Index(index, indexResult));
                    } else if (indexResult.getSeqNo() != SequenceNumbers.UNASSIGNED_SEQ_NO) {
                        // if we have document failure, record it as a no-op in the translog with the generated seq_no
                        location = translog.add(new Translog.NoOp(indexResult.getSeqNo(), index.primaryTerm(), indexResult.getFailure().getMessage()));
                    } else {
                        location = null;
                    }
                    indexResult.setTranslogLocation(location);
                }
                if (plan.indexIntoLucene && indexResult.getResultType() == Result.Type.SUCCESS) {
                    final Translog.Location translogLocation = trackTranslogLocation.get() ? indexResult.getTranslogLocation() : null;
                    versionMap.maybePutIndexUnderLock(index.uid().bytes(),
                        new IndexVersionValue(translogLocation, plan.versionForIndexing, plan.seqNoForIndexing, index.primaryTerm()));
                }
                if (indexResult.getSeqNo() != SequenceNumbers.UNASSIGNED_SEQ_NO) {
                    localCheckpointTracker.markSeqNoAsCompleted(indexResult.getSeqNo());
                }
                indexResult.setTook(System.nanoTime() - index.startTime());
                indexResult.freeze();
                return indexResult;
            }
        } catch (RuntimeException | IOException e) {
            try {
                maybeFailEngine(""index"", e);
            } catch (Exception inner) {
                e.addSuppressed(inner);
            }
            throw e;
        }
    }","public IndexResult index(Index index) throws IOException {
        assert Objects.equals(index.uid().field(), IdFieldMapper.NAME) : index.uid().field();
        final boolean doThrottle = index.origin().isRecovery() == false;
        try (ReleasableLock releasableLock = readLock.acquire()) {
            ensureOpen();
            assert assertIncomingSequenceNumber(index.origin(), index.seqNo());
            try (Releasable ignored = versionMap.acquireLock(index.uid().bytes());
                Releasable indexThrottle = doThrottle ? () -> {} : throttle.acquireThrottle()) {
                lastWriteNanos = index.startTime();
                /* A NOTE ABOUT APPEND ONLY OPTIMIZATIONS:
                 * if we have an autoGeneratedID that comes into the engine we can potentially optimize
                 * and just use addDocument instead of updateDocument and skip the entire version and index lookupVersion across the board.
                 * Yet, we have to deal with multiple document delivery, for this we use a property of the document that is added
                 * to detect if it has potentially been added before. We use the documents timestamp for this since it's something
                 * that:
                 *  - doesn't change per document
                 *  - is preserved in the transaction log
                 *  - and is assigned before we start to index / replicate
                 * NOTE: it's not important for this timestamp to be consistent across nodes etc. it's just a number that is in the common
                 * case increasing and can be used in the failure case when we retry and resent documents to establish a happens before relationship.
                 * for instance:
                 *  - doc A has autoGeneratedIdTimestamp = 10, isRetry = false
                 *  - doc B has autoGeneratedIdTimestamp = 9, isRetry = false
                 *
                 *  while both docs are in in flight, we disconnect on one node, reconnect and send doc A again
                 *  - now doc A' has autoGeneratedIdTimestamp = 10, isRetry = true
                 *
                 *  if A' arrives on the shard first we update maxUnsafeAutoIdTimestamp to 10 and use update document. All subsequent
                 *  documents that arrive (A and B) will also use updateDocument since their timestamps are less than maxUnsafeAutoIdTimestamp.
                 *  While this is not strictly needed for doc B it is just much simpler to implement since it will just de-optimize some doc in the worst case.
                 *
                 *  if A arrives on the shard first we use addDocument since maxUnsafeAutoIdTimestamp is < 10. A` will then just be skipped or calls
                 *  updateDocument.
                 */
                final IndexingStrategy plan;

                if (index.origin() == Operation.Origin.PRIMARY) {
                    plan = planIndexingAsPrimary(index);
                } else {
                    // non-primary mode (i.e., replica or recovery)
                    plan = planIndexingAsNonPrimary(index);
                }

                final IndexResult indexResult;
                if (plan.earlyResultOnPreFlightError.isPresent()) {
                    indexResult = plan.earlyResultOnPreFlightError.get();
                    assert indexResult.getResultType() == Result.Type.FAILURE : indexResult.getResultType();
                } else if (plan.indexIntoLucene) {
                    indexResult = indexIntoLucene(index, plan);
                } else {
                    indexResult = new IndexResult(
                            plan.versionForIndexing, getPrimaryTerm(), plan.seqNoForIndexing, plan.currentNotFoundOrDeleted);
                }
                if (index.origin() != Operation.Origin.LOCAL_TRANSLOG_RECOVERY) {
                    final Translog.Location location;
                    if (indexResult.getResultType() == Result.Type.SUCCESS) {
                        location = translog.add(new Translog.Index(index, indexResult));
                    } else if (indexResult.getSeqNo() != SequenceNumbers.UNASSIGNED_SEQ_NO) {
                        // if we have document failure, record it as a no-op in the translog with the generated seq_no
                        location = translog.add(new Translog.NoOp(indexResult.getSeqNo(), index.primaryTerm(), indexResult.getFailure().toString()));
                    } else {
                        location = null;
                    }
                    indexResult.setTranslogLocation(location);
                }
                if (plan.indexIntoLucene && indexResult.getResultType() == Result.Type.SUCCESS) {
                    final Translog.Location translogLocation = trackTranslogLocation.get() ? indexResult.getTranslogLocation() : null;
                    versionMap.maybePutIndexUnderLock(index.uid().bytes(),
                        new IndexVersionValue(translogLocation, plan.versionForIndexing, plan.seqNoForIndexing, index.primaryTerm()));
                }
                if (indexResult.getSeqNo() != SequenceNumbers.UNASSIGNED_SEQ_NO) {
                    localCheckpointTracker.markSeqNoAsCompleted(indexResult.getSeqNo());
                }
                indexResult.setTook(System.nanoTime() - index.startTime());
                indexResult.freeze();
                return indexResult;
            }
        } catch (RuntimeException | IOException e) {
            try {
                maybeFailEngine(""index"", e);
            } catch (Exception inner) {
                e.addSuppressed(inner);
            }
            throw e;
        }
    }",/server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
6ecb0234685c180223a866862bcd31b965e05783,563,504,"protected void doRun() throws Exception {
            boolean whileRunning = false;
            try (ThreadContext.StoredContext ignore = stashContext()){
                ctx.restore();
                whileRunning = true;
                in.doRun();
                whileRunning = false;
            } catch (IllegalStateException ex) {
                if (whileRunning || threadLocal.closed.get() == false) {
                    throw ex;
                }
                // if we hit an ISE here we have been shutting down
                // this comes from the threadcontext and barfs if
                // our threadpool has been shutting down
            }
        }","public void onAfter() {
            try {
                in.onAfter();
            } finally {
                if (threadsOriginalContext != null) {
                    threadsOriginalContext.restore();
                }
            }
        }",/core/src/main/java/org/elasticsearch/common/util/concurrent/ThreadContext.java
4158ea26bf19a9065af3a2b20ad2bf4a0f860e5b,563,254,"private void reindexDataframeAndStartAnalysis(DataFrameAnalyticsTask task, DataFrameAnalyticsConfig config) {
        if (task.isStopping()) {
            LOGGER.debug(""[{}] task is stopping. Marking as complete before starting reindexing and analysis."",
                task.getParams().getId());
            task.markAsCompleted();
            return;
        }

        final ParentTaskAssigningClient parentTaskClient = new ParentTaskAssigningClient(client, task.getParentTaskId());

        // Reindexing is complete; start analytics
        ActionListener<BulkByScrollResponse> reindexCompletedListener = ActionListener.wrap(
            reindexResponse -> {
                // If the reindex task is canceled, this listener is called.
                // Consequently, we should not signal reindex completion.
                if (task.isStopping()) {
                    LOGGER.debug(""[{}] task is stopping. Marking as complete before marking reindex as finished."",
                        task.getParams().getId());
                    task.markAsCompleted();
                    return;
                }
                task.setReindexingTaskId(null);
                task.setReindexingFinished();
                auditor.info(
                    config.getId(),
                    Messages.getMessage(Messages.DATA_FRAME_ANALYTICS_AUDIT_FINISHED_REINDEXING, config.getDest().getIndex(),
                        reindexResponse.getTook()));
                startAnalytics(task, config);
            },
            error -> {
                if (error instanceof TaskCancelledException && task.isStopping()) {
                    LOGGER.debug(new ParameterizedMessage(""[{}] Caught task cancelled exception while task is stopping"",
                        config.getId()), error);
                } else {
                    task.setFailed(ExceptionsHelper.unwrapCause(error).getMessage());
                }
            }
        );

        // Reindex
        ActionListener<CreateIndexResponse> copyIndexCreatedListener = ActionListener.wrap(
            createIndexResponse -> {
                ReindexRequest reindexRequest = new ReindexRequest();
                reindexRequest.setRefresh(true);
                reindexRequest.setSourceIndices(config.getSource().getIndex());
                reindexRequest.setSourceQuery(config.getSource().getParsedQuery());
                reindexRequest.getSearchRequest().source().fetchSource(config.getSource().getSourceFiltering());
                reindexRequest.setDestIndex(config.getDest().getIndex());
                reindexRequest.setScript(new Script(""ctx._source."" + DestinationIndex.ID_COPY + "" = ctx._id""));
                reindexRequest.setParentTask(task.getParentTaskId());

                final ThreadContext threadContext = parentTaskClient.threadPool().getThreadContext();
                final Supplier<ThreadContext.StoredContext> supplier = threadContext.newRestorableContext(false);
                try (ThreadContext.StoredContext ignore = threadContext.stashWithOrigin(ML_ORIGIN)) {
                    LOGGER.info(""[{}] Started reindexing"", config.getId());
                    Task reindexTask = client.executeLocally(ReindexAction.INSTANCE, reindexRequest,
                        new ContextPreservingActionListener<>(supplier, reindexCompletedListener));
                    task.setReindexingTaskId(reindexTask.getId());
                    auditor.info(config.getId(),
                        Messages.getMessage(Messages.DATA_FRAME_ANALYTICS_AUDIT_STARTED_REINDEXING, config.getDest().getIndex()));
                }
            },
            reindexCompletedListener::onFailure
        );

        // Create destination index if it does not exist
        ActionListener<GetIndexResponse> destIndexListener = ActionListener.wrap(
            indexResponse -> {
                auditor.info(
                    config.getId(),
                    Messages.getMessage(Messages.DATA_FRAME_ANALYTICS_AUDIT_REUSING_DEST_INDEX, indexResponse.indices()[0]));
                LOGGER.info(""[{}] Using existing destination index [{}]"", config.getId(), indexResponse.indices()[0]);
                DestinationIndex.updateMappingsToDestIndex(parentTaskClient, config, indexResponse, ActionListener.wrap(
                    acknowledgedResponse -> copyIndexCreatedListener.onResponse(null),
                    copyIndexCreatedListener::onFailure
                ));
            },
            e -> {
                if (ExceptionsHelper.unwrapCause(e) instanceof IndexNotFoundException) {
                    auditor.info(
                        config.getId(),
                        Messages.getMessage(Messages.DATA_FRAME_ANALYTICS_AUDIT_CREATING_DEST_INDEX, config.getDest().getIndex()));
                    LOGGER.info(""[{}] Creating destination index [{}]"", config.getId(), config.getDest().getIndex());
                    DestinationIndex.createDestinationIndex(parentTaskClient, Clock.systemUTC(), config, copyIndexCreatedListener);
                } else {
                    copyIndexCreatedListener.onFailure(e);
                }
            }
        );

        ClientHelper.executeWithHeadersAsync(config.getHeaders(), ML_ORIGIN, parentTaskClient, GetIndexAction.INSTANCE,
                new GetIndexRequest().indices(config.getDest().getIndex()), destIndexListener);
    }","private void reindexDataframeAndStartAnalysis(DataFrameAnalyticsTask task, DataFrameAnalyticsConfig config) {
        if (task.isStopping()) {
            LOGGER.debug(""[{}] task is stopping. Marking as complete before starting reindexing and analysis."",
                task.getParams().getId());
            task.markAsCompleted();
            return;
        }

        final ParentTaskAssigningClient parentTaskClient = new ParentTaskAssigningClient(client, task.getParentTaskId());

        // Reindexing is complete; start analytics
        ActionListener<BulkByScrollResponse> reindexCompletedListener = ActionListener.wrap(
            reindexResponse -> {
                // If the reindex task is canceled, this listener is called.
                // Consequently, we should not signal reindex completion.
                if (task.isStopping()) {
                    LOGGER.debug(""[{}] task is stopping. Marking as complete before marking reindex as finished."",
                        task.getParams().getId());
                    task.markAsCompleted();
                    return;
                }
                task.setReindexingTaskId(null);
                task.setReindexingFinished();
                auditor.info(
                    config.getId(),
                    Messages.getMessage(Messages.DATA_FRAME_ANALYTICS_AUDIT_FINISHED_REINDEXING, config.getDest().getIndex(),
                        reindexResponse.getTook()));
                startAnalytics(task, config);
            },
            error -> {
                if (error instanceof TaskCancelledException && task.isStopping()) {
                    LOGGER.debug(new ParameterizedMessage(""[{}] Caught task cancelled exception while task is stopping"",
                        config.getId()), error);
                    task.markAsCompleted();
                } else {
                    task.setFailed(ExceptionsHelper.unwrapCause(error).getMessage());
                }
            }
        );

        // Reindex
        ActionListener<CreateIndexResponse> copyIndexCreatedListener = ActionListener.wrap(
            createIndexResponse -> {
                ReindexRequest reindexRequest = new ReindexRequest();
                reindexRequest.setRefresh(true);
                reindexRequest.setSourceIndices(config.getSource().getIndex());
                reindexRequest.setSourceQuery(config.getSource().getParsedQuery());
                reindexRequest.getSearchRequest().source().fetchSource(config.getSource().getSourceFiltering());
                reindexRequest.setDestIndex(config.getDest().getIndex());
                reindexRequest.setScript(new Script(""ctx._source."" + DestinationIndex.ID_COPY + "" = ctx._id""));
                reindexRequest.setParentTask(task.getParentTaskId());

                final ThreadContext threadContext = parentTaskClient.threadPool().getThreadContext();
                final Supplier<ThreadContext.StoredContext> supplier = threadContext.newRestorableContext(false);
                try (ThreadContext.StoredContext ignore = threadContext.stashWithOrigin(ML_ORIGIN)) {
                    LOGGER.info(""[{}] Started reindexing"", config.getId());
                    Task reindexTask = client.executeLocally(ReindexAction.INSTANCE, reindexRequest,
                        new ContextPreservingActionListener<>(supplier, reindexCompletedListener));
                    task.setReindexingTaskId(reindexTask.getId());
                    auditor.info(config.getId(),
                        Messages.getMessage(Messages.DATA_FRAME_ANALYTICS_AUDIT_STARTED_REINDEXING, config.getDest().getIndex()));
                }
            },
            reindexCompletedListener::onFailure
        );

        // Create destination index if it does not exist
        ActionListener<GetIndexResponse> destIndexListener = ActionListener.wrap(
            indexResponse -> {
                auditor.info(
                    config.getId(),
                    Messages.getMessage(Messages.DATA_FRAME_ANALYTICS_AUDIT_REUSING_DEST_INDEX, indexResponse.indices()[0]));
                LOGGER.info(""[{}] Using existing destination index [{}]"", config.getId(), indexResponse.indices()[0]);
                DestinationIndex.updateMappingsToDestIndex(parentTaskClient, config, indexResponse, ActionListener.wrap(
                    acknowledgedResponse -> copyIndexCreatedListener.onResponse(null),
                    copyIndexCreatedListener::onFailure
                ));
            },
            e -> {
                if (ExceptionsHelper.unwrapCause(e) instanceof IndexNotFoundException) {
                    auditor.info(
                        config.getId(),
                        Messages.getMessage(Messages.DATA_FRAME_ANALYTICS_AUDIT_CREATING_DEST_INDEX, config.getDest().getIndex()));
                    LOGGER.info(""[{}] Creating destination index [{}]"", config.getId(), config.getDest().getIndex());
                    DestinationIndex.createDestinationIndex(parentTaskClient, Clock.systemUTC(), config, copyIndexCreatedListener);
                } else {
                    copyIndexCreatedListener.onFailure(e);
                }
            }
        );

        ClientHelper.executeWithHeadersAsync(config.getHeaders(), ML_ORIGIN, parentTaskClient, GetIndexAction.INSTANCE,
                new GetIndexRequest().indices(config.getDest().getIndex()), destIndexListener);
    }",/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/DataFrameAnalyticsManager.java
6e5989d4d7ae131d591deb9347c528e8c68e2011,690,121,"void write(MethodWriter writer, Globals globals) {
        writer.writeStatementOffset(location);

        Label jump = new Label();

        writer.mark(jump);
        writer.visitVarInsn(MethodWriter.getType(variable.clazz).getOpcode(Opcodes.ISTORE), variable.getSlot());

        if (block != null) {
            block.continu = continu;
            block.brake = brake;
            block.write(writer, globals);
        }

        writer.visitTryCatchBlock(begin, end, jump, MethodWriter.getType(variable.clazz).getInternalName());

        if (exception != null && !block.allEscape) {
            writer.goTo(exception);
        }
    }","void write(MethodWriter writer, Globals globals) {
        writer.writeStatementOffset(location);

        Label jump = new Label();

        writer.mark(jump);
        writer.visitVarInsn(MethodWriter.getType(variable.clazz).getOpcode(Opcodes.ISTORE), variable.getSlot());

        if (block != null) {
            block.continu = continu;
            block.brake = brake;
            block.write(writer, globals);
        }

        writer.visitTryCatchBlock(begin, end, jump, MethodWriter.getType(variable.clazz).getInternalName());

        if (exception != null && (block == null || !block.allEscape)) {
            writer.goTo(exception);
        }
    }",/modules/lang-painless/src/main/java/org/elasticsearch/painless/node/SCatch.java
13917162ad5c59a96ccb4d6a81a5044546c45c22,662,468,"private void updateGlobalCheckpoint(final String allocationId, final long globalCheckpoint, LongConsumer ifUpdated) {
        final CheckpointState cps = checkpoints.get(allocationId);
        assert !this.shardAllocationId.equals(allocationId) || cps != null;
        if (cps != null && globalCheckpoint > cps.globalCheckpoint) {
            ifUpdated.accept(cps.globalCheckpoint);
            cps.globalCheckpoint = globalCheckpoint;
        }
    }","public synchronized void updateGlobalCheckpointForShard(final String allocationId, final long globalCheckpoint) {
        assert primaryMode;
        assert handoffInProgress == false;
        assert invariant();
        updateGlobalCheckpoint(
                allocationId,
                globalCheckpoint,
                current -> logger.trace(
                        ""updating local knowledge for [{}] on the primary of the global checkpoint from [{}] to [{}]"",
                        allocationId,
                        current,
                        globalCheckpoint));
        assert invariant();
    }",/server/src/main/java/org/elasticsearch/index/seqno/ReplicationTracker.java
13917162ad5c59a96ccb4d6a81a5044546c45c22,690,302,"private boolean invariant() {
        assert checkpoints.get(shardAllocationId) != null :
            ""checkpoints map should always have an entry for the current shard"";

        // local checkpoints only set during primary mode
        assert primaryMode || checkpoints.values().stream()
            .allMatch(lcps -> lcps.localCheckpoint == SequenceNumbers.UNASSIGNED_SEQ_NO ||
                lcps.localCheckpoint == SequenceNumbers.PRE_60_NODE_CHECKPOINT);

        // global checkpoints for other shards only set during primary mode
        assert primaryMode
                || checkpoints
                .entrySet()
                .stream()
                .filter(e -> e.getKey().equals(shardAllocationId) == false)
                .map(Map.Entry::getValue)
                .allMatch(cps ->
                        (cps.globalCheckpoint == SequenceNumbers.UNASSIGNED_SEQ_NO
                                || cps.globalCheckpoint == SequenceNumbers.PRE_60_NODE_CHECKPOINT));

        // relocation handoff can only occur in primary mode
        assert !handoffInProgress || primaryMode;

        // the current shard is marked as in-sync when the global checkpoint tracker operates in primary mode
        assert !primaryMode || checkpoints.get(shardAllocationId).inSync;

        // the routing table and replication group is set when the global checkpoint tracker operates in primary mode
        assert !primaryMode || (routingTable != null && replicationGroup != null) :
            ""primary mode but routing table is "" + routingTable + "" and replication group is "" + replicationGroup;

        // when in primary mode, the current allocation ID is the allocation ID of the primary or the relocation allocation ID
        assert !primaryMode
                || (routingTable.primaryShard().allocationId().getId().equals(shardAllocationId)
                || routingTable.primaryShard().allocationId().getRelocationId().equals(shardAllocationId));

        // during relocation handoff there are no entries blocking global checkpoint advancement
        assert !handoffInProgress || pendingInSync.isEmpty() :
            ""entries blocking global checkpoint advancement during relocation handoff: "" + pendingInSync;

        // entries blocking global checkpoint advancement can only exist in primary mode and when not having a relocation handoff
        assert pendingInSync.isEmpty() || (primaryMode && !handoffInProgress);

        // the computed global checkpoint is always up-to-date
        assert !primaryMode
                || getGlobalCheckpoint() == computeGlobalCheckpoint(pendingInSync, checkpoints.values(), getGlobalCheckpoint())
                : ""global checkpoint is not up-to-date, expected: "" +
                computeGlobalCheckpoint(pendingInSync, checkpoints.values(), getGlobalCheckpoint()) + "" but was: "" + getGlobalCheckpoint();

        // when in primary mode, the global checkpoint is at most the minimum local checkpoint on all in-sync shard copies
        assert !primaryMode
                || getGlobalCheckpoint() <= inSyncCheckpointStates(checkpoints, CheckpointState::getLocalCheckpoint, LongStream::min)
                : ""global checkpoint ["" + getGlobalCheckpoint() + ""] ""
                + ""for primary mode allocation ID ["" + shardAllocationId + ""] ""
                + ""more than in-sync local checkpoints ["" + checkpoints + ""]"";

        // we have a routing table iff we have a replication group
        assert (routingTable == null) == (replicationGroup == null) :
            ""routing table is "" + routingTable + "" but replication group is "" + replicationGroup;

        assert replicationGroup == null || replicationGroup.equals(calculateReplicationGroup()) :
            ""cached replication group out of sync: expected: "" + calculateReplicationGroup() + "" but was: "" + replicationGroup;

        // all assigned shards from the routing table are tracked
        assert routingTable == null || checkpoints.keySet().containsAll(routingTable.getAllAllocationIds()) :
            ""local checkpoints "" + checkpoints + "" not in-sync with routing table "" + routingTable;

        for (Map.Entry<String, CheckpointState> entry : checkpoints.entrySet()) {
            // blocking global checkpoint advancement only happens for shards that are not in-sync
            assert !pendingInSync.contains(entry.getKey()) || !entry.getValue().inSync :
                ""shard copy "" + entry.getKey() + "" blocks global checkpoint advancement but is in-sync"";
            // in-sync shard copies are tracked
            assert !entry.getValue().inSync || entry.getValue().tracked :
                ""shard copy "" + entry.getKey() + "" is in-sync but not tracked"";
        }

        return true;
    }","private boolean invariant() {
        assert checkpoints.get(shardAllocationId) != null :
            ""checkpoints map should always have an entry for the current shard"";

        // local checkpoints only set during primary mode
        assert primaryMode || checkpoints.values().stream()
            .allMatch(lcps -> lcps.localCheckpoint == SequenceNumbers.UNASSIGNED_SEQ_NO ||
                lcps.localCheckpoint == SequenceNumbers.PRE_60_NODE_CHECKPOINT);

        // global checkpoints for other shards only set during primary mode
        assert primaryMode
                || checkpoints
                .entrySet()
                .stream()
                .filter(e -> e.getKey().equals(shardAllocationId) == false)
                .map(Map.Entry::getValue)
                .allMatch(cps ->
                        (cps.globalCheckpoint == SequenceNumbers.UNASSIGNED_SEQ_NO
                                || cps.globalCheckpoint == SequenceNumbers.PRE_60_NODE_CHECKPOINT));

        // relocation handoff can only occur in primary mode
        assert !handoffInProgress || primaryMode;

        // the current shard is marked as in-sync when the global checkpoint tracker operates in primary mode
        assert !primaryMode || checkpoints.get(shardAllocationId).inSync;

        // the routing table and replication group is set when the global checkpoint tracker operates in primary mode
        assert !primaryMode || (routingTable != null && replicationGroup != null) :
            ""primary mode but routing table is "" + routingTable + "" and replication group is "" + replicationGroup;

        // when in primary mode, the current allocation ID is the allocation ID of the primary or the relocation allocation ID
        assert !primaryMode
                || (routingTable.primaryShard().allocationId().getId().equals(shardAllocationId)
                || routingTable.primaryShard().allocationId().getRelocationId().equals(shardAllocationId));

        // during relocation handoff there are no entries blocking global checkpoint advancement
        assert !handoffInProgress || pendingInSync.isEmpty() :
            ""entries blocking global checkpoint advancement during relocation handoff: "" + pendingInSync;

        // entries blocking global checkpoint advancement can only exist in primary mode and when not having a relocation handoff
        assert pendingInSync.isEmpty() || (primaryMode && !handoffInProgress);

        // the computed global checkpoint is always up-to-date
        assert !primaryMode
                || getGlobalCheckpoint() == computeGlobalCheckpoint(pendingInSync, checkpoints.values(), getGlobalCheckpoint())
                : ""global checkpoint is not up-to-date, expected: "" +
                computeGlobalCheckpoint(pendingInSync, checkpoints.values(), getGlobalCheckpoint()) + "" but was: "" + getGlobalCheckpoint();

        // when in primary mode, the global checkpoint is at most the minimum local checkpoint on all in-sync shard copies
        assert !primaryMode
                || getGlobalCheckpoint() <= inSyncCheckpointStates(checkpoints, CheckpointState::getLocalCheckpoint, LongStream::min)
                : ""global checkpoint ["" + getGlobalCheckpoint() + ""] ""
                + ""for primary mode allocation ID ["" + shardAllocationId + ""] ""
                + ""more than in-sync local checkpoints ["" + checkpoints + ""]"";

        // we have a routing table iff we have a replication group
        assert (routingTable == null) == (replicationGroup == null) :
            ""routing table is "" + routingTable + "" but replication group is "" + replicationGroup;

        assert replicationGroup == null || replicationGroup.equals(calculateReplicationGroup()) :
            ""cached replication group out of sync: expected: "" + calculateReplicationGroup() + "" but was: "" + replicationGroup;

        // all assigned shards from the routing table are tracked
        assert routingTable == null || checkpoints.keySet().containsAll(routingTable.getAllAllocationIds()) :
            ""local checkpoints "" + checkpoints + "" not in-sync with routing table "" + routingTable;

        for (Map.Entry<String, CheckpointState> entry : checkpoints.entrySet()) {
            // blocking global checkpoint advancement only happens for shards that are not in-sync
            assert !pendingInSync.contains(entry.getKey()) || !entry.getValue().inSync :
                ""shard copy "" + entry.getKey() + "" blocks global checkpoint advancement but is in-sync"";
            // in-sync shard copies are tracked
            assert !entry.getValue().inSync || entry.getValue().tracked :
                ""shard copy "" + entry.getKey() + "" is in-sync but not tracked"";
        }

        // all pending in sync shards are tracked
        for (String aId : pendingInSync) {
            assert checkpoints.get(aId) != null : ""aId ["" + aId + ""] is pending in sync but isn't tracked"";
        }

        return true;
    }",/server/src/main/java/org/elasticsearch/index/seqno/ReplicationTracker.java
13917162ad5c59a96ccb4d6a81a5044546c45c22,662,811,"private Runnable getMasterUpdateOperationFromCurrentState() {
        assert primaryMode == false;
        final long lastAppliedClusterStateVersion = appliedClusterStateVersion;
        final Set<String> inSyncAllocationIds = new HashSet<>();
        final Set<String> pre60AllocationIds = new HashSet<>();
        checkpoints.entrySet().forEach(entry -> {
            if (entry.getValue().inSync) {
                inSyncAllocationIds.add(entry.getKey());
            }
            if (entry.getValue().getLocalCheckpoint() == SequenceNumbers.PRE_60_NODE_CHECKPOINT) {
                pre60AllocationIds.add(entry.getKey());
            }
        });
        final IndexShardRoutingTable lastAppliedRoutingTable = routingTable;
        return () -> updateFromMaster(lastAppliedClusterStateVersion, inSyncAllocationIds, lastAppliedRoutingTable, pre60AllocationIds);
    }","public synchronized void activateWithPrimaryContext(PrimaryContext primaryContext) {
        assert invariant();
        assert primaryMode == false;
        final Runnable runAfter = getMasterUpdateOperationFromCurrentState();
        primaryMode = true;
        // capture current state to possibly replay missed cluster state update
        appliedClusterStateVersion = primaryContext.clusterStateVersion();
        checkpoints.clear();
        for (Map.Entry<String, CheckpointState> entry : primaryContext.checkpoints.entrySet()) {
            checkpoints.put(entry.getKey(), entry.getValue().copy());
        }
        routingTable = primaryContext.getRoutingTable();
        replicationGroup = calculateReplicationGroup();
        updateGlobalCheckpointOnPrimary();
        // reapply missed cluster state update
        // note that if there was no cluster state update between start of the engine of this shard and the call to
        // initializeWithPrimaryContext, we might still have missed a cluster state update. This is best effort.
        runAfter.run();
        assert invariant();
    }",/server/src/main/java/org/elasticsearch/index/seqno/ReplicationTracker.java
6bb01984b6cceab38d50dcb92ba8da5c6a5f28ab,691,600,"public MultiMatchQueryBuilder randomizeType(MultiMatchQueryBuilder builder) {
        try {
            MultiMatchQueryBuilder.Type type = getType(builder);
            if (type == null && randomBoolean()) {
                return builder;
            }
            if (type == null) {
                type = MultiMatchQueryBuilder.Type.BEST_FIELDS;
            }
            if (randomBoolean()) {
                builder.type(type);
            } else {
                Object oType = type;
                switch (type) {
                    case BEST_FIELDS:
                        if (randomBoolean()) {
                            oType = MatchQuery.Type.BOOLEAN;
                        }
                        break;
                    case MOST_FIELDS:
                        if (randomBoolean()) {
                            oType = MatchQuery.Type.BOOLEAN;
                        }
                        break;
                    case CROSS_FIELDS:
                        break;
                    case PHRASE:
                        if (randomBoolean()) {
                            oType = MatchQuery.Type.PHRASE;
                        }
                        break;
                    case PHRASE_PREFIX:
                        if (randomBoolean()) {
                            oType = MatchQuery.Type.PHRASE_PREFIX;
                        }
                        break;
                }
                builder.type(oType);
            }
            return builder;
        } catch (Exception ex) {
            throw new RuntimeException(ex);
        }
    }","public void testCrossFieldMode() throws ExecutionException, InterruptedException {
        SearchResponse searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""captain america"", ""full_name"", ""first_name"", ""last_name"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                        .operator(Operator.OR))).get();
        assertFirstHit(searchResponse, hasId(""theone""));

        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""marvel hero captain america"", ""full_name"", ""first_name"", ""last_name"", ""category"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                        .operator(Operator.OR))).get();
        assertFirstHit(searchResponse, hasId(""theone""));
        assertSecondHit(searchResponse, hasId(""theother""));
        assertThat(searchResponse.getHits().hits()[0].getScore(), greaterThan(searchResponse.getHits().hits()[1].getScore()));

        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""marvel hero"", ""full_name"", ""first_name"", ""last_name"", ""category"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                        .operator(Operator.OR))).get();
        assertFirstHit(searchResponse, hasId(""theother""));

        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""captain america"", ""full_name"", ""first_name"", ""last_name"", ""category"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                        .operator(Operator.AND))).get();
        assertHitCount(searchResponse, 1l);
        assertFirstHit(searchResponse, hasId(""theone""));

        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""captain america 15"", ""full_name"", ""first_name"", ""last_name"", ""category"", ""skill"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                        .analyzer(""category"")
                        .operator(Operator.AND))).get();
        assertHitCount(searchResponse, 1l);
        assertFirstHit(searchResponse, hasId(""theone""));

        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""captain america 15"", ""full_name"", ""first_name"", ""last_name"", ""category"", ""skill"", ""int-field"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                        .analyzer(""category"")
                        .operator(Operator.AND))).get();
        assertHitCount(searchResponse, 1l);
        assertFirstHit(searchResponse, hasId(""theone""));

        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""captain america 15"", ""skill"", ""full_name"", ""first_name"", ""last_name"", ""category"", ""int-field"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                        .analyzer(""category"")
                        .operator(Operator.AND))).get();
        assertHitCount(searchResponse, 1l);
        assertFirstHit(searchResponse, hasId(""theone""));


        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""captain america 15"", ""first_name"", ""last_name"", ""skill"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                        .analyzer(""category""))).get();
        assertFirstHit(searchResponse, hasId(""theone""));

        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""25 15"", ""int-field"", ""skill"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                        .analyzer(""category""))).get();
        assertFirstHit(searchResponse, hasId(""theone""));

        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""25 15"", ""first_name"", ""int-field"", ""skill"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                        .analyzer(""category""))).get();
        assertFirstHit(searchResponse, hasId(""theone""));

        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""25 15"", ""int-field"", ""skill"", ""first_name"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                        .analyzer(""category""))).get();
        assertFirstHit(searchResponse, hasId(""theone""));

        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""25 15"", ""int-field"", ""first_name"", ""skill"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                        .analyzer(""category""))).get();
        assertFirstHit(searchResponse, hasId(""theone""));

        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""captain america marvel hero"", ""first_name"", ""last_name"", ""category"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                        .cutoffFrequency(0.1f)
                        .analyzer(""category"")
                        .operator(Operator.OR))).get();
        assertFirstHit(searchResponse, anyOf(hasId(""theother""), hasId(""theone"")));
        long numResults = searchResponse.getHits().totalHits();

        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""captain america marvel hero"", ""first_name"", ""last_name"", ""category"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                        .analyzer(""category"")
                        .operator(Operator.OR))).get();
        assertThat(numResults, lessThan(searchResponse.getHits().getTotalHits()));
        assertFirstHit(searchResponse, hasId(""theone""));


        // test group based on analyzer -- all fields are grouped into a cross field search
        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""captain america marvel hero"", ""first_name"", ""last_name"", ""category"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                        .analyzer(""category"")
                        .operator(Operator.AND))).get();
        assertHitCount(searchResponse, 1l);
        assertFirstHit(searchResponse, hasId(""theone""));
        // counter example
        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""captain america marvel hero"", ""first_name"", ""last_name"", ""category"")
                        .type(randomBoolean() ? MultiMatchQueryBuilder.Type.CROSS_FIELDS : MultiMatchQueryBuilder.DEFAULT_TYPE)
                        .operator(Operator.AND))).get();
        assertHitCount(searchResponse, 0l);

        // counter example
        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""captain america marvel hero"", ""first_name"", ""last_name"", ""category"")
                        .type(randomBoolean() ? MultiMatchQueryBuilder.Type.CROSS_FIELDS : MultiMatchQueryBuilder.DEFAULT_TYPE)
                        .operator(Operator.AND))).get();
        assertHitCount(searchResponse, 0l);

        // test if boosts work
        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""the ultimate"", ""full_name"", ""first_name"", ""last_name"", ""category"").field(""last_name"", 2)
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                        .operator(Operator.AND))).get();
        assertFirstHit(searchResponse, hasId(""ultimate1""));   // has ultimate in the last_name and that is boosted
        assertSecondHit(searchResponse, hasId(""ultimate2""));
        assertThat(searchResponse.getHits().hits()[0].getScore(), greaterThan(searchResponse.getHits().hits()[1].getScore()));

        // since we try to treat the matching fields as one field scores are very similar but we have a small bias towards the
        // more frequent field that acts as a tie-breaker internally
        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""the ultimate"", ""full_name"", ""first_name"", ""last_name"", ""category"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                        .operator(Operator.AND))).get();
        assertFirstHit(searchResponse, hasId(""ultimate2""));
        assertSecondHit(searchResponse, hasId(""ultimate1""));
        assertThat(searchResponse.getHits().hits()[0].getScore(), greaterThan(searchResponse.getHits().hits()[1].getScore()));

        // Test group based on numeric fields
        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""15"", ""skill"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS))).get();
        assertFirstHit(searchResponse, hasId(""theone""));

        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""15"", ""skill"", ""first_name"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS))).get();
        assertFirstHit(searchResponse, hasId(""theone""));

        // Two numeric fields together caused trouble at one point!
        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""15"", ""int-field"", ""skill"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS))).get();
        assertFirstHit(searchResponse, hasId(""theone""));

        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""15"", ""int-field"", ""first_name"", ""skill"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS))).get();
        assertFirstHit(searchResponse, hasId(""theone""));

        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""alpha 15"", ""first_name"", ""skill"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                        .lenient(true))).get();
        assertFirstHit(searchResponse, hasId(""ultimate1""));
        /*
         * Doesn't find theone because ""alpha 15"" isn't a number and we don't
         * break on spaces.
         */
        assertHitCount(searchResponse, 1);

        // Lenient wasn't always properly lenient with two numeric fields
        searchResponse = client().prepareSearch(""test"")
                .setQuery(randomizeType(multiMatchQuery(""alpha 15"", ""int-field"", ""first_name"", ""skill"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                        .lenient(true))).get();
        assertFirstHit(searchResponse, hasId(""ultimate1""));
    }",/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java
4439a86cb8364742e977ea324bb174bcf7f51f06,563,134,"public long roundKey(long utcMillis) {
            long timeLocal = utcMillis;
            timeLocal = timeZone.convertUTCToLocal(utcMillis);
            long rounded = field.roundFloor(timeLocal);
            return timeZone.convertLocalToUTC(rounded, false, utcMillis);
        }","public long roundKey(long utcMillis) {
            long rounded = field.roundFloor(utcMillis);
            if (timeZone.isFixed() == false && timeZone.getOffset(utcMillis) != timeZone.getOffset(rounded)) {
                // in this case, we crossed a time zone transition. In some edge cases this will
                // result in a value that is not a rounded value itself. We need to round again
                // to make sure. This will have no affect in cases where 'rounded' was already a proper
                // rounded value
                rounded = field.roundFloor(rounded);
            }
            assert rounded == field.roundFloor(rounded);
            return rounded;
        }",/core/src/main/java/org/elasticsearch/common/rounding/TimeZoneRounding.java
4439a86cb8364742e977ea324bb174bcf7f51f06,563,230,"public long nextRoundingValue(long time) {
            long timeLocal = time;
            timeLocal = timeZone.convertUTCToLocal(time);
            long next = timeLocal + interval;
            return timeZone.convertLocalToUTC(next, false);
        }","public long valueForKey(long time) {
            assert roundKey(time) == time;
            return time;
        }",/core/src/main/java/org/elasticsearch/common/rounding/TimeZoneRounding.java
2175b7b01cf5fcf3ab2bb21404a9bd454a8df3f0,563,52,"public void testVersionFromJarInJar() throws IOException {
        final String JDBC_JAR_NAME = ""es-sql-jdbc.jar"";
        final String JAR_PATH_SEPARATOR = ""!/"";

        Path dir = createTempDir();
        Path jarPath = dir.resolve(""uberjar.jar"");          // simulated uberjar containing the jdbc driver
        Path innerJarPath = dir.resolve(JDBC_JAR_NAME); // simulated ES JDBC driver file

        Manifest jdbcJarManifest = new Manifest();
        Attributes attributes = jdbcJarManifest.getMainAttributes();
        attributes.put(Attributes.Name.MANIFEST_VERSION, ""1.0.0"");
        attributes.put(new Attributes.Name(""Change""), ""abc"");
        attributes.put(new Attributes.Name(""X-Compile-Elasticsearch-Version""), ""1.2.3"");

        // create the jdbc driver file
        try (JarOutputStream jdbc = new JarOutputStream(Files.newOutputStream(innerJarPath, StandardOpenOption.CREATE), jdbcJarManifest)) {}

        // create the uberjar and embed the jdbc driver one into it
        try (BufferedInputStream in = new BufferedInputStream(Files.newInputStream(innerJarPath));
                JarOutputStream out = new JarOutputStream(Files.newOutputStream(jarPath, StandardOpenOption.CREATE), new Manifest())) {
            JarEntry entry = new JarEntry(JDBC_JAR_NAME + JAR_PATH_SEPARATOR);
            out.putNextEntry(entry);

            byte[] buffer = new byte[1024];
            while (true) {
                int count = in.read(buffer);
                if (count == -1) {
                    break;
                }
                out.write(buffer, 0, count);
            }
        }
        
        URL jarInJar = new URL(""jar:"" + jarPath.toUri().toURL().toString() + JAR_PATH_SEPARATOR + JDBC_JAR_NAME + JAR_PATH_SEPARATOR);

        SqlVersion version = ClientVersion.extractVersion(jarInJar);
        assertEquals(1, version.major);
        assertEquals(2, version.minor);
        assertEquals(3, version.revision);
        assertEquals(""1.2.3"", version.version);
    }","private static byte[] randomVersion() {
        byte[] parts = new byte[3];
        for (int i = 0; i < parts.length; i ++) {
            parts[i] = (byte) randomIntBetween(0, SqlVersion.REVISION_MULTIPLIER);
        }
        return parts;
    }",/x-pack/plugin/sql/sql-client/src/test/java/org/elasticsearch/xpack/sql/client/VersionTests.java
6181d8ecde5610878e014ac1b0b957901901c9df,690,899,"public void onFailedEngine(final ShardId shardId, final String reason, final @Nullable Throwable failure) {
            ShardRouting shardRouting = null;
            final IndexService indexService = indicesService.indexService(shardId.index().name());
            if (indexService != null) {
                IndexShard indexShard = indexService.shard(shardId.id());
                if (indexShard != null) {
                    shardRouting = indexShard.routingEntry();
                }
            }
            if (shardRouting == null) {
                logger.warn(""[{}][{}] engine failed, but can't find index shard. failure reason: [{}]"",
                        shardId.index().name(), shardId.id(), reason);
                return;
            }
            final ShardRouting fShardRouting = shardRouting;
            final String indexUUID = indexService.indexUUID(); // we know indexService is not null here.
            final String failureMessage = ""engine failure, message ["" + reason + ""]"" +
                    (failure == null ? """" : ""["" + detailedMessage(failure) + ""]"");
            threadPool.generic().execute(new Runnable() {
                @Override
                public void run() {
                    synchronized (mutex) {
                        if (indexService.hasShard(shardId.id())) {
                            try {

                                indexService.removeShard(shardId.id(), failureMessage);
                            } catch (IndexShardMissingException e) {
                                // the node got closed on us, ignore it
                            } catch (Throwable e1) {
                                logger.warn(""[{}][{}] failed to delete shard after failed engine ([{}])"", e1, indexService.index().name(), shardId.id(), reason);
                            }
                        }
                        try {
                            failedShards.put(fShardRouting.shardId(), new FailedShard(fShardRouting.version()));
                            shardStateAction.shardFailed(fShardRouting, indexUUID, failureMessage);
                        } catch (Throwable e1) {
                            logger.warn(""[{}][{}] failed to mark shard as failed after a failed engine ([{}])"", e1, indexService.index().name(), shardId.id(), reason);
                        }
                    }
                }
            });
        }","public void onFailedEngine(final ShardId shardId, final String reason, final @Nullable Throwable failure) {
            ShardRouting shardRouting = null;
            final IndexService indexService = indicesService.indexService(shardId.index().name());
            if (indexService != null) {
                IndexShard indexShard = indexService.shard(shardId.id());
                if (indexShard != null) {
                    shardRouting = indexShard.routingEntry();
                }
            }
            if (shardRouting == null) {
                logger.warn(""[{}][{}] engine failed, but can't find index shard. failure reason: [{}]"", failure,
                        shardId.index().name(), shardId.id(), reason);
                return;
            }
            final ShardRouting fShardRouting = shardRouting;
            threadPool.generic().execute(new Runnable() {
                @Override
                public void run() {
                    synchronized (mutex) {
                        failAndRemoveShard(fShardRouting, indexService, true, ""engine failure, reason ["" + reason + ""]"", failure);
                    }
                }
            });
        }",/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java
98db34907dc861f05ce16e249e2d383a29f29caf,561,319,"private void putIndex(String indexName, String dateType, boolean isDataStream) throws IOException {
        // create mapping and settings
        try (XContentBuilder builder = jsonBuilder()) {
            builder.startObject();
            {
                builder.startObject(""settings"").startObject(""index"");
                builder.field(""number_of_shards"", randomIntBetween(1, 5));
                if (randomBoolean()) {
                    builder.field(""codec"", ""best_compression"");
                }
                // TODO: crashes with assertions enabled in lucene
                if (false && randomBoolean()) {
                    List<String> sortedFields = new ArrayList<>(
                        // note: no index sort for geo_point
                        randomUnique(() -> randomFrom(""event"", ""metric"", ""run"", ""timestamp""), randomIntBetween(1, 3))
                    );
                    Collections.shuffle(sortedFields, random());
                    List<String> sortOrders = randomList(sortedFields.size(), sortedFields.size(), () -> randomFrom(""asc"", ""desc""));

                    builder.field(""sort.field"", sortedFields);
                    builder.field(""sort.order"", sortOrders);
                    if (randomBoolean()) {
                        builder.field(
                            ""sort.missing"",
                            randomList(sortedFields.size(), sortedFields.size(), () -> randomFrom(""_last"", ""_first""))
                        );
                    }
                }
                builder.endObject().endObject();
                builder.startObject(""mappings"").startObject(""properties"");
                builder.startObject(""timestamp"").field(""type"", dateType);
                if (dateType.equals(""date_nanos"")) {
                    builder.field(""format"", ""strict_date_optional_time_nanos"");
                }
                builder.endObject();

                builder.startObject(""event"")
                    .field(""type"", ""keyword"")
                    .endObject()
                    .startObject(""metric"")
                    .field(""type"", randomFrom(""integer"", ""long"", ""unsigned_long""))
                    .endObject()
                    .startObject(""location"")
                    .field(""type"", ""geo_point"")
                    .endObject()
                    .startObject(""run"")
                    .field(""type"", ""integer"")
                    .endObject()
                    .startObject(""metric-timestamp"")
                    .field(""type"", dateType)
                    .endObject()
                    .startObject(""some-timestamp"")
                    .field(""type"", dateType)
                    .endObject();

                builder.endObject(); // properties

                // add some runtime fields
                builder.startObject(""runtime"");

                builder.startObject(""metric-rt-2x"")
                    .field(""type"", ""long"")
                    .startObject(""script"")
                    .field(""source"", ""if (params._source.metric != null) {emit(params._source.metric * 2)}"")
                    .endObject()
                    .endObject()
                    .startObject(""event-upper"")
                    .field(""type"", ""keyword"")
                    .startObject(""script"")
                    .field(""source"", ""if (params._source.event != null) {emit(params._source.event.toUpperCase())}"")
                    .endObject()
                    .endObject()
                    .startObject(""timestamp-at-runtime"")
                    .field(""type"", ""date"")
                    .startObject(""script"")
                    .field(""source"", ""emit(parse(params._source.get('timestamp')))"")
                    .endObject()
                    .endObject()
                    .startObject(""metric-timestamp-5m-earlier"")
                    .field(""type"", ""date"")
                    .startObject(""script"")
                    .field(
                        ""source"",
                        ""if (doc['metric-timestamp'].size()!=0) {emit(doc['metric-timestamp'].value.minus(5, ChronoUnit.MINUTES).toInstant().toEpochMilli())}""
                    )
                    .endObject()
                    .endObject()
                    .startObject(""some-timestamp-10m-earlier"")
                    .field(""type"", ""date"")
                    .startObject(""script"")
                    .field(
                        ""source"",
                        ""if (doc['some-timestamp'].size()!=0) {emit(doc['some-timestamp'].value.minus(10, ChronoUnit.MINUTES).toInstant().toEpochMilli())}""
                    )
                    .endObject()
                    .endObject();

                // random overlay of existing field
                if (randomBoolean()) {
                    if (randomBoolean()) {
                        builder.startObject(""metric"").field(""type"", ""long"").endObject();
                    } else {
                        builder.startObject(""metric"")
                            .field(""type"", ""long"")
                            .startObject(""script"")
                            .field(""source"", ""if (params._source.metric != null) {emit(params._source.metric * 3)}"")
                            .endObject()
                            .endObject();
                    }
                }

                builder.endObject(); // runtime
                builder.endObject(); // mappings
            }
            builder.endObject();
            String indexSettingsAndMappings = Strings.toString(builder);
            logger.info(""Creating source index with: {}"", indexSettingsAndMappings);
            if (isDataStream) {
                Request createCompositeTemplate = new Request(""PUT"", ""_index_template/"" + indexName + ""_template"");
                createCompositeTemplate.setJsonEntity(
                    ""{\n""
                        + ""  \""index_patterns\"": [ \""""
                        + indexName
                        + ""\"" ],\n""
                        + ""  \""data_stream\"": {\n""
                        + ""  },\n""
                        + ""  \""template\"": \n""
                        + indexSettingsAndMappings
                        + ""}""
                );
                client().performRequest(createCompositeTemplate);
                client().performRequest(new Request(""PUT"", ""_data_stream/"" + indexName));
            } else {
                final StringEntity entity = new StringEntity(indexSettingsAndMappings, ContentType.APPLICATION_JSON);
                Request req = new Request(""PUT"", indexName);
                req.setEntity(entity);
                client().performRequest(req);
            }
        }
    }","private void putIndex(String indexName, String dateType, boolean isDataStream) throws IOException {
        // create mapping and settings
        try (XContentBuilder builder = jsonBuilder()) {
            builder.startObject();
            {
                builder.startObject(""settings"").startObject(""index"");
                builder.field(""number_of_shards"", randomIntBetween(1, 5));
                if (randomBoolean()) {
                    builder.field(""codec"", ""best_compression"");
                }
                if (randomBoolean()) {
                    List<String> sortedFields = new ArrayList<>(
                        // note: no index sort for geo_point
                        randomUnique(() -> randomFrom(""event"", ""metric"", ""run"", ""timestamp""), randomIntBetween(1, 3))
                    );
                    Collections.shuffle(sortedFields, random());
                    List<String> sortOrders = randomList(sortedFields.size(), sortedFields.size(), () -> randomFrom(""asc"", ""desc""));

                    builder.field(""sort.field"", sortedFields);
                    builder.field(""sort.order"", sortOrders);
                    if (randomBoolean()) {
                        builder.field(
                            ""sort.missing"",
                            randomList(sortedFields.size(), sortedFields.size(), () -> randomFrom(""_last"", ""_first""))
                        );
                    }
                }
                builder.endObject().endObject();
                builder.startObject(""mappings"").startObject(""properties"");
                builder.startObject(""timestamp"").field(""type"", dateType);
                if (dateType.equals(""date_nanos"")) {
                    builder.field(""format"", ""strict_date_optional_time_nanos"");
                }
                builder.endObject();

                builder.startObject(""event"")
                    .field(""type"", ""keyword"")
                    .endObject()
                    .startObject(""metric"")
                    .field(""type"", randomFrom(""integer"", ""long"", ""unsigned_long""))
                    .endObject()
                    .startObject(""location"")
                    .field(""type"", ""geo_point"")
                    .endObject()
                    .startObject(""run"")
                    .field(""type"", ""integer"")
                    .endObject()
                    .startObject(""metric-timestamp"")
                    .field(""type"", dateType)
                    .endObject()
                    .startObject(""some-timestamp"")
                    .field(""type"", dateType)
                    .endObject();

                builder.endObject(); // properties

                // add some runtime fields
                builder.startObject(""runtime"");

                builder.startObject(""metric-rt-2x"")
                    .field(""type"", ""long"")
                    .startObject(""script"")
                    .field(""source"", ""if (params._source.metric != null) {emit(params._source.metric * 2)}"")
                    .endObject()
                    .endObject()
                    .startObject(""event-upper"")
                    .field(""type"", ""keyword"")
                    .startObject(""script"")
                    .field(""source"", ""if (params._source.event != null) {emit(params._source.event.toUpperCase())}"")
                    .endObject()
                    .endObject()
                    .startObject(""timestamp-at-runtime"")
                    .field(""type"", ""date"")
                    .startObject(""script"")
                    .field(""source"", ""emit(parse(params._source.get('timestamp')))"")
                    .endObject()
                    .endObject()
                    .startObject(""metric-timestamp-5m-earlier"")
                    .field(""type"", ""date"")
                    .startObject(""script"")
                    .field(
                        ""source"",
                        ""if (doc['metric-timestamp'].size()!=0) {emit(doc['metric-timestamp'].value.minus(5, ChronoUnit.MINUTES).toInstant().toEpochMilli())}""
                    )
                    .endObject()
                    .endObject()
                    .startObject(""some-timestamp-10m-earlier"")
                    .field(""type"", ""date"")
                    .startObject(""script"")
                    .field(
                        ""source"",
                        ""if (doc['some-timestamp'].size()!=0) {emit(doc['some-timestamp'].value.minus(10, ChronoUnit.MINUTES).toInstant().toEpochMilli())}""
                    )
                    .endObject()
                    .endObject();

                // random overlay of existing field
                if (randomBoolean()) {
                    if (randomBoolean()) {
                        builder.startObject(""metric"").field(""type"", ""long"").endObject();
                    } else {
                        builder.startObject(""metric"")
                            .field(""type"", ""long"")
                            .startObject(""script"")
                            .field(""source"", ""if (params._source.metric != null) {emit(params._source.metric * 3)}"")
                            .endObject()
                            .endObject();
                    }
                }

                builder.endObject(); // runtime
                builder.endObject(); // mappings
            }
            builder.endObject();
            String indexSettingsAndMappings = Strings.toString(builder);
            logger.info(""Creating source index with: {}"", indexSettingsAndMappings);
            if (isDataStream) {
                Request createCompositeTemplate = new Request(""PUT"", ""_index_template/"" + indexName + ""_template"");
                createCompositeTemplate.setJsonEntity(
                    ""{\n""
                        + ""  \""index_patterns\"": [ \""""
                        + indexName
                        + ""\"" ],\n""
                        + ""  \""data_stream\"": {\n""
                        + ""  },\n""
                        + ""  \""template\"": \n""
                        + indexSettingsAndMappings
                        + ""}""
                );
                client().performRequest(createCompositeTemplate);
                client().performRequest(new Request(""PUT"", ""_data_stream/"" + indexName));
            } else {
                final StringEntity entity = new StringEntity(indexSettingsAndMappings, ContentType.APPLICATION_JSON);
                Request req = new Request(""PUT"", indexName);
                req.setEntity(entity);
                client().performRequest(req);
            }
        }
    }",/x-pack/plugin/transform/qa/multi-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/transform/integration/continuous/TransformContinuousIT.java
1b6d9d430c404b5c5fa28da6daede66cf10368c1,570,883,"public void testExecuteWatchNotFound() throws Exception {
        Watch watch = mock(Watch.class);
        when(watch.id()).thenReturn(""_id"");
        WatchExecutionContext ctx = mock(WatchExecutionContext.class);
        when(ctx.knownWatch()).thenReturn(true);
        when(watch.status()).thenReturn(new WatchStatus(now(), emptyMap()));
        when(ctx.watch()).thenReturn(watch);

        GetResponse getResponse = mock(GetResponse.class);
        when(getResponse.isExists()).thenReturn(false);
        boolean exceptionThrown = false;
        if (randomBoolean()) {
            mockGetWatchResponse(client, ""_id"", getResponse);
        } else {
            // this emulates any failure while getting the watch, while index not found is an accepted issue
            if (randomBoolean()) {
                exceptionThrown = true;
                ElasticsearchException e = new ElasticsearchException(""something went wrong, i.e. index not found"");
                mockGetWatchException(client, ""_id"", e);
                WatchExecutionResult result = new WatchExecutionResult(ctx, randomInt(10));
                WatchRecord wr = new WatchRecord.ExceptionWatchRecord(ctx, result, e);
                when(ctx.abortFailedExecution(eq(e))).thenReturn(wr);
            } else {
                mockGetWatchException(client, ""_id"", new IndexNotFoundException("".watch""));
            }
        }

        WatchRecord.MessageWatchRecord record = mock(WatchRecord.MessageWatchRecord.class);
        when(record.state()).thenReturn(ExecutionState.NOT_EXECUTED_WATCH_MISSING);
        when(ctx.abortBeforeExecution(eq(ExecutionState.NOT_EXECUTED_WATCH_MISSING), any())).thenReturn(record);
        when(ctx.executionPhase()).thenReturn(ExecutionPhase.AWAITS_EXECUTION);

        WatchRecord watchRecord = executionService.execute(ctx);
        if (exceptionThrown) {
            assertThat(watchRecord.state(), is(ExecutionState.FAILED));
        } else {
            assertThat(watchRecord.state(), is(ExecutionState.NOT_EXECUTED_WATCH_MISSING));
        }
    }","public void testExecuteWatchNotFound() throws Exception {
        Watch watch = mock(Watch.class);
        when(watch.id()).thenReturn(""_id"");
        TriggeredExecutionContext context = new TriggeredExecutionContext(watch.id(),
                new DateTime(0, UTC),
                new ScheduleTriggerEvent(watch.id(), new DateTime(0, UTC), new DateTime(0, UTC)),
                TimeValue.timeValueSeconds(5));

        GetResponse notFoundResponse = mock(GetResponse.class);
        when(notFoundResponse.isExists()).thenReturn(false);
        mockGetWatchResponse(client, ""_id"", notFoundResponse);

        WatchRecord watchRecord = executionService.execute(context);
        assertThat(watchRecord, not(nullValue()));
        assertThat(watchRecord.state(), is(ExecutionState.NOT_EXECUTED_WATCH_MISSING));
    }",/plugin/src/test/java/org/elasticsearch/xpack/watcher/execution/ExecutionServiceTests.java
91404bb48f14cb9ccc1108e9d4314e4bc58863c6,690,102,"private Tuple<CountDownLatch, AtomicLong> setupClusterStateListener(String node) {
        ClusterService clusterService = internalCluster().clusterService(node);
        CountDownLatch savedClusterState = new CountDownLatch(1);
        AtomicLong metadataVersion = new AtomicLong(-1);
        clusterService.addListener(new ClusterStateListener() {
            @Override
            public void clusterChanged(ClusterChangedEvent event) {
                ReservedStateMetadata reservedState = event.state().metadata().reservedStateMetadata().get(FileSettingsService.NAMESPACE);
                if (reservedState != null && reservedState.version() != 0L) {
                    ReservedStateHandlerMetadata handlerMetadata = reservedState.handlers().get(ReservedClusterSettingsAction.NAME);
                    if (handlerMetadata == null) {
                        fail(""Should've found cluster settings in this metadata"");
                    }
                    if (handlerMetadata.keys().contains(""indices.recovery.max_bytes_per_sec"")) {
                        clusterService.removeListener(this);
                        metadataVersion.set(event.state().metadata().version());
                        savedClusterState.countDown();
                    }
                }
            }
        });

        return new Tuple<>(savedClusterState, metadataVersion);
    }","private Tuple<CountDownLatch, AtomicLong> setupClusterStateListener(String node) {
        ClusterService clusterService = internalCluster().clusterService(node);
        CountDownLatch savedClusterState = new CountDownLatch(1);
        AtomicLong metadataVersion = new AtomicLong(-1);
        clusterService.addListener(new ClusterStateListener() {
            @Override
            public void clusterChanged(ClusterChangedEvent event) {
                ReservedStateMetadata reservedState = event.state().metadata().reservedStateMetadata().get(FileSettingsService.NAMESPACE);
                if (reservedState != null && reservedState.version() != 0L) {
                    ReservedStateHandlerMetadata handlerMetadata = reservedState.handlers().get(ReservedClusterSettingsAction.NAME);
                    if (handlerMetadata != null && handlerMetadata.keys().contains(""indices.recovery.max_bytes_per_sec"")) {
                        clusterService.removeListener(this);
                        metadataVersion.set(event.state().metadata().version());
                        savedClusterState.countDown();
                    }
                }
            }
        });

        return new Tuple<>(savedClusterState, metadataVersion);
    }",/server/src/internalClusterTest/java/org/elasticsearch/reservedstate/service/SnaphotsAndFileSettingsIT.java
99340fe71b259bbbe1f6cb1d1c01473bd7a8124b,561,367,"public void markShardAsEvictedInCache(SnapshotId snapshotId, IndexId indexId, ShardId shardId) {
        final ShardEviction shardEviction = new ShardEviction(snapshotId.getUUID(), indexId.getName(), shardId);
        if (evictedShards.add(shardEviction)) {
            threadPool.generic().submit(new AbstractRunnable() {
                @Override
                protected void doRun() {
                    runIfShardMarkedAsEvictedInCache(shardEviction, () -> {
                        assert shardsEvictionLock.isHeldByCurrentThread(shardEviction);
                        final Map<CacheKey, CacheFile> cacheFilesToEvict = new HashMap<>();
                        cache.forEach((cacheKey, cacheFile) -> {
                            if (shardEviction.matches(cacheKey)) {
                                cacheFilesToEvict.put(cacheKey, cacheFile);
                            }
                        });
                        for (Map.Entry<CacheKey, CacheFile> cacheFile : cacheFilesToEvict.entrySet()) {
                            try {
                                cache.invalidate(cacheFile.getKey(), cacheFile.getValue());
                            } catch (RuntimeException e) {
                                assert false : e;
                                logger.warn(() -> new ParameterizedMessage(""failed to evict cache file {}"", cacheFile.getKey()), e);
                            }
                        }
                    });
                }

                @Override
                public void onFailure(Exception e) {
                    assert false : e;
                    logger.warn(
                        () -> new ParameterizedMessage(""failed to evict cache files associated with evicted shard {}"", shardEviction),
                        e
                    );
                }
            });
        }
    }","public void markShardAsEvictedInCache(String snapshotUUID, String snapshotIndexName, ShardId shardId) {
        synchronized (shardsEvictionsMutex) {
            if (allowShardsEvictions) {
                final ShardEviction shardEviction = new ShardEviction(snapshotUUID, snapshotIndexName, shardId);
                pendingShardsEvictions.computeIfAbsent(shardEviction, shard -> threadPool.generic().submit(new AbstractRunnable() {
                    @Override
                    protected void doRun() {
                        processShardEviction(shardEviction);
                    }

                    @Override
                    public void onFailure(Exception e) {
                        logger.warn(
                            () -> new ParameterizedMessage(""failed to evict cache files associated with shard {}"", shardEviction),
                            e
                        );
                        assert false : e;
                    }
                }));
            }
        }
    }",/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java
655c692a48cbff0f09aebafd99e6ca90a2a2cc9d,561,394,") {
        final PlainActionFuture<Integer> future = PlainActionFuture.newFuture();
        Releasable decrementRef = null;
        try {
            final FileChannelReference reference = acquireFileChannelReference();
            decrementRef = Releasables.releaseOnce(reference::decRef);
            final List<SparseFileTracker.Gap> gaps = tracker.waitForRange(
                rangeToWrite,
                rangeToRead,
                rangeListener(rangeToRead, reader, future, reference, decrementRef)
            );

            for (SparseFileTracker.Gap gap : gaps) {
                try {
                    executor.execute(new AbstractRunnable() {

                        @Override
                        protected void doRun() throws Exception {
                            if (reference.tryIncRef() == false) {
                                throw new AlreadyClosedException(""Cache file channel has been released and closed"");
                            }
                            try {
                                ensureOpen();
                                writer.fillCacheRange(reference.fileChannel, gap.start(), gap.end(), gap::onProgress);
                                gap.onCompletion();
                                markAsNeedsFSync();
                            } finally {
                                reference.decRef();
                            }
                        }

                        @Override
                        public void onFailure(Exception e) {
                            gap.onFailure(e);
                        }
                    });
                } catch (Exception e) {
                    logger.error(() -> new ParameterizedMessage(""unexpected exception when submitting task to fill gap [{}]"", gap), e);
                    assert false : e;
                    gap.onFailure(e);
                }
            }
        } catch (Exception e) {
            releaseAndFail(future, decrementRef, e);
        }
        return future;
    }",") {
        final PlainActionFuture<Integer> future = PlainActionFuture.newFuture();
        Releasable decrementRef = null;
        try {
            final FileChannelReference reference = acquireFileChannelReference();
            decrementRef = Releasables.releaseOnce(reference::decRef);
            final List<SparseFileTracker.Gap> gaps = tracker.waitForRange(
                rangeToWrite,
                rangeToRead,
                rangeListener(rangeToRead, reader, future, reference, decrementRef)
            );

            for (SparseFileTracker.Gap gap : gaps) {
                executor.execute(new AbstractRunnable() {

                    @Override
                    protected void doRun() throws Exception {
                        if (reference.tryIncRef() == false) {
                            throw new AlreadyClosedException(""Cache file channel has been released and closed"");
                        }
                        try {
                            ensureOpen();
                            writer.fillCacheRange(reference.fileChannel, gap.start(), gap.end(), gap::onProgress);
                            gap.onCompletion();
                            markAsNeedsFSync();
                        } finally {
                            reference.decRef();
                        }
                    }

                    @Override
                    public void onFailure(Exception e) {
                        gap.onFailure(e);
                    }
                });
            }
        } catch (Exception e) {
            releaseAndFail(future, decrementRef, e);
        }
        return future;
    }",/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/common/CacheFile.java
655c692a48cbff0f09aebafd99e6ca90a2a2cc9d,561,800,") {
            assert rangeToRead.length() > 0;
            final StepListener<Integer> listener = new StepListener<>();
            Releasable decrementRef = null;
            try {
                ensureOpen();
                incRef();
                decrementRef = Releasables.releaseOnce(this::decRef);
                ensureOpen();
                Releasable finalDecrementRef = decrementRef;
                listener.whenComplete(integer -> finalDecrementRef.close(), throwable -> finalDecrementRef.close());
                final SharedBytes.IO fileChannel = sharedBytes.getFileChannel(sharedBytesPos);
                listener.whenComplete(integer -> fileChannel.decRef(), e -> fileChannel.decRef());
                final ActionListener<Void> rangeListener = rangeListener(rangeToRead, reader, listener, fileChannel);
                final List<SparseFileTracker.Gap> gaps = tracker.waitForRange(rangeToWrite, rangeToRead, rangeListener);

                for (SparseFileTracker.Gap gap : gaps) {
                    try {
                        executor.execute(new AbstractRunnable() {

                            @Override
                            protected void doRun() throws Exception {
                                if (CacheFileRegion.this.tryIncRef() == false) {
                                    throw new AlreadyClosedException(""Cache file channel has been released and closed"");
                                }
                                try {
                                    ensureOpen();
                                    final long start = gap.start();
                                    assert regionOwners[sharedBytesPos].get() == CacheFileRegion.this;
                                    writer.fillCacheRange(
                                        fileChannel,
                                        physicalStartOffset() + gap.start(),
                                        gap.start(),
                                        gap.end() - gap.start(),
                                        progress -> gap.onProgress(start + progress)
                                    );
                                    writeCount.increment();
                                } finally {
                                    decRef();
                                }
                                gap.onCompletion();
                            }

                            @Override
                            public void onFailure(Exception e) {
                                gap.onFailure(e);
                            }
                        });
                    } catch (Exception e) {
                        logger.error(() -> new ParameterizedMessage(""unexpected exception when submitting task to fill gap [{}]"", gap), e);
                        assert false : e;
                        gap.onFailure(e);
                    }
                }
            } catch (Exception e) {
                releaseAndFail(listener, decrementRef, e);
            }
            return listener;
        }",") {
            assert rangeToRead.length() > 0;
            final StepListener<Integer> listener = new StepListener<>();
            Releasable decrementRef = null;
            try {
                ensureOpen();
                incRef();
                decrementRef = Releasables.releaseOnce(this::decRef);
                ensureOpen();
                Releasable finalDecrementRef = decrementRef;
                listener.whenComplete(integer -> finalDecrementRef.close(), throwable -> finalDecrementRef.close());
                final SharedBytes.IO fileChannel = sharedBytes.getFileChannel(sharedBytesPos);
                listener.whenComplete(integer -> fileChannel.decRef(), e -> fileChannel.decRef());
                final ActionListener<Void> rangeListener = rangeListener(rangeToRead, reader, listener, fileChannel);
                final List<SparseFileTracker.Gap> gaps = tracker.waitForRange(rangeToWrite, rangeToRead, rangeListener);

                for (SparseFileTracker.Gap gap : gaps) {
                    executor.execute(new AbstractRunnable() {

                        @Override
                        protected void doRun() throws Exception {
                            if (CacheFileRegion.this.tryIncRef() == false) {
                                throw new AlreadyClosedException(""Cache file channel has been released and closed"");
                            }
                            try {
                                ensureOpen();
                                final long start = gap.start();
                                assert regionOwners[sharedBytesPos].get() == CacheFileRegion.this;
                                writer.fillCacheRange(
                                    fileChannel,
                                    physicalStartOffset() + gap.start(),
                                    gap.start(),
                                    gap.end() - gap.start(),
                                    progress -> gap.onProgress(start + progress)
                                );
                                writeCount.increment();
                            } finally {
                                decRef();
                            }
                            gap.onCompletion();
                        }

                        @Override
                        public void onFailure(Exception e) {
                            gap.onFailure(e);
                        }
                    });
                }
            } catch (Exception e) {
                releaseAndFail(listener, decrementRef, e);
            }
            return listener;
        }",/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/shared/FrozenCacheService.java
b333895ed3f506f349cf527b4058e334a37af787,570,207,"private List<TimeAndMaster> getRecentMasterHistory(List<TimeAndMaster> history) {
        if (history.size() < 2) {
            return history;
        }
        long now = currentTimeMillisSupplier.getAsLong();
        long oldestRelevantHistoryTime = now - maxHistoryAge.getMillis();
        TimeAndMaster mostRecent = history.isEmpty() ? null : history.get(history.size() - 1);
        List<TimeAndMaster> filteredHistory = history.stream()
            .filter(timeAndMaster -> timeAndMaster.startTimeMillis > oldestRelevantHistoryTime)
            .collect(Collectors.toList());
        if (filteredHistory.isEmpty() && mostRecent != null) { // The most recent entry was more than 30 minutes ago
            filteredHistory.add(mostRecent);
        }
        return filteredHistory;
    }","public boolean hasSeenMasterInLastNSeconds(int nSeconds) {
        if (getMostRecentMaster() != null) {
            return true;
        }
        List<TimeAndMaster> masterHistoryCopy = getRecentMasterHistory(masterHistory);
        long now = currentTimeMillisSupplier.getAsLong();
        TimeValue nSecondsTimeValue = new TimeValue(nSeconds, TimeUnit.SECONDS);
        long nSecondsAgo = now - nSecondsTimeValue.getMillis();

        /*
         * We traverse the list backwards (since it is ordered by time ascending). Once we find an entry whose
         * timeAndMaster.startTimeMillis was more than nSeconds ago we can stop because it is not possible that any more of the nodes
         * we'll see have ended within the last nSeconds.
         */
        for (int i = masterHistoryCopy.size() - 1; i >= 0; i--) {
            TimeAndMaster timeAndMaster = masterHistoryCopy.get(i);
            if (timeAndMaster.master != null) {
                return true;
            }
            if (timeAndMaster.startTimeMillis < nSecondsAgo) {
                break;
            }
        }
        return false;
    }",/server/src/main/java/org/elasticsearch/cluster/coordination/MasterHistory.java
1da59db3fbe7099eacce8a022c694ad8b9005aa8,690,218,"public void persistJob(JobTask jobTask, Consumer<Exception> handler) {
        AutodetectCommunicator communicator = getOpenAutodetectCommunicator(jobTask);
        communicator.persistJob((aVoid, e) -> handler.accept(e));
    }","public void persistJob(JobTask jobTask, Consumer<Exception> handler) {
        AutodetectCommunicator communicator = getOpenAutodetectCommunicator(jobTask);
        if (communicator == null) {
            String message = String.format(Locale.ROOT, ""Cannot persist because job [%s] does not have a corresponding autodetect process"",
                jobTask.getJobId());
            logger.debug(message);
            handler.accept(ExceptionsHelper.conflictStatusException(message));
            return;
        }
        communicator.persistJob((aVoid, e) -> handler.accept(e));
    }",/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/process/autodetect/AutodetectProcessManager.java
1da59db3fbe7099eacce8a022c694ad8b9005aa8,563,469,"private void runTask(TransportStartDatafeedAction.DatafeedTask task) {
            // This clearing of the thread context is not strictly necessary.  Every action performed by the
            // datafeed _should_ be done using the MlClientHelper, which will set the appropriate thread
            // context.  However, by clearing the thread context here if anyone forgets to use MlClientHelper
            // somewhere else in the datafeed code then it should cause a failure in the same way in single
            // and multi node clusters.  If we didn't clear the thread context here then there's a risk that
            // a context with sufficient permissions would coincidentally be in force in some single node
            // tests, leading to bugs not caught in CI due to many tests running in single node test clusters.
            try (ThreadContext.StoredContext ignore = threadPool.getThreadContext().stashContext()) {
                innerRun(runningDatafeedsOnThisNode.get(task.getAllocationId()), task.getDatafeedStartTime(), task.getEndTime());
            }
        }","private void runWhenJobIsOpened(TransportStartDatafeedAction.DatafeedTask datafeedTask) {
            ClusterState clusterState = clusterService.state();
            PersistentTasksCustomMetaData tasks = clusterState.getMetaData().custom(PersistentTasksCustomMetaData.TYPE);
            if (getJobState(tasks, datafeedTask) == JobState.OPENED && jobHasOpenAutodetectCommunicator(tasks, datafeedTask)) {
                runTask(datafeedTask);
            } else {
                logger.info(""Datafeed [{}] is waiting for job [{}] to be opened"",
                        datafeedTask.getDatafeedId(), getJobId(datafeedTask));
                tasksToRun.add(datafeedTask);
            }
        }",/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/datafeed/DatafeedManager.java
0c83ee2a5dc13cbf9069f02b007b89459373b477,595,113,"protected UpgradeResponse newResponse(UpgradeRequest request, int totalShards, int successfulShards, int failedShards, List<ShardUpgradeResult> shardUpgradeResults, List<ShardOperationFailedException> shardFailures, ClusterState clusterState) {
        Map<String, Integer> successfulPrimaryShards = new HashMap<>();
        Map<String, Tuple<Version, org.apache.lucene.util.Version>> versions = new HashMap<>();
        for (ShardUpgradeResult result : shardUpgradeResults) {
            successfulShards++;
            String index = result.getShardId().getIndex().getName();
            if (result.primary()) {
                Integer count = successfulPrimaryShards.get(index);
                successfulPrimaryShards.put(index, count == null ? 1 : count + 1);
            }
            Tuple<Version, org.apache.lucene.util.Version> versionTuple = versions.get(index);
            if (versionTuple == null) {
                versions.put(index, new Tuple<>(result.upgradeVersion(), result.oldestLuceneSegment()));
            } else {
                // We already have versions for this index - let's see if we need to update them based on the current shard
                Version version = versionTuple.v1();
                org.apache.lucene.util.Version luceneVersion = versionTuple.v2();
                // For the metadata we are interested in the _latest_ Elasticsearch version that was processing the metadata
                // Since we rewrite the mapping during upgrade the metadata is always rewritten by the latest version
                if (result.upgradeVersion().after(versionTuple.v1())) {
                    version = result.upgradeVersion();
                }
                // For the lucene version we are interested in the _oldest_ lucene version since it determines the
                // oldest version that we need to support
                if (result.oldestLuceneSegment().onOrAfter(versionTuple.v2()) == false) {
                    luceneVersion = result.oldestLuceneSegment();
                }
                versions.put(index, new Tuple<>(version, luceneVersion));
            }
        }
        Map<String, Tuple<org.elasticsearch.Version, String>> updatedVersions = new HashMap<>();
        MetaData metaData = clusterState.metaData();
        for (Map.Entry<String, Tuple<Version, org.apache.lucene.util.Version>> versionEntry : versions.entrySet()) {
            String index = versionEntry.getKey();
            Integer primaryCount = successfulPrimaryShards.get(index);
            int expectedPrimaryCount = metaData.index(index).getNumberOfShards();
            if (primaryCount == metaData.index(index).getNumberOfShards()) {
                updatedVersions.put(index, new Tuple<>(versionEntry.getValue().v1(), versionEntry.getValue().v2().toString()));
            } else {
                logger.warn(""Not updating settings for the index [{}] because upgraded of some primary shards failed - expected[{}], received[{}]"", index,
                        expectedPrimaryCount, primaryCount == null ? 0 : primaryCount);
            }
        }

        return new UpgradeResponse(updatedVersions, totalShards, successfulShards, failedShards, shardFailures);
    }","protected UpgradeResponse newResponse(UpgradeRequest request, int totalShards, int successfulShards, int failedShards, List<ShardUpgradeResult> shardUpgradeResults, List<DefaultShardOperationFailedException> shardFailures, ClusterState clusterState) {
        Map<String, Integer> successfulPrimaryShards = new HashMap<>();
        Map<String, Tuple<Version, org.apache.lucene.util.Version>> versions = new HashMap<>();
        for (ShardUpgradeResult result : shardUpgradeResults) {
            successfulShards++;
            String index = result.getShardId().getIndex().getName();
            if (result.primary()) {
                Integer count = successfulPrimaryShards.get(index);
                successfulPrimaryShards.put(index, count == null ? 1 : count + 1);
            }
            Tuple<Version, org.apache.lucene.util.Version> versionTuple = versions.get(index);
            if (versionTuple == null) {
                versions.put(index, new Tuple<>(result.upgradeVersion(), result.oldestLuceneSegment()));
            } else {
                // We already have versions for this index - let's see if we need to update them based on the current shard
                Version version = versionTuple.v1();
                org.apache.lucene.util.Version luceneVersion = versionTuple.v2();
                // For the metadata we are interested in the _latest_ Elasticsearch version that was processing the metadata
                // Since we rewrite the mapping during upgrade the metadata is always rewritten by the latest version
                if (result.upgradeVersion().after(versionTuple.v1())) {
                    version = result.upgradeVersion();
                }
                // For the lucene version we are interested in the _oldest_ lucene version since it determines the
                // oldest version that we need to support
                if (result.oldestLuceneSegment().onOrAfter(versionTuple.v2()) == false) {
                    luceneVersion = result.oldestLuceneSegment();
                }
                versions.put(index, new Tuple<>(version, luceneVersion));
            }
        }
        Map<String, Tuple<org.elasticsearch.Version, String>> updatedVersions = new HashMap<>();
        MetaData metaData = clusterState.metaData();
        for (Map.Entry<String, Tuple<Version, org.apache.lucene.util.Version>> versionEntry : versions.entrySet()) {
            String index = versionEntry.getKey();
            Integer primaryCount = successfulPrimaryShards.get(index);
            int expectedPrimaryCount = metaData.index(index).getNumberOfShards();
            if (primaryCount == metaData.index(index).getNumberOfShards()) {
                updatedVersions.put(index, new Tuple<>(versionEntry.getValue().v1(), versionEntry.getValue().v2().toString()));
            } else {
                logger.warn(""Not updating settings for the index [{}] because upgraded of some primary shards failed - expected[{}], received[{}]"", index,
                        expectedPrimaryCount, primaryCount == null ? 0 : primaryCount);
            }
        }

        return new UpgradeResponse(updatedVersions, totalShards, successfulShards, failedShards, shardFailures);
    }",/server/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java
cc8e8e6b89ba04c40d9b0be30c12c9a7899bfdb1,391,226,"protected void masterOperation(final ClusterHealthRequest request, final ClusterState unusedState, final ActionListener<ClusterHealthResponse> listener) throws ElasticsearchException {
        long endTime = System.currentTimeMillis() + request.timeout().millis();

        if (request.waitForEvents() != null) {
            final CountDownLatch latch = new CountDownLatch(1);
            final AtomicReference<ElasticsearchException> failure = new AtomicReference<>();
            clusterService.submitStateUpdateTask(""cluster_health (wait_for_events ["" + request.waitForEvents() + ""])"", request.waitForEvents(), new ProcessedClusterStateUpdateTask() {
                @Override
                public ClusterState execute(ClusterState currentState) {
                    return currentState;
                }

                @Override
                public void clusterStateProcessed(String source, ClusterState oldState, ClusterState newState) {
                    latch.countDown();
                }

                @Override
                public void onFailure(String source, Throwable t) {
                    logger.error(""unexpected failure during [{}]"", t, source);
                    failure.set(new ElasticsearchException(""Error while waiting for events"", t));
                    latch.countDown();
                }

                @Override
                public boolean runOnlyOnMaster() {
                    return !request.local();
                }
            });

            try {
                latch.await(request.timeout().millis(), TimeUnit.MILLISECONDS);
            } catch (InterruptedException e) {
                // ignore
            }
            if (failure.get() != null) {
                throw failure.get();
            }
        }


        int waitFor = 5;
        if (request.waitForStatus() == null) {
            waitFor--;
        }
        if (request.waitForRelocatingShards() == -1) {
            waitFor--;
        }
        if (request.waitForActiveShards() == -1) {
            waitFor--;
        }
        if (request.waitForNodes().isEmpty()) {
            waitFor--;
        }
        if (request.indices().length == 0) { // check that they actually exists in the meta data
            waitFor--;
        }
        if (waitFor == 0) {
            // no need to wait for anything
            ClusterState clusterState = clusterService.state();
            listener.onResponse(clusterHealth(request, clusterState));
            return;
        }
        while (true) {
            int waitForCounter = 0;
            ClusterState clusterState = clusterService.state();
            ClusterHealthResponse response = clusterHealth(request, clusterState);
            if (request.waitForStatus() != null && response.getStatus().value() <= request.waitForStatus().value()) {
                waitForCounter++;
            }
            if (request.waitForRelocatingShards() != -1 && response.getRelocatingShards() <= request.waitForRelocatingShards()) {
                waitForCounter++;
            }
            if (request.waitForActiveShards() != -1 && response.getActiveShards() >= request.waitForActiveShards()) {
                waitForCounter++;
            }
            if (request.indices().length > 0) {
                try {
                    clusterState.metaData().concreteIndices(IndicesOptions.strictExpand(), request.indices());
                    waitForCounter++;
                } catch (IndexMissingException e) {
                    response.status = ClusterHealthStatus.RED; // no indices, make sure its RED
                    // missing indices, wait a bit more...
                }
            }
            if (!request.waitForNodes().isEmpty()) {
                if (request.waitForNodes().startsWith("">="")) {
                    int expected = Integer.parseInt(request.waitForNodes().substring(2));
                    if (response.getNumberOfNodes() >= expected) {
                        waitForCounter++;
                    }
                } else if (request.waitForNodes().startsWith(""ge("")) {
                    int expected = Integer.parseInt(request.waitForNodes().substring(3, request.waitForNodes().length() - 1));
                    if (response.getNumberOfNodes() >= expected) {
                        waitForCounter++;
                    }
                } else if (request.waitForNodes().startsWith(""<="")) {
                    int expected = Integer.parseInt(request.waitForNodes().substring(2));
                    if (response.getNumberOfNodes() <= expected) {
                        waitForCounter++;
                    }
                } else if (request.waitForNodes().startsWith(""le("")) {
                    int expected = Integer.parseInt(request.waitForNodes().substring(3, request.waitForNodes().length() - 1));
                    if (response.getNumberOfNodes() <= expected) {
                        waitForCounter++;
                    }
                } else if (request.waitForNodes().startsWith("">"")) {
                    int expected = Integer.parseInt(request.waitForNodes().substring(1));
                    if (response.getNumberOfNodes() > expected) {
                        waitForCounter++;
                    }
                } else if (request.waitForNodes().startsWith(""gt("")) {
                    int expected = Integer.parseInt(request.waitForNodes().substring(3, request.waitForNodes().length() - 1));
                    if (response.getNumberOfNodes() > expected) {
                        waitForCounter++;
                    }
                } else if (request.waitForNodes().startsWith(""<"")) {
                    int expected = Integer.parseInt(request.waitForNodes().substring(1));
                    if (response.getNumberOfNodes() < expected) {
                        waitForCounter++;
                    }
                } else if (request.waitForNodes().startsWith(""lt("")) {
                    int expected = Integer.parseInt(request.waitForNodes().substring(3, request.waitForNodes().length() - 1));
                    if (response.getNumberOfNodes() < expected) {
                        waitForCounter++;
                    }
                } else {
                    int expected = Integer.parseInt(request.waitForNodes());
                    if (response.getNumberOfNodes() == expected) {
                        waitForCounter++;
                    }
                }
            }
            if (waitForCounter == waitFor) {
                listener.onResponse(response);
                return;
            }
            if (System.currentTimeMillis() > endTime) {
                response.timedOut = true;
                listener.onResponse(response);
                return;
            }
            try {
                Thread.sleep(200);
            } catch (InterruptedException e) {
                response.timedOut = true;
                listener.onResponse(response);
                return;
            }
        }
    }","private boolean prepareResponse(final ClusterHealthRequest request, final ClusterHealthResponse response, ClusterState clusterState, final int waitFor) {
        int waitForCounter = 0;
        if (request.waitForStatus() != null && response.getStatus().value() <= request.waitForStatus().value()) {
            waitForCounter++;
        }
        if (request.waitForRelocatingShards() != -1 && response.getRelocatingShards() <= request.waitForRelocatingShards()) {
            waitForCounter++;
        }
        if (request.waitForActiveShards() != -1 && response.getActiveShards() >= request.waitForActiveShards()) {
            waitForCounter++;
        }
        if (request.indices().length > 0) {
            try {
                clusterState.metaData().concreteIndices(IndicesOptions.strictExpand(), request.indices());
                waitForCounter++;
            } catch (IndexMissingException e) {
                response.status = ClusterHealthStatus.RED; // no indices, make sure its RED
                // missing indices, wait a bit more...
            }
        }
        if (!request.waitForNodes().isEmpty()) {
            if (request.waitForNodes().startsWith("">="")) {
                int expected = Integer.parseInt(request.waitForNodes().substring(2));
                if (response.getNumberOfNodes() >= expected) {
                    waitForCounter++;
                }
            } else if (request.waitForNodes().startsWith(""ge("")) {
                int expected = Integer.parseInt(request.waitForNodes().substring(3, request.waitForNodes().length() - 1));
                if (response.getNumberOfNodes() >= expected) {
                    waitForCounter++;
                }
            } else if (request.waitForNodes().startsWith(""<="")) {
                int expected = Integer.parseInt(request.waitForNodes().substring(2));
                if (response.getNumberOfNodes() <= expected) {
                    waitForCounter++;
                }
            } else if (request.waitForNodes().startsWith(""le("")) {
                int expected = Integer.parseInt(request.waitForNodes().substring(3, request.waitForNodes().length() - 1));
                if (response.getNumberOfNodes() <= expected) {
                    waitForCounter++;
                }
            } else if (request.waitForNodes().startsWith("">"")) {
                int expected = Integer.parseInt(request.waitForNodes().substring(1));
                if (response.getNumberOfNodes() > expected) {
                    waitForCounter++;
                }
            } else if (request.waitForNodes().startsWith(""gt("")) {
                int expected = Integer.parseInt(request.waitForNodes().substring(3, request.waitForNodes().length() - 1));
                if (response.getNumberOfNodes() > expected) {
                    waitForCounter++;
                }
            } else if (request.waitForNodes().startsWith(""<"")) {
                int expected = Integer.parseInt(request.waitForNodes().substring(1));
                if (response.getNumberOfNodes() < expected) {
                    waitForCounter++;
                }
            } else if (request.waitForNodes().startsWith(""lt("")) {
                int expected = Integer.parseInt(request.waitForNodes().substring(3, request.waitForNodes().length() - 1));
                if (response.getNumberOfNodes() < expected) {
                    waitForCounter++;
                }
            } else {
                int expected = Integer.parseInt(request.waitForNodes());
                if (response.getNumberOfNodes() == expected) {
                    waitForCounter++;
                }
            }
        }
        return waitForCounter == waitFor;
    }",/src/main/java/org/elasticsearch/action/admin/cluster/health/TransportClusterHealthAction.java
4b893c190068d6cf83a8f341c3f9ca535fb5738e,686,257,"private String syncedFlushDescription(ShardsSyncedFlushResult result) {
        String detail = result.shardResponses().entrySet().stream()
            .map(e -> ""Shard ["" + e.getKey() + ""], result ["" + e.getValue() + ""]"")
            .collect(Collectors.joining("",""));
        return String.format(Locale.ROOT, ""Total shards: [%d], failed: [%s], reason: [%s], detail: [%s]"",
            result.totalShards(), result.failed(), result.failureReason(), detail);
    }","public void testSyncedFlushSkipOutOfSyncReplicas() throws Exception {
        internalCluster().ensureAtLeastNumDataNodes(between(2, 3));
        final int numberOfReplicas = internalCluster().numDataNodes() - 1;
        assertAcked(
            prepareCreate(""test"").setSettings(Settings.builder()
                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)
                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, numberOfReplicas)).get()
        );
        ensureGreen();
        final Index index = clusterService().state().metaData().index(""test"").getIndex();
        final ShardId shardId = new ShardId(index, 0);
        final int numDocs = between(1, 10);
        for (int i = 0; i < numDocs; i++) {
            index(""test"", ""doc"", Integer.toString(i));
        }
        final List<IndexShard> indexShards = internalCluster().nodesInclude(""test"").stream()
            .map(node -> internalCluster().getInstance(IndicesService.class, node).getShardOrNull(shardId))
            .collect(Collectors.toList());
        // Index extra documents to one replica - synced-flush should fail on that replica.
        final IndexShard outOfSyncReplica = randomValueOtherThanMany(s -> s.routingEntry().primary(), () -> randomFrom(indexShards));
        final int extraDocs = between(1, 10);
        for (int i = 0; i < extraDocs; i++) {
            indexDoc(IndexShardTestCase.getEngine(outOfSyncReplica), ""extra_"" + i);
        }
        final ShardsSyncedFlushResult partialResult = SyncedFlushUtil.attemptSyncedFlush(logger, internalCluster(), shardId);
        assertThat(partialResult.totalShards(), equalTo(numberOfReplicas + 1));
        assertThat(partialResult.successfulShards(), equalTo(numberOfReplicas));
        assertThat(partialResult.shardResponses().get(outOfSyncReplica.routingEntry()).failureReason, equalTo(
            ""out of sync replica; num docs on replica ["" + (numDocs + extraDocs) + ""]; num docs on primary ["" + numDocs + ""]""));
        // Index extra documents to all shards - synced-flush should be ok.
        for (IndexShard indexShard : indexShards) {
            for (int i = 0; i < extraDocs; i++) {
                indexDoc(IndexShardTestCase.getEngine(indexShard), ""extra_"" + i);
            }
        }
        final ShardsSyncedFlushResult fullResult = SyncedFlushUtil.attemptSyncedFlush(logger, internalCluster(), shardId);
        assertThat(fullResult.totalShards(), equalTo(numberOfReplicas + 1));
        assertThat(fullResult.successfulShards(), equalTo(numberOfReplicas + 1));
    }",/server/src/test/java/org/elasticsearch/indices/flush/FlushIT.java
72880f732f8aa70f651e76fecfc0052997fab3cb,563,324,"public void testGetProcessorsInPipelineComplexConditional() throws Exception {
        LongSupplier relativeTimeProvider = mock(LongSupplier.class);
        String scriptName = ""conditionalScript"";
        ScriptService scriptService = new ScriptService(Settings.builder().build(),
            Collections.singletonMap(
                Script.DEFAULT_SCRIPT_LANG,
                new MockScriptEngine(
                    Script.DEFAULT_SCRIPT_LANG,
                    Collections.singletonMap(
                        scriptName, ctx -> {
                            ctx.get(""_type"");
                            return true;
                        }
                    ),
                    Collections.emptyMap()
                )
            ),
            new HashMap<>(ScriptModule.CORE_CONTEXTS)
        );

        Map<String, Processor.Factory> processors = new HashMap<>();
        processors.put(""complexSet"", (factories, tag, description, config) -> {
            String field = (String) config.remove(""field"");
            String value = (String) config.remove(""value"");

            return new ConditionalProcessor(randomAlphaOfLength(10), null,
                new Script(
                    ScriptType.INLINE, Script.DEFAULT_SCRIPT_LANG,
                    scriptName, Collections.emptyMap()), scriptService,
                new ConditionalProcessor(randomAlphaOfLength(10) + ""-nested"", null,
                    new Script(
                        ScriptType.INLINE, Script.DEFAULT_SCRIPT_LANG,
                        scriptName, Collections.emptyMap()), scriptService,
                    new FakeProcessor(""complexSet"", tag, description, (ingestDocument) -> ingestDocument.setFieldValue(field, value))));
        });

        IngestService ingestService = createWithProcessors(processors);
        String id = ""_id"";
        Pipeline pipeline = ingestService.getPipeline(id);
        assertThat(pipeline, nullValue());
        ClusterState clusterState = ClusterState.builder(new ClusterName(""_name"")).build(); // Start empty

        PutPipelineRequest putRequest = new PutPipelineRequest(id,
            new BytesArray(""{\""processors\"": [{\""complexSet\"" : {\""field\"": \""_field\"", \""value\"": \""_value\""}}]}""), XContentType.JSON);
        ClusterState previousClusterState = clusterState;
        clusterState = IngestService.innerPut(putRequest, clusterState);
        ingestService.applyClusterState(new ClusterChangedEvent("""", clusterState, previousClusterState));
        pipeline = ingestService.getPipeline(id);
        assertThat(pipeline, notNullValue());

        assertThat(ingestService.getProcessorsInPipeline(id, Processor.class).size(), equalTo(3));
        assertThat(ingestService.getProcessorsInPipeline(id, WrappingProcessor.class).size(), equalTo(2));
        assertThat(ingestService.getProcessorsInPipeline(id, FakeProcessor.class).size(), equalTo(1));
        assertThat(ingestService.getProcessorsInPipeline(id, ConditionalProcessor.class).size(), equalTo(2));

        assertThat(ingestService.getProcessorsInPipeline(id, WrappingProcessorImpl.class).size(), equalTo(0));
    }","public void testGetProcessorsInPipeline() throws Exception {
        IngestService ingestService = createWithProcessors();
        String id = ""_id"";
        Pipeline pipeline = ingestService.getPipeline(id);
        assertThat(pipeline, nullValue());
        ClusterState clusterState = ClusterState.builder(new ClusterName(""_name"")).build(); // Start empty

        PutPipelineRequest putRequest = new PutPipelineRequest(""_id"", new BytesArray(
            ""{\""processors\"": [{\""set\"" : {\""field\"": \""_field\"", \""value\"": \""_value\"", \""tag\"": \""tag1\""}},"" +
                ""{\""remove\"" : {\""field\"": \""_field\"", \""tag\"": \""tag2\""}}]}""),
            XContentType.JSON);
        ClusterState previousClusterState = clusterState;
        clusterState = IngestService.innerPut(putRequest, clusterState);
        ingestService.applyClusterState(new ClusterChangedEvent("""", clusterState, previousClusterState));
        pipeline = ingestService.getPipeline(id);
        assertThat(pipeline, notNullValue());

        assertThat(ingestService.getProcessorsInPipeline(id, Processor.class).size(), equalTo(3));
        assertThat(ingestService.getProcessorsInPipeline(id, WrappingProcessorImpl.class).size(), equalTo(1));
        assertThat(ingestService.getProcessorsInPipeline(id, WrappingProcessor.class).size(), equalTo(1));
        assertThat(ingestService.getProcessorsInPipeline(id, FakeProcessor.class).size(), equalTo(2));

        assertThat(ingestService.getProcessorsInPipeline(id, ConditionalProcessor.class).size(), equalTo(0));

        IllegalArgumentException e = expectThrows(IllegalArgumentException.class,
            () -> ingestService.getProcessorsInPipeline(""fakeID"", Processor.class));
        assertThat(""pipeline with id [fakeID] does not exist"", equalTo(e.getMessage()));
    }",/server/src/test/java/org/elasticsearch/ingest/IngestServiceTests.java
72880f732f8aa70f651e76fecfc0052997fab3cb,685,561,"public void applyClusterState(final ClusterChangedEvent event) {
        ClusterState state = event.state();
        if (state.blocks().hasGlobalBlock(GatewayService.STATE_NOT_RECOVERED_BLOCK)) {
            return;
        }

        // Publish cluster state to components that are used by processor factories before letting
        // processor factories create new processor instances.
        // (Note that this needs to be done also in the case when there is no change to ingest metadata, because in the case
        // when only the part of the cluster state that a component is interested in, is updated.)
        ingestClusterStateListeners.forEach(consumer -> consumer.accept(state));

        IngestMetadata newIngestMetadata = state.getMetadata().custom(IngestMetadata.TYPE);
        if (newIngestMetadata == null) {
            return;
        }

        try {
            innerUpdatePipelines(newIngestMetadata);
        } catch (ElasticsearchParseException e) {
            logger.warn(""failed to update ingest pipelines"", e);
        }
    }",") {
        while (it.hasNext()) {
            final String pipelineId = it.next();
            try {
                PipelineHolder holder = pipelines.get(pipelineId);
                if (holder == null) {
                    throw new IllegalArgumentException(""pipeline with id ["" + pipelineId + ""] does not exist"");
                }
                Pipeline pipeline = holder.pipeline;
                String originalIndex = indexRequest.indices()[0];
                innerExecute(slot, indexRequest, pipeline, onDropped, e -> {
                    if (e != null) {
                        onFailure.accept(slot, e);
                    }

                    Iterator<String> newIt = it;
                    boolean newHasFinalPipeline = hasFinalPipeline;
                    String newIndex = indexRequest.indices()[0];

                    if (Objects.equals(originalIndex, newIndex) == false) {
                        if (hasFinalPipeline && it.hasNext() == false) {
                            totalMetrics.ingestFailed();
                            onFailure.accept(slot, new IllegalStateException(""final pipeline ["" + pipelineId +
                                ""] can't change the target index""));
                        } else {

                            //Drain old it so it's not looped over
                            it.forEachRemaining($ -> {
                            });
                            indexRequest.isPipelineResolved(false);
                            resolvePipelines(null, indexRequest, state.metadata());
                            if (IngestService.NOOP_PIPELINE_NAME.equals(indexRequest.getFinalPipeline()) == false) {
                                newIt = Collections.singleton(indexRequest.getFinalPipeline()).iterator();
                                newHasFinalPipeline = true;
                            } else {
                                newIt = Collections.emptyIterator();
                            }
                        }
                    }

                    if (newIt.hasNext()) {
                        executePipelines(slot, newIt, newHasFinalPipeline, indexRequest, onDropped, onFailure, counter, onCompletion,
                            originalThread);
                    } else {
                        if (counter.decrementAndGet() == 0) {
                            onCompletion.accept(originalThread, null);
                        }
                        assert counter.get() >= 0;
                    }
                });
            } catch (Exception e) {
                onFailure.accept(slot, e);
                if (counter.decrementAndGet() == 0) {
                    onCompletion.accept(originalThread, null);
                }
                assert counter.get() >= 0;
                break;
            }
        }
    }",/server/src/main/java/org/elasticsearch/ingest/IngestService.java
ad8a482d198828d22d884263c2c4e76ab8ae2ee1,476,349,"private void loadPluginsIntoClassLoader() {
        File pluginsFile = environment.pluginsFile();
        if (!pluginsFile.exists()) {
            return;
        }
        if (!pluginsFile.isDirectory()) {
            return;
        }

        ClassLoader classLoader = settings.getClassLoader();
        Class classLoaderClass = classLoader.getClass();
        Method addURL = null;
        while (!classLoaderClass.equals(Object.class)) {
            try {
                addURL = classLoaderClass.getDeclaredMethod(""addURL"", URL.class);
                addURL.setAccessible(true);
                break;
            } catch (NoSuchMethodException e) {
                // no method, try the parent
                classLoaderClass = classLoaderClass.getSuperclass();
            }
        }
        if (addURL == null) {
            logger.debug(""failed to find addURL method on classLoader ["" + classLoader + ""] to add methods"");
            return;
        }

        File[] pluginsFiles = pluginsFile.listFiles();
        if (pluginsFile != null) {
            for (File pluginFile : pluginsFiles) {
                if (pluginFile.isDirectory()) {
                    if (logger.isTraceEnabled()) {
                        logger.trace(""--- adding plugin ["" + pluginFile.getAbsolutePath() + ""]"");
                    }
                    try {
                        // add the root
                        addURL.invoke(classLoader, pluginFile.toURI().toURL());
                        // gather files to add
                        List<File> libFiles = Lists.newArrayList();
                        if (pluginFile.listFiles() != null) {
                            libFiles.addAll(Arrays.asList(pluginFile.listFiles()));
                        }
                        File libLocation = new File(pluginFile, ""lib"");
                        if (libLocation.exists() && libLocation.isDirectory() && libLocation.listFiles() != null) {
                            libFiles.addAll(Arrays.asList(libLocation.listFiles()));
                        }

                        // if there are jars in it, add it as well
                        for (File libFile : libFiles) {
                            if (!(libFile.getName().endsWith("".jar"") || libFile.getName().endsWith("".zip""))) {
                                continue;
                            }
                            addURL.invoke(classLoader, libFile.toURI().toURL());
                        }
                    } catch (Throwable e) {
                        logger.warn(""failed to add plugin ["" + pluginFile + ""]"", e);
                    }
                }
            }
        } else {
            logger.debug(""failed to list plugins from {}. Check your right access."", pluginsFile.getAbsolutePath());
        }
    }","private void loadPluginsIntoClassLoader() {
        File pluginsDirectory = environment.pluginsFile();
        if (!isAccessibleDirectory(pluginsDirectory, logger)) {
            return;
        }

        ClassLoader classLoader = settings.getClassLoader();
        Class classLoaderClass = classLoader.getClass();
        Method addURL = null;
        while (!classLoaderClass.equals(Object.class)) {
            try {
                addURL = classLoaderClass.getDeclaredMethod(""addURL"", URL.class);
                addURL.setAccessible(true);
                break;
            } catch (NoSuchMethodException e) {
                // no method, try the parent
                classLoaderClass = classLoaderClass.getSuperclass();
            }
        }
        if (addURL == null) {
            logger.debug(""failed to find addURL method on classLoader ["" + classLoader + ""] to add methods"");
            return;
        }

        for (File plugin : pluginsDirectory.listFiles()) {
            // We check that subdirs are directories and readable
            if (!isAccessibleDirectory(plugin, logger)) {
                continue;
            }

            logger.trace(""--- adding plugin [{}]"", plugin.getAbsolutePath());

            try {
                // add the root
                addURL.invoke(classLoader, plugin.toURI().toURL());
                // gather files to add
                List<File> libFiles = Lists.newArrayList();
                if (plugin.listFiles() != null) {
                    libFiles.addAll(Arrays.asList(plugin.listFiles()));
                }
                File libLocation = new File(plugin, ""lib"");
                if (libLocation.exists() && libLocation.isDirectory() && libLocation.listFiles() != null) {
                    libFiles.addAll(Arrays.asList(libLocation.listFiles()));
                }

                // if there are jars in it, add it as well
                for (File libFile : libFiles) {
                    if (!(libFile.getName().endsWith("".jar"") || libFile.getName().endsWith("".zip""))) {
                        continue;
                    }
                    addURL.invoke(classLoader, libFile.toURI().toURL());
                }
            } catch (Throwable e) {
                logger.warn(""failed to add plugin ["" + plugin + ""]"", e);
            }
        }
    }",/src/main/java/org/elasticsearch/plugins/PluginsService.java
27c7e1fd21b97a9d860ad12be05ebe07149d4158,563,161,"public void testExecutePolicyWithDedicatedMasterNodes() throws Exception {
        var masterNodes = internalCluster().startNodes(3, masterOnlyNode());
        var regularNodes = internalCluster().startNodes(2, nonMasterNode());
        ensureStableCluster(5, (String) null);

        assertAcked(prepareCreate(SOURCE_INDEX_NAME).setMapping(MATCH_FIELD, ""type=keyword""));
        var enrichPolicy = new EnrichPolicy(
            EnrichPolicy.MATCH_TYPE,
            null,
            List.of(SOURCE_INDEX_NAME),
            MATCH_FIELD,
            List.of(DECORATE_FIELDS)
        );
        var putPolicyRequest = new PutEnrichPolicyAction.Request(POLICY_NAME, enrichPolicy);
        assertAcked(client().execute(PutEnrichPolicyAction.INSTANCE, putPolicyRequest).actionGet());
        var executePolicyRequest = new ExecuteEnrichPolicyAction.Request(POLICY_NAME);
        executePolicyRequest.setWaitForCompletion(false); // From tne returned taks id the node that executes the policy can be determined
        var executePolicyResponse = client().execute(ExecuteEnrichPolicyAction.INSTANCE, executePolicyRequest).actionGet();
        assertThat(executePolicyResponse.getStatus(), nullValue());
        assertThat(executePolicyResponse.getTaskId(), notNullValue());

        var getTaskRequest = new GetTaskRequest().setTaskId(executePolicyResponse.getTaskId()).setWaitForCompletion(true);
        clusterAdmin().getTask(getTaskRequest).actionGet();

        var discoNodes = clusterAdmin().state(new ClusterStateRequest()).actionGet().getState().nodes();
        assertThat(discoNodes.get(executePolicyResponse.getTaskId().getNodeId()).isMasterNode(), is(false));
    }","public void testStressEnrich() {
        List<String> nodes = internalCluster().startNodes(
            3,
            Settings.builder().put(""enrich.coordinator_proxy.max_concurrent_requests"", 1).build()
        );
        int indices = randomIntBetween(5, 10);
        final Map<String, List<String>> keys = Maps.newHashMapWithExpectedSize(indices);
        for (int i = 0; i < indices; i++) {
            final String indexName = ""index-"" + i;
            List<String> k = createSourceIndex(indexName, 64);
            final String policyName = ""policy-"" + i;
            createAndExecutePolicy(policyName, indexName);
            final String pipelineName = ""pipeline-"" + i;
            createPipeline(policyName, pipelineName);
            keys.put(pipelineName, k);
        }
        enrich(keys, randomFrom(nodes), 50);
    }",/x-pack/plugin/enrich/src/internalClusterTest/java/org/elasticsearch/xpack/enrich/EnrichMultiNodeIT.java
be7ee7d2ed204a470a7368a470c2e16a69863633,690,495,"Consumer<Exception> errorHandler) {
        String hitId = hit.getId();
        if (DataCounts.documentId(jobId).equals(hitId)) {
            paramsBuilder.setDataCounts(parseSearchHit(hit, DataCounts.PARSER, errorHandler));
        } else if (hitId.startsWith(ModelSizeStats.documentIdPrefix(jobId))) {
            ModelSizeStats.Builder modelSizeStats = parseSearchHit(hit, ModelSizeStats.LENIENT_PARSER, errorHandler);
            paramsBuilder.setModelSizeStats(modelSizeStats == null ? null : modelSizeStats.build());
        } else if (hitId.startsWith(ModelSnapshot.documentIdPrefix(jobId))) {
            ModelSnapshot.Builder modelSnapshot = parseSearchHit(hit, ModelSnapshot.LENIENT_PARSER, errorHandler);
            paramsBuilder.setModelSnapshot(modelSnapshot == null ? null : modelSnapshot.build());
        } else if (Quantiles.documentId(jobId).equals(hit.getId())) {
            paramsBuilder.setQuantiles(parseSearchHit(hit, Quantiles.LENIENT_PARSER, errorHandler));
        } else if (hitId.startsWith(MlFilter.DOCUMENT_ID_PREFIX)) {
            paramsBuilder.addFilter(parseSearchHit(hit, MlFilter.LENIENT_PARSER, errorHandler).build());
        } else {
            errorHandler.accept(new IllegalStateException(""Unexpected Id ["" + hitId + ""]""));
        }
    }","public void getAutodetectParams(Job job, Consumer<AutodetectParams> consumer, Consumer<Exception> errorHandler) {

        String jobId = job.getId();

        ActionListener<AutodetectParams.Builder> getScheduledEventsListener = ActionListener.wrap(
                paramsBuilder -> {
                    ScheduledEventsQueryBuilder scheduledEventsQueryBuilder = new ScheduledEventsQueryBuilder();
                    scheduledEventsQueryBuilder.start(job.earliestValidTimestamp(paramsBuilder.getDataCounts()));
                    scheduledEventsForJob(jobId, job.getGroups(), scheduledEventsQueryBuilder, ActionListener.wrap(
                            events -> {
                                paramsBuilder.setScheduledEvents(events.results());
                                consumer.accept(paramsBuilder.build());
                            },
                            errorHandler
                    ));
                },
                errorHandler
        );

        AutodetectParams.Builder paramsBuilder = new AutodetectParams.Builder(job.getId());
        String resultsIndex = AnomalyDetectorsIndex.jobResultsAliasedName(jobId);
        String stateIndex = AnomalyDetectorsIndex.jobStateIndexPattern();

        MultiSearchRequestBuilder msearch = client.prepareMultiSearch()
                .add(createLatestDataCountsSearch(resultsIndex, jobId))
                .add(createLatestModelSizeStatsSearch(resultsIndex))
                // These next two document IDs never need to be the legacy ones due to the rule
                // that you cannot open a 5.4 job in a subsequent version of the product
                .add(createDocIdSearch(resultsIndex, ModelSnapshot.documentId(jobId, job.getModelSnapshotId())))
                .add(createDocIdSearch(stateIndex, Quantiles.documentId(jobId)));

        for (String filterId : job.getAnalysisConfig().extractReferencedFilters()) {
            msearch.add(createDocIdSearch(MlMetaIndex.INDEX_NAME, MlFilter.documentId(filterId)));
        }

        executeAsyncWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN, msearch.request(),
                ActionListener.<MultiSearchResponse>wrap(
                        response -> {
                            for (int i = 0; i < response.getResponses().length; i++) {
                                MultiSearchResponse.Item itemResponse = response.getResponses()[i];
                                if (itemResponse.isFailure()) {
                                    errorHandler.accept(itemResponse.getFailure());
                                } else {
                                    SearchResponse searchResponse = itemResponse.getResponse();
                                    ShardSearchFailure[] shardFailures = searchResponse.getShardFailures();
                                    int unavailableShards = searchResponse.getTotalShards() - searchResponse.getSuccessfulShards();
                                    if (shardFailures != null && shardFailures.length > 0) {
                                        LOGGER.error(""[{}] Search request returned shard failures: {}"", jobId,
                                                Arrays.toString(shardFailures));
                                        errorHandler.accept(new ElasticsearchException(
                                                ExceptionsHelper.shardFailuresToErrorMsg(jobId, shardFailures)));
                                    } else if (unavailableShards > 0) {
                                        errorHandler.accept(new ElasticsearchException(""["" + jobId
                                                + ""] Search request encountered ["" + unavailableShards + ""] unavailable shards""));
                                    } else {
                                        SearchHits hits = searchResponse.getHits();
                                        long hitsCount = hits.getHits().length;
                                        if (hitsCount == 0) {
                                            SearchRequest searchRequest = msearch.request().requests().get(i);
                                            LOGGER.debug(""Found 0 hits for [{}]"", new Object[]{searchRequest.indices()});
                                        } else {
                                            for (SearchHit hit : hits) {
                                                parseAutodetectParamSearchHit(jobId, paramsBuilder, hit, errorHandler);
                                            }
                                        }
                                    }
                                }
                            }

                            getScheduledEventsListener.onResponse(paramsBuilder);
                        },
                        errorHandler
                ), client::multiSearch);
    }",/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/persistence/JobResultsProvider.java
be7ee7d2ed204a470a7368a470c2e16a69863633,563,908,"public QueryPage<ModelPlot> modelPlot(String jobId, int from, int size) {
        SearchResponse searchResponse;
        String indexName = AnomalyDetectorsIndex.jobResultsAliasedName(jobId);
        LOGGER.trace(""ES API CALL: search model plots from index {} from {} size {}"", indexName, from, size);

        try (ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN)) {
            searchResponse = client.prepareSearch(indexName)
                    .setIndicesOptions(MlIndicesUtils.addIgnoreUnavailable(SearchRequest.DEFAULT_INDICES_OPTIONS))
                    .setQuery(new TermsQueryBuilder(Result.RESULT_TYPE.getPreferredName(), ModelPlot.RESULT_TYPE_VALUE))
                    .setFrom(from).setSize(size)
                    .setTrackTotalHits(true)
                    .get();
        }

        List<ModelPlot> results = new ArrayList<>();

        for (SearchHit hit : searchResponse.getHits().getHits()) {
            BytesReference source = hit.getSourceRef();
            try (InputStream stream = source.streamInput();
                 XContentParser parser = XContentFactory.xContent(XContentType.JSON)
                         .createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, stream)) {
                ModelPlot modelPlot = ModelPlot.LENIENT_PARSER.apply(parser, null);
                results.add(modelPlot);
            } catch (IOException e) {
                throw new ElasticsearchParseException(""failed to parse modelPlot"", e);
            }
        }

        return new QueryPage<>(results, searchResponse.getHits().getTotalHits().value, ModelPlot.RESULTS_FIELD);
    }","Consumer<Exception> errorHandler) {
        if (Strings.isEmpty(sortField)) {
            sortField = ModelSnapshot.TIMESTAMP.getPreferredName();
        }

        QueryBuilder finalQuery = QueryBuilders.boolQuery()
                .filter(QueryBuilders.existsQuery(ModelSnapshot.SNAPSHOT_DOC_COUNT.getPreferredName()))
                .must(qb);

        FieldSortBuilder sb = new FieldSortBuilder(sortField)
                .order(sortDescending ? SortOrder.DESC : SortOrder.ASC);

        String indexName = AnomalyDetectorsIndex.jobResultsAliasedName(jobId);
        LOGGER.trace(""ES API CALL: search all model snapshots from index {} sort ascending {} with filter after sort from {} size {}"",
                indexName, sortField, from, size);

        SearchRequest searchRequest = new SearchRequest(indexName);
        searchRequest.indicesOptions(MlIndicesUtils.addIgnoreUnavailable(searchRequest.indicesOptions()));
        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();
        sourceBuilder.sort(sb);
        sourceBuilder.query(finalQuery);
        sourceBuilder.from(from);
        sourceBuilder.size(size);
        sourceBuilder.trackTotalHits(true);
        searchRequest.source(sourceBuilder);
        executeAsyncWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN, searchRequest,
                ActionListener.<SearchResponse>wrap(searchResponse -> {
                    List<ModelSnapshot> results = new ArrayList<>();
                    for (SearchHit hit : searchResponse.getHits().getHits()) {
                        results.add(ModelSnapshot.fromJson(hit.getSourceRef()));
                    }

                    QueryPage<ModelSnapshot> result =
                            new QueryPage<>(results, searchResponse.getHits().getTotalHits().value, ModelSnapshot.RESULTS_FIELD);
                    handler.accept(result);
                }, errorHandler), client::search);
    }",/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/persistence/JobResultsProvider.java
90fcb38448158d3a5d595307ee9f5c3d64b42e7f,691,365,"private void handshake() throws SSLException {
            boolean continueHandshaking = true;
            while (continueHandshaking) {
                switch (handshakeStatus) {
                    case NEED_UNWRAP:
                        // We UNWRAP as much as possible immediately after a read. Do not need to do it here.
                        continueHandshaking = false;
                        break;
                    case NEED_WRAP:
                        if (hasFlushPending() == false) {
                            handshakeStatus = wrap(EMPTY_BUFFER_ARRAY).getHandshakeStatus();
                        }
                        continueHandshaking = false;
                        break;
                    case NEED_TASK:
                        runTasks();
                        handshakeStatus = engine.getHandshakeStatus();
                        break;
                    case NOT_HANDSHAKING:
                        maybeFinishHandshake();
                        continueHandshaking = false;
                        break;
                    case FINISHED:
                        maybeFinishHandshake();
                        continueHandshaking = false;
                        break;
                }
            }
        }","private void handshake() throws SSLException {
            boolean continueHandshaking = true;
            while (continueHandshaking) {
                switch (handshakeStatus) {
                    case NEED_UNWRAP:
                        // We UNWRAP as much as possible immediately after a read. Do not need to do it here.
                        continueHandshaking = false;
                        break;
                    case NEED_WRAP:
                        if (hasFlushPending() == false) {
                            handshakeStatus = wrap(EMPTY_BUFFER_ARRAY).getHandshakeStatus();
                        }
                        // If we need NEED_TASK we should run the tasks immediately
                        if (handshakeStatus != SSLEngineResult.HandshakeStatus.NEED_TASK) {
                            continueHandshaking = false;
                        }
                        break;
                    case NEED_TASK:
                        runTasks();
                        handshakeStatus = engine.getHandshakeStatus();
                        break;
                    case NOT_HANDSHAKING:
                        maybeFinishHandshake();
                        continueHandshaking = false;
                        break;
                    case FINISHED:
                        maybeFinishHandshake();
                        continueHandshaking = false;
                        break;
                }
            }
        }",/x-pack/plugin/security/src/main/java/org/elasticsearch/xpack/security/transport/nio/SSLDriver.java
0ad4f52d84ddf706a3549c30f7a0e2ac429927e3,391,178,"public void testCloseWhileRelocatingShards() throws Exception {
        final String[] indices = new String[randomIntBetween(3, 5)];
        final Map<String, Long> docsPerIndex = new HashMap<>();
        final Map<String, BackgroundIndexer> indexers = new HashMap<>();

        for (int i = 0; i < indices.length; i++) {
            final String indexName = ""index-"" + i;
            int nbDocs = 0;
            switch (i) {
                case 0:
                    logger.debug(""creating empty index {}"", indexName);
                    createIndex(indexName);
                    break;
                case 1:
                    nbDocs = scaledRandomIntBetween(1, 100);
                    logger.debug(""creating index {} with {} documents"", indexName, nbDocs);
                    createIndex(indexName);
                    indexRandom(randomBoolean(), IntStream.range(0, nbDocs)
                        .mapToObj(n -> client().prepareIndex(indexName).setSource(""num"", n))
                        .collect(Collectors.toList()));
                    break;
                default:
                    logger.debug(""creating index {} with background indexing"", indexName);
                    final BackgroundIndexer indexer = new BackgroundIndexer(indexName, ""_doc"", client(), -1, 1);
                    indexers.put(indexName, indexer);
                    waitForDocs(1, indexer);
            }
            docsPerIndex.put(indexName, (long) nbDocs);
            indices[i] = indexName;
        }

        ensureGreen(indices);
        assertAcked(client().admin().cluster().prepareUpdateSettings()
            .setTransientSettings(Settings.builder()
                .put(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), Rebalance.NONE.toString())));

        final String targetNode = internalCluster().startDataOnlyNode();
        ensureClusterSizeConsistency(); // wait for the master to finish processing join.

        try {
            final ClusterService clusterService = internalCluster().getInstance(ClusterService.class, internalCluster().getMasterName());
            final ClusterState state = clusterService.state();
            final CountDownLatch latch = new CountDownLatch(indices.length);
            final CountDownLatch release = new CountDownLatch(indices.length);

            // relocate one shard for every index to be closed
            final AllocationCommands commands = new AllocationCommands();
            for (final String index : indices) {
                final NumShards numShards = getNumShards(index);
                final int shardId = numShards.numPrimaries == 1 ? 0 : randomIntBetween(0, numShards.numPrimaries - 1);
                final IndexRoutingTable indexRoutingTable = state.routingTable().index(index);

                final ShardRouting primary = indexRoutingTable.shard(shardId).primaryShard();
                assertTrue(primary.started());

                String currentNodeId = primary.currentNodeId();
                if (numShards.numReplicas > 0) {
                    final ShardRouting replica = indexRoutingTable.shard(shardId).replicaShards().iterator().next();
                    assertTrue(replica.started());
                    if (randomBoolean()) {
                        currentNodeId = replica.currentNodeId();
                    }
                }
                commands.add(new MoveAllocationCommand(index, shardId, state.nodes().resolveNode(currentNodeId).getName(), targetNode));
            }

            // Build the list of shards for which recoveries will be blocked
            final Set<ShardId> blockedShards = commands.commands().stream()
                .map(c -> (MoveAllocationCommand) c)
                .map(c -> new ShardId(clusterService.state().metaData().index(c.index()).getIndex(), c.shardId()))
                .collect(Collectors.toSet());
            assertThat(blockedShards, hasSize(indices.length));

            final Set<String> acknowledgedCloses = ConcurrentCollections.newConcurrentSet();
            final Set<String> interruptedRecoveries = ConcurrentCollections.newConcurrentSet();

            // Create a SendRequestBehavior that will block outgoing start recovery request
            final StubbableTransport.SendRequestBehavior sendBehavior = (connection, requestId, action, request, options) -> {
                if (PeerRecoverySourceService.Actions.START_RECOVERY.equals(action)) {
                    final StartRecoveryRequest startRecoveryRequest = ((StartRecoveryRequest) request);
                    if (blockedShards.contains(startRecoveryRequest.shardId())) {
                        logger.debug(""blocking recovery of shard {}"", startRecoveryRequest.shardId());
                        latch.countDown();
                        try {
                            release.await();
                            logger.debug(""releasing recovery of shard {}"", startRecoveryRequest.shardId());
                        } catch (final InterruptedException e) {
                            logger.warn(() -> new ParameterizedMessage(""exception when releasing recovery of shard {}"",
                                startRecoveryRequest.shardId()), e);
                            interruptedRecoveries.add(startRecoveryRequest.shardId().getIndexName());
                            Thread.currentThread().interrupt();
                            return;
                        }
                    }
                }
                connection.sendRequest(requestId, action, request, options);
            };

            final MockTransportService targetTransportService =
                (MockTransportService) internalCluster().getInstance(TransportService.class, targetNode);

            for (DiscoveryNode node : state.getNodes()) {
                if (node.isDataNode() && node.getName().equals(targetNode) == false) {
                    final TransportService sourceTransportService = internalCluster().getInstance(TransportService.class, node.getName());
                    targetTransportService.addSendBehavior(sourceTransportService, sendBehavior);
                }
            }

            assertAcked(client().admin().cluster().reroute(new ClusterRerouteRequest().commands(commands)).get());

            // start index closing threads
            final List<Thread> threads = new ArrayList<>();
            for (final String indexToClose : indices) {
                final Thread thread = new Thread(() -> {
                    try {
                        latch.await();
                    } catch (InterruptedException e) {
                        throw new AssertionError(e);
                    } finally {
                        release.countDown();
                    }
                    // Closing is not always acknowledged when shards are relocating: this is the case when the target shard is initializing
                    // or is catching up operations. In these cases the TransportVerifyShardBeforeCloseAction will detect that the global
                    // and max sequence number don't match and will not ack the close.
                    AcknowledgedResponse closeResponse = client().admin().indices().prepareClose(indexToClose).get();
                    if (closeResponse.isAcknowledged()) {
                        assertTrue(""Index closing should not be acknowledged twice"", acknowledgedCloses.add(indexToClose));
                    }
                });
                threads.add(thread);
                thread.start();
            }

            latch.countDown();
            for (Thread thread : threads) {
                thread.join();
            }

            for (Map.Entry<String, BackgroundIndexer> entry : indexers.entrySet()) {
                final BackgroundIndexer indexer = entry.getValue();
                indexer.setAssertNoFailuresOnStop(false);
                indexer.stop();

                final String indexName = entry.getKey();
                docsPerIndex.computeIfPresent(indexName, (key, value) -> value + indexer.totalIndexedDocs());

                final Throwable[] failures = indexer.getFailures();
                if (failures != null) {
                    for (Throwable failure : failures) {
                        assertException(failure, indexName);
                    }
                }
            }

            for (String index : indices) {
                if (acknowledgedCloses.contains(index)) {
                    assertIndexIsClosed(index);
                } else {
                    assertIndexIsOpened(index);
                }
            }

            targetTransportService.clearAllRules();

            // If a shard recovery has been interrupted, we expect its index to be closed
            interruptedRecoveries.forEach(CloseIndexIT::assertIndexIsClosed);

            assertThat(""Consider that the test failed if no indices were successfully closed"", acknowledgedCloses.size(), greaterThan(0));
            assertAcked(client().admin().indices().prepareOpen(""index-*""));
            ensureGreen(indices);

            for (String index : acknowledgedCloses) {
                long docsCount = client().prepareSearch(index).setSize(0).setTrackTotalHits(true).get().getHits().getTotalHits().value;
                assertEquals(""Expected "" + docsPerIndex.get(index) + "" docs in index "" + index + "" but got "" + docsCount
                    + "" (close acknowledged="" + acknowledgedCloses.contains(index) + "")"", (long) docsPerIndex.get(index), docsCount);
            }
        } finally {
            assertAcked(client().admin().cluster().prepareUpdateSettings()
                .setTransientSettings(Settings.builder()
                    .putNull(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey())));
        }
    }","public void testCloseWhileRelocatingShards() throws Exception {
        final String[] indices = new String[randomIntBetween(3, 5)];
        final Map<String, Long> docsPerIndex = new HashMap<>();
        final Map<String, BackgroundIndexer> indexers = new HashMap<>();

        for (int i = 0; i < indices.length; i++) {
            final String indexName = ""index-"" + i;
            int nbDocs = 0;
            switch (i) {
                case 0:
                    logger.debug(""creating empty index {}"", indexName);
                    createIndex(indexName);
                    break;
                case 1:
                    nbDocs = scaledRandomIntBetween(1, 100);
                    logger.debug(""creating index {} with {} documents"", indexName, nbDocs);
                    createIndex(indexName);
                    indexRandom(randomBoolean(), IntStream.range(0, nbDocs)
                        .mapToObj(n -> client().prepareIndex(indexName).setSource(""num"", n))
                        .collect(Collectors.toList()));
                    break;
                default:
                    logger.debug(""creating index {} with background indexing"", indexName);
                    final BackgroundIndexer indexer = new BackgroundIndexer(indexName, ""_doc"", client(), -1, 1);
                    indexers.put(indexName, indexer);
                    waitForDocs(1, indexer);
            }
            docsPerIndex.put(indexName, (long) nbDocs);
            indices[i] = indexName;
        }

        ensureGreen(TimeValue.timeValueSeconds(60L),indices);
        assertAcked(client().admin().cluster().prepareUpdateSettings()
            .setTransientSettings(Settings.builder()
                .put(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), Rebalance.NONE.toString())));

        final String targetNode = internalCluster().startDataOnlyNode();
        ensureClusterSizeConsistency(); // wait for the master to finish processing join.

        try {
            final ClusterService clusterService = internalCluster().getInstance(ClusterService.class, internalCluster().getMasterName());
            final ClusterState state = clusterService.state();
            final CountDownLatch latch = new CountDownLatch(indices.length);
            final CountDownLatch release = new CountDownLatch(indices.length);

            // relocate one shard for every index to be closed
            final AllocationCommands commands = new AllocationCommands();
            for (final String index : indices) {
                final NumShards numShards = getNumShards(index);
                final int shardId = numShards.numPrimaries == 1 ? 0 : randomIntBetween(0, numShards.numPrimaries - 1);
                final IndexRoutingTable indexRoutingTable = state.routingTable().index(index);

                final ShardRouting primary = indexRoutingTable.shard(shardId).primaryShard();
                assertTrue(primary.started());

                String currentNodeId = primary.currentNodeId();
                if (numShards.numReplicas > 0) {
                    final ShardRouting replica = indexRoutingTable.shard(shardId).replicaShards().iterator().next();
                    assertTrue(replica.started());
                    if (randomBoolean()) {
                        currentNodeId = replica.currentNodeId();
                    }
                }
                commands.add(new MoveAllocationCommand(index, shardId, state.nodes().resolveNode(currentNodeId).getName(), targetNode));
            }

            // Build the list of shards for which recoveries will be blocked
            final Set<ShardId> blockedShards = commands.commands().stream()
                .map(c -> (MoveAllocationCommand) c)
                .map(c -> new ShardId(clusterService.state().metaData().index(c.index()).getIndex(), c.shardId()))
                .collect(Collectors.toSet());
            assertThat(blockedShards, hasSize(indices.length));

            final Set<String> acknowledgedCloses = ConcurrentCollections.newConcurrentSet();
            final Set<String> interruptedRecoveries = ConcurrentCollections.newConcurrentSet();

            // Create a SendRequestBehavior that will block outgoing start recovery request
            final StubbableTransport.SendRequestBehavior sendBehavior = (connection, requestId, action, request, options) -> {
                if (PeerRecoverySourceService.Actions.START_RECOVERY.equals(action)) {
                    final StartRecoveryRequest startRecoveryRequest = ((StartRecoveryRequest) request);
                    if (blockedShards.contains(startRecoveryRequest.shardId())) {
                        logger.debug(""blocking recovery of shard {}"", startRecoveryRequest.shardId());
                        latch.countDown();
                        try {
                            release.await();
                            logger.debug(""releasing recovery of shard {}"", startRecoveryRequest.shardId());
                        } catch (final InterruptedException e) {
                            logger.warn(() -> new ParameterizedMessage(""exception when releasing recovery of shard {}"",
                                startRecoveryRequest.shardId()), e);
                            interruptedRecoveries.add(startRecoveryRequest.shardId().getIndexName());
                            Thread.currentThread().interrupt();
                            return;
                        }
                    }
                }
                connection.sendRequest(requestId, action, request, options);
            };

            final MockTransportService targetTransportService =
                (MockTransportService) internalCluster().getInstance(TransportService.class, targetNode);

            for (DiscoveryNode node : state.getNodes()) {
                if (node.isDataNode() && node.getName().equals(targetNode) == false) {
                    final TransportService sourceTransportService = internalCluster().getInstance(TransportService.class, node.getName());
                    targetTransportService.addSendBehavior(sourceTransportService, sendBehavior);
                }
            }

            assertAcked(client().admin().cluster().reroute(new ClusterRerouteRequest().commands(commands)).get());

            // start index closing threads
            final List<Thread> threads = new ArrayList<>();
            for (final String indexToClose : indices) {
                final Thread thread = new Thread(() -> {
                    try {
                        latch.await();
                    } catch (InterruptedException e) {
                        throw new AssertionError(e);
                    } finally {
                        release.countDown();
                    }
                    // Closing is not always acknowledged when shards are relocating: this is the case when the target shard is initializing
                    // or is catching up operations. In these cases the TransportVerifyShardBeforeCloseAction will detect that the global
                    // and max sequence number don't match and will not ack the close.
                    AcknowledgedResponse closeResponse = client().admin().indices().prepareClose(indexToClose).get();
                    if (closeResponse.isAcknowledged()) {
                        assertTrue(""Index closing should not be acknowledged twice"", acknowledgedCloses.add(indexToClose));
                    }
                });
                threads.add(thread);
                thread.start();
            }

            latch.countDown();
            for (Thread thread : threads) {
                thread.join();
            }

            for (Map.Entry<String, BackgroundIndexer> entry : indexers.entrySet()) {
                final BackgroundIndexer indexer = entry.getValue();
                indexer.setAssertNoFailuresOnStop(false);
                indexer.stop();

                final String indexName = entry.getKey();
                docsPerIndex.computeIfPresent(indexName, (key, value) -> value + indexer.totalIndexedDocs());

                final Throwable[] failures = indexer.getFailures();
                if (failures != null) {
                    for (Throwable failure : failures) {
                        assertException(failure, indexName);
                    }
                }
            }

            for (String index : indices) {
                if (acknowledgedCloses.contains(index)) {
                    assertIndexIsClosed(index);
                } else {
                    assertIndexIsOpened(index);
                }
            }

            targetTransportService.clearAllRules();

            // If a shard recovery has been interrupted, we expect its index to be closed
            interruptedRecoveries.forEach(CloseIndexIT::assertIndexIsClosed);

            assertThat(""Consider that the test failed if no indices were successfully closed"", acknowledgedCloses.size(), greaterThan(0));
            assertAcked(client().admin().indices().prepareOpen(""index-*""));
            ensureGreen(indices);

            for (String index : acknowledgedCloses) {
                long docsCount = client().prepareSearch(index).setSize(0).setTrackTotalHits(true).get().getHits().getTotalHits().value;
                assertEquals(""Expected "" + docsPerIndex.get(index) + "" docs in index "" + index + "" but got "" + docsCount
                    + "" (close acknowledged="" + acknowledgedCloses.contains(index) + "")"", (long) docsPerIndex.get(index), docsCount);
            }
        } finally {
            assertAcked(client().admin().cluster().prepareUpdateSettings()
                .setTransientSettings(Settings.builder()
                    .putNull(EnableAllocationDecider.CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey())));
        }
    }",/server/src/test/java/org/elasticsearch/indices/state/CloseWhileRelocatingShardsIT.java
82071659deb319ef70c7d17074f7b67dcf15c98e,662,869,"public void readFrom(StreamInput in) throws IOException {
            super.readFrom(in);
            int size = in.readVInt();
            for (int i = 0; i < size; i++) {
                File file = File.readFile(in);
                fileDetails.put(file.name, file);
            }
            sourceThrottlingInNanos = in.readLong();
            targetThrottleTimeInNanos = in.readLong();
        }","public synchronized void readFrom(StreamInput in) throws IOException {
            super.readFrom(in);
            int size = in.readVInt();
            for (int i = 0; i < size; i++) {
                File file = File.readFile(in);
                fileDetails.put(file.name, file);
            }
            sourceThrottlingInNanos = in.readLong();
            targetThrottleTimeInNanos = in.readLong();
        }",/src/main/java/org/elasticsearch/indices/recovery/RecoveryState.java
82071659deb319ef70c7d17074f7b67dcf15c98e,662,878,"public void writeTo(StreamOutput out) throws IOException {
            super.writeTo(out);
            final File[] files = fileDetails.values().toArray(new File[0]);
            out.writeVInt(files.length);
            for (File file : files) {
                file.writeTo(out);
            }
            out.writeLong(sourceThrottlingInNanos);
            out.writeLong(targetThrottleTimeInNanos);
        }","public synchronized void writeTo(StreamOutput out) throws IOException {
            super.writeTo(out);
            final File[] files = fileDetails.values().toArray(new File[0]);
            out.writeVInt(files.length);
            for (File file : files) {
                file.writeTo(out);
            }
            out.writeLong(sourceThrottlingInNanos);
            out.writeLong(targetThrottleTimeInNanos);
        }",/src/main/java/org/elasticsearch/indices/recovery/RecoveryState.java
4bf6a778b7ff9de358f94fb5bd28a2d7c4cfd13f,567,246,"protected void doNextBulk(BulkRequest request, ActionListener<BulkResponse> nextPhase) {
            ++bulkOps;
            nextPhase.onResponse(new BulkResponse(new BulkItemResponse[0], 100));
        }","protected void doNextSearch(long waitTimeInNanos, ActionListener<SearchResponse> nextPhase) {
            ++searchOps;
            final SearchResponseSections sections = new SearchResponseSections(
                new SearchHits(new SearchHit[0], new TotalHits(0, TotalHits.Relation.EQUAL_TO), 0), null,
                null, false, null, null, 1);

            if (processOps == 3) {
                awaitForLatch();
            }

            nextPhase.onResponse(new SearchResponse(sections, null, 1, 1, 0, 0, ShardSearchFailure.EMPTY_ARRAY, null));
        }",/x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/core/indexing/AsyncTwoPhaseIndexerTests.java
4bf6a778b7ff9de358f94fb5bd28a2d7c4cfd13f,567,123,"protected void doSaveState(IndexerState state, Integer position, Runnable next) {
            // for stop before finished we do not know if its stopped before are after the search
            if (stoppedBeforeFinished == false) {
                assertThat(step, equalTo(4));
            }
            ++step;
            next.run();
        }","protected void doNextBulk(BulkRequest request, ActionListener<BulkResponse> nextPhase) {
            fail(""should not be called"");
        }",/x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/core/indexing/AsyncTwoPhaseIndexerTests.java
4bf6a778b7ff9de358f94fb5bd28a2d7c4cfd13f,567,232,"protected void doNextSearch(long waitTimeInNanos, ActionListener<SearchResponse> nextPhase) {
            ++searchOps;
            final SearchResponseSections sections = new SearchResponseSections(
                new SearchHits(new SearchHit[0], new TotalHits(0, TotalHits.Relation.EQUAL_TO), 0), null,
                null, false, null, null, 1);

            if (processOps == 3) {
                awaitForLatch();
            }

            nextPhase.onResponse(new SearchResponse(sections, null, 1, 1, 0, 0, ShardSearchFailure.EMPTY_ARRAY, null));
        }","private void awaitForLatch() {
            if (latch == null) {
                return;
            }
            try {
                waitingForLatch = true;
                latch.await(10, TimeUnit.SECONDS);
                waitingForLatch = false;
            } catch (InterruptedException e) {
                throw new RuntimeException(e);
            }
        }",/x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/core/indexing/AsyncTwoPhaseIndexerTests.java
96abfe1ad133eb554081d642d696e74fe677bf18,628,304,"public void handle(final HttpExchange exchange) throws IOException {
            final String request = exchange.getRequestMethod() + "" "" + exchange.getRequestURI().toString();
            try {
                if (Regex.simpleMatch(""GET /storage/v1/b/bucket/o*"", request)) {
                    final Map<String, String> params = new HashMap<>();
                    RestUtils.decodeQueryString(exchange.getRequestURI().getQuery(), 0, params);
                    final String prefix = params.get(""prefix"");

                    final List<Map.Entry<String, BytesReference>> listOfBlobs = blobs.entrySet().stream()
                        .filter(blob -> prefix == null || blob.getKey().startsWith(prefix)).collect(Collectors.toList());

                    final StringBuilder list = new StringBuilder();
                    list.append(""{\""kind\"":\""storage#objects\"",\""items\"":["");
                    for (Iterator<Map.Entry<String, BytesReference>> it = listOfBlobs.iterator(); it.hasNext(); ) {
                        Map.Entry<String, BytesReference> blob = it.next();
                        list.append(""{\""kind\"":\""storage#object\"","");
                        list.append(""\""bucket\"":\""bucket\"","");
                        list.append(""\""name\"":\"""").append(blob.getKey()).append(""\"","");
                        list.append(""\""id\"":\"""").append(blob.getKey()).append(""\"","");
                        list.append(""\""size\"":\"""").append(blob.getValue().length()).append(""\"""");
                        list.append('}');

                        if (it.hasNext()) {
                            list.append(',');
                        }
                    }
                    list.append(""]}"");

                    byte[] response = list.toString().getBytes(UTF_8);
                    exchange.getResponseHeaders().add(""Content-Type"", ""application/json; charset=utf-8"");
                    exchange.sendResponseHeaders(RestStatus.OK.getStatus(), response.length);
                    exchange.getResponseBody().write(response);

                } else if (Regex.simpleMatch(""GET /storage/v1/b/bucket*"", request)) {
                    byte[] response = (""{\""kind\"":\""storage#bucket\"",\""name\"":\""bucket\"",\""id\"":\""0\""}"").getBytes(UTF_8);
                    exchange.getResponseHeaders().add(""Content-Type"", ""application/json; charset=utf-8"");
                    exchange.sendResponseHeaders(HttpStatus.SC_OK, response.length);
                    exchange.getResponseBody().write(response);

                } else if (Regex.simpleMatch(""GET /download/storage/v1/b/bucket/o/*"", request)) {
                    BytesReference blob = blobs.get(exchange.getRequestURI().getPath().replace(""/download/storage/v1/b/bucket/o/"", """"));
                    if (blob != null) {
                        exchange.getResponseHeaders().add(""Content-Type"", ""application/octet-stream"");
                        exchange.sendResponseHeaders(RestStatus.OK.getStatus(), blob.length());
                        exchange.getResponseBody().write(blob.toBytesRef().bytes);
                    } else {
                        exchange.sendResponseHeaders(RestStatus.NOT_FOUND.getStatus(), -1);
                    }

                } else if (Regex.simpleMatch(""DELETE /storage/v1/b/bucket/o/*"", request)) {
                    int deletions = 0;
                    for (Iterator<Map.Entry<String, BytesReference>> iterator = blobs.entrySet().iterator(); iterator.hasNext(); ) {
                        Map.Entry<String, BytesReference> blob = iterator.next();
                        if (blob.getKey().equals(exchange.getRequestURI().toString())) {
                            iterator.remove();
                            deletions++;
                        }
                    }
                    exchange.sendResponseHeaders((deletions > 0 ? RestStatus.OK : RestStatus.NO_CONTENT).getStatus(), -1);

                } else if (Regex.simpleMatch(""POST /batch/storage/v1"", request)) {
                    final String uri = ""/storage/v1/b/bucket/o/"";
                    final StringBuilder batch = new StringBuilder();
                    for (String line : Streams.readAllLines(new BufferedInputStream(exchange.getRequestBody()))) {
                        if (line.length() == 0 || line.startsWith(""--"") || line.toLowerCase(Locale.ROOT).startsWith(""content"")) {
                            batch.append(line).append('\n');
                        } else if (line.startsWith(""DELETE"")) {
                            final String name = line.substring(line.indexOf(uri) + uri.length(), line.lastIndexOf("" HTTP""));
                            if (Strings.hasText(name)) {
                                if (blobs.entrySet().removeIf(blob -> blob.getKey().equals(URLDecoder.decode(name, UTF_8)))) {
                                    batch.append(""HTTP/1.1 204 NO_CONTENT"").append('\n');
                                    batch.append('\n');
                                }
                            }
                        }
                    }
                    byte[] response = batch.toString().getBytes(UTF_8);
                    exchange.getResponseHeaders().add(""Content-Type"", exchange.getRequestHeaders().getFirst(""Content-Type""));
                    exchange.sendResponseHeaders(RestStatus.OK.getStatus(), response.length);
                    exchange.getResponseBody().write(response);

                } else if (Regex.simpleMatch(""POST /upload/storage/v1/b/bucket/*uploadType=multipart*"", request)) {
                    byte[] response = new byte[0];
                    try (BufferedInputStream in = new BufferedInputStream(new GZIPInputStream(exchange.getRequestBody()))) {
                        String blob = null;
                        int read;
                        while ((read = in.read()) != -1) {
                            boolean markAndContinue = false;
                            try (ByteArrayOutputStream out = new ByteArrayOutputStream()) {
                                do { // search next consecutive {carriage return, new line} chars and stop
                                    if ((char) read == '\r') {
                                        int next = in.read();
                                        if (next != -1) {
                                            if (next == '\n') {
                                                break;
                                            }
                                            out.write(read);
                                            out.write(next);
                                            continue;
                                        }
                                    }
                                    out.write(read);
                                } while ((read = in.read()) != -1);

                                final String line = new String(out.toByteArray(), UTF_8);
                                if (line.length() == 0 || line.equals(""\r\n"") || line.startsWith(""--"")
                                    || line.toLowerCase(Locale.ROOT).startsWith(""content"")) {
                                    markAndContinue = true;
                                } else if (line.startsWith(""{\""bucket\"":\""bucket\"""")) {
                                    markAndContinue = true;
                                    Matcher matcher = Pattern.compile(""\""name\"":\""([^\""]*)\"""").matcher(line);
                                    if (matcher.find()) {
                                        blob = matcher.group(1);
                                        response = line.getBytes(UTF_8);
                                    }
                                }
                                if (markAndContinue) {
                                    in.mark(Integer.MAX_VALUE);
                                    continue;
                                }
                            }
                            if (blob != null) {
                                in.reset();
                                try (ByteArrayOutputStream binary = new ByteArrayOutputStream()) {
                                    while ((read = in.read()) != -1) {
                                        binary.write(read);
                                    }
                                    binary.flush();
                                    byte[] tmp = binary.toByteArray();
                                    // removes the trailing end ""\r\n--__END_OF_PART__--\r\n"" which is 23 bytes long
                                    blobs.put(blob, new BytesArray(Arrays.copyOf(tmp, tmp.length - 23)));
                                } finally {
                                    blob = null;
                                }
                            }
                        }
                    }
                    exchange.getResponseHeaders().add(""Content-Type"", ""application/json"");
                    exchange.sendResponseHeaders(RestStatus.OK.getStatus(), response.length);
                    exchange.getResponseBody().write(response);

                } else {
                    exchange.sendResponseHeaders(RestStatus.INTERNAL_SERVER_ERROR.getStatus(), -1);
                }
            } finally {
                exchange.close();
            }
        }","public void handle(final HttpExchange exchange) throws IOException {
            final String request = exchange.getRequestMethod() + "" "" + exchange.getRequestURI().toString();
            try {
                if (Regex.simpleMatch(""GET /storage/v1/b/bucket/o*"", request)) {
                    final Map<String, String> params = new HashMap<>();
                    RestUtils.decodeQueryString(exchange.getRequestURI().getQuery(), 0, params);
                    final String prefix = params.get(""prefix"");

                    final List<Map.Entry<String, BytesArray>> listOfBlobs = blobs.entrySet().stream()
                        .filter(blob -> prefix == null || blob.getKey().startsWith(prefix)).collect(Collectors.toList());

                    final StringBuilder list = new StringBuilder();
                    list.append(""{\""kind\"":\""storage#objects\"",\""items\"":["");
                    for (Iterator<Map.Entry<String, BytesArray>> it = listOfBlobs.iterator(); it.hasNext(); ) {
                        Map.Entry<String, BytesArray> blob = it.next();
                        list.append(""{\""kind\"":\""storage#object\"","");
                        list.append(""\""bucket\"":\""bucket\"","");
                        list.append(""\""name\"":\"""").append(blob.getKey()).append(""\"","");
                        list.append(""\""id\"":\"""").append(blob.getKey()).append(""\"","");
                        list.append(""\""size\"":\"""").append(blob.getValue().length()).append(""\"""");
                        list.append('}');

                        if (it.hasNext()) {
                            list.append(',');
                        }
                    }
                    list.append(""]}"");

                    byte[] response = list.toString().getBytes(UTF_8);
                    exchange.getResponseHeaders().add(""Content-Type"", ""application/json; charset=utf-8"");
                    exchange.sendResponseHeaders(RestStatus.OK.getStatus(), response.length);
                    exchange.getResponseBody().write(response);

                } else if (Regex.simpleMatch(""GET /storage/v1/b/bucket*"", request)) {
                    byte[] response = (""{\""kind\"":\""storage#bucket\"",\""name\"":\""bucket\"",\""id\"":\""0\""}"").getBytes(UTF_8);
                    exchange.getResponseHeaders().add(""Content-Type"", ""application/json; charset=utf-8"");
                    exchange.sendResponseHeaders(HttpStatus.SC_OK, response.length);
                    exchange.getResponseBody().write(response);

                } else if (Regex.simpleMatch(""GET /download/storage/v1/b/bucket/o/*"", request)) {
                    BytesArray blob = blobs.get(exchange.getRequestURI().getPath().replace(""/download/storage/v1/b/bucket/o/"", """"));
                    if (blob != null) {
                        final String range = exchange.getRequestHeaders().getFirst(""Range"");
                        Matcher matcher = Pattern.compile(""bytes=([0-9]*)-([0-9]*)"").matcher(range);
                        assert matcher.find();

                        byte[] response = Integer.parseInt(matcher.group(1)) == 0 ? blob.array() : new byte[0];
                        exchange.getResponseHeaders().add(""Content-Type"", ""application/octet-stream"");
                        exchange.sendResponseHeaders(RestStatus.OK.getStatus(), response.length);
                        exchange.getResponseBody().write(response);
                    } else {
                        exchange.sendResponseHeaders(RestStatus.NOT_FOUND.getStatus(), -1);
                    }

                } else if (Regex.simpleMatch(""DELETE /storage/v1/b/bucket/o/*"", request)) {
                    int deletions = 0;
                    for (Iterator<Map.Entry<String, BytesArray>> iterator = blobs.entrySet().iterator(); iterator.hasNext(); ) {
                        Map.Entry<String, BytesArray> blob = iterator.next();
                        if (blob.getKey().equals(exchange.getRequestURI().toString())) {
                            iterator.remove();
                            deletions++;
                        }
                    }
                    exchange.sendResponseHeaders((deletions > 0 ? RestStatus.OK : RestStatus.NO_CONTENT).getStatus(), -1);

                } else if (Regex.simpleMatch(""POST /batch/storage/v1"", request)) {
                    final String uri = ""/storage/v1/b/bucket/o/"";
                    final StringBuilder batch = new StringBuilder();
                    for (String line : Streams.readAllLines(new BufferedInputStream(exchange.getRequestBody()))) {
                        if (line.length() == 0 || line.startsWith(""--"") || line.toLowerCase(Locale.ROOT).startsWith(""content"")) {
                            batch.append(line).append('\n');
                        } else if (line.startsWith(""DELETE"")) {
                            final String name = line.substring(line.indexOf(uri) + uri.length(), line.lastIndexOf("" HTTP""));
                            if (Strings.hasText(name)) {
                                if (blobs.entrySet().removeIf(blob -> blob.getKey().equals(URLDecoder.decode(name, UTF_8)))) {
                                    batch.append(""HTTP/1.1 204 NO_CONTENT"").append('\n');
                                    batch.append('\n');
                                }
                            }
                        }
                    }
                    byte[] response = batch.toString().getBytes(UTF_8);
                    exchange.getResponseHeaders().add(""Content-Type"", exchange.getRequestHeaders().getFirst(""Content-Type""));
                    exchange.sendResponseHeaders(RestStatus.OK.getStatus(), response.length);
                    exchange.getResponseBody().write(response);

                } else if (Regex.simpleMatch(""POST /upload/storage/v1/b/bucket/*uploadType=multipart*"", request)) {
                    try (BufferedInputStream in = new BufferedInputStream(new GZIPInputStream(exchange.getRequestBody()))) {
                        byte[] response = new byte[0];
                        String blob = null;
                        int read;
                        while ((read = in.read()) != -1) {
                            boolean markAndContinue = false;
                            try (ByteArrayOutputStream out = new ByteArrayOutputStream()) {
                                do { // search next consecutive {carriage return, new line} chars and stop
                                    if ((char) read == '\r') {
                                        int next = in.read();
                                        if (next != -1) {
                                            if (next == '\n') {
                                                break;
                                            }
                                            out.write(read);
                                            out.write(next);
                                            continue;
                                        }
                                    }
                                    out.write(read);
                                } while ((read = in.read()) != -1);

                                final String line = new String(out.toByteArray(), UTF_8);
                                if (line.length() == 0 || line.equals(""\r\n"") || line.startsWith(""--"")
                                    || line.toLowerCase(Locale.ROOT).startsWith(""content"")) {
                                    markAndContinue = true;
                                } else if (line.startsWith(""{\""bucket\"":\""bucket\"""")) {
                                    markAndContinue = true;
                                    Matcher matcher = Pattern.compile(""\""name\"":\""([^\""]*)\"""").matcher(line);
                                    if (matcher.find()) {
                                        blob = matcher.group(1);
                                        response = line.getBytes(UTF_8);
                                    }
                                }
                                if (markAndContinue) {
                                    in.mark(Integer.MAX_VALUE);
                                    continue;
                                }
                            }
                            if (blob != null) {
                                in.reset();
                                try (ByteArrayOutputStream binary = new ByteArrayOutputStream()) {
                                    while ((read = in.read()) != -1) {
                                        binary.write(read);
                                    }
                                    binary.flush();
                                    byte[] tmp = binary.toByteArray();
                                    // removes the trailing end ""\r\n--__END_OF_PART__--\r\n"" which is 23 bytes long
                                    blobs.put(blob, new BytesArray(Arrays.copyOf(tmp, tmp.length - 23)));

                                    exchange.getResponseHeaders().add(""Content-Type"", ""application/json"");
                                    exchange.sendResponseHeaders(RestStatus.OK.getStatus(), response.length);
                                    exchange.getResponseBody().write(response);

                                } finally {
                                    blob = null;
                                }
                            }
                        }
                    }

                } else if (Regex.simpleMatch(""POST /upload/storage/v1/b/bucket/*uploadType=resumable*"", request)) {
                    final Map<String, String> params = new HashMap<>();
                    RestUtils.decodeQueryString(exchange.getRequestURI().getQuery(), 0, params);
                    final String blobName = params.get(""name"");
                    blobs.put(blobName, BytesArray.EMPTY);

                    byte[] response = Streams.readFully(exchange.getRequestBody()).utf8ToString().getBytes(UTF_8);
                    exchange.getResponseHeaders().add(""Content-Type"", ""application/json"");
                    exchange.getResponseHeaders().add(""Location"", httpServerUrl() + ""/upload/storage/v1/b/bucket/o?""
                        + ""uploadType=resumable""
                        + ""&upload_id="" + UUIDs.randomBase64UUID()
                        + ""&test_blob_name="" + blobName); // not a Google Storage parameter, but it allows to pass the blob name
                    exchange.sendResponseHeaders(RestStatus.OK.getStatus(), response.length);
                    exchange.getResponseBody().write(response);

                } else if (Regex.simpleMatch(""PUT /upload/storage/v1/b/bucket/o?*uploadType=resumable*"", request)) {
                    final Map<String, String> params = new HashMap<>();
                    RestUtils.decodeQueryString(exchange.getRequestURI().getQuery(), 0, params);

                    final String blobName = params.get(""test_blob_name"");
                    final String range = exchange.getRequestHeaders().getFirst(""Content-Range"");
                    assert Strings.hasLength(range);

                    Matcher matcher = Pattern.compile(""bytes ([^/]*)/([0-9\\*]*)"").matcher(range);
                    if (matcher.find()) {
                        String bytes = matcher.group(1);
                        String limit = matcher.group(2);
                        byte[] blob = blobs.get(blobName).array();
                        assert blob != null;
                        // client is uploading a chunk
                        matcher = Pattern.compile(""([0-9]*)-([0-9]*)"").matcher(bytes);
                        assert matcher.find();

                        int end = Integer.parseInt(matcher.group(2));
                        int start = Integer.parseInt(matcher.group(1));

                        final ByteArrayOutputStream out = new ByteArrayOutputStream();
                        long count = Streams.copy(exchange.getRequestBody(), out);
                        int length = Math.max(end + 1, ""*"".equals(limit) ? 0 : Integer.parseInt(limit));
                        assert count <= length;
                        if (length > blob.length) {
                            blob = ArrayUtil.growExact(blob, length);
                        }
                        assert blob.length >= end;
                        System.arraycopy(out.toByteArray(), 0, blob, start, Math.toIntExact(count));
                        blobs.put(blobName, new BytesArray(blob));

                        if (""*"".equals(limit)) {
                            exchange.getResponseHeaders().add(""Range"", String.format(Locale.ROOT, ""bytes=%d/%d"", start, end));
                            exchange.getResponseHeaders().add(""Content-Length"", ""0"");
                            exchange.sendResponseHeaders(308 /* Resume Incomplete */, -1);
                        } else {
                            assert blob.length == Integer.parseInt(limit);
                            exchange.sendResponseHeaders(RestStatus.OK.getStatus(), -1);
                        }
                    }
                } else {
                    exchange.sendResponseHeaders(RestStatus.INTERNAL_SERVER_ERROR.getStatus(), -1);
                }
            } finally {
                exchange.close();
            }
        }",/plugins/repository-gcs/src/test/java/org/elasticsearch/repositories/gcs/GoogleCloudStorageBlobStoreRepositoryTests.java
4366360895dbcd28bf993000b80c95f83ecb79a5,662,255,"private void removeCompletionListener(long id) {
        synchronized (this) {
            if (hasCompleted == false) {
                completionListeners.remove(id);
            }
        }
    }","private void internalAddCompletionListener(ActionListener<AsyncSearchResponse> listener, TimeValue waitForCompletion) {
        boolean executeImmediately = false;
        synchronized (this) {
            if (hasCompleted || waitForCompletion.getMillis() == 0) {
                executeImmediately = true;
            } else {
                // ensure that we consumes the listener only once
                AtomicBoolean hasRun = new AtomicBoolean(false);
                long id = completionId++;
                final Cancellable cancellable;
                try {
                     cancellable = threadPool.schedule(
                         () -> {
                            if (hasRun.compareAndSet(false, true)) {
                                // timeout occurred before completion
                                removeCompletionListener(id);
                                listener.onResponse(getResponseWithHeaders());
                            }
                        },
                        waitForCompletion,
                        ""generic"");
                } catch(Exception exc) {
                    listener.onFailure(exc);
                    return;
                }
                completionListeners.put(
                    id,
                    resp -> {
                        if (hasRun.compareAndSet(false, true)) {
                            // completion occurred before timeout
                            cancellable.cancel();
                            listener.onResponse(resp);
                        }
                    });
            }
        }
        if (executeImmediately) {
            listener.onResponse(getResponseWithHeaders());
        }
    }",/x-pack/plugin/async-search/src/main/java/org/elasticsearch/xpack/search/AsyncSearchTask.java
4366360895dbcd28bf993000b80c95f83ecb79a5,662,277,"private void executeInitListeners() {
        synchronized (this) {
            if (hasInitialized) {
                return;
            }
            hasInitialized = true;
        }
        for (Runnable listener : initListeners) {
            listener.run();
        }
        initListeners.clear();
    }","private void addInitListener(Runnable listener) {
        boolean executeImmediately = false;
        synchronized (this) {
            if (hasInitialized) {
                executeImmediately = true;
            } else {
                initListeners.add(listener);
            }
        }
        if (executeImmediately) {
            listener.run();
        }
    }",/x-pack/plugin/async-search/src/main/java/org/elasticsearch/xpack/search/AsyncSearchTask.java
4366360895dbcd28bf993000b80c95f83ecb79a5,662,264,"private void addInitListener(Runnable listener) {
        boolean executeImmediately = false;
        synchronized (this) {
            if (hasInitialized) {
                executeImmediately = true;
            } else {
                initListeners.add(listener);
            }
        }
        if (executeImmediately) {
            listener.run();
        }
    }","private void removeCompletionListener(long id) {
        synchronized (this) {
            if (hasCompleted == false) {
                completionListeners.remove(id);
            }
        }
    }",/x-pack/plugin/async-search/src/main/java/org/elasticsearch/xpack/search/AsyncSearchTask.java
4366360895dbcd28bf993000b80c95f83ecb79a5,662,154,"void addShardFailure(int shardIndex, ShardSearchFailure failure) {
        synchronized (this) {
            failIfFrozen();
        }
        shardFailures.set(shardIndex, failure);
    }","private SearchResponse buildResponse(long taskStartTimeNanos, InternalAggregations reducedAggs) {
        InternalSearchResponse internal = new InternalSearchResponse(
            new SearchHits(SearchHits.EMPTY, totalHits, Float.NaN), reducedAggs, null, null, false, false, reducePhase);
        long tookInMillis = TimeValue.timeValueNanos(System.nanoTime() - taskStartTimeNanos).getMillis();
        return new SearchResponse(internal, null, totalShards, successfulShards, skippedShards,
            tookInMillis, buildShardFailures(), clusters);
    }",/x-pack/plugin/async-search/src/main/java/org/elasticsearch/xpack/search/MutableSearchResponse.java
c17c140cd2843e82a26fe61eecf9abf56b54099b,571,174,"public ExitStatus execute(Settings settings, Environment env) throws Exception {
            Path file = FileUserPasswdStore.resolveFile(settings, env);
            Map<String, char[]> users = new HashMap<>(FileUserPasswdStore.parseFile(file, null));
            if (users != null) {
                char[] passwd = users.remove(username);
                if (passwd != null) {
                    FileUserPasswdStore.writeFile(users, file);
                } else {
                    terminal.println(""Warning: users file [%s] did not contain password entry for user [%s]"", file.toAbsolutePath(), username);
                }
            }

            file = FileUserRolesStore.resolveFile(settings, env);
            Map<String, String[]> userRoles = new HashMap<>(FileUserRolesStore.parseFile(file, null));
            if (userRoles != null) {
                String[] roles = userRoles.remove(username);
                if (roles != null) {
                    FileUserRolesStore.writeFile(userRoles, file);
                } else {
                    terminal.println(""Warning: users_roles file [%s] did not contain roles entry for user [%s]"", file.toAbsolutePath(), username);
                }
            }

            return ExitStatus.OK;
        }","public ExitStatus execute(Settings settings, Environment env) throws Exception {
            Path file = FileUserPasswdStore.resolveFile(settings, env);
            Map<String, char[]> users = new HashMap<>(FileUserPasswdStore.parseFile(file, null));
            if (Files.exists(file)) {
                char[] passwd = users.remove(username);
                if (passwd != null) {
                    FileUserPasswdStore.writeFile(users, file);
                } else {
                    terminal.println(""Warning: users file [%s] did not contain password entry for user [%s]"", file.toAbsolutePath(), username);
                }
            }

            file = FileUserRolesStore.resolveFile(settings, env);
            Map<String, String[]> userRoles = new HashMap<>(FileUserRolesStore.parseFile(file, null));
            if (Files.exists(file)) {
                String[] roles = userRoles.remove(username);
                if (roles != null) {
                    FileUserRolesStore.writeFile(userRoles, file);
                } else {
                    terminal.println(""Warning: users_roles file [%s] did not contain roles entry for user [%s]"", file.toAbsolutePath(), username);
                }
            }

            return ExitStatus.OK;
        }",/src/main/java/org/elasticsearch/shield/authc/esusers/tool/ESUsersTool.java
c17c140cd2843e82a26fe61eecf9abf56b54099b,570,123,"public ExitStatus execute(Settings settings, Environment env) throws Exception {
            Path file = FileUserPasswdStore.resolveFile(settings, env);
            Map<String, char[]> users = new HashMap<>(FileUserPasswdStore.parseFile(file, null));
            if (users == null) {
                // file doesn't exist so we just create a new file
                users = new HashMap<>();
            }
            if (users.containsKey(username)) {
                terminal.println(""User [%s] already exists"", username);
                return ExitStatus.CODE_ERROR;
            }
            Hasher hasher = Hasher.HTPASSWD;
            users.put(username, hasher.hash(passwd));
            FileUserPasswdStore.writeFile(users, file);


            file = FileUserRolesStore.resolveFile(settings, env);
            Map<String, String[]> userRoles = new HashMap<>(FileUserRolesStore.parseFile(file, null));
            if (userRoles == null) {
                // file doesn't exist, so we just create a new file
                userRoles = new HashMap<>();
            }
            userRoles.put(username, roles);
            FileUserRolesStore.writeFile(userRoles, file);
            return ExitStatus.OK;
        }","public ExitStatus execute(Settings settings, Environment env) throws Exception {
            Path file = FileUserPasswdStore.resolveFile(settings, env);
            Map<String, char[]> users = new HashMap<>(FileUserPasswdStore.parseFile(file, null));
            if (users.containsKey(username)) {
                terminal.println(""User [%s] already exists"", username);
                return ExitStatus.CODE_ERROR;
            }
            Hasher hasher = Hasher.HTPASSWD;
            users.put(username, hasher.hash(passwd));
            FileUserPasswdStore.writeFile(users, file);


            file = FileUserRolesStore.resolveFile(settings, env);
            Map<String, String[]> userRoles = new HashMap<>(FileUserRolesStore.parseFile(file, null));
            userRoles.put(username, roles);
            FileUserRolesStore.writeFile(userRoles, file);
            return ExitStatus.OK;
        }",/src/main/java/org/elasticsearch/shield/authc/esusers/tool/ESUsersTool.java
24e73a2c83ff334047a5bb9858be7be22c4e04bf,563,458,"public Snapshot newSnapshot() {
        try (ReleasableLock lock = readLock.acquire()) {
            // leave one place for current.
            final FsChannelReader[] readers = uncommittedTranslogs.toArray(new FsChannelReader[uncommittedTranslogs.size() + 1]);
            readers[readers.length - 1] = current;
            return createdSnapshot(readers);
        }
    }","public Translog.View newView() {
        // we need to acquire the read lock to make sure new translog is created
        // and will be missed by the view we're making
        try (ReleasableLock lock = readLock.acquire()) {
            ArrayList<FsChannelReader> translogs = new ArrayList<>();
            try {
                for (FsChannelImmutableReader translog : uncommittedTranslogs) {
                    translogs.add(translog.clone());
                }
                translogs.add(current.reader());
                FsView view = new FsView(translogs);
                // this is safe as we know that no new translog is being made at the moment
                // (we hold a read lock) and the view will be notified of any future one
                outstandingViews.add(view);
                translogs.clear();
                return view;
            } finally {
                // close if anything happend and we didn't reach the clear
                IOUtils.closeWhileHandlingException(translogs);
            }
        }
    }",/src/main/java/org/elasticsearch/index/translog/fs/FsTranslog.java
24e73a2c83ff334047a5bb9858be7be22c4e04bf,662,643,"void ensureOpen() {
            if (closed) {
                throw new ElasticsearchException(""View is already closed"");
            }
        }","public void run() {
            // don't re-schedule  if its closed..., we are done
            if (closed.get()) {
                return;
            }
            if (syncNeeded()) {
                threadPool.executor(ThreadPool.Names.FLUSH).execute(new Runnable() {
                    @Override
                    public void run() {
                        try {
                            sync();
                        } catch (Exception e) {
                            logger.warn(""failed to sync translog"", e);
                        }
                        if (closed.get() == false) {
                            syncScheduler = threadPool.schedule(syncInterval, ThreadPool.Names.SAME, Sync.this);
                        }
                    }
                });
            } else {
                syncScheduler = threadPool.schedule(syncInterval, ThreadPool.Names.SAME, Sync.this);
            }
        }",/src/main/java/org/elasticsearch/index/translog/fs/FsTranslog.java
24e73a2c83ff334047a5bb9858be7be22c4e04bf,563,250,"public int totalOperations() {
        int ops = 0;
        try (ReleasableLock lock = readLock.acquire()) {
            ops += current.totalOperations();
            for (FsChannelReader translog : uncommittedTranslogs) {
                int tops = translog.totalOperations();
                if (tops == FsChannelReader.UNKNOWN_OP_COUNT) {
                    return FsChannelReader.UNKNOWN_OP_COUNT;
                }
                ops += tops;
            }
        }
        return ops;
    }","public long currentId() {
        try (ReleasableLock lock = readLock.acquire()) {
            return current.translogId();
        }
    }",/src/main/java/org/elasticsearch/index/translog/fs/FsTranslog.java
24e73a2c83ff334047a5bb9858be7be22c4e04bf,563,396,"protected FsTranslogFile createTranslogFile(@Nullable FsTranslogFile reuse) throws IOException {
        FsTranslogFile newFile;
        long size = Long.MAX_VALUE;
        try {
            long id = idGenerator++;
            newFile = type.create(shardId, id, new InternalChannelReference(id, location.resolve(getFilename(id)), StandardOpenOption.READ, StandardOpenOption.WRITE, StandardOpenOption.CREATE_NEW), bufferSize);
        } catch (IOException e) {
            throw new TranslogException(shardId, ""failed to create new translog file"", e);
        }
        if (reuse != null) {
            newFile.reuse(reuse);
        }
        return newFile;
    }","public Location add(Operation operation) throws TranslogException {
        ReleasableBytesStreamOutput out = new ReleasableBytesStreamOutput(bigArrays);
        try {
            TranslogStreams.writeTranslogOperation(out, operation);
            ReleasablePagedBytesReference bytes = out.bytes();
            try (ReleasableLock lock = readLock.acquire()) {
                Location location = current.add(bytes);
                if (syncOnEachOperation) {
                    current.sync();
                }

                assert current.assertBytesAtLocation(location, bytes);
                return location;
            }
        } catch (Throwable e) {
            throw new TranslogException(shardId, ""Failed to write operation ["" + operation + ""]"", e);
        } finally {
            Releasables.close(out.bytes());
        }
    }",/src/main/java/org/elasticsearch/index/translog/fs/FsTranslog.java
24e73a2c83ff334047a5bb9858be7be22c4e04bf,563,313,"public String[] getUnreferenced() throws IOException {
        if (ChannelReference.openedFiles == null) {
            return Strings.EMPTY_ARRAY; // not supported
        }
        ArrayList<String> result = new ArrayList<>();
        try (ReleasableLock lock = writeLock.acquire()) {
            try (DirectoryStream<Path> stream = Files.newDirectoryStream(location, TRANSLOG_FILE_PREFIX + ""[0-9]*"")) {
                for (Path file : stream) {
                    final long id = parseIdFromFileName(file);
                    if (id < 0) {
                        logger.trace(""failed to extract translog id from [{}]"", file);
                    } else if (ChannelReference.openedFiles.containsKey(file.toString()) == false) {
                        result.add(file.toString());
                    }
                }
            }
        }
        return result.toArray(Strings.EMPTY_ARRAY);
    }","public void markCommitted(final long translogId) throws FileNotFoundException {
        try (ReleasableLock lock = writeLock.acquire()) {
            logger.trace(""updating translogs on commit of [{}]"", translogId);
            if (translogId < lastCommittedTranslogId) {
                throw new IllegalArgumentException(""committed translog id can only go up (current [""
                        + lastCommittedTranslogId + ""], got ["" + translogId + ""]"");
            }
            boolean found = false;
            if (current.translogId() == translogId) {
                found = true;
            } else {
                if (translogId > current.translogId()) {
                    throw new IllegalArgumentException(""committed translog id must be lower or equal to current id (current [""
                            + current.translogId() + ""], got ["" + translogId + ""]"");
                }
            }
            if (found == false) {
                // try to find it in uncommittedTranslogs
                for (FsChannelImmutableReader translog : uncommittedTranslogs) {
                    if (translog.translogId() == translogId) {
                        found = true;
                        break;
                    }
                }
            }
            if (found == false) {
                ArrayList<Long> currentIds = new ArrayList<>();
                for (FsChannelReader translog : Iterables.concat(uncommittedTranslogs, Collections.singletonList(current))) {
                    currentIds.add(translog.translogId());
                }
                throw new FileNotFoundException(""committed translog id can not be found (current [""
                        + Strings.collectionToCommaDelimitedString(currentIds) + ""], got ["" + translogId + ""]"");
            }
            lastCommittedTranslogId = translogId;
            while (uncommittedTranslogs.isEmpty() == false && uncommittedTranslogs.get(0).translogId() < translogId) {
                FsChannelReader old = uncommittedTranslogs.remove(0);
                logger.trace(""removed [{}] from uncommitted translog list"", old.translogId());
                try {
                    old.close();
                } catch (IOException e) {
                    logger.error(""failed to closed old translog [{}] (committed id [{}])"", e, old, translogId);
                }
            }
        }
    }",/src/main/java/org/elasticsearch/index/translog/fs/FsTranslog.java
24e73a2c83ff334047a5bb9858be7be22c4e04bf,563,377,"public long newTranslog() throws TranslogException, IOException {
        try (ReleasableLock lock = writeLock.acquire()) {
            final FsTranslogFile old = current;
            final FsTranslogFile newFile = createTranslogFile(old);
            current = newFile;
            FsChannelImmutableReader reader = old.immutableReader();
            uncommittedTranslogs.add(reader);
            // notify all outstanding views of the new translog (no views are created now as
            // we hold a write lock).
            for (FsView view : outstandingViews) {
                view.onNewTranslog(old.immutableReader(), current.reader());
            }
            IOUtils.close(old);
            logger.trace(""current translog set to [{}]"", current.translogId());
            return current.translogId();
        }
    }","public Translog.Operation read(Location location) {
        try (ReleasableLock lock = readLock.acquire()) {
            FsChannelReader reader = null;
            if (current.translogId() == location.translogId) {
                reader = current;
            } else {
                for (FsChannelReader translog : uncommittedTranslogs) {
                    if (translog.translogId() == location.translogId) {
                        reader = translog;
                        break;
                    }
                }
            }
            return reader == null ? null : reader.read(location);
        } catch (IOException e) {
            throw new ElasticsearchException(""failed to read source from translog location "" + location, e);
        }
    }",/src/main/java/org/elasticsearch/index/translog/fs/FsTranslog.java
24e73a2c83ff334047a5bb9858be7be22c4e04bf,563,206,"public void updateBuffer(ByteSizeValue bufferSize) {
        this.bufferSize = bufferSize.bytesAsInt();
        try (ReleasableLock lock = writeLock.acquire()) {
            current.updateBufferSize(this.bufferSize);
        }
    }","public static long parseIdFromFileName(Path translogFile) {
        final String fileName = translogFile.getFileName().toString();
        final Matcher matcher = PARSE_ID_PATTERN.matcher(fileName);
        if (matcher.matches()) {
            try {
                return Long.parseLong(matcher.group(1));
            } catch (NumberFormatException e) {
                throw new ElasticsearchException(""number formatting issue in a file that passed PARSE_ID_PATTERN: "" + fileName + ""]"", e);
            }
        }
        return -1;
    }",/src/main/java/org/elasticsearch/index/translog/fs/FsTranslog.java
24e73a2c83ff334047a5bb9858be7be22c4e04bf,563,416,"public Translog.Operation read(Location location) {
        try (ReleasableLock lock = readLock.acquire()) {
            FsChannelReader reader = null;
            if (current.translogId() == location.translogId) {
                reader = current;
            } else {
                for (FsChannelReader translog : uncommittedTranslogs) {
                    if (translog.translogId() == location.translogId) {
                        reader = translog;
                        break;
                    }
                }
            }
            return reader == null ? null : reader.read(location);
        } catch (IOException e) {
            throw new ElasticsearchException(""failed to read source from translog location "" + location, e);
        }
    }","public Snapshot newSnapshot() {
        try (ReleasableLock lock = readLock.acquire()) {
            // leave one place for current.
            final FsChannelReader[] readers = uncommittedTranslogs.toArray(new FsChannelReader[uncommittedTranslogs.size() + 1]);
            readers[readers.length - 1] = current;
            return createdSnapshot(readers);
        }
    }",/src/main/java/org/elasticsearch/index/translog/fs/FsTranslog.java
24e73a2c83ff334047a5bb9858be7be22c4e04bf,563,266,"public long sizeInBytes() {
        long size = 0;
        try (ReleasableLock lock = readLock.acquire()) {
            size += current.sizeInBytes();
            for (FsChannelReader translog : uncommittedTranslogs) {
                size += translog.sizeInBytes();
            }
        }
        return size;
    }","public int totalOperations() {
        int ops = 0;
        try (ReleasableLock lock = readLock.acquire()) {
            ops += current.totalOperations();
            for (FsChannelReader translog : uncommittedTranslogs) {
                int tops = translog.totalOperations();
                if (tops == FsChannelReader.UNKNOWN_OP_COUNT) {
                    return FsChannelReader.UNKNOWN_OP_COUNT;
                }
                ops += tops;
            }
        }
        return ops;
    }",/src/main/java/org/elasticsearch/index/translog/fs/FsTranslog.java
24e73a2c83ff334047a5bb9858be7be22c4e04bf,563,519,"public boolean syncNeeded() {
        try (ReleasableLock lock = readLock.acquire()) {
            return current.syncNeeded();
        }
    }","protected void closeInternal() {
            super.closeInternal();
            try (ReleasableLock lock = writeLock.acquire()) {
                if (isReferencedTranslogId(translogId) == false) {
                    // if the given path is not the current we can safely delete the file since all references are released
                    logger.trace(""delete translog file - not referenced and not current anymore {}"", file());
                    IOUtils.deleteFilesIgnoringExceptions(file());
                }
            }
        }",/src/main/java/org/elasticsearch/index/translog/fs/FsTranslog.java
3261586cac21a45f1b135050f310ee8cb3986ad3,682,256,"DelayedPrepareBulkRequest rethrottle(float newRequestsPerSecond) {
            if (newRequestsPerSecond != 0 && newRequestsPerSecond < requestsPerSecond) {
                /*
                 * The user is attempting to slow the request down. We'll let the change in throttle take effect the next time we delay
                 * prepareBulkRequest. We can't just reschedule the request further out in the future the bulk context might time out.
                 */
                logger.debug(""[{}]: skipping rescheduling because the new throttle [{}] is slower than the old one [{}]"", getId(),
                        newRequestsPerSecond, requestsPerSecond);
                return this;
            }

            long remainingDelay = future.getDelay(TimeUnit.NANOSECONDS);
            // Actually reschedule the task
            if (false == FutureUtils.cancel(future)) {
                // Couldn't cancel, probably because the task has finished or been scheduled. Either way we have nothing to do here.
                logger.debug(""[{}]: skipping rescheduling because we couldn't cancel the task"", getId());
                return this;
            }

            /*
             * Strangely enough getting here doesn't mean that you actually cancelled the request, just that you probably did. If you stress
             * test it you'll find that requests sneak through. So each request is given a runOnce boolean to prevent that.
             */
            TimeValue newDelay = newDelay(remainingDelay, newRequestsPerSecond);
            logger.debug(""[{}]: rescheduling for [{}] in the future"", getId(), newDelay);
            return new DelayedPrepareBulkRequest(threadPool, requestsPerSecond, newDelay, command);
        }","public void onFailure(Exception e) {
                    command.onFailure(e);
                }",/core/src/main/java/org/elasticsearch/index/reindex/WorkingBulkByScrollTask.java
e15d2e09e60273bf05f9c4443eba128339e90aa5,563,513,"public void testGetApiKeysOwnedByCurrentAuthenticatedUser() throws InterruptedException, ExecutionException {
        int noOfSuperuserApiKeys = randomIntBetween(3, 5);
        int noOfApiKeysForUserWithManageApiKeyRole = randomIntBetween(3, 5);
        List<CreateApiKeyResponse> defaultUserCreatedKeys = createApiKeys(noOfSuperuserApiKeys, null);
        String userWithManageApiKeyRole = randomFrom(""user_with_manage_api_key_role"", ""user_with_manage_own_api_key_role"");
        List<CreateApiKeyResponse> userWithManageApiKeyRoleApiKeys = createApiKeys(userWithManageApiKeyRole,
            noOfApiKeysForUserWithManageApiKeyRole, null, ""monitor"");
        final Client client = client().filterWithHeader(Collections.singletonMap(""Authorization"", UsernamePasswordToken
            .basicAuthHeaderValue(userWithManageApiKeyRole, SecuritySettingsSourceField.TEST_PASSWORD_SECURE_STRING)));

        PlainActionFuture<GetApiKeyResponse> listener = new PlainActionFuture<>();
        client.execute(GetApiKeyAction.INSTANCE, GetApiKeyRequest.forOwnedApiKeys(), listener);
        GetApiKeyResponse response = listener.get();
        verifyGetResponse(userWithManageApiKeyRole, noOfApiKeysForUserWithManageApiKeyRole, userWithManageApiKeyRoleApiKeys,
            response, userWithManageApiKeyRoleApiKeys.stream().map(o -> o.getId()).collect(Collectors.toSet()), null);
    }","public void testGetApiKeysForRealmAndUser() throws InterruptedException, ExecutionException {
        List<CreateApiKeyResponse> responses = createApiKeys(1, null);
        Client client = client().filterWithHeader(Collections.singletonMap(""Authorization"", UsernamePasswordToken
                .basicAuthHeaderValue(SecuritySettingsSource.TEST_SUPERUSER, SecuritySettingsSourceField.TEST_PASSWORD_SECURE_STRING)));
        PlainActionFuture<GetApiKeyResponse> listener = new PlainActionFuture<>();
        client.execute(GetApiKeyAction.INSTANCE, GetApiKeyRequest.usingRealmAndUserName(""file"", SecuritySettingsSource.TEST_SUPERUSER),
                listener);
        GetApiKeyResponse response = listener.get();
        verifyGetResponse(1, responses, response, Collections.singleton(responses.get(0).getId()), null);
    }",/x-pack/plugin/security/src/test/java/org/elasticsearch/xpack/security/authc/ApiKeyIntegTests.java
e15d2e09e60273bf05f9c4443eba128339e90aa5,563,530,"public void testInvalidateApiKeysOwnedByCurrentAuthenticatedUser() throws InterruptedException, ExecutionException {
        int noOfSuperuserApiKeys = randomIntBetween(3, 5);
        int noOfApiKeysForUserWithManageApiKeyRole = randomIntBetween(3, 5);
        List<CreateApiKeyResponse> defaultUserCreatedKeys = createApiKeys(noOfSuperuserApiKeys, null);
        String userWithManageApiKeyRole = randomFrom(""user_with_manage_api_key_role"", ""user_with_manage_own_api_key_role"");
        List<CreateApiKeyResponse> userWithManageApiKeyRoleApiKeys = createApiKeys(userWithManageApiKeyRole,
            noOfApiKeysForUserWithManageApiKeyRole, null, ""monitor"");
        final Client client = client().filterWithHeader(Collections.singletonMap(""Authorization"", UsernamePasswordToken
            .basicAuthHeaderValue(userWithManageApiKeyRole, SecuritySettingsSourceField.TEST_PASSWORD_SECURE_STRING)));

        PlainActionFuture<InvalidateApiKeyResponse> listener = new PlainActionFuture<>();
        client.execute(InvalidateApiKeyAction.INSTANCE, InvalidateApiKeyRequest.forOwnedApiKeys(), listener);
        InvalidateApiKeyResponse invalidateResponse = listener.get();

        verifyInvalidateResponse(noOfApiKeysForUserWithManageApiKeyRole, userWithManageApiKeyRoleApiKeys, invalidateResponse);
    }","public void testGetApiKeysForApiKeyName() throws InterruptedException, ExecutionException {
        List<CreateApiKeyResponse> responses = createApiKeys(1, null);
        Client client = client().filterWithHeader(Collections.singletonMap(""Authorization"", UsernamePasswordToken
                .basicAuthHeaderValue(SecuritySettingsSource.TEST_SUPERUSER, SecuritySettingsSourceField.TEST_PASSWORD_SECURE_STRING)));
        PlainActionFuture<GetApiKeyResponse> listener = new PlainActionFuture<>();
        client.execute(GetApiKeyAction.INSTANCE, GetApiKeyRequest.usingApiKeyName(responses.get(0).getName(), false), listener);
        GetApiKeyResponse response = listener.get();
        verifyGetResponse(1, responses, response, Collections.singleton(responses.get(0).getId()), null);
    }",/x-pack/plugin/security/src/test/java/org/elasticsearch/xpack/security/authc/ApiKeyIntegTests.java
177bd62aba99ae6b1d7f37517c55e4e210732a37,563,177,"public void testPolicyManualExecution() throws Exception {
        final String indexName = ""test"";
        final String policyName = ""test-policy"";
        final String repoId = ""my-repo"";
        int docCount = randomIntBetween(10, 50);
        List<IndexRequestBuilder> indexReqs = new ArrayList<>();
        for (int i = 0; i < docCount; i++) {
            index(client(), indexName, """" + i, ""foo"", ""bar"");
        }

        // Create a snapshot repo
        inializeRepo(repoId);

        createSnapshotPolicy(policyName, ""snap"", ""1 2 3 4 5 ?"", repoId, indexName, true);

        ResponseException badResp = expectThrows(ResponseException.class,
            () -> client().performRequest(new Request(""PUT"", ""/_slm/policy/"" + policyName + ""-bad/_execute"")));
        assertThat(EntityUtils.toString(badResp.getResponse().getEntity()),
            containsString(""no such snapshot lifecycle policy ["" + policyName + ""-bad]""));

        Response goodResp = client().performRequest(new Request(""PUT"", ""/_slm/policy/"" + policyName + ""/_execute""));

        try (XContentParser parser = JsonXContent.jsonXContent.createParser(NamedXContentRegistry.EMPTY,
            DeprecationHandler.THROW_UNSUPPORTED_OPERATION, EntityUtils.toByteArray(goodResp.getEntity()))) {
            final String snapshotName = parser.mapStrings().get(""snapshot_name"");

            // Check that the executed snapshot is created
            assertBusy(() -> {
                try {
                    Response response = client().performRequest(new Request(""GET"", ""/_snapshot/"" + repoId + ""/"" + snapshotName));
                    Map<String, Object> snapshotResponseMap;
                    try (InputStream is = response.getEntity().getContent()) {
                        snapshotResponseMap = XContentHelper.convertToMap(XContentType.JSON.xContent(), is, true);
                    }
                    assertThat(snapshotResponseMap.size(), greaterThan(0));
                    final Map<String, Object> metadata = extractMetadata(snapshotResponseMap, snapshotName);
                    assertNotNull(metadata);
                    assertThat(metadata.get(""policy""), equalTo(policyName));
                    assertHistoryIsPresent(policyName, true, repoId);
                } catch (ResponseException e) {
                    fail(""expected snapshot to exist but it does not: "" + EntityUtils.toString(e.getResponse().getEntity()));
                }
            });
        }

        Request delReq = new Request(""DELETE"", ""/_slm/policy/"" + policyName);
        assertOK(client().performRequest(delReq));

        // It's possible there could have been a snapshot in progress when the
        // policy is deleted, so wait for it to be finished
        assertBusy(() -> {
            assertThat(wipeSnapshots().size(), equalTo(0));
        });
    }","public void testPolicyManualExecution() throws Exception {
        final String indexName = ""test"";
        final String policyName = ""test-policy"";
        final String repoId = ""my-repo"";
        int docCount = randomIntBetween(10, 50);
        for (int i = 0; i < docCount; i++) {
            index(client(), indexName, """" + i, ""foo"", ""bar"");
        }

        // Create a snapshot repo
        inializeRepo(repoId);

        createSnapshotPolicy(policyName, ""snap"", ""1 2 3 4 5 ?"", repoId, indexName, true);

        ResponseException badResp = expectThrows(ResponseException.class,
            () -> client().performRequest(new Request(""PUT"", ""/_slm/policy/"" + policyName + ""-bad/_execute"")));
        assertThat(EntityUtils.toString(badResp.getResponse().getEntity()),
            containsString(""no such snapshot lifecycle policy ["" + policyName + ""-bad]""));

        Response goodResp = client().performRequest(new Request(""PUT"", ""/_slm/policy/"" + policyName + ""/_execute""));

        try (XContentParser parser = JsonXContent.jsonXContent.createParser(NamedXContentRegistry.EMPTY,
            DeprecationHandler.THROW_UNSUPPORTED_OPERATION, EntityUtils.toByteArray(goodResp.getEntity()))) {
            final String snapshotName = parser.mapStrings().get(""snapshot_name"");

            // Check that the executed snapshot is created
            assertBusy(() -> {
                try {
                    Response response = client().performRequest(new Request(""GET"", ""/_snapshot/"" + repoId + ""/"" + snapshotName));
                    Map<String, Object> snapshotResponseMap;
                    try (InputStream is = response.getEntity().getContent()) {
                        snapshotResponseMap = XContentHelper.convertToMap(XContentType.JSON.xContent(), is, true);
                    }
                    assertThat(snapshotResponseMap.size(), greaterThan(0));
                    final Map<String, Object> metadata = extractMetadata(snapshotResponseMap, snapshotName);
                    assertNotNull(metadata);
                    assertThat(metadata.get(""policy""), equalTo(policyName));
                    assertHistoryIsPresent(policyName, true, repoId);
                } catch (ResponseException e) {
                    fail(""expected snapshot to exist but it does not: "" + EntityUtils.toString(e.getResponse().getEntity()));
                }
            });
        }

        Request delReq = new Request(""DELETE"", ""/_slm/policy/"" + policyName);
        assertOK(client().performRequest(delReq));

        // It's possible there could have been a snapshot in progress when the
        // policy is deleted, so wait for it to be finished
        assertBusy(() -> {
            assertThat(wipeSnapshots().size(), equalTo(0));
        });
    }",/x-pack/plugin/ilm/qa/multi-node/src/test/java/org/elasticsearch/xpack/slm/SnapshotLifecycleIT.java
3dd833ca0a2b33159d78ad011b1c66df20a7192a,563,1158,"public void testKeystoreRequiredCreated() throws Exception {
        Tuple<Path, Environment> env = createEnv(fs, temp);
        Path pluginDir = createPluginDir(temp);
        String pluginZip = createPluginUrl(""fake"", pluginDir, ""requires.keystore"", ""true"");
        MockTerminal terminal = installPlugin(pluginZip, env.v1());
        assertTrue(Files.exists(KeyStoreWrapper.keystorePath(env.v2().configFile())));
    }","public void testKeystoreRequiredAlreadyExists() throws Exception {
        Tuple<Path, Environment> env = createEnv(fs, temp);
        KeyStoreWrapper keystore = KeyStoreWrapper.create(new char[0]);
        keystore.save(env.v2().configFile());
        byte[] expectedBytes = Files.readAllBytes(KeyStoreWrapper.keystorePath(env.v2().configFile()));
        Path pluginDir = createPluginDir(temp);
        String pluginZip = createPluginUrl(""fake"", pluginDir, ""requires.keystore"", ""true"");
        installPlugin(pluginZip, env.v1());
        byte[] gotBytes = Files.readAllBytes(KeyStoreWrapper.keystorePath(env.v2().configFile()));
        assertArrayEquals(""Keystore was modified"", expectedBytes, gotBytes);
    }",/distribution/tools/plugin-cli/src/test/java/org/elasticsearch/plugins/InstallPluginCommandTests.java
3dd833ca0a2b33159d78ad011b1c66df20a7192a,563,1169,"public void testKeystoreRequiredCreatedWithMetaPlugin() throws Exception {
        Tuple<Path, Environment> env = createEnv(fs, temp);
        Path metaDir = createPluginDir(temp);
        Path pluginDir = metaDir.resolve(""fake"");
        Files.createDirectory(pluginDir);
        writePlugin(""fake"", pluginDir, false, ""requires.keystore"", ""true"");
        String metaZip = createMetaPluginUrl(""my_plugins"", metaDir);
        MockTerminal terminal = installPlugin(metaZip, env.v1());
        assertTrue(Files.exists(KeyStoreWrapper.keystorePath(env.v2().configFile())));
    }","public void testKeystoreRequiredCreated() throws Exception {
        Tuple<Path, Environment> env = createEnv(fs, temp);
        Path pluginDir = createPluginDir(temp);
        String pluginZip = createPluginUrl(""fake"", pluginDir, ""requires.keystore"", ""true"");
        installPlugin(pluginZip, env.v1());
        assertTrue(Files.exists(KeyStoreWrapper.keystorePath(env.v2().configFile())));
    }",/distribution/tools/plugin-cli/src/test/java/org/elasticsearch/plugins/InstallPluginCommandTests.java
bc8745dcc27caca6d66e646e759017514a021b55,563,1328,"public void commit() throws IOException {
        ImmutableTranslogReader toClose = null;
        try (ReleasableLock lock = writeLock.acquire()) {
            ensureOpen();
            if (currentCommittingTranslog == null) {
                prepareCommit();
            }
            lastCommittedTranslogFileGeneration = current.getGeneration(); // this is important - otherwise old files will not be cleaned up
            if (recoveredTranslogs.isEmpty() == false) {
                IOUtils.close(recoveredTranslogs);
                recoveredTranslogs.clear();
            }
            toClose = this.currentCommittingTranslog;
            this.currentCommittingTranslog = null;
        } finally {
            IOUtils.close(toClose);
        }
    }","public void prepareCommit() throws IOException {
        try (ReleasableLock lock = writeLock.acquire()) {
            ensureOpen();
            if (currentCommittingTranslog != null) {
                throw new IllegalStateException(""already committing a translog with generation: "" + currentCommittingTranslog.getGeneration());
            }
            final TranslogWriter oldCurrent = current;
            oldCurrent.ensureOpen();
            oldCurrent.sync();
            currentCommittingTranslog = current.immutableReader();
            Path checkpoint = location.resolve(CHECKPOINT_FILE_NAME);
            assert Checkpoint.read(checkpoint).generation == currentCommittingTranslog.getGeneration();
            Path commitCheckpoint = location.resolve(getCommitCheckpointFileName(currentCommittingTranslog.getGeneration()));
            Files.copy(checkpoint, commitCheckpoint);
            IOUtils.fsync(commitCheckpoint, false);
            IOUtils.fsync(commitCheckpoint.getParent(), true);
            // create a new translog file - this will sync it and update the checkpoint data;
            current = createWriter(current.getGeneration() + 1);
            // notify all outstanding views of the new translog (no views are created now as
            // we hold a write lock).
            for (View view : outstandingViews) {
                view.onNewTranslog(currentCommittingTranslog.clone(), current.newReaderFromWriter());
            }
            IOUtils.close(oldCurrent);
            logger.trace(""current translog set to [{}]"", current.getGeneration());
            assert oldCurrent.syncNeeded() == false : ""old translog oldCurrent must not need a sync"";

        } catch (Throwable t) {
            IOUtils.closeWhileHandlingException(this); // tragic event
            throw t;
        }
    }",/core/src/main/java/org/elasticsearch/index/translog/Translog.java
bc8745dcc27caca6d66e646e759017514a021b55,563,495,"public void sync() throws IOException {
        try (ReleasableLock lock = readLock.acquire()) {
            if (closed.get() == false) {
                current.sync();
            }
        }
    }","public Translog.View newView() {
        // we need to acquire the read lock to make sure no new translog is created
        // and will be missed by the view we're making
        try (ReleasableLock lock = readLock.acquire()) {
            ArrayList<TranslogReader> translogs = new ArrayList<>();
            try {
                if (currentCommittingTranslog != null) {
                    translogs.add(currentCommittingTranslog.clone());
                }
                translogs.add(current.newReaderFromWriter());
                View view = new View(translogs, onViewClose);
                // this is safe as we know that no new translog is being made at the moment
                // (we hold a read lock) and the view will be notified of any future one
                outstandingViews.add(view);
                translogs.clear();
                return view;
            } finally {
                // close if anything happend and we didn't reach the clear
                IOUtils.closeWhileHandlingException(translogs);
            }
        }
    }",/core/src/main/java/org/elasticsearch/index/translog/Translog.java
bc8745dcc27caca6d66e646e759017514a021b55,567,135,"public Translog.Location add(BytesReference data) throws IOException {
        final long position;
        try (ReleasableLock lock = writeLock.acquire()) {
            ensureOpen();
            position = writtenOffset;
            data.writeTo(channel);
            writtenOffset = writtenOffset + data.length();
            operationCounter = operationCounter + 1;
        }
        return new Translog.Location(generation, position, data.length());
    }","protected final void closeWithTragicEvent(Throwable throwable) throws IOException {
        try (ReleasableLock lock = writeLock.acquire()) {
            if (tragedy == null) {
                tragedy = throwable;
            } else {
                tragedy.addSuppressed(throwable);
            }
            close();
        }
    }",/core/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java
bc8745dcc27caca6d66e646e759017514a021b55,662,662,"void ensureOpen() {
            if (closed) {
                throw new ElasticsearchException(""View is already closed"");
            }
        }","public synchronized int totalOperations() {
            int ops = 0;
            for (TranslogReader translog : orderedTranslogs) {
                int tops = translog.totalOperations();
                if (tops == TranslogReader.UNKNOWN_OP_COUNT) {
                    return -1;
                }
                assert tops >= 0;
                ops += tops;
            }
            return ops;
        }",/core/src/main/java/org/elasticsearch/index/translog/Translog.java
bc8745dcc27caca6d66e646e759017514a021b55,662,671,"public void close() {
            final List<TranslogReader> toClose = new ArrayList<>();
            try {
                synchronized (this) {
                    if (closed == false) {
                        try {
                            if (onClose != null) {
                                onClose.handle(this);
                            }
                        } finally {
                            closed = true;
                            toClose.addAll(orderedTranslogs);
                            orderedTranslogs.clear();
                        }
                    }
                }
            } finally {
                try {
                    // Close out of lock to prevent deadlocks between channel close which checks for
                    // references in InternalChannelReference.closeInternal (waiting on a read lock)
                    // and other FsTranslog#newTranslog calling FsView.onNewTranslog (while having a write lock)
                    IOUtils.close(toClose);
                } catch (Exception e) {
                    throw new ElasticsearchException(""failed to close view"", e);
                }
            }
        }","public synchronized long sizeInBytes() {
            long size = 0;
            for (TranslogReader translog : orderedTranslogs) {
                size += translog.sizeInBytes();
            }
            return size;
        }",/core/src/main/java/org/elasticsearch/index/translog/Translog.java
bc8745dcc27caca6d66e646e759017514a021b55,563,152,"public void sync() throws IOException {
        // check if we really need to sync here...
        if (syncNeeded()) {
            try (ReleasableLock lock = writeLock.acquire()) {
                lastSyncedOffset = writtenOffset;
                checkpoint(lastSyncedOffset, operationCounter, channelReference);
            }
        }
    }","public Translog.Location add(BytesReference data) throws IOException {
        final long position;
        try (ReleasableLock lock = writeLock.acquire()) {
            ensureOpen();
            position = writtenOffset;
            try {
                data.writeTo(channel);
            } catch (Throwable e) {
                closeWithTragicEvent(e);
                throw e;
            }
            writtenOffset = writtenOffset + data.length();
            operationCounter++;;
        }
        return new Translog.Location(generation, position, data.length());
    }",/core/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java
bc8745dcc27caca6d66e646e759017514a021b55,567,62,"public Translog.Location add(BytesReference data) throws IOException {
        try (ReleasableLock lock = writeLock.acquire()) {
            ensureOpen();
            operationCounter++;
            final long offset = totalOffset;
            if (data.length() >= buffer.length) {
                flush();
                // we use the channel to write, since on windows, writing to the RAF might not be reflected
                // when reading through the channel
                data.writeTo(channel);
                writtenOffset += data.length();
                totalOffset += data.length();
                return new Translog.Location(generation, offset, data.length());
            }
            if (data.length() > buffer.length - bufferCount) {
                flush();
            }
            data.writeTo(bufferOs);
            totalOffset += data.length();
            return new Translog.Location(generation, offset, data.length());
        }
    }","public Translog.Location add(BytesReference data) throws IOException {
        try (ReleasableLock lock = writeLock.acquire()) {
            ensureOpen();
            final long offset = totalOffset;
            if (data.length() >= buffer.length) {
                flush();
                // we use the channel to write, since on windows, writing to the RAF might not be reflected
                // when reading through the channel
                try {
                    data.writeTo(channel);
                } catch (Throwable ex) {
                    closeWithTragicEvent(ex);
                    throw ex;
                }
                writtenOffset += data.length();
                totalOffset += data.length();
            } else {
                if (data.length() > buffer.length - bufferCount) {
                    flush();
                }
                data.writeTo(bufferOs);
                totalOffset += data.length();
            }
            operationCounter++;
            return new Translog.Location(generation, offset, data.length());
        }
    }",/core/src/main/java/org/elasticsearch/index/translog/BufferingTranslogWriter.java
bc8745dcc27caca6d66e646e759017514a021b55,662,112,"public void sync() throws IOException {
        if (!syncNeeded()) {
            return;
        }
        synchronized (this) {
            channelReference.incRef();
            try {
                try (ReleasableLock lock = writeLock.acquire()) {
                    flush();
                    lastSyncedOffset = totalOffset;
                }
                // we can do this outside of the write lock but we have to protect from
                // concurrent syncs
                checkpoint(lastSyncedOffset, operationCounter, channelReference);
            } finally {
                channelReference.decRef();
            }
        }
    }","protected void readBytes(ByteBuffer targetBuffer, long position) throws IOException {
        try (ReleasableLock lock = readLock.acquire()) {
            if (position >= writtenOffset) {
                assert targetBuffer.hasArray() : ""buffer must have array"";
                final int sourcePosition = (int) (position - writtenOffset);
                System.arraycopy(buffer, sourcePosition,
                        targetBuffer.array(), targetBuffer.position(), targetBuffer.limit());
                targetBuffer.position(targetBuffer.limit());
                return;
            }
        }
        // we don't have to have a read lock here because we only write ahead to the file, so all writes has been complete
        // for the requested location.
        Channels.readFromFileChannelWithEofException(channel, position, targetBuffer);
    }",/core/src/main/java/org/elasticsearch/index/translog/BufferingTranslogWriter.java
bc8745dcc27caca6d66e646e759017514a021b55,563,537,"public TranslogStats stats() {
        // acquire lock to make the two numbers roughly consistent (no file change half way)
        try (ReleasableLock lock = readLock.acquire()) {
            return new TranslogStats(totalOperations(), sizeInBytes());
        }
    }","static String getCommitCheckpointFileName(long generation) {
        return TRANSLOG_FILE_PREFIX + generation + CHECKPOINT_SUFFIX;
    }",/core/src/main/java/org/elasticsearch/index/translog/Translog.java
bc8745dcc27caca6d66e646e759017514a021b55,563,130,"public void updateBufferSize(int bufferSize) {
        try (ReleasableLock lock = writeLock.acquire()) {
            ensureOpen();
            if (this.buffer.length != bufferSize) {
                flush();
                this.buffer = new byte[bufferSize];
            }
        } catch (IOException e) {
            throw new TranslogException(shardId, ""failed to flush"", e);
        }
    }","public synchronized void sync() throws IOException {
        if (syncNeeded()) {
            ensureOpen(); // this call gives a better exception that the incRef if we are closed by a tragic event
            channelReference.incRef();
            try {
                final long offsetToSync;
                final int opsCounter;
                try (ReleasableLock lock = writeLock.acquire()) {
                    flush();
                    offsetToSync = totalOffset;
                    opsCounter = operationCounter;
                }
                // we can do this outside of the write lock but we have to protect from
                // concurrent syncs
                ensureOpen(); // just for kicks - the checkpoint happens or not either way
                try {
                    checkpoint(offsetToSync, opsCounter, channelReference);
                } catch (Throwable ex) {
                    closeWithTragicEvent(ex);
                    throw ex;
                }
                lastSyncedOffset = offsetToSync;
            } finally {
                channelReference.decRef();
            }
        }
    }",/core/src/main/java/org/elasticsearch/index/translog/BufferingTranslogWriter.java
bc8745dcc27caca6d66e646e759017514a021b55,563,87,"protected void readBytes(ByteBuffer targetBuffer, long position) throws IOException {
        try (ReleasableLock lock = readLock.acquire()) {
            if (position >= writtenOffset) {
                assert targetBuffer.hasArray() : ""buffer must have array"";
                final int sourcePosition = (int) (position - writtenOffset);
                System.arraycopy(buffer, sourcePosition,
                        targetBuffer.array(), targetBuffer.position(), targetBuffer.limit());
                targetBuffer.position(targetBuffer.limit());
                return;
            }
        }
        // we don't have to have a read lock here because we only write ahead to the file, so all writes has been complete
        // for the requested location.
        Channels.readFromFileChannelWithEofException(channel, position, targetBuffer);
    }","protected final void flush() throws IOException {
        assert writeLock.isHeldByCurrentThread();
        if (bufferCount > 0) {
            ensureOpen();
            // we use the channel to write, since on windows, writing to the RAF might not be reflected
            // when reading through the channel
            final int bufferSize = bufferCount;
            try {
                Channels.writeToChannel(buffer, 0, bufferSize, channel);
            } catch (Throwable ex) {
                closeWithTragicEvent(ex);
                throw ex;
            }
            writtenOffset += bufferSize;
            bufferCount = 0;
        }
    }",/core/src/main/java/org/elasticsearch/index/translog/BufferingTranslogWriter.java
bc8745dcc27caca6d66e646e759017514a021b55,563,292,"public void close() throws IOException {
        if (closed.compareAndSet(false, true)) {
            try (ReleasableLock lock = writeLock.acquire()) {
                try {
                    IOUtils.close(current, currentCommittingTranslog);
                } finally {
                    IOUtils.close(recoveredTranslogs);
                    recoveredTranslogs.clear();
                }
            } finally {
                FutureUtils.cancel(syncScheduler);
                logger.debug(""translog closed"");
            }
        }
    }","public void close() throws IOException {
        if (closed.compareAndSet(false, true)) {
            try (ReleasableLock lock = writeLock.acquire()) {
                try {
                    current.sync();
                } finally {
                    try {
                        IOUtils.close(current, currentCommittingTranslog);
                    } finally {
                        IOUtils.close(recoveredTranslogs);
                        recoveredTranslogs.clear();
                    }
                }
            } finally {
                FutureUtils.cancel(syncScheduler);
                logger.debug(""translog closed"");
            }
        }
    }",/core/src/main/java/org/elasticsearch/index/translog/Translog.java
bc8745dcc27caca6d66e646e759017514a021b55,563,1369,"public TranslogGeneration getGeneration() {
        try (ReleasableLock lock = writeLock.acquire()) {
            return new TranslogGeneration(translogUUID, currentFileGeneration());
        }
    }","public void rollback() throws IOException {
        ensureOpen();
        close();
    }",/core/src/main/java/org/elasticsearch/index/translog/Translog.java
bc8745dcc27caca6d66e646e759017514a021b55,563,435,"public Snapshot newSnapshot() {
        try (ReleasableLock lock = readLock.acquire()) {
            ArrayList<TranslogReader> toOpen = new ArrayList<>();
            toOpen.addAll(recoveredTranslogs);
            if (currentCommittingTranslog != null) {
                toOpen.add(currentCommittingTranslog);
            }
            toOpen.add(current);
            return createSnapshot(toOpen.toArray(new TranslogReader[toOpen.size()]));
        }
    }","public Location add(Operation operation) throws IOException {
        final ReleasableBytesStreamOutput out = new ReleasableBytesStreamOutput(bigArrays);
        try {
            final BufferedChecksumStreamOutput checksumStreamOutput = new BufferedChecksumStreamOutput(out);
            final long start = out.position();
            out.skip(RamUsageEstimator.NUM_BYTES_INT);
            writeOperationNoSize(checksumStreamOutput, operation);
            final long end = out.position();
            final int operationSize = (int) (end - RamUsageEstimator.NUM_BYTES_INT - start);
            out.seek(start);
            out.writeInt(operationSize);
            out.seek(end);
            final ReleasablePagedBytesReference bytes = out.bytes();
            try (ReleasableLock lock = readLock.acquire()) {
                ensureOpen();
                Location location = current.add(bytes);
                if (config.isSyncOnEachOperation()) {
                    current.sync();
                }
                assert current.assertBytesAtLocation(location, bytes);
                return location;
            }
        } catch (AlreadyClosedException | IOException ex) {
            if (current.getTragicException() != null) {
                try {
                    close();
                } catch (Exception inner) {
                    ex.addSuppressed(inner);
                }
            }
            throw ex;
        } catch (Throwable e) {
            throw new TranslogException(shardId, ""Failed to write operation ["" + operation + ""]"", e);
        } finally {
            Releasables.close(out.bytes());
        }
    }",/core/src/main/java/org/elasticsearch/index/translog/Translog.java
bc8745dcc27caca6d66e646e759017514a021b55,563,818,"public List<Segment> segments(boolean verbose) {
        try (ReleasableLock lock = readLock.acquire()) {
            Segment[] segmentsArr = getSegmentInfo(lastCommittedSegmentInfos, verbose);

            // fill in the merges flag
            Set<OnGoingMerge> onGoingMerges = mergeScheduler.onGoingMerges();
            for (OnGoingMerge onGoingMerge : onGoingMerges) {
                for (SegmentCommitInfo segmentInfoPerCommit : onGoingMerge.getMergedSegments()) {
                    for (Segment segment : segmentsArr) {
                        if (segment.getName().equals(segmentInfoPerCommit.info.name)) {
                            segment.mergeId = onGoingMerge.getId();
                            break;
                        }
                    }
                }
            }
            return Arrays.asList(segmentsArr);
        }
    }","public long indexWriterRAMBytesUsed() {
        return indexWriter.ramBytesUsed();
    }",/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
bc8745dcc27caca6d66e646e759017514a021b55,691,1279,"static Translog.Operation newOperationFromType(Translog.Operation.Type type) throws IOException {
        switch (type) {
            case CREATE:
                // the deserialization logic in Index was identical to that of Create when create was deprecated
                return new Index();
            case DELETE:
                return new Translog.Delete();
            case INDEX:
                return new Index();
            default:
                throw new IOException(""No type for ["" + type + ""]"");
        }
    }","public static void writeOperations(StreamOutput outStream, List<Operation> toWrite) throws IOException {
        final ReleasableBytesStreamOutput out = new ReleasableBytesStreamOutput(BigArrays.NON_RECYCLING_INSTANCE);
        try {
            outStream.writeInt(toWrite.size());
            final BufferedChecksumStreamOutput checksumStreamOutput = new BufferedChecksumStreamOutput(out);
            for (Operation op : toWrite) {
                out.reset();
                final long start = out.position();
                out.skip(RamUsageEstimator.NUM_BYTES_INT);
                writeOperationNoSize(checksumStreamOutput, op);
                long end = out.position();
                int operationSize = (int) (out.position() - RamUsageEstimator.NUM_BYTES_INT - start);
                out.seek(start);
                out.writeInt(operationSize);
                out.seek(end);
                ReleasablePagedBytesReference bytes = out.bytes();
                bytes.writeTo(outStream);
            }
        } finally {
            Releasables.close(out.bytes());
        }

    }",/core/src/main/java/org/elasticsearch/index/translog/Translog.java
bc8745dcc27caca6d66e646e759017514a021b55,563,471,"public Translog.View newView() {
        // we need to acquire the read lock to make sure no new translog is created
        // and will be missed by the view we're making
        try (ReleasableLock lock = readLock.acquire()) {
            ArrayList<TranslogReader> translogs = new ArrayList<>();
            try {
                if (currentCommittingTranslog != null) {
                    translogs.add(currentCommittingTranslog.clone());
                }
                translogs.add(current.newReaderFromWriter());
                View view = new View(translogs, onViewClose);
                // this is safe as we know that no new translog is being made at the moment
                // (we hold a read lock) and the view will be notified of any future one
                outstandingViews.add(view);
                translogs.clear();
                return view;
            } finally {
                // close if anything happend and we didn't reach the clear
                IOUtils.closeWhileHandlingException(translogs);
            }
        }
    }","private static Snapshot createSnapshot(TranslogReader... translogs) {
        Snapshot[] snapshots = new Snapshot[translogs.length];
        boolean success = false;
        try {
            for (int i = 0; i < translogs.length; i++) {
                snapshots[i] = translogs[i].newSnapshot();
            }

            Snapshot snapshot = new MultiSnapshot(snapshots);
            success = true;
            return snapshot;
        } finally {
            if (success == false) {
                Releasables.close(snapshots);
            }
        }
    }",/core/src/main/java/org/elasticsearch/index/translog/Translog.java
b5d159bc1c83756b1a0f4d325041da2b2b6f6ab3,563,58,"public void testLookbackOnly() throws Exception {
        client().admin().indices().prepareCreate(""data-1"")
                .addMapping(""type"", ""time"", ""type=date"")
                .get();
        long numDocs = randomIntBetween(32, 2048);
        long now = System.currentTimeMillis();
        long oneWeekAgo = now - 604800000;
        long twoWeeksAgo = oneWeekAgo - 604800000;
        indexDocs(logger, ""data-1"", numDocs, twoWeeksAgo, oneWeekAgo);

        client().admin().indices().prepareCreate(""data-2"")
                .addMapping(""type"", ""time"", ""type=date"")
                .get();
        ClusterHealthResponse r = client().admin().cluster().prepareHealth(""data-1"", ""data-2"").setWaitForYellowStatus().get();
        long numDocs2 = randomIntBetween(32, 2048);
        indexDocs(logger, ""data-2"", numDocs2, oneWeekAgo, now);

        Job.Builder job = createScheduledJob(""lookback-job"");
        registerJob(job);
        PutJobAction.Response putJobResponse = putJob(job);
        assertTrue(putJobResponse.isAcknowledged());
        assertThat(putJobResponse.getResponse().getJobVersion(), equalTo(Version.CURRENT));
        openJob(job.getId());
        assertBusy(() -> {
            assertEquals(getJobStats(job.getId()).get(0).getState(), JobState.OPENED);
        });

        List<String> t = new ArrayList<>(2);
        t.add(""data-1"");
        t.add(""data-2"");
        DatafeedConfig datafeedConfig = createDatafeed(job.getId() + ""-datafeed"", job.getId(), t);
        registerDatafeed(datafeedConfig);
        assertTrue(putDatafeed(datafeedConfig).isAcknowledged());

        startDatafeed(datafeedConfig.getId(), 0L, now);
        assertBusy(() -> {
            DataCounts dataCounts = getDataCounts(job.getId());
            assertThat(dataCounts.getProcessedRecordCount(), equalTo(numDocs + numDocs2));
            assertThat(dataCounts.getOutOfOrderTimeStampCount(), equalTo(0L));

            GetDatafeedsStatsAction.Request request = new GetDatafeedsStatsAction.Request(datafeedConfig.getId());
            GetDatafeedsStatsAction.Response response = client().execute(GetDatafeedsStatsAction.INSTANCE, request).actionGet();
            assertThat(response.getResponse().results().get(0).getDatafeedState(), equalTo(DatafeedState.STOPPED));
        }, 60, TimeUnit.SECONDS);

        waitUntilJobIsClosed(job.getId());
    }","public void testLookbackOnly() throws Exception {
        client().admin().indices().prepareCreate(""data-1"")
                .addMapping(""type"", ""time"", ""type=date"")
                .get();
        long numDocs = randomIntBetween(32, 2048);
        long now = System.currentTimeMillis();
        long oneWeekAgo = now - 604800000;
        long twoWeeksAgo = oneWeekAgo - 604800000;
        indexDocs(logger, ""data-1"", numDocs, twoWeeksAgo, oneWeekAgo);

        client().admin().indices().prepareCreate(""data-2"")
                .addMapping(""type"", ""time"", ""type=date"")
                .get();
        client().admin().cluster().prepareHealth(""data-1"", ""data-2"").setWaitForYellowStatus().get();
        long numDocs2 = randomIntBetween(32, 2048);
        indexDocs(logger, ""data-2"", numDocs2, oneWeekAgo, now);

        Job.Builder job = createScheduledJob(""lookback-job"");
        registerJob(job);
        PutJobAction.Response putJobResponse = putJob(job);
        assertTrue(putJobResponse.isAcknowledged());
        assertThat(putJobResponse.getResponse().getJobVersion(), equalTo(Version.CURRENT));
        openJob(job.getId());
        assertBusy(() -> assertEquals(getJobStats(job.getId()).get(0).getState(), JobState.OPENED));

        List<String> t = new ArrayList<>(2);
        t.add(""data-1"");
        t.add(""data-2"");
        DatafeedConfig datafeedConfig = createDatafeed(job.getId() + ""-datafeed"", job.getId(), t);
        registerDatafeed(datafeedConfig);
        assertTrue(putDatafeed(datafeedConfig).isAcknowledged());

        startDatafeed(datafeedConfig.getId(), 0L, now);
        assertBusy(() -> {
            DataCounts dataCounts = getDataCounts(job.getId());
            assertThat(dataCounts.getProcessedRecordCount(), equalTo(numDocs + numDocs2));
            assertThat(dataCounts.getOutOfOrderTimeStampCount(), equalTo(0L));

            GetDatafeedsStatsAction.Request request = new GetDatafeedsStatsAction.Request(datafeedConfig.getId());
            GetDatafeedsStatsAction.Response response = client().execute(GetDatafeedsStatsAction.INSTANCE, request).actionGet();
            assertThat(response.getResponse().results().get(0).getDatafeedState(), equalTo(DatafeedState.STOPPED));
        }, 60, TimeUnit.SECONDS);

        waitUntilJobIsClosed(job.getId());
    }",/plugin/src/test/java/org/elasticsearch/xpack/ml/integration/DatafeedJobsIT.java
952097b1c063e566851eb4aea1af28cb1acaf9c2,563,53,"public void testDelayShards() throws Exception {
        logger.info(""--> starting 3 nodes"");
        List<String> nodes = internalCluster().startNodesAsync(3).get();

        // Wait for all 3 nodes to be up
        logger.info(""--> waiting for 3 nodes to be up"");
        assertBusy(() -> {
            NodesStatsResponse resp = client().admin().cluster().prepareNodesStats().get();
            assertThat(resp.getNodes().size(), equalTo(3));
        });

        logger.info(""--> creating 'test' index"");
        assertAcked(prepareCreate(""test"").setSettings(Settings.builder()
                .put(UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), ""1m"")
                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 5)
                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1))
                .setWaitForActiveShards(ActiveShardCount.ALL).get());

        logger.info(""--> stopping a random node"");
        assertTrue(internalCluster().stopRandomDataNode());

        ensureYellow(""test"");

        ClusterAllocationExplainResponse resp = client().admin().cluster().prepareAllocationExplain().useAnyUnassignedShard().get();
        ClusterAllocationExplanation cae = resp.getExplanation();
        assertThat(cae.getShard().getIndexName(), equalTo(""test""));
        assertFalse(cae.isPrimary());
        assertFalse(cae.isAssigned());
        assertThat(""expecting a remaining delay, got: "" + cae.getRemainingDelayMillis(), cae.getRemainingDelayMillis(), greaterThan(0L));
    }","public void testDelayShards() throws Exception {
        logger.info(""--> starting 3 nodes"");
        internalCluster().startNodesAsync(3).get();

        // Wait for all 3 nodes to be up
        logger.info(""--> waiting for 3 nodes to be up"");
        ensureStableCluster(3);

        logger.info(""--> creating 'test' index"");
        assertAcked(prepareCreate(""test"").setSettings(Settings.builder()
                .put(UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), ""1m"")
                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 5)
                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1))
                .setWaitForActiveShards(ActiveShardCount.ALL).get());

        logger.info(""--> stopping a random node"");
        assertTrue(internalCluster().stopRandomDataNode());

        logger.info(""--> waiting for the master to remove the stopped node from the cluster state"");
        ensureStableCluster(2);

        ClusterAllocationExplainResponse resp = client().admin().cluster().prepareAllocationExplain().useAnyUnassignedShard().get();
        ClusterAllocationExplanation cae = resp.getExplanation();
        assertThat(cae.getShard().getIndexName(), equalTo(""test""));
        assertFalse(cae.isPrimary());
        assertFalse(cae.isAssigned());
        assertThat(""expecting a remaining delay, got: "" + cae.getRemainingDelayMillis(), cae.getRemainingDelayMillis(), greaterThan(0L));
    }",/core/src/test/java/org/elasticsearch/action/admin/cluster/allocation/ClusterAllocationExplainIT.java
8b821706cc901cecdc7e9758f4074384bdd9896d,563,520,"public void testCorruptTranslogTruncationOfReplica() throws Exception {
        internalCluster().startNodes(2, Settings.EMPTY);

        final String node1 = internalCluster().getNodeNames()[0];
        final String node2 = internalCluster().getNodeNames()[1];
        logger.info(""--> nodes name: {}, {}"", node1, node2);

        final String indexName = ""test"";
        assertAcked(prepareCreate(indexName).setSettings(Settings.builder()
            .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)
            .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 1)
            .put(IndexSettings.INDEX_REFRESH_INTERVAL_SETTING.getKey(), ""-1"")
            .put(MockEngineSupport.DISABLE_FLUSH_ON_CLOSE.getKey(), true) // never flush - always recover from translog
            .put(""index.routing.allocation.exclude._name"", node2)
        ));
        ensureYellow();

        assertAcked(client().admin().indices().prepareUpdateSettings(indexName).setSettings(Settings.builder()
            .put(""index.routing.allocation.exclude._name"", (String)null)
        ));
        ensureGreen();

        // Index some documents
        int numDocsToKeep = randomIntBetween(0, 100);
        logger.info(""--> indexing [{}] docs to be kept"", numDocsToKeep);
        IndexRequestBuilder[] builders = new IndexRequestBuilder[numDocsToKeep];
        for (int i = 0; i < builders.length; i++) {
            builders[i] = client().prepareIndex(indexName, ""type"").setSource(""foo"", ""bar"");
        }
        indexRandom(false, false, false, Arrays.asList(builders));
        flush(indexName);
        disableTranslogFlush(indexName);
        // having no extra docs is an interesting case for seq no based recoveries - test it more often
        int numDocsToTruncate = randomBoolean() ? 0 : randomIntBetween(0, 100);
        logger.info(""--> indexing [{}] more docs to be truncated"", numDocsToTruncate);
        builders = new IndexRequestBuilder[numDocsToTruncate];
        for (int i = 0; i < builders.length; i++) {
            builders[i] = client().prepareIndex(indexName, ""type"").setSource(""foo"", ""bar"");
        }
        indexRandom(false, false, false, Arrays.asList(builders));
        final int totalDocs = numDocsToKeep + numDocsToTruncate;

        // sample the replica node translog dirs
        final ShardId shardId = new ShardId(resolveIndex(indexName), 0);
        final Set<Path> translogDirs = getDirs(node2, shardId, ShardPath.TRANSLOG_FOLDER_NAME);

        // stop the cluster nodes. we don't use full restart so the node start up order will be the same
        // and shard roles will be maintained
        internalCluster().stopRandomDataNode();
        internalCluster().stopRandomDataNode();

        // Corrupt the translog file(s)
        logger.info(""--> corrupting translog"");
        TestTranslog.corruptRandomTranslogFile(logger, random(), translogDirs);

        // Restart the single node
        logger.info(""--> starting node"");
        internalCluster().startNode();

        ensureYellow();

        // Run a search and make sure it succeeds
        assertHitCount(client().prepareSearch(indexName).setQuery(matchAllQuery()).get(), totalDocs);

        final RemoveCorruptedShardDataCommand command = new RemoveCorruptedShardDataCommand();
        final MockTerminal terminal = new MockTerminal();
        final OptionParser parser = command.getParser();

        final Environment environment = TestEnvironment.newEnvironment(internalCluster().getDefaultSettings());

        internalCluster().restartRandomDataNode(new InternalTestCluster.RestartCallback() {
            @Override
            public Settings onNodeStopped(String nodeName) throws Exception {
                logger.info(""--> node {} stopped"", nodeName);
                for (Path translogDir : translogDirs) {
                    final Path idxLocation = translogDir.getParent().resolve(ShardPath.INDEX_FOLDER_NAME);
                    assertBusy(() -> {
                        logger.info(""--> checking that lock has been released for {}"", idxLocation);
                        try (Directory dir = FSDirectory.open(idxLocation, NativeFSLockFactory.INSTANCE);
                             Lock writeLock = dir.obtainLock(IndexWriter.WRITE_LOCK_NAME)) {
                            // Great, do nothing, we just wanted to obtain the lock
                        }  catch (LockObtainFailedException lofe) {
                            logger.info(""--> failed acquiring lock for {}"", idxLocation);
                            fail(""still waiting for lock release at ["" + idxLocation + ""]"");
                        } catch (IOException ioe) {
                            fail(""Got an IOException: "" + ioe);
                        }
                    });

                    terminal.addTextInput(""y"");
                    OptionSet options = parser.parse(""-d"", translogDir.toAbsolutePath().toString());
                    logger.info(""--> running command for [{}]"", translogDir.toAbsolutePath());
                    command.execute(terminal, options, environment);
                    logger.info(""--> output:\n{}"", terminal.getOutput());
                }

                return super.onNodeStopped(nodeName);
            }
        });

        logger.info(""--> starting the replica node to test recovery"");
        internalCluster().startNode();
        ensureGreen(indexName);
        for (String node : internalCluster().nodesInclude(indexName)) {
            assertHitCount(client().prepareSearch(indexName)
                .setPreference(""_only_nodes:"" + node).setQuery(matchAllQuery()).get(), totalDocs);
        }

        final RecoveryResponse recoveryResponse = client().admin().indices().prepareRecoveries(indexName).setActiveOnly(false).get();
        final RecoveryState replicaRecoveryState = recoveryResponse.shardRecoveryStates().get(indexName).stream()
            .filter(recoveryState -> recoveryState.getPrimary() == false).findFirst().get();
        // the replica translog was disabled so it doesn't know what hte global checkpoint is and thus can't do ops based recovery
        assertThat(replicaRecoveryState.getIndex().toString(), replicaRecoveryState.getIndex().recoveredFileCount(), greaterThan(0));
        // Ensure that the global checkpoint and local checkpoint are restored from the max seqno of the last commit.
        final SeqNoStats seqNoStats = getSeqNoStats(indexName, 0);
        assertThat(seqNoStats.getGlobalCheckpoint(), equalTo(seqNoStats.getMaxSeqNo()));
        assertThat(seqNoStats.getLocalCheckpoint(), equalTo(seqNoStats.getMaxSeqNo()));
    }","public void testCorruptTranslogTruncationOfReplica() throws Exception {
        internalCluster().startMasterOnlyNode();

        final String node1 = internalCluster().startDataOnlyNode();
        final String node2 = internalCluster().startDataOnlyNode();
        logger.info(""--> nodes name: {}, {}"", node1, node2);

        final String indexName = ""test"";
        assertAcked(prepareCreate(indexName).setSettings(Settings.builder()
            .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)
            .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 1)
            .put(IndexSettings.INDEX_REFRESH_INTERVAL_SETTING.getKey(), ""-1"")
            .put(MockEngineSupport.DISABLE_FLUSH_ON_CLOSE.getKey(), true) // never flush - always recover from translog
            .put(""index.routing.allocation.exclude._name"", node2)
        ));
        ensureYellow();

        assertAcked(client().admin().indices().prepareUpdateSettings(indexName).setSettings(Settings.builder()
            .put(""index.routing.allocation.exclude._name"", (String)null)
        ));
        ensureGreen();

        // Index some documents
        int numDocsToKeep = randomIntBetween(0, 100);
        logger.info(""--> indexing [{}] docs to be kept"", numDocsToKeep);
        IndexRequestBuilder[] builders = new IndexRequestBuilder[numDocsToKeep];
        for (int i = 0; i < builders.length; i++) {
            builders[i] = client().prepareIndex(indexName, ""type"").setSource(""foo"", ""bar"");
        }
        indexRandom(false, false, false, Arrays.asList(builders));
        flush(indexName);
        disableTranslogFlush(indexName);
        // having no extra docs is an interesting case for seq no based recoveries - test it more often
        int numDocsToTruncate = randomBoolean() ? 0 : randomIntBetween(0, 100);
        logger.info(""--> indexing [{}] more docs to be truncated"", numDocsToTruncate);
        builders = new IndexRequestBuilder[numDocsToTruncate];
        for (int i = 0; i < builders.length; i++) {
            builders[i] = client().prepareIndex(indexName, ""type"").setSource(""foo"", ""bar"");
        }
        indexRandom(false, false, false, Arrays.asList(builders));
        final int totalDocs = numDocsToKeep + numDocsToTruncate;

        // sample the replica node translog dirs
        final ShardId shardId = new ShardId(resolveIndex(indexName), 0);
        final Set<Path> translogDirs = getDirs(node2, shardId, ShardPath.TRANSLOG_FOLDER_NAME);

        // stop data nodes. After the restart the 1st node will be primary and the 2nd node will be replica
        internalCluster().stopRandomDataNode();
        internalCluster().stopRandomDataNode();

        // Corrupt the translog file(s) on the replica
        logger.info(""--> corrupting translog"");
        TestTranslog.corruptRandomTranslogFile(logger, random(), translogDirs);

        // Restart the single node
        logger.info(""--> starting node"");
        internalCluster().startNode();

        ensureYellow();

        // Run a search and make sure it succeeds
        assertHitCount(client().prepareSearch(indexName).setQuery(matchAllQuery()).get(), totalDocs);

        final RemoveCorruptedShardDataCommand command = new RemoveCorruptedShardDataCommand();
        final MockTerminal terminal = new MockTerminal();
        final OptionParser parser = command.getParser();

        final Environment environment = TestEnvironment.newEnvironment(internalCluster().getDefaultSettings());

        internalCluster().restartRandomDataNode(new InternalTestCluster.RestartCallback() {
            @Override
            public Settings onNodeStopped(String nodeName) throws Exception {
                logger.info(""--> node {} stopped"", nodeName);
                for (Path translogDir : translogDirs) {
                    final Path idxLocation = translogDir.getParent().resolve(ShardPath.INDEX_FOLDER_NAME);
                    assertBusy(() -> {
                        logger.info(""--> checking that lock has been released for {}"", idxLocation);
                        try (Directory dir = FSDirectory.open(idxLocation, NativeFSLockFactory.INSTANCE);
                             Lock writeLock = dir.obtainLock(IndexWriter.WRITE_LOCK_NAME)) {
                            // Great, do nothing, we just wanted to obtain the lock
                        }  catch (LockObtainFailedException lofe) {
                            logger.info(""--> failed acquiring lock for {}"", idxLocation);
                            fail(""still waiting for lock release at ["" + idxLocation + ""]"");
                        } catch (IOException ioe) {
                            fail(""Got an IOException: "" + ioe);
                        }
                    });

                    terminal.addTextInput(""y"");
                    OptionSet options = parser.parse(""-d"", translogDir.toAbsolutePath().toString());
                    logger.info(""--> running command for [{}]"", translogDir.toAbsolutePath());
                    command.execute(terminal, options, environment);
                    logger.info(""--> output:\n{}"", terminal.getOutput());
                }

                return super.onNodeStopped(nodeName);
            }
        });

        logger.info(""--> starting the replica node to test recovery"");
        internalCluster().startNode();
        ensureGreen(indexName);
        for (String node : internalCluster().nodesInclude(indexName)) {
            assertHitCount(client().prepareSearch(indexName)
                .setPreference(""_only_nodes:"" + node).setQuery(matchAllQuery()).get(), totalDocs);
        }

        final RecoveryResponse recoveryResponse = client().admin().indices().prepareRecoveries(indexName).setActiveOnly(false).get();
        final RecoveryState replicaRecoveryState = recoveryResponse.shardRecoveryStates().get(indexName).stream()
            .filter(recoveryState -> recoveryState.getPrimary() == false).findFirst().get();
        // the replica translog was disabled so it doesn't know what hte global checkpoint is and thus can't do ops based recovery
        assertThat(replicaRecoveryState.getIndex().toString(), replicaRecoveryState.getIndex().recoveredFileCount(), greaterThan(0));
        // Ensure that the global checkpoint and local checkpoint are restored from the max seqno of the last commit.
        final SeqNoStats seqNoStats = getSeqNoStats(indexName, 0);
        assertThat(seqNoStats.getGlobalCheckpoint(), equalTo(seqNoStats.getMaxSeqNo()));
        assertThat(seqNoStats.getLocalCheckpoint(), equalTo(seqNoStats.getMaxSeqNo()));
    }",/server/src/test/java/org/elasticsearch/index/shard/RemoveCorruptedShardDataCommandIT.java
8b821706cc901cecdc7e9758f4074384bdd9896d,563,352,"public void testCorruptTranslogTruncation() throws Exception {
        internalCluster().startNodes(2, Settings.EMPTY);

        final String node1 = internalCluster().getNodeNames()[0];
        final String node2 = internalCluster().getNodeNames()[1];

        final String indexName = ""test"";
        assertAcked(prepareCreate(indexName).setSettings(Settings.builder()
            .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)
            .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 1)
            .put(IndexSettings.INDEX_REFRESH_INTERVAL_SETTING.getKey(), ""-1"")
            .put(MockEngineSupport.DISABLE_FLUSH_ON_CLOSE.getKey(), true) // never flush - always recover from translog
            .put(""index.routing.allocation.exclude._name"", node2)
        ));
        ensureYellow();

        assertAcked(client().admin().indices().prepareUpdateSettings(indexName).setSettings(Settings.builder()
            .put(""index.routing.allocation.exclude._name"", (String)null)
        ));
        ensureGreen();

        // Index some documents
        int numDocsToKeep = randomIntBetween(10, 100);
        logger.info(""--> indexing [{}] docs to be kept"", numDocsToKeep);
        IndexRequestBuilder[] builders = new IndexRequestBuilder[numDocsToKeep];
        for (int i = 0; i < builders.length; i++) {
            builders[i] = client().prepareIndex(indexName, ""type"").setSource(""foo"", ""bar"");
        }
        indexRandom(false, false, false, Arrays.asList(builders));
        flush(indexName);

        disableTranslogFlush(indexName);
        // having no extra docs is an interesting case for seq no based recoveries - test it more often
        int numDocsToTruncate = randomBoolean() ? 0 : randomIntBetween(0, 100);
        logger.info(""--> indexing [{}] more doc to be truncated"", numDocsToTruncate);
        builders = new IndexRequestBuilder[numDocsToTruncate];
        for (int i = 0; i < builders.length; i++) {
            builders[i] = client().prepareIndex(indexName, ""type"").setSource(""foo"", ""bar"");
        }
        indexRandom(false, false, false, Arrays.asList(builders));
        Set<Path> translogDirs = getDirs(indexName, ShardPath.TRANSLOG_FOLDER_NAME);

        RemoveCorruptedShardDataCommand command = new RemoveCorruptedShardDataCommand();
        MockTerminal terminal = new MockTerminal();
        OptionParser parser = command.getParser();

        if (randomBoolean() && numDocsToTruncate > 0) {
            // flush the replica, so it will have more docs than what the primary will have
            Index index = resolveIndex(indexName);
            IndexShard replica = internalCluster().getInstance(IndicesService.class, node2).getShardOrNull(new ShardId(index, 0));
            replica.flush(new FlushRequest());
            logger.info(""--> performed extra flushing on replica"");
        }

        // shut down the replica node to be tested later
        internalCluster().stopRandomNode(InternalTestCluster.nameFilter(node2));

        // Corrupt the translog file(s)
        logger.info(""--> corrupting translog"");
        corruptRandomTranslogFiles(indexName);

        // Restart the single node
        logger.info(""--> restarting node"");
        internalCluster().restartRandomDataNode();

        // all shards should be failed due to a corrupted translog
        assertBusy(() -> {
            final ClusterAllocationExplanation explanation =
                client().admin().cluster().prepareAllocationExplain()
                    .setIndex(indexName).setShard(0).setPrimary(true)
                    .get().getExplanation();

            final UnassignedInfo unassignedInfo = explanation.getUnassignedInfo();
            assertThat(unassignedInfo.getReason(), equalTo(UnassignedInfo.Reason.ALLOCATION_FAILED));
        });

        // have to shut down primary node - otherwise node lock is present
        final InternalTestCluster.RestartCallback callback =
            new InternalTestCluster.RestartCallback() {
                @Override
                public Settings onNodeStopped(String nodeName) throws Exception {
                    // and we can actually truncate the translog
                    for (Path translogDir : translogDirs) {
                        final Path idxLocation = translogDir.getParent().resolve(ShardPath.INDEX_FOLDER_NAME);
                        assertBusy(() -> {
                            logger.info(""--> checking that lock has been released for {}"", idxLocation);
                            try (Directory dir = FSDirectory.open(idxLocation, NativeFSLockFactory.INSTANCE);
                                 Lock writeLock = dir.obtainLock(IndexWriter.WRITE_LOCK_NAME)) {
                                // Great, do nothing, we just wanted to obtain the lock
                            } catch (LockObtainFailedException lofe) {
                                logger.info(""--> failed acquiring lock for {}"", idxLocation);
                                fail(""still waiting for lock release at ["" + idxLocation + ""]"");
                            } catch (IOException ioe) {
                                fail(""Got an IOException: "" + ioe);
                            }
                        });

                        final Settings defaultSettings = internalCluster().getDefaultSettings();
                        final Environment environment = TestEnvironment.newEnvironment(defaultSettings);

                        terminal.addTextInput(""y"");
                        OptionSet options = parser.parse(""-d"", translogDir.toAbsolutePath().toString());
                        logger.info(""--> running command for [{}]"", translogDir.toAbsolutePath());
                        command.execute(terminal, options, environment);
                        logger.info(""--> output:\n{}"", terminal.getOutput());
                    }

                    return super.onNodeStopped(nodeName);
                }
            };
        internalCluster().restartNode(node1, callback);

        String primaryNodeId = null;
        final ClusterState state = client().admin().cluster().prepareState().get().getState();
        final DiscoveryNodes nodes = state.nodes();
        for (ObjectObjectCursor<String, DiscoveryNode> cursor : nodes.getNodes()) {
            final String name = cursor.value.getName();
            if (name.equals(node1)) {
                primaryNodeId = cursor.key;
                break;
            }
        }
        assertThat(primaryNodeId, notNullValue());

        assertThat(terminal.getOutput(), containsString(""allocate_stale_primary""));
        assertThat(terminal.getOutput(), containsString(""\""node\"" : \"""" + primaryNodeId + ""\""""));

        // there is only _stale_ primary (due to new allocation id)
        assertBusy(() -> {
            final ClusterAllocationExplanation explanation =
                client().admin().cluster().prepareAllocationExplain()
                    .setIndex(indexName).setShard(0).setPrimary(true)
                    .get().getExplanation();

            final ShardAllocationDecision shardAllocationDecision = explanation.getShardAllocationDecision();
            assertThat(shardAllocationDecision.isDecisionTaken(), equalTo(true));
            assertThat(shardAllocationDecision.getAllocateDecision().getAllocationDecision(),
                equalTo(AllocationDecision.NO_VALID_SHARD_COPY));
        });

        client().admin().cluster().prepareReroute()
            .add(new AllocateStalePrimaryAllocationCommand(indexName, 0, primaryNodeId, true))
            .get();

        assertBusy(() -> {
            final ClusterAllocationExplanation explanation =
                client().admin().cluster().prepareAllocationExplain()
                    .setIndex(indexName).setShard(0).setPrimary(true)
                    .get().getExplanation();

            assertThat(explanation.getCurrentNode(), notNullValue());
            assertThat(explanation.getShardState(), equalTo(ShardRoutingState.STARTED));
        });

        ensureYellow(indexName);

        // Run a search and make sure it succeeds
        assertHitCount(client().prepareSearch(indexName).setQuery(matchAllQuery()).get(), numDocsToKeep);

        logger.info(""--> starting the replica node to test recovery"");
        internalCluster().startNode();
        ensureGreen(indexName);
        for (String node : internalCluster().nodesInclude(indexName)) {
            SearchRequestBuilder q = client().prepareSearch(indexName).setPreference(""_only_nodes:"" + node).setQuery(matchAllQuery());
            assertHitCount(q.get(), numDocsToKeep);
        }
        final RecoveryResponse recoveryResponse = client().admin().indices().prepareRecoveries(indexName).setActiveOnly(false).get();
        final RecoveryState replicaRecoveryState = recoveryResponse.shardRecoveryStates().get(indexName).stream()
            .filter(recoveryState -> recoveryState.getPrimary() == false).findFirst().get();
        assertThat(replicaRecoveryState.getIndex().toString(), replicaRecoveryState.getIndex().recoveredFileCount(), greaterThan(0));
        // Ensure that the global checkpoint and local checkpoint are restored from the max seqno of the last commit.
        final SeqNoStats seqNoStats = getSeqNoStats(indexName, 0);
        assertThat(seqNoStats.getGlobalCheckpoint(), equalTo(seqNoStats.getMaxSeqNo()));
        assertThat(seqNoStats.getLocalCheckpoint(), equalTo(seqNoStats.getMaxSeqNo()));
    }","public void testCorruptTranslogTruncation() throws Exception {
        internalCluster().startNodes(2);

        final String node1 = internalCluster().getNodeNames()[0];
        final String node2 = internalCluster().getNodeNames()[1];

        final String indexName = ""test"";
        assertAcked(prepareCreate(indexName).setSettings(Settings.builder()
            .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)
            .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 1)
            .put(IndexSettings.INDEX_REFRESH_INTERVAL_SETTING.getKey(), ""-1"")
            .put(MockEngineSupport.DISABLE_FLUSH_ON_CLOSE.getKey(), true) // never flush - always recover from translog
            .put(""index.routing.allocation.exclude._name"", node2)
        ));
        ensureYellow();

        assertAcked(client().admin().indices().prepareUpdateSettings(indexName).setSettings(Settings.builder()
            .put(""index.routing.allocation.exclude._name"", (String)null)
        ));
        ensureGreen();

        // Index some documents
        int numDocsToKeep = randomIntBetween(10, 100);
        logger.info(""--> indexing [{}] docs to be kept"", numDocsToKeep);
        IndexRequestBuilder[] builders = new IndexRequestBuilder[numDocsToKeep];
        for (int i = 0; i < builders.length; i++) {
            builders[i] = client().prepareIndex(indexName, ""type"").setSource(""foo"", ""bar"");
        }
        indexRandom(false, false, false, Arrays.asList(builders));
        flush(indexName);

        disableTranslogFlush(indexName);
        // having no extra docs is an interesting case for seq no based recoveries - test it more often
        int numDocsToTruncate = randomBoolean() ? 0 : randomIntBetween(0, 100);
        logger.info(""--> indexing [{}] more doc to be truncated"", numDocsToTruncate);
        builders = new IndexRequestBuilder[numDocsToTruncate];
        for (int i = 0; i < builders.length; i++) {
            builders[i] = client().prepareIndex(indexName, ""type"").setSource(""foo"", ""bar"");
        }
        indexRandom(false, false, false, Arrays.asList(builders));
        Set<Path> translogDirs = getDirs(indexName, ShardPath.TRANSLOG_FOLDER_NAME);

        RemoveCorruptedShardDataCommand command = new RemoveCorruptedShardDataCommand();
        MockTerminal terminal = new MockTerminal();
        OptionParser parser = command.getParser();

        if (randomBoolean() && numDocsToTruncate > 0) {
            // flush the replica, so it will have more docs than what the primary will have
            Index index = resolveIndex(indexName);
            IndexShard replica = internalCluster().getInstance(IndicesService.class, node2).getShardOrNull(new ShardId(index, 0));
            replica.flush(new FlushRequest());
            logger.info(""--> performed extra flushing on replica"");
        }

        // shut down the replica node to be tested later
        internalCluster().stopRandomNode(InternalTestCluster.nameFilter(node2));

        // Corrupt the translog file(s)
        logger.info(""--> corrupting translog"");
        corruptRandomTranslogFiles(indexName);

        // Restart the single node
        logger.info(""--> restarting node"");
        internalCluster().restartRandomDataNode();

        // all shards should be failed due to a corrupted translog
        assertBusy(() -> {
            final ClusterAllocationExplanation explanation =
                client().admin().cluster().prepareAllocationExplain()
                    .setIndex(indexName).setShard(0).setPrimary(true)
                    .get().getExplanation();

            final UnassignedInfo unassignedInfo = explanation.getUnassignedInfo();
            assertThat(unassignedInfo.getReason(), equalTo(UnassignedInfo.Reason.ALLOCATION_FAILED));
        });

        // have to shut down primary node - otherwise node lock is present
        final InternalTestCluster.RestartCallback callback =
            new InternalTestCluster.RestartCallback() {
                @Override
                public Settings onNodeStopped(String nodeName) throws Exception {
                    // and we can actually truncate the translog
                    for (Path translogDir : translogDirs) {
                        final Path idxLocation = translogDir.getParent().resolve(ShardPath.INDEX_FOLDER_NAME);
                        assertBusy(() -> {
                            logger.info(""--> checking that lock has been released for {}"", idxLocation);
                            try (Directory dir = FSDirectory.open(idxLocation, NativeFSLockFactory.INSTANCE);
                                 Lock writeLock = dir.obtainLock(IndexWriter.WRITE_LOCK_NAME)) {
                                // Great, do nothing, we just wanted to obtain the lock
                            } catch (LockObtainFailedException lofe) {
                                logger.info(""--> failed acquiring lock for {}"", idxLocation);
                                fail(""still waiting for lock release at ["" + idxLocation + ""]"");
                            } catch (IOException ioe) {
                                fail(""Got an IOException: "" + ioe);
                            }
                        });

                        final Settings defaultSettings = internalCluster().getDefaultSettings();
                        final Environment environment = TestEnvironment.newEnvironment(defaultSettings);

                        terminal.addTextInput(""y"");
                        OptionSet options = parser.parse(""-d"", translogDir.toAbsolutePath().toString());
                        logger.info(""--> running command for [{}]"", translogDir.toAbsolutePath());
                        command.execute(terminal, options, environment);
                        logger.info(""--> output:\n{}"", terminal.getOutput());
                    }

                    return super.onNodeStopped(nodeName);
                }
            };
        internalCluster().restartNode(node1, callback);

        String primaryNodeId = null;
        final ClusterState state = client().admin().cluster().prepareState().get().getState();
        final DiscoveryNodes nodes = state.nodes();
        for (ObjectObjectCursor<String, DiscoveryNode> cursor : nodes.getNodes()) {
            final String name = cursor.value.getName();
            if (name.equals(node1)) {
                primaryNodeId = cursor.key;
                break;
            }
        }
        assertThat(primaryNodeId, notNullValue());

        assertThat(terminal.getOutput(), containsString(""allocate_stale_primary""));
        assertThat(terminal.getOutput(), containsString(""\""node\"" : \"""" + primaryNodeId + ""\""""));

        // there is only _stale_ primary (due to new allocation id)
        assertBusy(() -> {
            final ClusterAllocationExplanation explanation =
                client().admin().cluster().prepareAllocationExplain()
                    .setIndex(indexName).setShard(0).setPrimary(true)
                    .get().getExplanation();

            final ShardAllocationDecision shardAllocationDecision = explanation.getShardAllocationDecision();
            assertThat(shardAllocationDecision.isDecisionTaken(), equalTo(true));
            assertThat(shardAllocationDecision.getAllocateDecision().getAllocationDecision(),
                equalTo(AllocationDecision.NO_VALID_SHARD_COPY));
        });

        client().admin().cluster().prepareReroute()
            .add(new AllocateStalePrimaryAllocationCommand(indexName, 0, primaryNodeId, true))
            .get();

        assertBusy(() -> {
            final ClusterAllocationExplanation explanation =
                client().admin().cluster().prepareAllocationExplain()
                    .setIndex(indexName).setShard(0).setPrimary(true)
                    .get().getExplanation();

            assertThat(explanation.getCurrentNode(), notNullValue());
            assertThat(explanation.getShardState(), equalTo(ShardRoutingState.STARTED));
        });

        ensureYellow(indexName);

        // Run a search and make sure it succeeds
        assertHitCount(client().prepareSearch(indexName).setQuery(matchAllQuery()).get(), numDocsToKeep);

        logger.info(""--> starting the replica node to test recovery"");
        internalCluster().startNode();
        ensureGreen(indexName);
        for (String node : internalCluster().nodesInclude(indexName)) {
            SearchRequestBuilder q = client().prepareSearch(indexName).setPreference(""_only_nodes:"" + node).setQuery(matchAllQuery());
            assertHitCount(q.get(), numDocsToKeep);
        }
        final RecoveryResponse recoveryResponse = client().admin().indices().prepareRecoveries(indexName).setActiveOnly(false).get();
        final RecoveryState replicaRecoveryState = recoveryResponse.shardRecoveryStates().get(indexName).stream()
            .filter(recoveryState -> recoveryState.getPrimary() == false).findFirst().get();
        assertThat(replicaRecoveryState.getIndex().toString(), replicaRecoveryState.getIndex().recoveredFileCount(), greaterThan(0));
        // Ensure that the global checkpoint and local checkpoint are restored from the max seqno of the last commit.
        final SeqNoStats seqNoStats = getSeqNoStats(indexName, 0);
        assertThat(seqNoStats.getGlobalCheckpoint(), equalTo(seqNoStats.getMaxSeqNo()));
        assertThat(seqNoStats.getLocalCheckpoint(), equalTo(seqNoStats.getMaxSeqNo()));
    }",/server/src/test/java/org/elasticsearch/index/shard/RemoveCorruptedShardDataCommandIT.java
3175b10605f5f5a164ad40d999c6205612bf493a,688,44,"public void testNewTrialAllowed() {
        var randomVersion = new TrialLicenseVersion(randomNonNegativeInt());
        var subsequentVersion = new TrialLicenseVersion(
            randomVersion.asInt() + randomIntBetween(0, Integer.MAX_VALUE - randomVersion.asInt())
        );
        assertFalse(randomVersion.ableToStartNewTrialSince(randomVersion));
        assertTrue(subsequentVersion.ableToStartNewTrialSince(randomVersion));
    }","public void testNewTrialAllowed() {
        assertTrue(new TrialLicenseVersion(randomIntBetween(7_00_00_00, 7_99_99_99)).ableToStartNewTrial());
        assertFalse(new TrialLicenseVersion(CURRENT.asInt()).ableToStartNewTrial());
        assertFalse(new TrialLicenseVersion(randomIntBetween(8_00_00_00, TRIAL_VERSION_CUTOVER)).ableToStartNewTrial());
        final int trialVersion = randomIntBetween(TRIAL_VERSION_CUTOVER, CURRENT.asInt());
        if (trialVersion < CURRENT.asInt()) {
            assertTrue(new TrialLicenseVersion(trialVersion).ableToStartNewTrial());
        } else {
            assertFalse(new TrialLicenseVersion(trialVersion).ableToStartNewTrial());
        }
    }",/x-pack/plugin/core/src/test/java/org/elasticsearch/license/internal/TrialLicenseVersionTests.java
e83c728265651aff4c895d1efeccae45e07d2914,563,525,"public boolean syncNeeded() {
        try (ReleasableLock lock = readLock.acquire()) {
            return current.syncNeeded();
        }
    }","static String getCommitCheckpointFileName(long generation) {
        return TRANSLOG_FILE_PREFIX + generation + CHECKPOINT_SUFFIX;
    }",/core/src/main/java/org/elasticsearch/index/translog/Translog.java
e83c728265651aff4c895d1efeccae45e07d2914,563,508,"public void sync() throws IOException {
        try (ReleasableLock lock = readLock.acquire()) {
            if (closed.get() == false) {
                current.sync();
            }
        } catch (AlreadyClosedException | IOException ex) {
            if (current.getTragicException() != null) {
                try {
                    close();
                } catch (Exception inner) {
                    ex.addSuppressed(inner);
                }
            }
            throw ex;
        }
    }","public void sync() throws IOException {
        try (ReleasableLock lock = readLock.acquire()) {
            if (closed.get() == false) {
                current.sync();
            }
        } catch (AlreadyClosedException | IOException ex) {
            closeOnTragicEvent(ex);
            throw ex;
        }
    }",/core/src/main/java/org/elasticsearch/index/translog/Translog.java
a2372778ddb7445282f8a977b81464afcc631b12,563,222,"public long roundKey(long utcMillis) {
            long timeLocal = utcMillis;
            timeLocal = timeZone.convertUTCToLocal(utcMillis);
            long rounded = Rounding.Interval.roundValue(Rounding.Interval.roundKey(timeLocal, interval), interval);
            return timeZone.convertLocalToUTC(rounded, false);
        }","public long roundKey(long utcMillis) {
            long timeLocal = timeZone.convertUTCToLocal(utcMillis);
            long rounded = Rounding.Interval.roundValue(Rounding.Interval.roundKey(timeLocal, interval), interval);
            return timeZone.convertLocalToUTC(rounded, false, utcMillis);
        }",/core/src/main/java/org/elasticsearch/common/rounding/TimeZoneRounding.java
e03b0a5329f7cb230831dd566724956b6c4e855e,563,219,"public void testMultipleSlowLoggersUseSingleLog4jLogger() {
        LoggerContext context = (LoggerContext) LogManager.getContext(false);

        SearchContext ctx1 = searchContextWithSourceAndTask(createIndex(""index-1""));
        IndexSettings settings1 = new IndexSettings(createIndexMetadata(""index-1"", settings(UUIDs.randomBase64UUID())), Settings.EMPTY);
        SearchSlowLog log1 = new SearchSlowLog(settings1);
        int numberOfLoggersBefore = context.getLoggers().size();

        SearchContext ctx2 = searchContextWithSourceAndTask(createIndex(""index-2""));
        IndexSettings settings2 = new IndexSettings(createIndexMetadata(""index-2"", settings(UUIDs.randomBase64UUID())), Settings.EMPTY);
        SearchSlowLog log2 = new SearchSlowLog(settings2);

        int numberOfLoggersAfter = context.getLoggers().size();
        assertThat(numberOfLoggersAfter, equalTo(numberOfLoggersBefore));
    }","public void testMultipleSlowLoggersUseSingleLog4jLogger() {
        LoggerContext context = (LoggerContext) LogManager.getContext(false);

        try (SearchContext ctx1 = searchContextWithSourceAndTask(createIndex(""index-1""))) {
            IndexSettings settings1 = new IndexSettings(createIndexMetadata(""index-1"", settings(UUIDs.randomBase64UUID())), Settings.EMPTY);
            SearchSlowLog log1 = new SearchSlowLog(settings1);
            int numberOfLoggersBefore = context.getLoggers().size();

            try (SearchContext ctx2 = searchContextWithSourceAndTask(createIndex(""index-2""))) {
                IndexSettings settings2 = new IndexSettings(
                    createIndexMetadata(""index-2"", settings(UUIDs.randomBase64UUID())),
                    Settings.EMPTY
                );
                SearchSlowLog log2 = new SearchSlowLog(settings2);

                int numberOfLoggersAfter = context.getLoggers().size();
                assertThat(numberOfLoggersAfter, equalTo(numberOfLoggersBefore));
            }
        }
    }",/server/src/test/java/org/elasticsearch/index/SearchSlowLogTests.java
e03b0a5329f7cb230831dd566724956b6c4e855e,697,991,"private static void assertSortResults(TopDocs topDocs, long totalNumDocs, boolean isDoubleSort) {
        assertEquals(TotalHits.Relation.GREATER_THAN_OR_EQUAL_TO, topDocs.totalHits.relation);
        assertThat(topDocs.totalHits.value, lessThan(totalNumDocs)); // we collected less docs than total number
        long cur1, cur2;
        long prev1 = Long.MIN_VALUE;
        long prev2 = Long.MIN_VALUE;
        for (ScoreDoc scoreDoc : topDocs.scoreDocs) {
            cur1 = (long) ((FieldDoc) scoreDoc).fields[0];
            assertThat(cur1, greaterThan(prev1)); // test that docs are properly sorted on the first sort
            if (isDoubleSort) {
                cur2 = (long) ((FieldDoc) scoreDoc).fields[1];
                if (cur1 == prev1) {
                    assertThat(cur2, greaterThan(prev2)); // test that docs are properly sorted on the secondary sort
                }
                prev2 = cur2;
            }
            prev1 = cur1;
        }
    }","public void testMinScore() throws Exception {
        IndexWriterConfig iwc = newIndexWriterConfig();
        RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);
        for (int i = 0; i < 10; i++) {
            Document doc = new Document();
            doc.add(new StringField(""foo"", ""bar"", Store.NO));
            doc.add(new StringField(""filter"", ""f1"", Store.NO));
            w.addDocument(doc);
        }
        w.close();
        reader = DirectoryReader.open(dir);

        BooleanQuery booleanQuery = new BooleanQuery.Builder().add(new TermQuery(new Term(""foo"", ""bar"")), Occur.MUST)
            .add(new TermQuery(new Term(""filter"", ""f1"")), Occur.SHOULD)
            .build();
        try (TestSearchContext context = createContext(newContextSearcher(reader), booleanQuery)) {
            context.minimumScore(0.01f);
            context.setSize(1);
            context.trackTotalHitsUpTo(5);

            QueryPhase.addCollectorsAndSearch(context);
            assertEquals(10, context.queryResult().topDocs().topDocs.totalHits.value);
        }
    }",/server/src/test/java/org/elasticsearch/search/query/QueryPhaseTests.java
b887fad51ad587c464c03ab1763193a13ff82bea,690,106,"public static Map<String, char[]> parseFile(Path path, @Nullable ESLogger logger) {
        if (!Files.exists(path)) {
            return ImmutableMap.of();
        }

        List<String> lines = null;
        try {
            lines = Files.readAllLines(path, Charsets.UTF_8);
        } catch (IOException ioe) {
            throw new ElasticsearchException(""Could not read users file ["" + path.toAbsolutePath() + ""]"", ioe);
        }

        ImmutableMap.Builder<String, char[]> users = ImmutableMap.builder();

        int lineNr = 0;
        for (String line : lines) {
            lineNr++;
            int i = line.indexOf("":"");
            if (i <= 0 || i == line.length() - 1) {
                logger.error(""Invalid entry in users file ["" + path.toAbsolutePath() + ""], line ["" + lineNr + ""]. Skipping..."");
                continue;
            }
            String username = line.substring(0, i).trim();
            String hash = line.substring(i + 1).trim();
            users.put(username, hash.toCharArray());
        }

        return users.build();
    }","public static Map<String, char[]> parseFile(Path path, @Nullable ESLogger logger) {
        if (!Files.exists(path)) {
            return ImmutableMap.of();
        }

        List<String> lines = null;
        try {
            lines = Files.readAllLines(path, Charsets.UTF_8);
        } catch (IOException ioe) {
            throw new ElasticsearchException(""Could not read users file ["" + path.toAbsolutePath() + ""]"", ioe);
        }

        ImmutableMap.Builder<String, char[]> users = ImmutableMap.builder();

        int lineNr = 0;
        for (String line : lines) {
            lineNr++;
            int i = line.indexOf("":"");
            if (i <= 0 || i == line.length() - 1) {
                if (logger != null) {
                    logger.error(""Invalid entry in users file ["" + path.toAbsolutePath() + ""], line ["" + lineNr + ""]. Skipping..."");
                }
                continue;
            }
            String username = line.substring(0, i).trim();
            String hash = line.substring(i + 1).trim();
            users.put(username, hash.toCharArray());
        }

        return users.build();
    }",/src/main/java/org/elasticsearch/shield/authc/esusers/FileUserPasswdStore.java
b887fad51ad587c464c03ab1763193a13ff82bea,690,99,"public static Map<String, String[]> parseFile(Path path, @Nullable ESLogger logger) {
        if (!Files.exists(path)) {
            return ImmutableMap.of();
        }

        List<String> lines = null;
        try {
            lines = Files.readAllLines(path, Charsets.UTF_8);
        } catch (IOException ioe) {
            throw new ElasticsearchException(""Could not read users file ["" + path.toAbsolutePath() + ""]"", ioe);
        }

        ImmutableMap.Builder<String, String[]> usersRoles = ImmutableMap.builder();

        int lineNr = 0;
        for (String line : lines) {
            lineNr++;
            int i = line.indexOf("":"");
            if (i <= 0 || i == line.length() - 1) {
                logger.error(""Invalid entry in users file ["" + path.toAbsolutePath() + ""], line ["" + lineNr + ""]. Skipping..."");
                continue;
            }
            String username = line.substring(0, i).trim();
            String rolesStr = line.substring(i + 1).trim();
            String[] roles = ROLES_DELIM.split(rolesStr);
            usersRoles.put(username, roles);
        }

        return usersRoles.build();
    }","public static Map<String, String[]> parseFile(Path path, @Nullable ESLogger logger) {
        if (!Files.exists(path)) {
            return ImmutableMap.of();
        }

        List<String> lines = null;
        try {
            lines = Files.readAllLines(path, Charsets.UTF_8);
        } catch (IOException ioe) {
            throw new ElasticsearchException(""Could not read users file ["" + path.toAbsolutePath() + ""]"", ioe);
        }

        ImmutableMap.Builder<String, String[]> usersRoles = ImmutableMap.builder();

        int lineNr = 0;
        for (String line : lines) {
            lineNr++;
            int i = line.indexOf("":"");
            if (i <= 0 || i == line.length() - 1) {
                if (logger != null) {
                    logger.error(""Invalid entry in users file ["" + path.toAbsolutePath() + ""], line ["" + lineNr + ""]. Skipping..."");
                }
                continue;
            }
            String username = line.substring(0, i).trim();
            if (Strings.isEmpty(username)) {
                if (logger != null) {
                    logger.error(""Invalid username entry in users file ["" + path.toAbsolutePath() + ""], line ["" + lineNr + ""]. Skipping..."");
                }
                continue;
            }
            String rolesStr = line.substring(i + 1).trim();
            if (Strings.isEmpty(rolesStr)) {
                if (logger != null) {
                    logger.error(""Invalid roles entry in users file ["" + path.toAbsolutePath() + ""], line ["" + lineNr + ""]. Skipping..."");
                }
                continue;
            }
            String[] roles = ROLES_DELIM.split(rolesStr);
            if (roles.length == 0) {
                if (logger != null) {
                    logger.error(""Invalid roles entry in users file ["" + path.toAbsolutePath() + ""], line ["" + lineNr + ""]. Skipping..."");
                }
                continue;
            }
            usersRoles.put(username, roles);
        }

        return usersRoles.build();
    }",/src/main/java/org/elasticsearch/shield/authc/esusers/FileUserRolesStore.java
c3110624763bcdec584269473a5dda28aa18c45e,685,965,"public void onConnectionClosed(Transport.Connection connection) {
        try {
            List<Transport.ResponseContext<? extends TransportResponse>> pruned =
                responseHandlers.prune(h -> h.connection().getCacheKey().equals(connection.getCacheKey()));
            // callback that an exception happened, but on a different thread since we don't
            // want handlers to worry about stack overflows
            getExecutorService().execute(() -> {
                for (Transport.ResponseContext holderToNotify : pruned) {
                    holderToNotify.handler().handleException(new NodeDisconnectedException(connection.getNode(), holderToNotify.action()));
                }
            });
        } catch (EsRejectedExecutionException ex) {
            logger.debug(""Rejected execution on onConnectionClosed"", ex);
        }
    }","public void onConnectionClosed(Transport.Connection connection) {
        try {
            List<Transport.ResponseContext<? extends TransportResponse>> pruned =
                responseHandlers.prune(h -> h.connection().getCacheKey().equals(connection.getCacheKey()));
            // callback that an exception happened, but on a different thread since we don't
            // want handlers to worry about stack overflows
            getExecutorService().execute(new Runnable() {
                @Override
                public void run() {
                    for (Transport.ResponseContext holderToNotify : pruned) {
                        holderToNotify.handler().handleException(
                            new NodeDisconnectedException(connection.getNode(), holderToNotify.action()));
                    }
                }

                @Override
                public String toString() {
                    return ""onConnectionClosed("" + connection.getNode() + "")"";
                }
            });
        } catch (EsRejectedExecutionException ex) {
            logger.debug(""Rejected execution on onConnectionClosed"", ex);
        }
    }",/server/src/main/java/org/elasticsearch/transport/TransportService.java
c3110624763bcdec584269473a5dda28aa18c45e,570,1256,"void runRandomly() {

            // TODO supporting (preserving?) existing disruptions needs implementing if needed, for now we just forbid it
            assertThat(""may reconnect disconnected nodes, probably unexpected"", disconnectedNodes, empty());
            assertThat(""may reconnect blackholed nodes, probably unexpected"", blackholedNodes, empty());

            final List<Runnable> cleanupActions = new ArrayList<>();
            cleanupActions.add(disconnectedNodes::clear);
            cleanupActions.add(blackholedNodes::clear);
            cleanupActions.add(() -> disruptStorage = false);

            final int randomSteps = scaledRandomIntBetween(10, 10000);
            logger.info(""--> start of safety phase of at least [{}] steps"", randomSteps);

            deterministicTaskQueue.setExecutionDelayVariabilityMillis(EXTREME_DELAY_VARIABILITY);
            disruptStorage = true;
            int step = 0;
            long finishTime = -1;

            while (finishTime == -1 || deterministicTaskQueue.getCurrentTimeMillis() <= finishTime) {
                step++;
                final int thisStep = step; // for lambdas

                if (randomSteps <= step && finishTime == -1) {
                    finishTime = deterministicTaskQueue.getLatestDeferredExecutionTime();
                    deterministicTaskQueue.setExecutionDelayVariabilityMillis(DEFAULT_DELAY_VARIABILITY);
                    logger.debug(""----> [runRandomly {}] reducing delay variability and running until [{}ms]"", step, finishTime);
                }

                try {
                    if (rarely()) {
                        final ClusterNode clusterNode = getAnyNodePreferringLeaders();
                        final int newValue = randomInt();
                        clusterNode.onNode(() -> {
                            logger.debug(""----> [runRandomly {}] proposing new value [{}] to [{}]"",
                                thisStep, newValue, clusterNode.getId());
                            clusterNode.submitValue(newValue);
                        }).run();
                    } else if (rarely()) {
                        final ClusterNode clusterNode = getAnyNodePreferringLeaders();
                        final boolean autoShrinkVotingConfiguration = randomBoolean();
                        clusterNode.onNode(
                            () -> {
                                logger.debug(""----> [runRandomly {}] setting auto-shrink configuration to {} on {}"",
                                    thisStep, autoShrinkVotingConfiguration, clusterNode.getId());
                                clusterNode.submitSetAutoShrinkVotingConfiguration(autoShrinkVotingConfiguration);
                            }).run();
                    } else if (rarely()) {
                        // reboot random node
                        final ClusterNode clusterNode = getAnyNode();
                        logger.debug(""----> [runRandomly {}] rebooting [{}]"", thisStep, clusterNode.getId());
                        clusterNode.close();
                        clusterNodes.forEach(
                            cn -> deterministicTaskQueue.scheduleNow(cn.onNode(
                                new Runnable() {
                                    @Override
                                    public void run() {
                                        cn.transportService.disconnectFromNode(clusterNode.getLocalNode());
                                    }

                                    @Override
                                    public String toString() {
                                        return ""disconnect from "" + clusterNode.getLocalNode() + "" after shutdown"";
                                    }
                                })));
                        clusterNodes.replaceAll(cn -> cn == clusterNode ? cn.restartedNode() : cn);
                    } else if (rarely()) {
                        final ClusterNode clusterNode = getAnyNode();
                        clusterNode.onNode(() -> {
                            logger.debug(""----> [runRandomly {}] forcing {} to become candidate"", thisStep, clusterNode.getId());
                            synchronized (clusterNode.coordinator.mutex) {
                                clusterNode.coordinator.becomeCandidate(""runRandomly"");
                            }
                        }).run();
                    } else if (rarely()) {
                        final ClusterNode clusterNode = getAnyNode();

                        switch (randomInt(2)) {
                            case 0:
                                if (clusterNode.heal()) {
                                    logger.debug(""----> [runRandomly {}] healing {}"", step, clusterNode.getId());
                                }
                                break;
                            case 1:
                                if (clusterNode.disconnect()) {
                                    logger.debug(""----> [runRandomly {}] disconnecting {}"", step, clusterNode.getId());
                                }
                                break;
                            case 2:
                                if (clusterNode.blackhole()) {
                                    logger.debug(""----> [runRandomly {}] blackholing {}"", step, clusterNode.getId());
                                }
                                break;
                        }
                    } else if (rarely()) {
                        final ClusterNode clusterNode = getAnyNode();
                        logger.debug(""----> [runRandomly {}] applying initial configuration on {}"", step, clusterNode.getId());
                        clusterNode.applyInitialConfiguration();
                    } else {
                        if (deterministicTaskQueue.hasDeferredTasks() && randomBoolean()) {
                            deterministicTaskQueue.advanceTime();
                        } else if (deterministicTaskQueue.hasRunnableTasks()) {
                            deterministicTaskQueue.runRandomTask();
                        }
                    }

                    // TODO other random steps:
                    // - reboot a node
                    // - abdicate leadership

                } catch (CoordinationStateRejectedException | UncheckedIOException ignored) {
                    // This is ok: it just means a message couldn't currently be handled.
                }

                assertConsistentStates();
            }

            logger.debug(""running {} cleanup actions"", cleanupActions.size());
            cleanupActions.forEach(Runnable::run);
            logger.debug(""finished running cleanup actions"");
        }","void runRandomly(boolean allowReboots) {

            // TODO supporting (preserving?) existing disruptions needs implementing if needed, for now we just forbid it
            assertThat(""may reconnect disconnected nodes, probably unexpected"", disconnectedNodes, empty());
            assertThat(""may reconnect blackholed nodes, probably unexpected"", blackholedNodes, empty());

            final List<Runnable> cleanupActions = new ArrayList<>();
            cleanupActions.add(disconnectedNodes::clear);
            cleanupActions.add(blackholedNodes::clear);
            cleanupActions.add(() -> disruptStorage = false);

            final int randomSteps = scaledRandomIntBetween(10, 10000);
            logger.info(""--> start of safety phase of at least [{}] steps"", randomSteps);

            deterministicTaskQueue.setExecutionDelayVariabilityMillis(EXTREME_DELAY_VARIABILITY);
            disruptStorage = true;
            int step = 0;
            long finishTime = -1;

            while (finishTime == -1 || deterministicTaskQueue.getCurrentTimeMillis() <= finishTime) {
                step++;
                final int thisStep = step; // for lambdas

                if (randomSteps <= step && finishTime == -1) {
                    finishTime = deterministicTaskQueue.getLatestDeferredExecutionTime();
                    deterministicTaskQueue.setExecutionDelayVariabilityMillis(DEFAULT_DELAY_VARIABILITY);
                    logger.debug(""----> [runRandomly {}] reducing delay variability and running until [{}ms]"", step, finishTime);
                }

                try {
                    if (rarely()) {
                        final ClusterNode clusterNode = getAnyNodePreferringLeaders();
                        final int newValue = randomInt();
                        clusterNode.onNode(() -> {
                            logger.debug(""----> [runRandomly {}] proposing new value [{}] to [{}]"",
                                thisStep, newValue, clusterNode.getId());
                            clusterNode.submitValue(newValue);
                        }).run();
                    } else if (rarely()) {
                        final ClusterNode clusterNode = getAnyNodePreferringLeaders();
                        final boolean autoShrinkVotingConfiguration = randomBoolean();
                        clusterNode.onNode(
                            () -> {
                                logger.debug(""----> [runRandomly {}] setting auto-shrink configuration to {} on {}"",
                                    thisStep, autoShrinkVotingConfiguration, clusterNode.getId());
                                clusterNode.submitSetAutoShrinkVotingConfiguration(autoShrinkVotingConfiguration);
                            }).run();
                    } else if (allowReboots && rarely()) {
                        // reboot random node
                        final ClusterNode clusterNode = getAnyNode();
                        logger.debug(""----> [runRandomly {}] rebooting [{}]"", thisStep, clusterNode.getId());
                        clusterNode.close();
                        clusterNodes.forEach(
                            cn -> deterministicTaskQueue.scheduleNow(cn.onNode(
                                new Runnable() {
                                    @Override
                                    public void run() {
                                        cn.transportService.disconnectFromNode(clusterNode.getLocalNode());
                                    }

                                    @Override
                                    public String toString() {
                                        return ""disconnect from "" + clusterNode.getLocalNode() + "" after shutdown"";
                                    }
                                })));
                        clusterNodes.replaceAll(cn -> cn == clusterNode ? cn.restartedNode() : cn);
                    } else if (rarely()) {
                        final ClusterNode clusterNode = getAnyNode();
                        clusterNode.onNode(() -> {
                            logger.debug(""----> [runRandomly {}] forcing {} to become candidate"", thisStep, clusterNode.getId());
                            synchronized (clusterNode.coordinator.mutex) {
                                clusterNode.coordinator.becomeCandidate(""runRandomly"");
                            }
                        }).run();
                    } else if (rarely()) {
                        final ClusterNode clusterNode = getAnyNode();

                        switch (randomInt(2)) {
                            case 0:
                                if (clusterNode.heal()) {
                                    logger.debug(""----> [runRandomly {}] healing {}"", step, clusterNode.getId());
                                }
                                break;
                            case 1:
                                if (clusterNode.disconnect()) {
                                    logger.debug(""----> [runRandomly {}] disconnecting {}"", step, clusterNode.getId());
                                }
                                break;
                            case 2:
                                if (clusterNode.blackhole()) {
                                    logger.debug(""----> [runRandomly {}] blackholing {}"", step, clusterNode.getId());
                                }
                                break;
                        }
                    } else if (rarely()) {
                        final ClusterNode clusterNode = getAnyNode();
                        logger.debug(""----> [runRandomly {}] applying initial configuration on {}"", step, clusterNode.getId());
                        clusterNode.applyInitialConfiguration();
                    } else {
                        if (deterministicTaskQueue.hasDeferredTasks() && randomBoolean()) {
                            deterministicTaskQueue.advanceTime();
                        } else if (deterministicTaskQueue.hasRunnableTasks()) {
                            deterministicTaskQueue.runRandomTask();
                        }
                    }

                    // TODO other random steps:
                    // - reboot a node
                    // - abdicate leadership

                } catch (CoordinationStateRejectedException | UncheckedIOException ignored) {
                    // This is ok: it just means a message couldn't currently be handled.
                }

                assertConsistentStates();
            }

            logger.debug(""running {} cleanup actions"", cleanupActions.size());
            cleanupActions.forEach(Runnable::run);
            logger.debug(""finished running cleanup actions"");
        }",/server/src/test/java/org/elasticsearch/cluster/coordination/CoordinatorTests.java
c3110624763bcdec584269473a5dda28aa18c45e,563,1111,"public void handleException(TransportException exp) {
            if(handler != null) {
                handler.cancel();
            }
            try (ThreadContext.StoredContext ignore = contextSupplier.get()) {
                delegate.handleException(exp);
            }
        }","public void handleResponse(T response) {
            if(handler != null) {
                handler.cancel();
            }
            try (ThreadContext.StoredContext ignore = contextSupplier.get()) {
                delegate.handleResponse(response);
            }
        }",/server/src/main/java/org/elasticsearch/transport/TransportService.java
6edd2e47ccd6a6b9c67ad15946a2d110ffd3e407,691,1174,") {
        if (fail) {
            String expectedErrorMessage = ""no such index ["" + dataStream + ""]"";
            if (requestBuilder instanceof MultiSearchRequestBuilder) {
                MultiSearchResponse multiSearchResponse = ((MultiSearchRequestBuilder) requestBuilder).get();
                assertThat(multiSearchResponse.getResponses().length, equalTo(1));
                assertThat(multiSearchResponse.getResponses()[0].isFailure(), is(true));
                assertThat(multiSearchResponse.getResponses()[0].getFailure(), instanceOf(IllegalArgumentException.class));
                assertThat(multiSearchResponse.getResponses()[0].getFailure().getMessage(), equalTo(expectedErrorMessage));
            } else if (requestBuilder instanceof ValidateQueryRequestBuilder) {
                Exception e = expectThrows(IndexNotFoundException.class, requestBuilder::get);
                assertThat(e.getMessage(), equalTo(expectedErrorMessage));
            } else {
                Exception e = expectThrows(IndexNotFoundException.class, requestBuilder::get);
                assertThat(e.getMessage(), equalTo(expectedErrorMessage));
            }
        } else {
            if (requestBuilder instanceof SearchRequestBuilder) {
                SearchRequestBuilder searchRequestBuilder = (SearchRequestBuilder) requestBuilder;
                assertHitCount(searchRequestBuilder.get(), expectedCount);
            } else if (requestBuilder instanceof MultiSearchRequestBuilder) {
                MultiSearchResponse multiSearchResponse = ((MultiSearchRequestBuilder) requestBuilder).get();
                assertThat(multiSearchResponse.getResponses()[0].isFailure(), is(false));
            } else {
                requestBuilder.get();
            }
        }
    }","public void testMultiThreadedRollover() throws Exception {
        final String dsName = ""potato-biscuit"";
        putComposableIndexTemplate(""id1"", List.of(""potato-*""));

        ensureGreen();

        final int threadCount = randomIntBetween(5, 10);
        final CyclicBarrier barrier = new CyclicBarrier(threadCount + 1);
        final AtomicBoolean running = new AtomicBoolean(true);
        Set<Thread> threads = IntStream.range(0, threadCount).mapToObj(i -> new Thread(() -> {
            try {
                logger.info(""--> [{}] waiting for all the other threads before starting"", i);
                barrier.await();
                while (running.get()) {
                    RolloverResponse resp = client().admin().indices().prepareRolloverIndex(dsName).addMaxIndexDocsCondition(2).get();
                    if (resp.isRolledOver()) {
                        logger.info(""--> thread [{}] successfully rolled over: {}"", i, Strings.toString(resp));
                        assertThat(resp.getOldIndex(), equalTo(DataStream.getDefaultBackingIndexName(""potato-biscuit"", 1)));
                        assertThat(resp.getNewIndex(), equalTo(DataStream.getDefaultBackingIndexName(""potato-biscuit"", 2)));
                    }
                }
            } catch (Exception e) {
                logger.error(new ParameterizedMessage(""thread [{}] encountered unexpected exception"", i), e);
                fail(""we should not encounter unexpected exceptions"");
            }
        }, ""rollover-thread-"" + i)).collect(Collectors.toSet());

        threads.forEach(Thread::start);

        indexDocs(dsName, 1);

        // Okay, signal the floodgates to open
        barrier.await();

        indexDocs(dsName, 1);

        assertBusy(() -> {
            try {
                client().admin().indices().prepareGetIndex().addIndices(DataStream.getDefaultBackingIndexName(""potato-biscuit"", 2)).get();
            } catch (Exception e) {
                logger.info(""--> expecting second index to be created but it has not yet been created"");
                fail(""expecting second index to exist"");
            }
        });

        // Tell everyone to stop trying to roll over
        running.set(false);

        threads.forEach(thread -> {
            try {
                thread.join(1000);
            } catch (Exception e) {
                logger.warn(""expected thread to be stopped, but got"", e);
            }
        });

        // We should *NOT* have a third index, it should have rolled over *exactly* once
        expectThrows(
            Exception.class,
            () -> client().admin().indices().prepareGetIndex().addIndices(DataStream.getDefaultBackingIndexName(""potato-biscuit"", 3)).get()
        );
    }",/x-pack/plugin/data-streams/src/internalClusterTest/java/org/elasticsearch/datastreams/DataStreamIT.java
df9f0f729fd47ad9585f7c80f863a5779ce2c5bf,690,461,"final Set<String> pre60AllocationIds) throws IOException {
        final ShardRouting currentRouting;
        synchronized (mutex) {
            currentRouting = this.shardRouting;

            if (!newRouting.shardId().equals(shardId())) {
                throw new IllegalArgumentException(""Trying to set a routing entry with shardId "" +
                    newRouting.shardId() + "" on a shard with shardId "" + shardId());
            }
            if ((currentRouting == null || newRouting.isSameAllocation(currentRouting)) == false) {
                throw new IllegalArgumentException(""Trying to set a routing entry with a different allocation. Current "" +
                    currentRouting + "", new "" + newRouting);
            }
            if (currentRouting != null && currentRouting.primary() && newRouting.primary() == false) {
                throw new IllegalArgumentException(""illegal state: trying to move shard from primary mode to replica mode. Current ""
                    + currentRouting + "", new "" + newRouting);
            }

            if (newRouting.primary()) {
                replicationTracker.updateFromMaster(applyingClusterStateVersion, inSyncAllocationIds, routingTable, pre60AllocationIds);
            }

            if (state == IndexShardState.POST_RECOVERY && newRouting.active()) {
                assert currentRouting.active() == false : ""we are in POST_RECOVERY, but our shard routing is active "" + currentRouting;
                assert currentRouting.isRelocationTarget()  == false || currentRouting.primary() == false ||
                        replicationTracker.isPrimaryMode() :
                    ""a primary relocation is completed by the master, but primary mode is not active "" + currentRouting;

                changeState(IndexShardState.STARTED, ""global state is ["" + newRouting.state() + ""]"");
            } else if (currentRouting.primary() && currentRouting.relocating() && replicationTracker.isRelocated() &&
                (newRouting.relocating() == false || newRouting.equalsIgnoringMetaData(currentRouting) == false)) {
                // if the shard is not in primary mode anymore (after primary relocation) we have to fail when any changes in shard
                // routing occur (e.g. due to recovery failure / cancellation). The reason is that at the moment we cannot safely
                // reactivate primary mode without risking two active primaries.
                throw new IndexShardRelocatedException(shardId(), ""Shard is marked as relocated, cannot safely move to state "" +
                    newRouting.state());
            }
            assert newRouting.active() == false || state == IndexShardState.STARTED || state == IndexShardState.CLOSED :
                ""routing is active, but local shard state isn't. routing: "" + newRouting + "", local state: "" + state;
            persistMetadata(path, indexSettings, newRouting, currentRouting, logger);
            final CountDownLatch shardStateUpdated = new CountDownLatch(1);

            if (newRouting.primary()) {
                if (newPrimaryTerm == pendingPrimaryTerm) {
                    if (currentRouting.initializing() && currentRouting.isRelocationTarget() == false && newRouting.active()) {
                        // the master started a recovering primary, activate primary mode.
                        replicationTracker.activatePrimaryMode(getLocalCheckpoint());
                    }
                } else {
                    assert currentRouting.primary() == false : ""term is only increased as part of primary promotion"";
                    /* Note that due to cluster state batching an initializing primary shard term can failed and re-assigned
                     * in one state causing it's term to be incremented. Note that if both current shard state and new
                     * shard state are initializing, we could replace the current shard and reinitialize it. It is however
                     * possible that this shard is being started. This can happen if:
                     * 1) Shard is post recovery and sends shard started to the master
                     * 2) Node gets disconnected and rejoins
                     * 3) Master assigns the shard back to the node
                     * 4) Master processes the shard started and starts the shard
                     * 5) The node process the cluster state where the shard is both started and primary term is incremented.
                     *
                     * We could fail the shard in that case, but this will cause it to be removed from the insync allocations list
                     * potentially preventing re-allocation.
                     */
                    assert newRouting.initializing() == false :
                        ""a started primary shard should never update its term; ""
                            + ""shard "" + newRouting + "", ""
                            + ""current term ["" + pendingPrimaryTerm + ""], ""
                            + ""new term ["" + newPrimaryTerm + ""]"";
                    assert newPrimaryTerm > pendingPrimaryTerm :
                        ""primary terms can only go up; current term ["" + pendingPrimaryTerm + ""], new term ["" + newPrimaryTerm + ""]"";
                    /*
                     * Before this call returns, we are guaranteed that all future operations are delayed and so this happens before we
                     * increment the primary term. The latch is needed to ensure that we do not unblock operations before the primary
                     * term is incremented.
                     */
                    // to prevent primary relocation handoff while resync is not completed
                    boolean resyncStarted = primaryReplicaResyncInProgress.compareAndSet(false, true);
                    if (resyncStarted == false) {
                        throw new IllegalStateException(""cannot start resync while it's already in progress"");
                    }
                    bumpPrimaryTerm(newPrimaryTerm,
                        () -> {
                            shardStateUpdated.await();
                            assert pendingPrimaryTerm == newPrimaryTerm :
                                ""shard term changed on primary. expected ["" + newPrimaryTerm + ""] but was ["" + pendingPrimaryTerm + ""]"" +
                                "", current routing: "" + currentRouting + "", new routing: "" + newRouting;
                            assert getOperationPrimaryTerm() == newPrimaryTerm;
                            try {
                                replicationTracker.activatePrimaryMode(getLocalCheckpoint());
                                /*
                                 * If this shard was serving as a replica shard when another shard was promoted to primary then
                                 * its Lucene index was reset during the primary term transition. In particular, the Lucene index
                                 * on this shard was reset to the global checkpoint and the operations above the local checkpoint
                                 * were reverted. If the other shard that was promoted to primary subsequently fails before the
                                 * primary/replica re-sync completes successfully and we are now being promoted, we have to restore
                                 * the reverted operations on this shard by replaying the translog to avoid losing acknowledged writes.
                                 */
                                final Engine engine = getEngine();
                                if (getMaxSeqNoOfUpdatesOrDeletes() == UNASSIGNED_SEQ_NO) {
                                    // If the old primary was on an old version that did not replicate the msu,
                                    // we need to bootstrap it manually from its local history.
                                    assert indexSettings.getIndexVersionCreated().before(Version.V_6_5_0);
                                    engine.advanceMaxSeqNoOfUpdatesOrDeletes(seqNoStats().getMaxSeqNo());
                                }
                                engine.restoreLocalHistoryFromTranslog((resettingEngine, snapshot) ->
                                    runTranslogRecovery(resettingEngine, snapshot, Engine.Operation.Origin.LOCAL_RESET, () -> {}));
                                /* Rolling the translog generation is not strictly needed here (as we will never have collisions between
                                 * sequence numbers in a translog generation in a new primary as it takes the last known sequence number
                                 * as a starting point), but it simplifies reasoning about the relationship between primary terms and
                                 * translog generations.
                                 */
                                engine.rollTranslogGeneration();
                                engine.fillSeqNoGaps(newPrimaryTerm);
                                replicationTracker.updateLocalCheckpoint(currentRouting.allocationId().getId(), getLocalCheckpoint());
                                primaryReplicaSyncer.accept(this, new ActionListener<ResyncTask>() {
                                    @Override
                                    public void onResponse(ResyncTask resyncTask) {
                                        logger.info(""primary-replica resync completed with {} operations"",
                                            resyncTask.getResyncedOperations());
                                        boolean resyncCompleted =
                                            primaryReplicaResyncInProgress.compareAndSet(true, false);
                                        assert resyncCompleted : ""primary-replica resync finished but was not started"";
                                    }

                                    @Override
                                    public void onFailure(Exception e) {
                                        boolean resyncCompleted =
                                            primaryReplicaResyncInProgress.compareAndSet(true, false);
                                        assert resyncCompleted : ""primary-replica resync finished but was not started"";
                                        if (state == IndexShardState.CLOSED) {
                                            // ignore, shutting down
                                        } else {
                                            failShard(""exception during primary-replica resync"", e);
                                        }
                                    }
                                });
                            } catch (final AlreadyClosedException e) {
                                // okay, the index was deleted
                            }
                        }, null);
                }
            }
            // set this last, once we finished updating all internal state.
            this.shardRouting = newRouting;

            assert this.shardRouting.primary() == false ||
                this.shardRouting.started() == false || // note that we use started and not active to avoid relocating shards
                this.indexShardOperationPermits.isBlocked() || // if permits are blocked, we are still transitioning
                this.replicationTracker.isPrimaryMode()
                : ""a started primary with non-pending operation term must be in primary mode "" + this.shardRouting;
            shardStateUpdated.countDown();
        }
        if (currentRouting != null && currentRouting.active() == false && newRouting.active()) {
            indexEventListener.afterIndexShardStarted(this);
        }
        if (newRouting.equals(currentRouting) == false) {
            indexEventListener.shardRoutingChanged(this, currentRouting, newRouting);
        }
    }","final Set<String> pre60AllocationIds) throws IOException {
        final ShardRouting currentRouting;
        synchronized (mutex) {
            currentRouting = this.shardRouting;

            if (!newRouting.shardId().equals(shardId())) {
                throw new IllegalArgumentException(""Trying to set a routing entry with shardId "" +
                    newRouting.shardId() + "" on a shard with shardId "" + shardId());
            }
            if ((currentRouting == null || newRouting.isSameAllocation(currentRouting)) == false) {
                throw new IllegalArgumentException(""Trying to set a routing entry with a different allocation. Current "" +
                    currentRouting + "", new "" + newRouting);
            }
            if (currentRouting != null && currentRouting.primary() && newRouting.primary() == false) {
                throw new IllegalArgumentException(""illegal state: trying to move shard from primary mode to replica mode. Current ""
                    + currentRouting + "", new "" + newRouting);
            }

            if (newRouting.primary()) {
                replicationTracker.updateFromMaster(applyingClusterStateVersion, inSyncAllocationIds, routingTable, pre60AllocationIds);
            }

            if (state == IndexShardState.POST_RECOVERY && newRouting.active()) {
                assert currentRouting.active() == false : ""we are in POST_RECOVERY, but our shard routing is active "" + currentRouting;
                assert currentRouting.isRelocationTarget()  == false || currentRouting.primary() == false ||
                        replicationTracker.isPrimaryMode() :
                    ""a primary relocation is completed by the master, but primary mode is not active "" + currentRouting;

                changeState(IndexShardState.STARTED, ""global state is ["" + newRouting.state() + ""]"");
            } else if (currentRouting.primary() && currentRouting.relocating() && replicationTracker.isRelocated() &&
                (newRouting.relocating() == false || newRouting.equalsIgnoringMetaData(currentRouting) == false)) {
                // if the shard is not in primary mode anymore (after primary relocation) we have to fail when any changes in shard
                // routing occur (e.g. due to recovery failure / cancellation). The reason is that at the moment we cannot safely
                // reactivate primary mode without risking two active primaries.
                throw new IndexShardRelocatedException(shardId(), ""Shard is marked as relocated, cannot safely move to state "" +
                    newRouting.state());
            }
            assert newRouting.active() == false || state == IndexShardState.STARTED || state == IndexShardState.CLOSED :
                ""routing is active, but local shard state isn't. routing: "" + newRouting + "", local state: "" + state;
            persistMetadata(path, indexSettings, newRouting, currentRouting, logger);
            final CountDownLatch shardStateUpdated = new CountDownLatch(1);

            if (newRouting.primary()) {
                if (newPrimaryTerm == pendingPrimaryTerm) {
                    if (currentRouting.initializing() && currentRouting.isRelocationTarget() == false && newRouting.active()) {
                        // the master started a recovering primary, activate primary mode.
                        replicationTracker.activatePrimaryMode(getLocalCheckpoint());
                    }
                } else {
                    assert currentRouting.primary() == false : ""term is only increased as part of primary promotion"";
                    /* Note that due to cluster state batching an initializing primary shard term can failed and re-assigned
                     * in one state causing it's term to be incremented. Note that if both current shard state and new
                     * shard state are initializing, we could replace the current shard and reinitialize it. It is however
                     * possible that this shard is being started. This can happen if:
                     * 1) Shard is post recovery and sends shard started to the master
                     * 2) Node gets disconnected and rejoins
                     * 3) Master assigns the shard back to the node
                     * 4) Master processes the shard started and starts the shard
                     * 5) The node process the cluster state where the shard is both started and primary term is incremented.
                     *
                     * We could fail the shard in that case, but this will cause it to be removed from the insync allocations list
                     * potentially preventing re-allocation.
                     */
                    assert newRouting.initializing() == false :
                        ""a started primary shard should never update its term; ""
                            + ""shard "" + newRouting + "", ""
                            + ""current term ["" + pendingPrimaryTerm + ""], ""
                            + ""new term ["" + newPrimaryTerm + ""]"";
                    assert newPrimaryTerm > pendingPrimaryTerm :
                        ""primary terms can only go up; current term ["" + pendingPrimaryTerm + ""], new term ["" + newPrimaryTerm + ""]"";
                    /*
                     * Before this call returns, we are guaranteed that all future operations are delayed and so this happens before we
                     * increment the primary term. The latch is needed to ensure that we do not unblock operations before the primary
                     * term is incremented.
                     */
                    // to prevent primary relocation handoff while resync is not completed
                    boolean resyncStarted = primaryReplicaResyncInProgress.compareAndSet(false, true);
                    if (resyncStarted == false) {
                        throw new IllegalStateException(""cannot start resync while it's already in progress"");
                    }
                    bumpPrimaryTerm(newPrimaryTerm,
                        () -> {
                            shardStateUpdated.await();
                            assert pendingPrimaryTerm == newPrimaryTerm :
                                ""shard term changed on primary. expected ["" + newPrimaryTerm + ""] but was ["" + pendingPrimaryTerm + ""]"" +
                                "", current routing: "" + currentRouting + "", new routing: "" + newRouting;
                            assert getOperationPrimaryTerm() == newPrimaryTerm;
                            try {
                                replicationTracker.activatePrimaryMode(getLocalCheckpoint());
                                /*
                                 * If this shard was serving as a replica shard when another shard was promoted to primary then
                                 * its Lucene index was reset during the primary term transition. In particular, the Lucene index
                                 * on this shard was reset to the global checkpoint and the operations above the local checkpoint
                                 * were reverted. If the other shard that was promoted to primary subsequently fails before the
                                 * primary/replica re-sync completes successfully and we are now being promoted, we have to restore
                                 * the reverted operations on this shard by replaying the translog to avoid losing acknowledged writes.
                                 */
                                final Engine engine = getEngine();
                                if (getMaxSeqNoOfUpdatesOrDeletes() == UNASSIGNED_SEQ_NO) {
                                    // If the old primary was on an old version that did not replicate the msu,
                                    // we need to bootstrap it manually from its local history.
                                    assert indexSettings.getIndexVersionCreated().before(Version.V_6_5_0);
                                    engine.advanceMaxSeqNoOfUpdatesOrDeletes(seqNoStats().getMaxSeqNo());
                                }
                                // in case we previously reset engine, we need to forward MSU before replaying translog.
                                engine.reinitializeMaxSeqNoOfUpdatesOrDeletes();
                                engine.restoreLocalHistoryFromTranslog((resettingEngine, snapshot) ->
                                    runTranslogRecovery(resettingEngine, snapshot, Engine.Operation.Origin.LOCAL_RESET, () -> {}));
                                /* Rolling the translog generation is not strictly needed here (as we will never have collisions between
                                 * sequence numbers in a translog generation in a new primary as it takes the last known sequence number
                                 * as a starting point), but it simplifies reasoning about the relationship between primary terms and
                                 * translog generations.
                                 */
                                engine.rollTranslogGeneration();
                                engine.fillSeqNoGaps(newPrimaryTerm);
                                replicationTracker.updateLocalCheckpoint(currentRouting.allocationId().getId(), getLocalCheckpoint());
                                primaryReplicaSyncer.accept(this, new ActionListener<ResyncTask>() {
                                    @Override
                                    public void onResponse(ResyncTask resyncTask) {
                                        logger.info(""primary-replica resync completed with {} operations"",
                                            resyncTask.getResyncedOperations());
                                        boolean resyncCompleted =
                                            primaryReplicaResyncInProgress.compareAndSet(true, false);
                                        assert resyncCompleted : ""primary-replica resync finished but was not started"";
                                    }

                                    @Override
                                    public void onFailure(Exception e) {
                                        boolean resyncCompleted =
                                            primaryReplicaResyncInProgress.compareAndSet(true, false);
                                        assert resyncCompleted : ""primary-replica resync finished but was not started"";
                                        if (state == IndexShardState.CLOSED) {
                                            // ignore, shutting down
                                        } else {
                                            failShard(""exception during primary-replica resync"", e);
                                        }
                                    }
                                });
                            } catch (final AlreadyClosedException e) {
                                // okay, the index was deleted
                            }
                        }, null);
                }
            }
            // set this last, once we finished updating all internal state.
            this.shardRouting = newRouting;

            assert this.shardRouting.primary() == false ||
                this.shardRouting.started() == false || // note that we use started and not active to avoid relocating shards
                this.indexShardOperationPermits.isBlocked() || // if permits are blocked, we are still transitioning
                this.replicationTracker.isPrimaryMode()
                : ""a started primary with non-pending operation term must be in primary mode "" + this.shardRouting;
            shardStateUpdated.countDown();
        }
        if (currentRouting != null && currentRouting.active() == false && newRouting.active()) {
            indexEventListener.afterIndexShardStarted(this);
        }
        if (newRouting.equals(currentRouting) == false) {
            indexEventListener.shardRoutingChanged(this, currentRouting, newRouting);
        }
    }",/server/src/main/java/org/elasticsearch/index/shard/IndexShard.java
7166af0b72c75907fa7360a991888191d39b41aa,690,1924,"private void removeExclusions(Set<String> excludedNodeIds) {
        assert Thread.holdsLock(this);
        if (excludedNodeIds.isEmpty() == false) {
            logger.info(""removing voting config exclusions for {} after restart/shutdown"", excludedNodeIds);
            try {
                Client client = getRandomNodeAndClient(node -> excludedNodeIds.contains(node.name) == false).client();
                client.execute(ClearVotingConfigExclusionsAction.INSTANCE, new ClearVotingConfigExclusionsRequest()).get();
            } catch (InterruptedException | ExecutionException e) {
                throw new AssertionError(""unexpected"", e);
            }
        }
    }","private Set<String> excludeMasters(Collection<NodeAndClient> nodeAndClients) {
        assert Thread.holdsLock(this);
        final Set<String> excludedNodeNames = new HashSet<>();
        if (autoManageMasterNodes && nodeAndClients.size() > 0) {

            final long currentMasters = nodes.values().stream().filter(NodeAndClient::isMasterEligible).count();
            final long stoppingMasters = nodeAndClients.stream().filter(NodeAndClient::isMasterEligible).count();

            assert stoppingMasters <= currentMasters : currentMasters + "" < "" + stoppingMasters;
            if (stoppingMasters != currentMasters && stoppingMasters > 0) {
                // If stopping few enough master-nodes that there's still a majority left, there is no need to withdraw their votes first.
                // However, we do not yet have a way to be sure there's a majority left, because the voting configuration may not yet have
                // been updated when the previous nodes shut down, so we must always explicitly withdraw votes.
                // TODO add cluster health API to check that voting configuration is optimal so this isn't always needed
                nodeAndClients.stream().filter(NodeAndClient::isMasterEligible).map(NodeAndClient::getName).forEach(excludedNodeNames::add);
                assert excludedNodeNames.size() == stoppingMasters;

                logger.info(""adding voting config exclusions {} prior to restart/shutdown"", excludedNodeNames);
                try {
                    client().execute(
                        AddVotingConfigExclusionsAction.INSTANCE,
                        new AddVotingConfigExclusionsRequest(excludedNodeNames.toArray(Strings.EMPTY_ARRAY))
                    ).get();
                } catch (InterruptedException | ExecutionException e) {
                    throw new AssertionError(""unexpected"", e);
                }
            }
        }
        return excludedNodeNames;
    }",/test/framework/src/main/java/org/elasticsearch/test/InternalTestCluster.java
243a0ef952d03cf823dff3cb929009501a251fa4,628,98,"private Map<String, String> getJvmCommandLines() throws IOException {
        /*
         * jps will truncate the command line to 1024 characters; so we collect the pids and then run jcmd <pid> VM.command_line to get the
         * full command line.
         */
        final String jpsPath = PathUtils.get(System.getProperty(""runtime.java.home""), ""bin/jps"").toString();
        final Process process = new ProcessBuilder().command(jpsPath, ""-v"").start();

        final List<String> pids = new ArrayList<>();
        try (
            InputStream is = process.getInputStream();
            BufferedReader in = new BufferedReader(new InputStreamReader(is, StandardCharsets.UTF_8))
        ) {
            String line;
            while ((line = in.readLine()) != null) {
                pids.add(line.substring(0, line.indexOf(' ')));
            }
        }

        final String jcmdPath = PathUtils.get(System.getProperty(""runtime.java.home""), ""bin/jcmd"").toString();
        final Map<String, String> jvmCommandLines = new HashMap<>();
        for (final String pid : pids) {
            final Process jcmdProcess = new ProcessBuilder().command(jcmdPath, pid, ""VM.command_line"").start();
            try (
                InputStream is = jcmdProcess.getInputStream();
                BufferedReader in = new BufferedReader(new InputStreamReader(is, StandardCharsets.UTF_8))
            ) {
                String line;
                while ((line = in.readLine()) != null) {
                    if (line.startsWith(""jvm_args"")) {
                        jvmCommandLines.put(pid, line);
                    }
                }
            }
        }
        return jvmCommandLines;
    }","private Map<String, String> getElasticsearchCommandLines() throws IOException {
        /*
         * jps will truncate the command line to 1024 characters; so we collect the pids and then run jcmd <pid> VM.command_line to get the
         * full command line.
         */
        final String jpsPath = PathUtils.get(System.getProperty(""runtime.java.home""), ""bin/jps"").toString();
        final Process process = new ProcessBuilder().command(jpsPath, ""-q"").start();

        final List<String> pids = new ArrayList<>();
        try (
            InputStream is = process.getInputStream();
            BufferedReader in = new BufferedReader(new InputStreamReader(is, StandardCharsets.UTF_8))
        ) {
            String line;
            while ((line = in.readLine()) != null) {
                pids.add(line);
            }
        }

        final String jcmdPath = PathUtils.get(System.getProperty(""runtime.java.home""), ""bin/jcmd"").toString();
        final Map<String, String> esCommandLines = new HashMap<>();
        for (final String pid : pids) {
            final Process jcmdProcess = new ProcessBuilder().command(jcmdPath, pid, ""VM.command_line"").start();
            try (
                InputStream is = jcmdProcess.getInputStream();
                BufferedReader in = new BufferedReader(new InputStreamReader(is, StandardCharsets.UTF_8))
            ) {
                boolean isElasticsearch = false;
                String jvmArgs = null;
                String line;
                while ((line = in.readLine()) != null) {
                    if (line.equals(""java_command: org.elasticsearch.bootstrap.Elasticsearch"")) {
                        isElasticsearch = true;
                    }
                    if (line.startsWith(""jvm_args"")) {
                        jvmArgs = line;
                    }
                }
                if (isElasticsearch) {
                    assertNotNull(pid, jvmArgs);
                    esCommandLines.put(pid, jvmArgs);
                }
            }
        }
        return esCommandLines;
    }",/test/external-modules/die-with-dignity/src/javaRestTest/java/org/elasticsearch/qa/die_with_dignity/DieWithDignityIT.java
8f28a7a47a17c503f0d8afdc8d74fc0160731da2,563,245,"public void testParsePersistedConfig() {

        // Null model variant
        {
            var service = createService(mock(Client.class));
            var settings = new HashMap<String, Object>();
            settings.put(
                ModelConfigurations.SERVICE_SETTINGS,
                new HashMap<>(
                    Map.of(ElasticsearchInternalServiceSettings.NUM_ALLOCATIONS, 1, ElasticsearchInternalServiceSettings.NUM_THREADS, 4)
                )
            );

            var e5ServiceSettings = new MultilingualE5SmallInternalServiceSettings(
                1,
                4,
                ElasticsearchInternalService.MULTILINGUAL_E5_SMALL_MODEL_ID
            );

            expectThrows(IllegalArgumentException.class, () -> service.parsePersistedConfig(randomInferenceEntityId, taskType, settings));

        }

        // Invalid model variant
        // because this is a persisted config, we assume that the model does exist, even though it doesn't. In practice, the trained models
        // API would throw an exception when the model is used
        {
            var service = createService(mock(Client.class));
            var settings = new HashMap<String, Object>();
            settings.put(
                ModelConfigurations.SERVICE_SETTINGS,
                new HashMap<>(
                    Map.of(
                        ElasticsearchInternalServiceSettings.NUM_ALLOCATIONS,
                        1,
                        ElasticsearchInternalServiceSettings.NUM_THREADS,
                        4,
                        InternalServiceSettings.MODEL_ID,
                        ""invalid""
                    )
                )
            );

            CustomElandModel parsedModel = (CustomElandModel) service.parsePersistedConfig(randomInferenceEntityId, taskType, settings);
            var elandServiceSettings = new CustomElandInternalServiceSettings(1, 4, ""invalid"");
            assertEquals(
                new CustomElandModel(randomInferenceEntityId, taskType, ElasticsearchInternalService.NAME, elandServiceSettings),
                parsedModel
            );
        }

        // Valid model variant
        {
            var service = createService(mock(Client.class));
            var settings = new HashMap<String, Object>();
            settings.put(
                ModelConfigurations.SERVICE_SETTINGS,
                new HashMap<>(
                    Map.of(
                        ElasticsearchInternalServiceSettings.NUM_ALLOCATIONS,
                        1,
                        ElasticsearchInternalServiceSettings.NUM_THREADS,
                        4,
                        InternalServiceSettings.MODEL_ID,
                        ElasticsearchInternalService.MULTILINGUAL_E5_SMALL_MODEL_ID
                    )
                )
            );

            var e5ServiceSettings = new MultilingualE5SmallInternalServiceSettings(
                1,
                4,
                ElasticsearchInternalService.MULTILINGUAL_E5_SMALL_MODEL_ID
            );

            MultilingualE5SmallModel parsedModel = (MultilingualE5SmallModel) service.parsePersistedConfig(
                randomInferenceEntityId,
                taskType,
                settings
            );
            assertEquals(
                new MultilingualE5SmallModel(randomInferenceEntityId, taskType, ElasticsearchInternalService.NAME, e5ServiceSettings),
                parsedModel
            );
        }

        // Invalid config map
        {
            var service = createService(mock(Client.class));
            var settings = new HashMap<String, Object>();
            settings.put(
                ModelConfigurations.SERVICE_SETTINGS,
                new HashMap<>(
                    Map.of(ElasticsearchInternalServiceSettings.NUM_ALLOCATIONS, 1, ElasticsearchInternalServiceSettings.NUM_THREADS, 4)
                )
            );
            settings.put(""not_a_valid_config_setting"", randomAlphaOfLength(10));
            expectThrows(IllegalArgumentException.class, () -> service.parsePersistedConfig(randomInferenceEntityId, taskType, settings));
        }

        // Invalid service settings
        {
            var service = createService(mock(Client.class));
            var settings = new HashMap<String, Object>();
            settings.put(
                ModelConfigurations.SERVICE_SETTINGS,
                new HashMap<>(
                    Map.of(
                        ElasticsearchInternalServiceSettings.NUM_ALLOCATIONS,
                        1,
                        ElasticsearchInternalServiceSettings.NUM_THREADS,
                        4,
                        ""not_a_valid_service_setting"",
                        randomAlphaOfLength(10)
                    )
                )
            );
            expectThrows(IllegalArgumentException.class, () -> service.parsePersistedConfig(randomInferenceEntityId, taskType, settings));
        }
    }","public void testParsePersistedConfig() {

        // Null model variant
        {
            var service = createService(mock(Client.class));
            var settings = new HashMap<String, Object>();
            settings.put(
                ModelConfigurations.SERVICE_SETTINGS,
                new HashMap<>(
                    Map.of(
                        ElasticsearchInternalServiceSettings.NUM_ALLOCATIONS,
                        1,
                        ElasticsearchInternalServiceSettings.NUM_THREADS,
                        4,
                        ServiceFields.SIMILARITY,
                        SimilarityMeasure.L2_NORM.toString()
                    )
                )
            );

            expectThrows(IllegalArgumentException.class, () -> service.parsePersistedConfig(randomInferenceEntityId, taskType, settings));

        }

        // Invalid model variant
        // because this is a persisted config, we assume that the model does exist, even though it doesn't. In practice, the trained models
        // API would throw an exception when the model is used
        {
            var service = createService(mock(Client.class));
            var settings = new HashMap<String, Object>();
            settings.put(
                ModelConfigurations.SERVICE_SETTINGS,
                new HashMap<>(
                    Map.of(
                        ElasticsearchInternalServiceSettings.NUM_ALLOCATIONS,
                        1,
                        ElasticsearchInternalServiceSettings.NUM_THREADS,
                        4,
                        InternalServiceSettings.MODEL_ID,
                        ""invalid""
                    )
                )
            );

            CustomElandModel parsedModel = (CustomElandModel) service.parsePersistedConfig(randomInferenceEntityId, taskType, settings);
            var elandServiceSettings = new CustomElandInternalServiceSettings(1, 4, ""invalid"");
            assertEquals(
                new CustomElandModel(randomInferenceEntityId, taskType, ElasticsearchInternalService.NAME, elandServiceSettings),
                parsedModel
            );
        }

        // Valid model variant
        {
            var service = createService(mock(Client.class));
            var settings = new HashMap<String, Object>();
            settings.put(
                ModelConfigurations.SERVICE_SETTINGS,
                new HashMap<>(
                    Map.of(
                        ElasticsearchInternalServiceSettings.NUM_ALLOCATIONS,
                        1,
                        ElasticsearchInternalServiceSettings.NUM_THREADS,
                        4,
                        InternalServiceSettings.MODEL_ID,
                        ElasticsearchInternalService.MULTILINGUAL_E5_SMALL_MODEL_ID,
                        ServiceFields.DIMENSIONS,
                        1
                    )
                )
            );

            var e5ServiceSettings = new MultilingualE5SmallInternalServiceSettings(
                1,
                4,
                ElasticsearchInternalService.MULTILINGUAL_E5_SMALL_MODEL_ID
            );

            MultilingualE5SmallModel parsedModel = (MultilingualE5SmallModel) service.parsePersistedConfig(
                randomInferenceEntityId,
                taskType,
                settings
            );
            assertEquals(
                new MultilingualE5SmallModel(randomInferenceEntityId, taskType, ElasticsearchInternalService.NAME, e5ServiceSettings),
                parsedModel
            );
        }

        // Invalid config map
        {
            var service = createService(mock(Client.class));
            var settings = new HashMap<String, Object>();
            settings.put(
                ModelConfigurations.SERVICE_SETTINGS,
                new HashMap<>(
                    Map.of(ElasticsearchInternalServiceSettings.NUM_ALLOCATIONS, 1, ElasticsearchInternalServiceSettings.NUM_THREADS, 4)
                )
            );
            settings.put(""not_a_valid_config_setting"", randomAlphaOfLength(10));
            expectThrows(IllegalArgumentException.class, () -> service.parsePersistedConfig(randomInferenceEntityId, taskType, settings));
        }

        // Invalid service settings
        {
            var service = createService(mock(Client.class));
            var settings = new HashMap<String, Object>();
            settings.put(
                ModelConfigurations.SERVICE_SETTINGS,
                new HashMap<>(
                    Map.of(
                        ElasticsearchInternalServiceSettings.NUM_ALLOCATIONS,
                        1,
                        ElasticsearchInternalServiceSettings.NUM_THREADS,
                        4,
                        ""not_a_valid_service_setting"",
                        randomAlphaOfLength(10)
                    )
                )
            );
            expectThrows(IllegalArgumentException.class, () -> service.parsePersistedConfig(randomInferenceEntityId, taskType, settings));
        }
    }",/x-pack/plugin/inference/src/test/java/org/elasticsearch/xpack/inference/services/elasticsearch/ElasticsearchInternalServiceTests.java
85e17af7ea0db9d1b4a74871f9d843d2d863fc99,571,134,") {
        Logger logger = Logging.getLogger(TestClusterConfiguration.class);
        waitConditions.forEach((description, predicate) -> {
            long thisConditionStartedAt = System.currentTimeMillis();
            boolean conditionMet = false;
            Throwable lastException = null;
            while (
                System.currentTimeMillis() - startedAtMillis < TimeUnit.MILLISECONDS.convert(nodeUpTimeout, nodeUpTimeoutUnit)
            ) {
                if (context.isProcessAlive() == false) {
                    throw new TestClustersException(
                        ""process was found dead while waiting for "" + description + "", "" + this
                    );
                }

                try {
                    if(predicate.test(context)) {
                        conditionMet = true;
                        break;
                    }
                } catch (TestClustersException e) {
                    throw e;
                } catch (Exception e) {
                    throw  e;
                }
            }
            if (conditionMet == false) {
                String message = ""`"" + context + ""` failed to wait for "" + description + "" after "" +
                    nodeUpTimeout + "" "" + nodeUpTimeoutUnit;
                if (lastException == null) {
                    throw new TestClustersException(message);
                } else {
                    throw new TestClustersException(message + message, lastException);
                }
            }
            logger.info(
                ""{}: {} took {} seconds"",
                this,  description,
                (System.currentTimeMillis() - thisConditionStartedAt) / 1000.0
            );
        });
    }",") {
        Logger logger = Logging.getLogger(TestClusterConfiguration.class);
        waitConditions.forEach((description, predicate) -> {
            long thisConditionStartedAt = System.currentTimeMillis();
            boolean conditionMet = false;
            Throwable lastException = null;
            while (
                System.currentTimeMillis() - startedAtMillis < TimeUnit.MILLISECONDS.convert(nodeUpTimeout, nodeUpTimeoutUnit)
            ) {
                if (context.isProcessAlive() == false) {
                    throw new TestClustersException(
                        ""process was found dead while waiting for "" + description + "", "" + this
                    );
                }

                try {
                    if(predicate.test(context)) {
                        conditionMet = true;
                        break;
                    }
                } catch (TestClustersException e) {
                    throw e;
                } catch (Exception e) {
                    lastException = e;
                }
            }
            if (conditionMet == false) {
                String message = ""`"" + context + ""` failed to wait for "" + description + "" after "" +
                    nodeUpTimeout + "" "" + nodeUpTimeoutUnit;
                if (lastException == null) {
                    throw new TestClustersException(message);
                } else {
                    String extraCause = """";
                    Throwable cause = lastException;
                    int ident = 2;
                    while (cause != null) {
                        if (cause.getMessage() != null && cause.getMessage().isEmpty() == false) {
                            extraCause += ""\n"" + "" "".repeat(ident) + cause.getMessage();
                            ident += 2;
                        }
                        cause = cause.getCause();
                    }
                    throw new TestClustersException(message + extraCause, lastException);
                }
            }
            logger.info(
                ""{}: {} took {} seconds"",
                this,  description,
                (System.currentTimeMillis() - thisConditionStartedAt) / 1000.0
            );
        });
    }",/buildSrc/src/main/java/org/elasticsearch/gradle/testclusters/TestClusterConfiguration.java
37e97d76dbefbd2531611855de4511fd0f8c0f5c,691,243,"private static Object randomFieldValue(Random random, int dataType) {
        switch(dataType) {
            case 0:
                return RandomStrings.randomAsciiLettersOfLengthBetween(random, 3, 10);
            case 1:
                return RandomStrings.randomAsciiLettersOfLengthBetween(random, 3, 10);
            case 2:
                return random.nextLong();
            case 3:
                return random.nextDouble();
            default:
                throw new UnsupportedOperationException();
        }
    }","private static int randomDataType(Random random) {
        return randomIntBetween(random, 0, 3);
    }",/test/framework/src/main/java/org/elasticsearch/test/RandomObjects.java
88aff40eef94f97830c8884171bed2f8dcedae92,563,206,"public void testFailedAllocation() {
        ClusterState clusterState = createInitialClusterState();
        RoutingTable routingTable = clusterState.routingTable();
        final int retries = MaxRetryAllocationDecider.SETTING_ALLOCATION_MAX_RETRY.get(Settings.EMPTY);
        // now fail it N-1 times
        for (int i = 0; i < retries-1; i++) {
            List<FailedRerouteAllocation.FailedShard> failedShards = Collections.singletonList(
                new FailedRerouteAllocation.FailedShard(routingTable.index(""idx"").shard(0).shards().get(0), ""boom"" + i,
                    new UnsupportedOperationException()));
            RoutingAllocation.Result result = strategy.applyFailedShards(clusterState, failedShards);
            assertTrue(result.changed());
            routingTable = result.routingTable();
            clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
            assertEquals(routingTable.index(""idx"").shards().size(), 1);
            assertEquals(routingTable.index(""idx"").shard(0).shards().get(0).state(), INITIALIZING);
            assertEquals(routingTable.index(""idx"").shard(0).shards().get(0).unassignedInfo().getNumFailedAllocations(), i+1);
            assertEquals(routingTable.index(""idx"").shard(0).shards().get(0).unassignedInfo().getMessage(), ""boom"" + i);
        }
        // now we go and check that we are actually stick to unassigned on the next failure
        {
            List<FailedRerouteAllocation.FailedShard> failedShards = Collections.singletonList(
                new FailedRerouteAllocation.FailedShard(routingTable.index(""idx"").shard(0).shards().get(0), ""boom"",
                    new UnsupportedOperationException()));
            RoutingAllocation.Result result = strategy.applyFailedShards(clusterState, failedShards);
            assertTrue(result.changed());
            routingTable = result.routingTable();
            clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
            assertEquals(routingTable.index(""idx"").shards().size(), 1);
            assertEquals(routingTable.index(""idx"").shard(0).shards().get(0).unassignedInfo().getNumFailedAllocations(), retries);
            assertEquals(routingTable.index(""idx"").shard(0).shards().get(0).state(), UNASSIGNED);
            assertEquals(routingTable.index(""idx"").shard(0).shards().get(0).unassignedInfo().getMessage(), ""boom"");
        }

        // change the settings and ensure we can do another round of allocation for that index.
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable)
            .metaData(MetaData.builder(clusterState.metaData())
                .put(IndexMetaData.builder(clusterState.metaData().index(""idx"")).settings(
                    Settings.builder().put(clusterState.metaData().index(""idx"").getSettings()).put(""index.allocation.max_retries"",
                        retries+1).build()
                ).build(), true).build()).build();
        RoutingAllocation.Result result = strategy.reroute(clusterState, ""settings changed"", false);
        assertTrue(result.changed());
        routingTable = result.routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        // good we are initializing and we are maintaining failure information
        assertEquals(routingTable.index(""idx"").shards().size(), 1);
        assertEquals(routingTable.index(""idx"").shard(0).shards().get(0).unassignedInfo().getNumFailedAllocations(), retries);
        assertEquals(routingTable.index(""idx"").shard(0).shards().get(0).state(), INITIALIZING);
        assertEquals(routingTable.index(""idx"").shard(0).shards().get(0).unassignedInfo().getMessage(), ""boom"");

        // now we start the shard
        routingTable = strategy.applyStartedShards(clusterState, Collections.singletonList(routingTable.index(""idx"")
            .shard(0).shards().get(0))).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        // all counters have been reset to 0 ie. no unassigned info
        assertEquals(routingTable.index(""idx"").shards().size(), 1);
        assertNull(routingTable.index(""idx"").shard(0).shards().get(0).unassignedInfo());
        assertEquals(routingTable.index(""idx"").shard(0).shards().get(0).state(), STARTED);

        // now fail again and see if it has a new counter
        List<FailedRerouteAllocation.FailedShard> failedShards = Collections.singletonList(
            new FailedRerouteAllocation.FailedShard(routingTable.index(""idx"").shard(0).shards().get(0), ""ZOOOMG"",
                new UnsupportedOperationException()));
        result = strategy.applyFailedShards(clusterState, failedShards);
        assertTrue(result.changed());
        routingTable = result.routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        assertEquals(routingTable.index(""idx"").shards().size(), 1);
        assertEquals(routingTable.index(""idx"").shard(0).shards().get(0).unassignedInfo().getNumFailedAllocations(), 1);
        assertEquals(routingTable.index(""idx"").shard(0).shards().get(0).state(), INITIALIZING);
        assertEquals(routingTable.index(""idx"").shard(0).shards().get(0).unassignedInfo().getMessage(), ""ZOOOMG"");
    }","public void testFailedAllocation() {
        ClusterState clusterState = createInitialClusterState();
        RoutingTable routingTable = clusterState.routingTable();
        final int retries = MaxRetryAllocationDecider.SETTING_ALLOCATION_MAX_RETRY.get(Settings.EMPTY);
        // now fail it N-1 times
        for (int i = 0; i < retries-1; i++) {
            List<FailedRerouteAllocation.FailedShard> failedShards = Collections.singletonList(
                new FailedRerouteAllocation.FailedShard(routingTable.index(""idx"").shard(0).shards().get(0), ""boom"" + i,
                    new UnsupportedOperationException()));
            RoutingAllocation.Result result = strategy.applyFailedShards(clusterState, failedShards);
            assertTrue(result.changed());
            routingTable = result.routingTable();
            clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
            assertEquals(routingTable.index(""idx"").shards().size(), 1);
            ShardRouting unassignedPrimary = routingTable.index(""idx"").shard(0).shards().get(0);
            assertEquals(unassignedPrimary.state(), INITIALIZING);
            assertEquals(unassignedPrimary.unassignedInfo().getNumFailedAllocations(), i+1);
            assertEquals(unassignedPrimary.unassignedInfo().getMessage(), ""boom"" + i);
            // MaxRetryAllocationDecider#canForceAllocatePrimary should return YES decisions because canAllocate returns YES here
            assertEquals(Decision.YES, new MaxRetryAllocationDecider(Settings.EMPTY).canForceAllocatePrimary(
                unassignedPrimary, null, new RoutingAllocation(null, null, clusterState, null, 0, false)));
        }
        // now we go and check that we are actually stick to unassigned on the next failure
        {
            List<FailedRerouteAllocation.FailedShard> failedShards = Collections.singletonList(
                new FailedRerouteAllocation.FailedShard(routingTable.index(""idx"").shard(0).shards().get(0), ""boom"",
                    new UnsupportedOperationException()));
            RoutingAllocation.Result result = strategy.applyFailedShards(clusterState, failedShards);
            assertTrue(result.changed());
            routingTable = result.routingTable();
            clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
            assertEquals(routingTable.index(""idx"").shards().size(), 1);
            ShardRouting unassignedPrimary = routingTable.index(""idx"").shard(0).shards().get(0);
            assertEquals(unassignedPrimary.unassignedInfo().getNumFailedAllocations(), retries);
            assertEquals(unassignedPrimary.state(), UNASSIGNED);
            assertEquals(unassignedPrimary.unassignedInfo().getMessage(), ""boom"");
            // MaxRetryAllocationDecider#canForceAllocatePrimary should return a NO decision because canAllocate returns NO here
            assertEquals(Decision.NO, new MaxRetryAllocationDecider(Settings.EMPTY).canForceAllocatePrimary(
                unassignedPrimary, null, new RoutingAllocation(null, null, clusterState, null, 0, false)));
        }

        // change the settings and ensure we can do another round of allocation for that index.
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable)
            .metaData(MetaData.builder(clusterState.metaData())
                .put(IndexMetaData.builder(clusterState.metaData().index(""idx"")).settings(
                    Settings.builder().put(clusterState.metaData().index(""idx"").getSettings()).put(""index.allocation.max_retries"",
                        retries+1).build()
                ).build(), true).build()).build();
        RoutingAllocation.Result result = strategy.reroute(clusterState, ""settings changed"", false);
        assertTrue(result.changed());
        routingTable = result.routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        // good we are initializing and we are maintaining failure information
        assertEquals(routingTable.index(""idx"").shards().size(), 1);
        ShardRouting unassignedPrimary = routingTable.index(""idx"").shard(0).shards().get(0);
        assertEquals(unassignedPrimary.unassignedInfo().getNumFailedAllocations(), retries);
        assertEquals(unassignedPrimary.state(), INITIALIZING);
        assertEquals(unassignedPrimary.unassignedInfo().getMessage(), ""boom"");
        // bumped up the max retry count, so canForceAllocatePrimary should return a YES decision
        assertEquals(Decision.YES, new MaxRetryAllocationDecider(Settings.EMPTY).canForceAllocatePrimary(
            routingTable.index(""idx"").shard(0).shards().get(0), null, new RoutingAllocation(null, null, clusterState, null, 0, false)));

        // now we start the shard
        routingTable = strategy.applyStartedShards(clusterState, Collections.singletonList(
            routingTable.index(""idx"").shard(0).shards().get(0))).routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();

        // all counters have been reset to 0 ie. no unassigned info
        assertEquals(routingTable.index(""idx"").shards().size(), 1);
        assertNull(routingTable.index(""idx"").shard(0).shards().get(0).unassignedInfo());
        assertEquals(routingTable.index(""idx"").shard(0).shards().get(0).state(), STARTED);

        // now fail again and see if it has a new counter
        List<FailedRerouteAllocation.FailedShard> failedShards = Collections.singletonList(
            new FailedRerouteAllocation.FailedShard(routingTable.index(""idx"").shard(0).shards().get(0), ""ZOOOMG"",
                new UnsupportedOperationException()));
        result = strategy.applyFailedShards(clusterState, failedShards);
        assertTrue(result.changed());
        routingTable = result.routingTable();
        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
        assertEquals(routingTable.index(""idx"").shards().size(), 1);
        unassignedPrimary = routingTable.index(""idx"").shard(0).shards().get(0);
        assertEquals(unassignedPrimary.unassignedInfo().getNumFailedAllocations(), 1);
        assertEquals(unassignedPrimary.state(), INITIALIZING);
        assertEquals(unassignedPrimary.unassignedInfo().getMessage(), ""ZOOOMG"");
        // Counter reset, so MaxRetryAllocationDecider#canForceAllocatePrimary should return a YES decision
        assertEquals(Decision.YES, new MaxRetryAllocationDecider(Settings.EMPTY).canForceAllocatePrimary(
            unassignedPrimary, null, new RoutingAllocation(null, null, clusterState, null, 0, false)));
    }",/core/src/test/java/org/elasticsearch/cluster/routing/allocation/MaxRetryAllocationDeciderTests.java
e66a6871c08d48357985c257df2bc80b854c7f99,563,283,"public void testAdAuthWithHostnameVerification() throws Exception {
        RealmConfig config = new RealmConfig(""ad-test"", buildAdSettings(AD_LDAP_URL, AD_DOMAIN, true), globalSettings);
        ActiveDirectorySessionFactory sessionFactory = new ActiveDirectorySessionFactory(config, clientSSLService);

        String userName = ""ironman"";
        try (LdapSession ldap = sessionFactory.session(userName, SecuredStringTests.build(PASSWORD))) {
            fail(""Test active directory certificate does not have proper hostname/ip address for hostname verification"");
        } catch (IOException e) {
            assertThat(e.getMessage(), containsString(""failed to connect to any active directory servers""));
        }
    }","public void testAdAuthWithHostnameVerification() throws Exception {
        RealmConfig config = new RealmConfig(""ad-test"", buildAdSettings(AD_LDAP_URL, AD_DOMAIN, true), globalSettings);
        ActiveDirectorySessionFactory sessionFactory = new ActiveDirectorySessionFactory(config, clientSSLService).init();

        String userName = ""ironman"";
        try (LdapSession ldap = sessionFactory.session(userName, SecuredStringTests.build(PASSWORD))) {
            fail(""Test active directory certificate does not have proper hostname/ip address for hostname verification"");
        } catch (IOException e) {
            assertThat(e.getMessage(), containsString(""failed to connect to any active directory servers""));
        }
    }",/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authc/activedirectory/ActiveDirectorySessionFactoryTests.java
e66a6871c08d48357985c257df2bc80b854c7f99,563,301,"public void testStandardLdapHostnameVerification() throws Exception {
        String groupSearchBase = ""DC=ad,DC=test,DC=elasticsearch,DC=com"";
        String userTemplate = ""CN={0},CN=Users,DC=ad,DC=test,DC=elasticsearch,DC=com"";
        Settings settings = Settings.builder()
                .put(LdapTestCase.buildLdapSettings(AD_LDAP_URL, userTemplate, groupSearchBase, LdapSearchScope.SUB_TREE))
                .put(LdapSessionFactory.HOSTNAME_VERIFICATION_SETTING, true)
                .build();
        RealmConfig config = new RealmConfig(""ad-test"", settings, globalSettings);
        LdapSessionFactory sessionFactory = new LdapSessionFactory(config, clientSSLService);

        String user = ""Bruce Banner"";
        try (LdapSession ldap = sessionFactory.session(user, SecuredStringTests.build(PASSWORD))) {
            fail(""Test active directory certificate does not have proper hostname/ip address for hostname verification"");
        } catch (IOException e) {
            assertThat(e.getMessage(), containsString(""failed to connect to any LDAP servers""));
        }
    }","public void testStandardLdapHostnameVerification() throws Exception {
        String groupSearchBase = ""DC=ad,DC=test,DC=elasticsearch,DC=com"";
        String userTemplate = ""CN={0},CN=Users,DC=ad,DC=test,DC=elasticsearch,DC=com"";
        Settings settings = Settings.builder()
                .put(LdapTestCase.buildLdapSettings(AD_LDAP_URL, userTemplate, groupSearchBase, LdapSearchScope.SUB_TREE))
                .put(LdapSessionFactory.HOSTNAME_VERIFICATION_SETTING, true)
                .build();
        RealmConfig config = new RealmConfig(""ad-test"", settings, globalSettings);
        LdapSessionFactory sessionFactory = new LdapSessionFactory(config, clientSSLService).init();

        String user = ""Bruce Banner"";
        try (LdapSession ldap = sessionFactory.session(user, SecuredStringTests.build(PASSWORD))) {
            fail(""Test active directory certificate does not have proper hostname/ip address for hostname verification"");
        } catch (IOException e) {
            assertThat(e.getMessage(), containsString(""failed to connect to any LDAP servers""));
        }
    }",/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authc/activedirectory/ActiveDirectorySessionFactoryTests.java
e66a6871c08d48357985c257df2bc80b854c7f99,563,141,"public void testStandardLdapConnectionHostnameVerification() throws Exception {
        //openldap does not use cn as naming attributes by default
        String groupSearchBase = ""ou=people,dc=oldap,dc=test,dc=elasticsearch,dc=com"";
        String userTemplate = ""uid={0},ou=people,dc=oldap,dc=test,dc=elasticsearch,dc=com"";
        Settings settings = Settings.builder()
                .put(LdapTestCase.buildLdapSettings(OPEN_LDAP_URL, userTemplate, groupSearchBase, LdapSearchScope.ONE_LEVEL))
                .put(LdapSessionFactory.HOSTNAME_VERIFICATION_SETTING, true)
                .build();

        RealmConfig config = new RealmConfig(""oldap-test"", settings, globalSettings);
        LdapSessionFactory sessionFactory = new LdapSessionFactory(config, clientSSLService);

        String user = ""blackwidow"";
        try (LdapSession ldap = sessionFactory.session(user, SecuredStringTests.build(PASSWORD))) {
            fail(""OpenLDAP certificate does not contain the correct hostname/ip so hostname verification should fail on open"");
        } catch (IOException e) {
            assertThat(e.getMessage(), containsString(""failed to connect to any LDAP servers""));
        }
    }","public void testStandardLdapConnectionHostnameVerification() throws Exception {
        //openldap does not use cn as naming attributes by default
        String groupSearchBase = ""ou=people,dc=oldap,dc=test,dc=elasticsearch,dc=com"";
        String userTemplate = ""uid={0},ou=people,dc=oldap,dc=test,dc=elasticsearch,dc=com"";
        Settings settings = Settings.builder()
                .put(LdapTestCase.buildLdapSettings(OPEN_LDAP_URL, userTemplate, groupSearchBase, LdapSearchScope.ONE_LEVEL))
                .put(LdapSessionFactory.HOSTNAME_VERIFICATION_SETTING, true)
                .build();

        RealmConfig config = new RealmConfig(""oldap-test"", settings, globalSettings);
        LdapSessionFactory sessionFactory = new LdapSessionFactory(config, clientSSLService).init();

        String user = ""blackwidow"";
        try (LdapSession ldap = sessionFactory.session(user, SecuredStringTests.build(PASSWORD))) {
            fail(""OpenLDAP certificate does not contain the correct hostname/ip so hostname verification should fail on open"");
        } catch (IOException e) {
            assertThat(e.getMessage(), containsString(""failed to connect to any LDAP servers""));
        }
    }",/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authc/ldap/OpenLdapTests.java
e66a6871c08d48357985c257df2bc80b854c7f99,563,60,"public void testBindWithReadTimeout() throws Exception {
        InMemoryDirectoryServer ldapServer = randomFrom(ldapServers);
        String ldapUrl = new LDAPURL(""ldap"", ""localhost"", ldapServer.getListenPort(), null, null, null, null).toString();
        String groupSearchBase = ""o=sevenSeas"";
        String userTemplates = ""cn={0},ou=people,o=sevenSeas"";

        Settings settings = Settings.builder()
                .put(buildLdapSettings(ldapUrl, userTemplates, groupSearchBase, LdapSearchScope.SUB_TREE))
                .put(SessionFactory.TIMEOUT_TCP_READ_SETTING, ""1ms"") //1 millisecond
                .put(""path.home"", createTempDir())
                .build();

        RealmConfig config = new RealmConfig(""ldap_realm"", settings, globalSettings);
        LdapSessionFactory sessionFactory = new LdapSessionFactory(config, null);
        String user = ""Horatio Hornblower"";
        SecuredString userPass = SecuredStringTests.build(""pass"");

        ldapServer.setProcessingDelayMillis(500L);
        try (LdapSession session = sessionFactory.session(user, userPass)) {
            fail(""expected connection timeout error here"");
        } catch (Throwable t) {
            assertThat(t, instanceOf(ElasticsearchSecurityException.class));
            assertThat(t.getCause().getMessage(), containsString(""A client-side timeout was encountered while waiting ""));
        } finally {
            ldapServer.setProcessingDelayMillis(0L);
        }
    }","public void testBindWithReadTimeout() throws Exception {
        InMemoryDirectoryServer ldapServer = randomFrom(ldapServers);
        String ldapUrl = new LDAPURL(""ldap"", ""localhost"", ldapServer.getListenPort(), null, null, null, null).toString();
        String groupSearchBase = ""o=sevenSeas"";
        String userTemplates = ""cn={0},ou=people,o=sevenSeas"";

        Settings settings = Settings.builder()
                .put(buildLdapSettings(ldapUrl, userTemplates, groupSearchBase, LdapSearchScope.SUB_TREE))
                .put(SessionFactory.TIMEOUT_TCP_READ_SETTING, ""1ms"") //1 millisecond
                .put(""path.home"", createTempDir())
                .build();

        RealmConfig config = new RealmConfig(""ldap_realm"", settings, globalSettings);
        LdapSessionFactory sessionFactory = new LdapSessionFactory(config, null).init();
        String user = ""Horatio Hornblower"";
        SecuredString userPass = SecuredStringTests.build(""pass"");

        ldapServer.setProcessingDelayMillis(500L);
        try (LdapSession session = sessionFactory.session(user, userPass)) {
            fail(""expected connection timeout error here"");
        } catch (Throwable t) {
            assertThat(t, instanceOf(ElasticsearchSecurityException.class));
            assertThat(t.getCause().getMessage(), containsString(""A client-side timeout was encountered while waiting ""));
        } finally {
            ldapServer.setProcessingDelayMillis(0L);
        }
    }",/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authc/ldap/LdapSessionFactoryTests.java
e66a6871c08d48357985c257df2bc80b854c7f99,563,134,"public void testBindWithBogusTemplates() throws Exception {
        String groupSearchBase = ""o=sevenSeas"";
        String[] userTemplates = new String[] {
                ""cn={0},ou=something,ou=obviously,ou=incorrect,o=sevenSeas"",
                ""wrongname={0},ou=people,o=sevenSeas"",
                ""asdf={0},ou=people,o=sevenSeas"", //none of these should work
        };
        RealmConfig config = new RealmConfig(""ldap_realm"", buildLdapSettings(ldapUrls(), userTemplates, groupSearchBase,
                LdapSearchScope.SUB_TREE), globalSettings);

        LdapSessionFactory ldapFac = new LdapSessionFactory(config, null);

        String user = ""Horatio Hornblower"";
        SecuredString userPass = SecuredStringTests.build(""pass"");
        try (LdapSession ldapConnection = ldapFac.session(user, userPass)) {
            fail(""Expected ElasticsearchSecurityException"");
        } catch (ElasticsearchSecurityException e) {
            assertThat(e.getMessage(), is(""failed LDAP authentication""));
        }
    }","public void testBindWithBogusTemplates() throws Exception {
        String groupSearchBase = ""o=sevenSeas"";
        String[] userTemplates = new String[] {
                ""cn={0},ou=something,ou=obviously,ou=incorrect,o=sevenSeas"",
                ""wrongname={0},ou=people,o=sevenSeas"",
                ""asdf={0},ou=people,o=sevenSeas"", //none of these should work
        };
        RealmConfig config = new RealmConfig(""ldap_realm"", buildLdapSettings(ldapUrls(), userTemplates, groupSearchBase,
                LdapSearchScope.SUB_TREE), globalSettings);

        LdapSessionFactory ldapFac = new LdapSessionFactory(config, null).init();

        String user = ""Horatio Hornblower"";
        SecuredString userPass = SecuredStringTests.build(""pass"");
        try (LdapSession ldapConnection = ldapFac.session(user, userPass)) {
            fail(""Expected ElasticsearchSecurityException"");
        } catch (ElasticsearchSecurityException e) {
            assertThat(e.getMessage(), is(""failed LDAP authentication""));
        }
    }",/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authc/ldap/LdapSessionFactoryTests.java
e66a6871c08d48357985c257df2bc80b854c7f99,563,89,"public void testConnectTimeout() {
        // Local sockets connect too fast...
        String ldapUrl = ""ldap://54.200.235.244:389"";
        String groupSearchBase = ""o=sevenSeas"";
        String userTemplates = ""cn={0},ou=people,o=sevenSeas"";

        Settings settings = Settings.builder()
                .put(buildLdapSettings(ldapUrl, userTemplates, groupSearchBase, LdapSearchScope.SUB_TREE))
                .put(SessionFactory.TIMEOUT_TCP_CONNECTION_SETTING, ""1ms"") //1 millisecond
                .build();

        RealmConfig config = new RealmConfig(""ldap_realm"", settings, globalSettings);
        LdapSessionFactory sessionFactory = new LdapSessionFactory(config, null);
        String user = ""Horatio Hornblower"";
        SecuredString userPass = SecuredStringTests.build(""pass"");

        long start = System.currentTimeMillis();
        try (LdapSession session = sessionFactory.session(user, userPass)) {
            fail(""expected connection timeout error here"");
        } catch (Throwable t) {
            long time = System.currentTimeMillis() - start;
            assertThat(time, lessThan(10000L));
            assertThat(t, instanceOf(IOException.class));
            assertThat(t.getCause().getCause().getMessage(), containsString(""within the configured timeout of""));
        }
    }","public void testConnectTimeout() {
        // Local sockets connect too fast...
        String ldapUrl = ""ldap://54.200.235.244:389"";
        String groupSearchBase = ""o=sevenSeas"";
        String userTemplates = ""cn={0},ou=people,o=sevenSeas"";

        Settings settings = Settings.builder()
                .put(buildLdapSettings(ldapUrl, userTemplates, groupSearchBase, LdapSearchScope.SUB_TREE))
                .put(SessionFactory.TIMEOUT_TCP_CONNECTION_SETTING, ""1ms"") //1 millisecond
                .build();

        RealmConfig config = new RealmConfig(""ldap_realm"", settings, globalSettings);
        LdapSessionFactory sessionFactory = new LdapSessionFactory(config, null).init();
        String user = ""Horatio Hornblower"";
        SecuredString userPass = SecuredStringTests.build(""pass"");

        long start = System.currentTimeMillis();
        try (LdapSession session = sessionFactory.session(user, userPass)) {
            fail(""expected connection timeout error here"");
        } catch (Throwable t) {
            long time = System.currentTimeMillis() - start;
            assertThat(time, lessThan(10000L));
            assertThat(t, instanceOf(IOException.class));
            assertThat(t.getCause().getCause().getMessage(), containsString(""within the configured timeout of""));
        }
    }",/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authc/ldap/LdapSessionFactoryTests.java
a7f6feaad5d1ef00082849ac33efea4e67f87e08,690,200,"private void cancelTask(Long allocationId) {
        AllocatedPersistentTask task = runningTasks.remove(allocationId);
        if (task.markAsCancelled()) {
            // Cancel the local task using the task manager
            String reason = ""task has been removed, cancelling locally"";
            persistentTasksService.sendCancelRequest(task.getId(), reason, new ActionListener<CancelTasksResponse>() {
                @Override
                public void onResponse(CancelTasksResponse cancelTasksResponse) {
                    logger.trace(""Persistent task [{}] with id [{}] and allocation id [{}] was cancelled"", task.getAction(),
                            task.getPersistentTaskId(), task.getAllocationId());
                }

                @Override
                public void onFailure(Exception e) {
                    // There is really nothing we can do in case of failure here
                    logger.warn(() -> new ParameterizedMessage(
                        ""failed to cancel task [{}] with id [{}] and allocation id [{}]"",
                        task.getAction(), task.getPersistentTaskId(), task.getAllocationId()), e);
                }
            });
        }
    }","private <Params extends PersistentTaskParams> void startTask(PersistentTask<Params> taskInProgress) {
        PersistentTasksExecutor<Params> executor =
                persistentTasksExecutorRegistry.getPersistentTaskExecutorSafe(taskInProgress.getTaskName());

        TaskAwareRequest request = new TaskAwareRequest() {
            TaskId parentTaskId = new TaskId(""cluster"", taskInProgress.getAllocationId());

            @Override
            public void setParentTask(TaskId taskId) {
                throw new UnsupportedOperationException(""parent task if for persistent tasks shouldn't change"");
            }

            @Override
            public TaskId getParentTask() {
                return parentTaskId;
            }

            @Override
            public Task createTask(long id, String type, String action, TaskId parentTaskId, Map<String, String> headers) {
                return executor.createTask(id, type, action, parentTaskId, taskInProgress, headers);
            }
        };

        AllocatedPersistentTask task;
        try {
            task = (AllocatedPersistentTask) taskManager.register(""persistent"", taskInProgress.getTaskName() + ""[c]"", request);
        } catch (Exception e) {
            logger.error(""Fatal error registering persistent task ["" + taskInProgress.getTaskName()
                + ""] with id ["" + taskInProgress.getId() + ""] and allocation id ["" + taskInProgress.getAllocationId()
                + ""], removing from persistent tasks"", e);
            notifyMasterOfFailedTask(taskInProgress, e);
            return;
        }

        boolean processed = false;
        try {
            task.init(persistentTasksService, taskManager, logger, taskInProgress.getId(), taskInProgress.getAllocationId());
            logger.trace(""Persistent task [{}] with id [{}] and allocation id [{}] was created"", task.getAction(),
                    task.getPersistentTaskId(), task.getAllocationId());
            try {
                runningTasks.put(taskInProgress.getAllocationId(), task);
                nodePersistentTasksExecutor.executeTask(taskInProgress.getParams(), taskInProgress.getState(), task, executor);
            } catch (Exception e) {
                // Submit task failure
                task.markAsFailed(e);
            }
            processed = true;
        } finally {
            if (processed == false) {
                // something went wrong - unregistering task
                logger.warn(""Persistent task [{}] with id [{}] and allocation id [{}] failed to create"", task.getAction(),
                        task.getPersistentTaskId(), task.getAllocationId());
                taskManager.unregister(task);
            }
        }
    }",/server/src/main/java/org/elasticsearch/persistent/PersistentTasksNodeService.java
3d1b5cfbffb1862c4888b94977fb22b58ae1b81e,457,80,"public void testOverShardLimit() {
        int nodesInCluster = randomIntBetween(1, 90);
        ShardCounts counts = forDataNodeCount(nodesInCluster);
        ClusterState state = createClusterForShardLimitTest(
            nodesInCluster,
            counts.getFirstIndexShards(),
            counts.getFirstIndexReplicas(),
            counts.getShardsPerNode(),
            NORMAL_GROUP
        );

        int shardsToAdd = counts.getFailingIndexShards() * (1 + counts.getFailingIndexReplicas());
        Optional<String> errorMessage = ShardLimitValidator.checkShardLimit(
            shardsToAdd,
            state,
            counts.getShardsPerNode(),
            nodesInCluster,
            NORMAL_GROUP
        );

        int totalShards = counts.getFailingIndexShards() * (1 + counts.getFailingIndexReplicas());
        int currentShards = counts.getFirstIndexShards() * (1 + counts.getFirstIndexReplicas());
        int maxShards = counts.getShardsPerNode() * nodesInCluster;
        assertTrue(errorMessage.isPresent());
        assertEquals(
            ""this action would add [""
                + totalShards
                + ""] shards, but this cluster currently has [""
                + currentShards
                + ""]/[""
                + maxShards
                + ""] maximum ""
                + NORMAL_GROUP
                + "" shards open"",
            errorMessage.get()
        );
        assertFalse(ShardLimitValidator.canAddShardsToCluster(counts.getFailingIndexShards(), counts.getFailingIndexReplicas(), state));
    }","public void testOverShardLimit() {
        int nodesInCluster = randomIntBetween(1, 90);
        ShardCounts counts = forDataNodeCount(nodesInCluster);
        ClusterState state = createClusterForShardLimitTest(
            nodesInCluster,
            counts.getFirstIndexShards(),
            counts.getFirstIndexReplicas(),
            counts.getShardsPerNode(),
            NORMAL_GROUP
        );

        int shardsToAdd = counts.getFailingIndexShards() * (1 + counts.getFailingIndexReplicas());
        var shardLimitsResult = ShardLimitValidator.checkShardLimit(
            shardsToAdd,
            state,
            counts.getShardsPerNode(),
            nodesInCluster,
            NORMAL_GROUP
        );

        int totalShards = counts.getFailingIndexShards() * (1 + counts.getFailingIndexReplicas());
        int currentOpenShards = counts.getFirstIndexShards() * (1 + counts.getFirstIndexReplicas());
        int maxShards = counts.getShardsPerNode() * nodesInCluster;

        assertFalse(shardLimitsResult.canAddShards());
        assertEquals(
            ""this action would add [""
                + totalShards
                + ""] shards, but this cluster currently has [""
                + currentOpenShards
                + ""]/[""
                + maxShards
                + ""] maximum ""
                + NORMAL_GROUP
                + "" shards open"",
            ShardLimitValidator.errorMessageFrom(shardLimitsResult)
        );
        assertEquals(shardLimitsResult.maxShardsInCluster(), maxShards);
        assertEquals(shardLimitsResult.totalShardsToAdd(), totalShards);
        shardLimitsResult.currentUsedShards()
            .ifPresentOrElse(v -> assertEquals(currentOpenShards, v.intValue()), () -> fail(""currentUsedShard should be defined""));
        assertEquals(shardLimitsResult.group(), ""normal"");
    }",/server/src/test/java/org/elasticsearch/indices/ShardLimitValidatorTests.java
beb7e53a7aa76d47da89bae4c228e161ae8ea564,391,557,"protected void doExecute(Task task, TestRequest request, ActionListener<TestResponse> listener) {
            arrivedLatches.get(request).countDown();
            List<TestRequest> subRequests = request.subRequests;
            GroupedActionListener<TestResponse> groupedListener = new GroupedActionListener<>(
                subRequests.size() + 1,
                listener.map(r -> new TestResponse())
            );
            transportService.getThreadPool().generic().execute(ActionRunnable.supply(groupedListener, () -> {
                assertTrue(beforeExecuteLatches.get(request).await(60, TimeUnit.SECONDS));
                if (request.timeout) {
                    // Simulate working until cancelled
                    while (((CancellableTask) task).isCancelled() == false) {
                        try {
                            Thread.sleep(1);
                        } catch (InterruptedException e) {}
                    }
                } else {
                    ((CancellableTask) task).ensureNotCancelled();
                }
                return new TestResponse();
            }));
            for (TestRequest subRequest : subRequests) {
                TaskId parentTaskId = new TaskId(client.getLocalNodeId(), task.getId());
                startSubTask(parentTaskId, subRequest, groupedListener);
            }
        }","private void schedule(Task task, TestRequest request, TimeValue delay, ActionListener<TestResponse> listener) {
            transportService.getThreadPool().schedule(new AbstractRunnable() {
                @Override
                public void onFailure(Exception e) {
                    listener.onFailure(e);
                }

                @Override
                protected void doRun() throws Exception {
                    assertTrue(beforeExecuteLatches.get(request).await(60, TimeUnit.SECONDS));
                    if (request.timeout) {
                        // Repeat work until cancelled
                        if (((CancellableTask) task).isCancelled() == false) {
                            schedule(task, request, TimeValue.timeValueMillis(10), listener);
                            return;
                        }
                    } else {
                        ((CancellableTask) task).ensureNotCancelled();
                    }
                    listener.onResponse(new TestResponse());
                }
            }, delay, ThreadPool.Names.GENERIC);
        }",/server/src/internalClusterTest/java/org/elasticsearch/action/admin/cluster/node/tasks/CancellableTasksIT.java
0411627efa2da64e30c775edc74458a49e409bab,595,170,"void merge(ReloadResult other) {
            assert this.indexName == other.index;
            this.reloadedAnalyzers.addAll(other.reloadedSearchAnalyzers);
            this.reloadedIndicesNodes.add(other.nodeId);
        }","void merge(ReloadResult other) {
            assert this.indexName.equals(other.index);
            this.reloadedAnalyzers.addAll(other.reloadedSearchAnalyzers);
            this.reloadedIndicesNodes.add(other.nodeId);
        }",/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/action/ReloadAnalyzersResponse.java
685e35e0aed59a5c2ac1c84a21e6d4620531ee5c,570,86,"private void warnAboutDiskIfNeeded(DiskUsage usage) {
        // Check absolute disk values
        if (usage.getFreeBytes() < diskThresholdSettings.getFreeBytesThresholdFloodStage().getBytes()) {
            logger.warn(""flood stage disk watermark [{}] exceeded on {}, all indices on this node will marked read-only"",
                diskThresholdSettings.getFreeBytesThresholdFloodStage(), usage);
        } else if (usage.getFreeBytes() < diskThresholdSettings.getFreeBytesThresholdHigh().getBytes()) {
            logger.warn(""high disk watermark [{}] exceeded on {}, shards will be relocated away from this node"",
                diskThresholdSettings.getFreeBytesThresholdHigh(), usage);
        } else if (usage.getFreeBytes() < diskThresholdSettings.getFreeBytesThresholdLow().getBytes()) {
            logger.info(""low disk watermark [{}] exceeded on {}, replicas will not be assigned to this node"",
                diskThresholdSettings.getFreeBytesThresholdLow(), usage);
        }

        // Check percentage disk values
        if (usage.getFreeDiskAsPercentage() < diskThresholdSettings.getFreeDiskThresholdHigh()) {
            logger.warn(""flood stage disk watermark [{}] exceeded on {}, all indices on this node will marked read-only"",
                Strings.format1Decimals(100.0 - diskThresholdSettings.getFreeDiskThresholdFloodStage(), ""%""), usage);
        } else if (usage.getFreeDiskAsPercentage() < diskThresholdSettings.getFreeDiskThresholdHigh()) {
            logger.warn(""high disk watermark [{}] exceeded on {}, shards will be relocated away from this node"",
                Strings.format1Decimals(100.0 - diskThresholdSettings.getFreeDiskThresholdHigh(), ""%""), usage);
        } else if (usage.getFreeDiskAsPercentage() < diskThresholdSettings.getFreeDiskThresholdLow()) {
            logger.info(""low disk watermark [{}] exceeded on {}, replicas will not be assigned to this node"",
                Strings.format1Decimals(100.0 - diskThresholdSettings.getFreeDiskThresholdLow(), ""%""), usage);
        }
    }","private void warnAboutDiskIfNeeded(DiskUsage usage) {
        // Check absolute disk values
        if (usage.getFreeBytes() < diskThresholdSettings.getFreeBytesThresholdFloodStage().getBytes()) {
            logger.warn(""flood stage disk watermark [{}] exceeded on {}, all indices on this node will marked read-only"",
                diskThresholdSettings.getFreeBytesThresholdFloodStage(), usage);
        } else if (usage.getFreeBytes() < diskThresholdSettings.getFreeBytesThresholdHigh().getBytes()) {
            logger.warn(""high disk watermark [{}] exceeded on {}, shards will be relocated away from this node"",
                diskThresholdSettings.getFreeBytesThresholdHigh(), usage);
        } else if (usage.getFreeBytes() < diskThresholdSettings.getFreeBytesThresholdLow().getBytes()) {
            logger.info(""low disk watermark [{}] exceeded on {}, replicas will not be assigned to this node"",
                diskThresholdSettings.getFreeBytesThresholdLow(), usage);
        }

        // Check percentage disk values
        if (usage.getFreeDiskAsPercentage() < diskThresholdSettings.getFreeDiskThresholdFloodStage()) {
            logger.warn(""flood stage disk watermark [{}] exceeded on {}, all indices on this node will marked read-only"",
                Strings.format1Decimals(100.0 - diskThresholdSettings.getFreeDiskThresholdFloodStage(), ""%""), usage);
        } else if (usage.getFreeDiskAsPercentage() < diskThresholdSettings.getFreeDiskThresholdHigh()) {
            logger.warn(""high disk watermark [{}] exceeded on {}, shards will be relocated away from this node"",
                Strings.format1Decimals(100.0 - diskThresholdSettings.getFreeDiskThresholdHigh(), ""%""), usage);
        } else if (usage.getFreeDiskAsPercentage() < diskThresholdSettings.getFreeDiskThresholdLow()) {
            logger.info(""low disk watermark [{}] exceeded on {}, replicas will not be assigned to this node"",
                Strings.format1Decimals(100.0 - diskThresholdSettings.getFreeDiskThresholdLow(), ""%""), usage);
        }
    }",/core/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdMonitor.java
c6336153dd54b0fa850366951b2299bb085a02a8,563,167,"public void testCreateAndRestorePartialSearchableSnapshot() throws Exception {
        final String fsRepoName = randomAlphaOfLength(10);
        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);
        final String aliasName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);
        final String restoredIndexName = randomBoolean() ? indexName : randomAlphaOfLength(10).toLowerCase(Locale.ROOT);
        final String snapshotName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);

        createRepository(
            fsRepoName,
            ""fs"",
            Settings.builder().put(""location"", randomRepoPath()).put(""chunk_size"", randomIntBetween(100, 1000), ByteSizeUnit.BYTES)
        );

        // Peer recovery always copies .liv files but we do not permit writing to searchable snapshot directories so this doesn't work, but
        // we can bypass this by forcing soft deletes to be used. TODO this restriction can be lifted when #55142 is resolved.
        final Settings.Builder originalIndexSettings = Settings.builder().put(INDEX_SOFT_DELETES_SETTING.getKey(), true);
        if (randomBoolean()) {
            originalIndexSettings.put(IndexSettings.INDEX_CHECK_ON_STARTUP.getKey(), randomFrom(""false"", ""true"", ""checksum""));
        }
        assertAcked(prepareCreate(indexName, originalIndexSettings));
        assertAcked(client().admin().indices().prepareAliases().addAlias(indexName, aliasName));

        populateIndex(indexName, 10_000);

        final TotalHits originalAllHits = internalCluster().client()
            .prepareSearch(indexName)
            .setTrackTotalHits(true)
            .get()
            .getHits()
            .getTotalHits();
        final TotalHits originalBarHits = internalCluster().client()
            .prepareSearch(indexName)
            .setTrackTotalHits(true)
            .setQuery(matchQuery(""foo"", ""bar""))
            .get()
            .getHits()
            .getTotalHits();
        logger.info(""--> [{}] in total, of which [{}] match the query"", originalAllHits, originalBarHits);

        expectThrows(
            ResourceNotFoundException.class,
            ""Searchable snapshot stats on a non snapshot searchable index should fail"",
            () -> client().execute(SearchableSnapshotsStatsAction.INSTANCE, new SearchableSnapshotsStatsRequest()).actionGet()
        );

        final SnapshotInfo snapshotInfo = createFullSnapshot(fsRepoName, snapshotName);
        ensureGreen(indexName);

        assertShardFolders(indexName, false);

        assertThat(
            client().admin()
                .cluster()
                .prepareState()
                .clear()
                .setMetadata(true)
                .setIndices(indexName)
                .get()
                .getState()
                .metadata()
                .index(indexName)
                .getTimestampRange(),
            sameInstance(IndexLongFieldRange.UNKNOWN)
        );

        final boolean deletedBeforeMount = randomBoolean();
        if (deletedBeforeMount) {
            assertAcked(client().admin().indices().prepareDelete(indexName));
        } else {
            assertAcked(client().admin().indices().prepareClose(indexName));
        }

        logger.info(""--> restoring partial index [{}] with cache enabled"", restoredIndexName);

        Settings.Builder indexSettingsBuilder = Settings.builder().put(SearchableSnapshots.SNAPSHOT_CACHE_ENABLED_SETTING.getKey(), true);
        final List<String> nonCachedExtensions;
        if (randomBoolean()) {
            nonCachedExtensions = randomSubsetOf(Arrays.asList(""fdt"", ""fdx"", ""nvd"", ""dvd"", ""tip"", ""cfs"", ""dim""));
            indexSettingsBuilder.putList(SearchableSnapshots.SNAPSHOT_CACHE_EXCLUDED_FILE_TYPES_SETTING.getKey(), nonCachedExtensions);
        } else {
            nonCachedExtensions = Collections.emptyList();
        }
        if (randomBoolean()) {
            indexSettingsBuilder.put(
                SearchableSnapshots.SNAPSHOT_UNCACHED_CHUNK_SIZE_SETTING.getKey(),
                new ByteSizeValue(randomLongBetween(10, 100_000))
            );
        }
        final int expectedReplicas;
        if (randomBoolean()) {
            expectedReplicas = numberOfReplicas();
            indexSettingsBuilder.put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, expectedReplicas);
        } else {
            expectedReplicas = 0;
        }
        final String indexCheckOnStartup;
        if (randomBoolean()) {
            indexCheckOnStartup = randomFrom(""false"", ""true"", ""checksum"");
            indexSettingsBuilder.put(IndexSettings.INDEX_CHECK_ON_STARTUP.getKey(), indexCheckOnStartup);
        } else {
            indexCheckOnStartup = ""false"";
        }
        final String expectedDataTiersPreference;
        expectedDataTiersPreference = MountSearchableSnapshotRequest.Storage.SHARED_CACHE.defaultDataTiersPreference();

        indexSettingsBuilder.put(Store.INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), TimeValue.ZERO);
        final AtomicBoolean statsWatcherRunning = new AtomicBoolean(true);
        final Thread statsWatcher = new Thread(() -> {
            while (statsWatcherRunning.get()) {
                final IndicesStatsResponse indicesStatsResponse;
                try {
                    indicesStatsResponse = client().admin().indices().prepareStats(restoredIndexName).clear().setStore(true).get();
                } catch (IndexNotFoundException | IndexClosedException e) {
                    continue;
                    // ok
                }

                for (ShardStats shardStats : indicesStatsResponse.getShards()) {
                    StoreStats store = shardStats.getStats().getStore();
                    assertThat(shardStats.getShardRouting().toString(), store.getReservedSize().getBytes(), equalTo(0L));
                    assertThat(shardStats.getShardRouting().toString(), store.getSize().getBytes(), equalTo(0L));
                }
                if (indicesStatsResponse.getShards().length > 0) {
                    assertThat(indicesStatsResponse.getTotal().getStore().getReservedSize().getBytes(), equalTo(0L));
                    assertThat(indicesStatsResponse.getTotal().getStore().getSize().getBytes(), equalTo(0L));
                }
            }
        }, ""test-stats-watcher"");
        statsWatcher.start();

        final MountSearchableSnapshotRequest req = new MountSearchableSnapshotRequest(
            restoredIndexName,
            fsRepoName,
            snapshotInfo.snapshotId().getName(),
            indexName,
            indexSettingsBuilder.build(),
            Strings.EMPTY_ARRAY,
            true,
            MountSearchableSnapshotRequest.Storage.SHARED_CACHE
        );

        final RestoreSnapshotResponse restoreSnapshotResponse = client().execute(MountSearchableSnapshotAction.INSTANCE, req).get();
        assertThat(restoreSnapshotResponse.getRestoreInfo().failedShards(), equalTo(0));

        final Map<Integer, SnapshotIndexShardStatus> snapshotShards = clusterAdmin().prepareSnapshotStatus(fsRepoName)
            .setSnapshots(snapshotInfo.snapshotId().getName())
            .get()
            .getSnapshots()
            .get(0)
            .getIndices()
            .get(indexName)
            .getShards();

        ensureGreen(restoredIndexName);

        final IndicesStatsResponse indicesStatsResponse = client().admin()
            .indices()
            .prepareStats(restoredIndexName)
            .clear()
            .setStore(true)
            .get();
        assertThat(indicesStatsResponse.getShards().length, greaterThan(0));
        long totalExpectedSize = 0;
        for (ShardStats shardStats : indicesStatsResponse.getShards()) {
            StoreStats store = shardStats.getStats().getStore();

            final ShardRouting shardRouting = shardStats.getShardRouting();
            assertThat(shardRouting.toString(), store.getReservedSize().getBytes(), equalTo(0L));
            assertThat(shardRouting.toString(), store.getSize().getBytes(), equalTo(0L));

            // the original shard size from the snapshot
            final long originalSize = snapshotShards.get(shardRouting.getId()).getStats().getTotalSize();
            totalExpectedSize += originalSize;

            // an extra segments_N file is created for bootstrapping new history and associating translog. We can extract the size of this
            // extra file but we have to unwrap the in-memory directory first.
            final Directory unwrappedDir = FilterDirectory.unwrap(
                internalCluster().getInstance(IndicesService.class, getDiscoveryNodes().resolveNode(shardRouting.currentNodeId()).getName())
                    .indexServiceSafe(shardRouting.index())
                    .getShard(shardRouting.getId())
                    .store()
                    .directory()
            );
            assertThat(shardRouting.toString(), unwrappedDir, notNullValue());
            assertThat(shardRouting.toString(), unwrappedDir, instanceOf(ByteBuffersDirectory.class));

            final ByteBuffersDirectory inMemoryDir = (ByteBuffersDirectory) unwrappedDir;
            assertThat(inMemoryDir.listAll(), arrayWithSize(1));

            final String segmentsFileName = SegmentInfos.getLastCommitSegmentsFileName(inMemoryDir);
            assertThat(""Fail to find segment file name directory for "" + shardRouting.toString(), segmentsFileName, notNullValue());
            final long extraSegmentFileSize = inMemoryDir.fileLength(segmentsFileName);

            assertThat(shardRouting.toString(), store.getTotalDataSetSize().getBytes(), equalTo(originalSize + extraSegmentFileSize));
            totalExpectedSize += extraSegmentFileSize;
        }

        final StoreStats store = indicesStatsResponse.getTotal().getStore();
        assertThat(store.getTotalDataSetSize().getBytes(), equalTo(totalExpectedSize));

        statsWatcherRunning.set(false);
        statsWatcher.join();

        final Settings settings = client().admin()
            .indices()
            .prepareGetSettings(restoredIndexName)
            .get()
            .getIndexToSettings()
            .get(restoredIndexName);
        assertThat(SearchableSnapshots.SNAPSHOT_SNAPSHOT_NAME_SETTING.get(settings), equalTo(snapshotName));
        assertThat(IndexModule.INDEX_STORE_TYPE_SETTING.get(settings), equalTo(SEARCHABLE_SNAPSHOT_STORE_TYPE));
        assertThat(IndexModule.INDEX_RECOVERY_TYPE_SETTING.get(settings), equalTo(SNAPSHOT_RECOVERY_STATE_FACTORY_KEY));
        assertTrue(IndexMetadata.INDEX_BLOCKS_WRITE_SETTING.get(settings));
        assertTrue(SearchableSnapshots.SNAPSHOT_SNAPSHOT_ID_SETTING.exists(settings));
        assertTrue(SearchableSnapshots.SNAPSHOT_INDEX_ID_SETTING.exists(settings));
        assertThat(IndexMetadata.INDEX_AUTO_EXPAND_REPLICAS_SETTING.get(settings).toString(), equalTo(""false""));
        assertThat(IndexMetadata.INDEX_NUMBER_OF_REPLICAS_SETTING.get(settings), equalTo(expectedReplicas));
        assertThat(DataTier.TIER_PREFERENCE_SETTING.get(settings), equalTo(expectedDataTiersPreference));
        assertTrue(SearchableSnapshotsSettings.SNAPSHOT_PARTIAL_SETTING.get(settings));
        assertTrue(DiskThresholdDecider.SETTING_IGNORE_DISK_WATERMARKS.get(settings));
        assertThat(IndexSettings.INDEX_CHECK_ON_STARTUP.get(settings), equalTo(indexCheckOnStartup));

        checkSoftDeletesNotEagerlyLoaded(restoredIndexName);
        assertTotalHits(restoredIndexName, originalAllHits, originalBarHits);
        assertRecoveryStats(restoredIndexName, false);
        // TODO: fix
        // assertSearchableSnapshotStats(restoredIndexName, true, nonCachedExtensions);
        ensureGreen(restoredIndexName);
        assertShardFolders(restoredIndexName, true);

        assertThat(
            client().admin()
                .cluster()
                .prepareState()
                .clear()
                .setMetadata(true)
                .setIndices(restoredIndexName)
                .get()
                .getState()
                .metadata()
                .index(restoredIndexName)
                .getTimestampRange(),
            sameInstance(IndexLongFieldRange.UNKNOWN)
        );

        if (deletedBeforeMount) {
            assertThat(client().admin().indices().prepareGetAliases(aliasName).get().getAliases().size(), equalTo(0));
            assertAcked(client().admin().indices().prepareAliases().addAlias(restoredIndexName, aliasName));
        } else if (indexName.equals(restoredIndexName) == false) {
            assertThat(client().admin().indices().prepareGetAliases(aliasName).get().getAliases().size(), equalTo(1));
            assertAcked(
                client().admin()
                    .indices()
                    .prepareAliases()
                    .addAliasAction(IndicesAliasesRequest.AliasActions.remove().index(indexName).alias(aliasName).mustExist(true))
                    .addAlias(restoredIndexName, aliasName)
            );
        }
        assertThat(client().admin().indices().prepareGetAliases(aliasName).get().getAliases().size(), equalTo(1));
        assertTotalHits(aliasName, originalAllHits, originalBarHits);

        final Decision diskDeciderDecision = client().admin()
            .cluster()
            .prepareAllocationExplain()
            .setIndex(restoredIndexName)
            .setShard(0)
            .setPrimary(true)
            .setIncludeYesDecisions(true)
            .get()
            .getExplanation()
            .getShardAllocationDecision()
            .getMoveDecision()
            .getCanRemainDecision()
            .getDecisions()
            .stream()
            .filter(d -> d.label().equals(DiskThresholdDecider.NAME))
            .findFirst()
            .orElseThrow();
        assertThat(diskDeciderDecision.type(), equalTo(Decision.Type.YES));
        assertThat(
            diskDeciderDecision.getExplanation(),
            oneOf(""disk watermarks are ignored on this index"", ""there is only a single data node present"")
        );

        internalCluster().fullRestart();
        assertTotalHits(restoredIndexName, originalAllHits, originalBarHits);
        assertRecoveryStats(restoredIndexName, false);
        assertTotalHits(aliasName, originalAllHits, originalBarHits);
        // TODO: fix
        // assertSearchableSnapshotStats(restoredIndexName, false, nonCachedExtensions);

        internalCluster().ensureAtLeastNumDataNodes(2);

        final DiscoveryNode dataNode = randomFrom(
            client().admin().cluster().prepareState().get().getState().nodes().getDataNodes().values()
        );

        assertAcked(
            client().admin()
                .indices()
                .prepareUpdateSettings(restoredIndexName)
                .setSettings(
                    Settings.builder()
                        .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)
                        .put(
                            IndexMetadata.INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(""_name"").getKey(),
                            dataNode.getName()
                        )
                )
        );

        assertFalse(
            client().admin()
                .cluster()
                .prepareHealth(restoredIndexName)
                .setWaitForNoRelocatingShards(true)
                .setWaitForEvents(Priority.LANGUID)
                .get()
                .isTimedOut()
        );

        assertTotalHits(restoredIndexName, originalAllHits, originalBarHits);
        assertRecoveryStats(restoredIndexName, false);
        // TODO: fix
        // assertSearchableSnapshotStats(restoredIndexName, false, nonCachedExtensions);

        assertAcked(
            client().admin()
                .indices()
                .prepareUpdateSettings(restoredIndexName)
                .setSettings(
                    Settings.builder()
                        .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1)
                        .putNull(IndexMetadata.INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(""_name"").getKey())
                )
        );

        assertTotalHits(restoredIndexName, originalAllHits, originalBarHits);
        assertRecoveryStats(restoredIndexName, false);

        final String clonedIndexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);
        assertAcked(
            client().admin()
                .indices()
                .prepareResizeIndex(restoredIndexName, clonedIndexName)
                .setResizeType(ResizeType.CLONE)
                .setSettings(
                    Settings.builder()
                        .putNull(IndexModule.INDEX_STORE_TYPE_SETTING.getKey())
                        .putNull(IndexModule.INDEX_RECOVERY_TYPE_SETTING.getKey())
                        .put(DataTier.TIER_PREFERENCE, DataTier.DATA_HOT)
                        .build()
                )
        );
        ensureGreen(clonedIndexName);
        assertTotalHits(clonedIndexName, originalAllHits, originalBarHits);

        final Settings clonedIndexSettings = client().admin()
            .indices()
            .prepareGetSettings(clonedIndexName)
            .get()
            .getIndexToSettings()
            .get(clonedIndexName);
        assertFalse(clonedIndexSettings.hasValue(IndexModule.INDEX_STORE_TYPE_SETTING.getKey()));
        assertFalse(clonedIndexSettings.hasValue(SearchableSnapshots.SNAPSHOT_SNAPSHOT_NAME_SETTING.getKey()));
        assertFalse(clonedIndexSettings.hasValue(SearchableSnapshots.SNAPSHOT_SNAPSHOT_ID_SETTING.getKey()));
        assertFalse(clonedIndexSettings.hasValue(SearchableSnapshots.SNAPSHOT_INDEX_ID_SETTING.getKey()));
        assertFalse(clonedIndexSettings.hasValue(IndexModule.INDEX_RECOVERY_TYPE_SETTING.getKey()));

        assertAcked(client().admin().indices().prepareDelete(restoredIndexName));
        assertThat(client().admin().indices().prepareGetAliases(aliasName).get().getAliases().size(), equalTo(0));
        assertAcked(client().admin().indices().prepareAliases().addAlias(clonedIndexName, aliasName));
        assertTotalHits(aliasName, originalAllHits, originalBarHits);
    }","public void testCreateAndRestorePartialSearchableSnapshot() throws Exception {
        final String fsRepoName = randomAlphaOfLength(10);
        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);
        final String aliasName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);
        final String restoredIndexName = randomBoolean() ? indexName : randomAlphaOfLength(10).toLowerCase(Locale.ROOT);
        final String snapshotName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);

        createRepository(
            fsRepoName,
            ""fs"",
            Settings.builder().put(""location"", randomRepoPath()).put(""chunk_size"", randomIntBetween(100, 1000), ByteSizeUnit.BYTES)
        );

        // Peer recovery always copies .liv files but we do not permit writing to searchable snapshot directories so this doesn't work, but
        // we can bypass this by forcing soft deletes to be used. TODO this restriction can be lifted when #55142 is resolved.
        final Settings.Builder originalIndexSettings = Settings.builder().put(INDEX_SOFT_DELETES_SETTING.getKey(), true);
        if (randomBoolean()) {
            originalIndexSettings.put(IndexSettings.INDEX_CHECK_ON_STARTUP.getKey(), randomFrom(""false"", ""true"", ""checksum""));
        }
        assertAcked(prepareCreate(indexName, originalIndexSettings));
        assertAcked(client().admin().indices().prepareAliases().addAlias(indexName, aliasName));

        populateIndex(indexName, 10_000);

        final TotalHits originalAllHits = internalCluster().client()
            .prepareSearch(indexName)
            .setTrackTotalHits(true)
            .get()
            .getHits()
            .getTotalHits();
        final TotalHits originalBarHits = internalCluster().client()
            .prepareSearch(indexName)
            .setTrackTotalHits(true)
            .setQuery(matchQuery(""foo"", ""bar""))
            .get()
            .getHits()
            .getTotalHits();
        logger.info(""--> [{}] in total, of which [{}] match the query"", originalAllHits, originalBarHits);

        expectThrows(
            ResourceNotFoundException.class,
            ""Searchable snapshot stats on a non snapshot searchable index should fail"",
            () -> client().execute(SearchableSnapshotsStatsAction.INSTANCE, new SearchableSnapshotsStatsRequest()).actionGet()
        );

        final SnapshotInfo snapshotInfo = createFullSnapshot(fsRepoName, snapshotName);
        ensureGreen(indexName);

        assertShardFolders(indexName, false);

        assertThat(
            client().admin()
                .cluster()
                .prepareState()
                .clear()
                .setMetadata(true)
                .setIndices(indexName)
                .get()
                .getState()
                .metadata()
                .index(indexName)
                .getTimestampRange(),
            sameInstance(IndexLongFieldRange.UNKNOWN)
        );

        final boolean deletedBeforeMount = randomBoolean();
        if (deletedBeforeMount) {
            assertAcked(client().admin().indices().prepareDelete(indexName));
        } else {
            assertAcked(client().admin().indices().prepareClose(indexName));
        }

        logger.info(""--> restoring partial index [{}] with cache enabled"", restoredIndexName);

        Settings.Builder indexSettingsBuilder = Settings.builder().put(SearchableSnapshots.SNAPSHOT_CACHE_ENABLED_SETTING.getKey(), true);
        final List<String> nonCachedExtensions;
        if (randomBoolean()) {
            nonCachedExtensions = randomSubsetOf(Arrays.asList(""fdt"", ""fdx"", ""nvd"", ""dvd"", ""tip"", ""cfs"", ""dim""));
            indexSettingsBuilder.putList(SearchableSnapshots.SNAPSHOT_CACHE_EXCLUDED_FILE_TYPES_SETTING.getKey(), nonCachedExtensions);
        } else {
            nonCachedExtensions = Collections.emptyList();
        }
        if (randomBoolean()) {
            indexSettingsBuilder.put(
                SearchableSnapshots.SNAPSHOT_UNCACHED_CHUNK_SIZE_SETTING.getKey(),
                new ByteSizeValue(randomLongBetween(10, 100_000))
            );
        }
        final int expectedReplicas;
        if (randomBoolean()) {
            expectedReplicas = numberOfReplicas();
            indexSettingsBuilder.put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, expectedReplicas);
        } else {
            expectedReplicas = 0;
        }
        final String indexCheckOnStartup;
        if (randomBoolean()) {
            indexCheckOnStartup = randomFrom(""false"", ""true"", ""checksum"");
            indexSettingsBuilder.put(IndexSettings.INDEX_CHECK_ON_STARTUP.getKey(), indexCheckOnStartup);
        } else {
            indexCheckOnStartup = ""false"";
        }
        final String expectedDataTiersPreference;
        expectedDataTiersPreference = MountSearchableSnapshotRequest.Storage.SHARED_CACHE.defaultDataTiersPreference();

        indexSettingsBuilder.put(Store.INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), TimeValue.ZERO);
        final AtomicBoolean statsWatcherRunning = new AtomicBoolean(true);
        final Thread statsWatcher = new Thread(() -> {
            while (statsWatcherRunning.get()) {
                final IndicesStatsResponse indicesStatsResponse;
                try {
                    indicesStatsResponse = client().admin().indices().prepareStats(restoredIndexName).clear().setStore(true).get();
                } catch (IndexNotFoundException | IndexClosedException e) {
                    continue;
                    // ok
                }

                for (ShardStats shardStats : indicesStatsResponse.getShards()) {
                    StoreStats store = shardStats.getStats().getStore();
                    assertThat(shardStats.getShardRouting().toString(), store.getReservedSize().getBytes(), equalTo(0L));
                    assertThat(shardStats.getShardRouting().toString(), store.getSize().getBytes(), equalTo(0L));
                }
                if (indicesStatsResponse.getShards().length > 0) {
                    assertThat(indicesStatsResponse.getTotal().getStore().getReservedSize().getBytes(), equalTo(0L));
                    assertThat(indicesStatsResponse.getTotal().getStore().getSize().getBytes(), equalTo(0L));
                }
            }
        }, ""test-stats-watcher"");
        statsWatcher.start();

        final MountSearchableSnapshotRequest req = new MountSearchableSnapshotRequest(
            restoredIndexName,
            fsRepoName,
            snapshotInfo.snapshotId().getName(),
            indexName,
            indexSettingsBuilder.build(),
            Strings.EMPTY_ARRAY,
            true,
            MountSearchableSnapshotRequest.Storage.SHARED_CACHE
        );

        final RestoreSnapshotResponse restoreSnapshotResponse = client().execute(MountSearchableSnapshotAction.INSTANCE, req).get();
        assertThat(restoreSnapshotResponse.getRestoreInfo().failedShards(), equalTo(0));

        final Map<Integer, SnapshotIndexShardStatus> snapshotShards = clusterAdmin().prepareSnapshotStatus(fsRepoName)
            .setSnapshots(snapshotInfo.snapshotId().getName())
            .get()
            .getSnapshots()
            .get(0)
            .getIndices()
            .get(indexName)
            .getShards();

        ensureGreen(restoredIndexName);

        final IndicesStatsResponse indicesStatsResponse = client().admin()
            .indices()
            .prepareStats(restoredIndexName)
            .clear()
            .setStore(true)
            .get();
        assertThat(indicesStatsResponse.getShards().length, greaterThan(0));
        long totalExpectedSize = 0;
        for (ShardStats shardStats : indicesStatsResponse.getShards()) {
            StoreStats store = shardStats.getStats().getStore();

            final ShardRouting shardRouting = shardStats.getShardRouting();
            assertThat(shardRouting.toString(), store.getReservedSize().getBytes(), equalTo(0L));
            assertThat(shardRouting.toString(), store.getSize().getBytes(), equalTo(0L));

            // the original shard size from the snapshot
            final long originalSize = snapshotShards.get(shardRouting.getId()).getStats().getTotalSize();
            totalExpectedSize += originalSize;

            // an extra segments_N file is created for bootstrapping new history and associating translog. We can extract the size of this
            // extra file but we have to unwrap the in-memory directory first.
            final Directory unwrappedDir = FilterDirectory.unwrap(
                internalCluster().getInstance(IndicesService.class, getDiscoveryNodes().resolveNode(shardRouting.currentNodeId()).getName())
                    .indexServiceSafe(shardRouting.index())
                    .getShard(shardRouting.getId())
                    .store()
                    .directory()
            );
            assertThat(shardRouting.toString(), unwrappedDir, notNullValue());
            assertThat(shardRouting.toString(), unwrappedDir, instanceOf(ByteBuffersDirectory.class));

            final ByteBuffersDirectory inMemoryDir = (ByteBuffersDirectory) unwrappedDir;
            assertThat(inMemoryDir.listAll(), arrayWithSize(1));

            final String segmentsFileName = SegmentInfos.getLastCommitSegmentsFileName(inMemoryDir);
            assertThat(""Fail to find segment file name directory for "" + shardRouting.toString(), segmentsFileName, notNullValue());
            final long extraSegmentFileSize = inMemoryDir.fileLength(segmentsFileName);

            assertThat(shardRouting.toString(), store.getTotalDataSetSize().getBytes(), equalTo(originalSize + extraSegmentFileSize));
            totalExpectedSize += extraSegmentFileSize;
        }

        final StoreStats store = indicesStatsResponse.getTotal().getStore();
        assertThat(store.getTotalDataSetSize().getBytes(), equalTo(totalExpectedSize));

        statsWatcherRunning.set(false);
        statsWatcher.join();

        final Settings settings = client().admin()
            .indices()
            .prepareGetSettings(restoredIndexName)
            .get()
            .getIndexToSettings()
            .get(restoredIndexName);
        assertThat(SearchableSnapshots.SNAPSHOT_SNAPSHOT_NAME_SETTING.get(settings), equalTo(snapshotName));
        assertThat(IndexModule.INDEX_STORE_TYPE_SETTING.get(settings), equalTo(SEARCHABLE_SNAPSHOT_STORE_TYPE));
        assertThat(IndexModule.INDEX_RECOVERY_TYPE_SETTING.get(settings), equalTo(SNAPSHOT_RECOVERY_STATE_FACTORY_KEY));
        assertTrue(IndexMetadata.INDEX_BLOCKS_WRITE_SETTING.get(settings));
        assertTrue(SearchableSnapshots.SNAPSHOT_SNAPSHOT_ID_SETTING.exists(settings));
        assertTrue(SearchableSnapshots.SNAPSHOT_INDEX_ID_SETTING.exists(settings));
        assertThat(IndexMetadata.INDEX_AUTO_EXPAND_REPLICAS_SETTING.get(settings).toString(), equalTo(""false""));
        assertThat(IndexMetadata.INDEX_NUMBER_OF_REPLICAS_SETTING.get(settings), equalTo(expectedReplicas));
        assertThat(DataTier.TIER_PREFERENCE_SETTING.get(settings), equalTo(expectedDataTiersPreference));
        assertTrue(SearchableSnapshotsSettings.SNAPSHOT_PARTIAL_SETTING.get(settings));
        assertTrue(DiskThresholdDecider.SETTING_IGNORE_DISK_WATERMARKS.get(settings));
        assertThat(IndexSettings.INDEX_CHECK_ON_STARTUP.get(settings), equalTo(indexCheckOnStartup));

        checkSoftDeletesNotEagerlyLoaded(restoredIndexName);
        assertTotalHits(restoredIndexName, originalAllHits, originalBarHits);
        assertRecoveryStats(restoredIndexName, false);
        // TODO: fix
        // assertSearchableSnapshotStats(restoredIndexName, true, nonCachedExtensions);
        ensureGreen(restoredIndexName);
        assertBusy(() -> assertShardFolders(restoredIndexName, true));

        assertThat(
            client().admin()
                .cluster()
                .prepareState()
                .clear()
                .setMetadata(true)
                .setIndices(restoredIndexName)
                .get()
                .getState()
                .metadata()
                .index(restoredIndexName)
                .getTimestampRange(),
            sameInstance(IndexLongFieldRange.UNKNOWN)
        );

        if (deletedBeforeMount) {
            assertThat(client().admin().indices().prepareGetAliases(aliasName).get().getAliases().size(), equalTo(0));
            assertAcked(client().admin().indices().prepareAliases().addAlias(restoredIndexName, aliasName));
        } else if (indexName.equals(restoredIndexName) == false) {
            assertThat(client().admin().indices().prepareGetAliases(aliasName).get().getAliases().size(), equalTo(1));
            assertAcked(
                client().admin()
                    .indices()
                    .prepareAliases()
                    .addAliasAction(IndicesAliasesRequest.AliasActions.remove().index(indexName).alias(aliasName).mustExist(true))
                    .addAlias(restoredIndexName, aliasName)
            );
        }
        assertThat(client().admin().indices().prepareGetAliases(aliasName).get().getAliases().size(), equalTo(1));
        assertTotalHits(aliasName, originalAllHits, originalBarHits);

        final Decision diskDeciderDecision = client().admin()
            .cluster()
            .prepareAllocationExplain()
            .setIndex(restoredIndexName)
            .setShard(0)
            .setPrimary(true)
            .setIncludeYesDecisions(true)
            .get()
            .getExplanation()
            .getShardAllocationDecision()
            .getMoveDecision()
            .getCanRemainDecision()
            .getDecisions()
            .stream()
            .filter(d -> d.label().equals(DiskThresholdDecider.NAME))
            .findFirst()
            .orElseThrow();
        assertThat(diskDeciderDecision.type(), equalTo(Decision.Type.YES));
        assertThat(
            diskDeciderDecision.getExplanation(),
            oneOf(""disk watermarks are ignored on this index"", ""there is only a single data node present"")
        );

        internalCluster().fullRestart();
        assertTotalHits(restoredIndexName, originalAllHits, originalBarHits);
        assertRecoveryStats(restoredIndexName, false);
        assertTotalHits(aliasName, originalAllHits, originalBarHits);
        // TODO: fix
        // assertSearchableSnapshotStats(restoredIndexName, false, nonCachedExtensions);

        internalCluster().ensureAtLeastNumDataNodes(2);

        final DiscoveryNode dataNode = randomFrom(
            client().admin().cluster().prepareState().get().getState().nodes().getDataNodes().values()
        );

        assertAcked(
            client().admin()
                .indices()
                .prepareUpdateSettings(restoredIndexName)
                .setSettings(
                    Settings.builder()
                        .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)
                        .put(
                            IndexMetadata.INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(""_name"").getKey(),
                            dataNode.getName()
                        )
                )
        );

        assertFalse(
            client().admin()
                .cluster()
                .prepareHealth(restoredIndexName)
                .setWaitForNoRelocatingShards(true)
                .setWaitForEvents(Priority.LANGUID)
                .get()
                .isTimedOut()
        );

        assertTotalHits(restoredIndexName, originalAllHits, originalBarHits);
        assertRecoveryStats(restoredIndexName, false);
        // TODO: fix
        // assertSearchableSnapshotStats(restoredIndexName, false, nonCachedExtensions);

        assertAcked(
            client().admin()
                .indices()
                .prepareUpdateSettings(restoredIndexName)
                .setSettings(
                    Settings.builder()
                        .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1)
                        .putNull(IndexMetadata.INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(""_name"").getKey())
                )
        );

        assertTotalHits(restoredIndexName, originalAllHits, originalBarHits);
        assertRecoveryStats(restoredIndexName, false);

        final String clonedIndexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);
        assertAcked(
            client().admin()
                .indices()
                .prepareResizeIndex(restoredIndexName, clonedIndexName)
                .setResizeType(ResizeType.CLONE)
                .setSettings(
                    Settings.builder()
                        .putNull(IndexModule.INDEX_STORE_TYPE_SETTING.getKey())
                        .putNull(IndexModule.INDEX_RECOVERY_TYPE_SETTING.getKey())
                        .put(DataTier.TIER_PREFERENCE, DataTier.DATA_HOT)
                        .build()
                )
        );
        ensureGreen(clonedIndexName);
        assertTotalHits(clonedIndexName, originalAllHits, originalBarHits);

        final Settings clonedIndexSettings = client().admin()
            .indices()
            .prepareGetSettings(clonedIndexName)
            .get()
            .getIndexToSettings()
            .get(clonedIndexName);
        assertFalse(clonedIndexSettings.hasValue(IndexModule.INDEX_STORE_TYPE_SETTING.getKey()));
        assertFalse(clonedIndexSettings.hasValue(SearchableSnapshots.SNAPSHOT_SNAPSHOT_NAME_SETTING.getKey()));
        assertFalse(clonedIndexSettings.hasValue(SearchableSnapshots.SNAPSHOT_SNAPSHOT_ID_SETTING.getKey()));
        assertFalse(clonedIndexSettings.hasValue(SearchableSnapshots.SNAPSHOT_INDEX_ID_SETTING.getKey()));
        assertFalse(clonedIndexSettings.hasValue(IndexModule.INDEX_RECOVERY_TYPE_SETTING.getKey()));

        assertAcked(client().admin().indices().prepareDelete(restoredIndexName));
        assertThat(client().admin().indices().prepareGetAliases(aliasName).get().getAliases().size(), equalTo(0));
        assertAcked(client().admin().indices().prepareAliases().addAlias(clonedIndexName, aliasName));
        assertTotalHits(aliasName, originalAllHits, originalBarHits);
    }",/x-pack/plugin/searchable-snapshots/src/internalClusterTest/java/org/elasticsearch/xpack/searchablesnapshots/FrozenSearchableSnapshotsIntegTests.java
28b89b4265ee7473e44ed97a660ca1d548317e36,691,217,"Supplier<CollapseBuilder> randomCollapseBuilder) {
        SearchSourceBuilder builder = new SearchSourceBuilder();
        if (randomBoolean()) {
            builder.from(randomIntBetween(0, 10000));
        }
        if (randomBoolean()) {
            builder.size(randomIntBetween(0, 10000));
        }
        if (randomBoolean()) {
            builder.explain(randomBoolean());
        }
        if (randomBoolean()) {
            builder.version(randomBoolean());
        }
        if (randomBoolean()) {
            builder.seqNoAndPrimaryTerm(randomBoolean());
        }
        if (randomBoolean()) {
            builder.trackScores(randomBoolean());
        }
        if (randomBoolean()) {
            builder.minScore(randomFloat() * 1000);
        }
        if (randomBoolean()) {
            builder.timeout(TimeValue.parseTimeValue(randomTimeValue(), null, ""timeout""));
        }
        if (randomBoolean()) {
            builder.terminateAfter(randomIntBetween(1, 100000));
        }
        if (randomBoolean()) {
            if (randomBoolean()) {
                builder.trackTotalHits(randomBoolean());
            } else {
                builder.trackTotalHitsUpTo(
                    randomIntBetween(SearchContext.TRACK_TOTAL_HITS_DISABLED, SearchContext.TRACK_TOTAL_HITS_ACCURATE)
                );
            }
        }

        switch(randomInt(2)) {
            case 0:
                builder.storedFields();
                break;
            case 1:
                builder.storedField(""_none_"");
                break;
            case 2:
                int fieldsSize = randomInt(25);
                List<String> fields = new ArrayList<>(fieldsSize);
                for (int i = 0; i < fieldsSize; i++) {
                    fields.add(randomAlphaOfLengthBetween(5, 50));
                }
                builder.storedFields(fields);
                break;
            default:
                throw new IllegalStateException();
        }

        if (randomBoolean()) {
            int numFields = randomInt(5);
            for (int i = 0; i < numFields; i++) {
                builder.fetchField(randomAlphaOfLengthBetween(5, 10));
            }
        }

        if (randomBoolean()) {
            int scriptFieldsSize = randomInt(25);
            for (int i = 0; i < scriptFieldsSize; i++) {
                if (randomBoolean()) {
                    builder.scriptField(randomAlphaOfLengthBetween(5, 50), mockScript(""foo""), randomBoolean());
                } else {
                    builder.scriptField(randomAlphaOfLengthBetween(5, 50), mockScript(""foo""));
                }
            }
        }
        if (randomBoolean()) {
            FetchSourceContext fetchSourceContext;
            int branch = randomInt(5);
            String[] includes = new String[randomIntBetween(0, 20)];
            for (int i = 0; i < includes.length; i++) {
                includes[i] = randomAlphaOfLengthBetween(5, 20);
            }
            String[] excludes = new String[randomIntBetween(0, 20)];
            for (int i = 0; i < excludes.length; i++) {
                excludes[i] = randomAlphaOfLengthBetween(5, 20);
            }
            switch (branch) {
                case 0:
                    fetchSourceContext = new FetchSourceContext(randomBoolean());
                    break;
                case 1:
                    fetchSourceContext = new FetchSourceContext(true, includes, excludes);
                    break;
                case 2:
                    fetchSourceContext = new FetchSourceContext(true, new String[]{randomAlphaOfLengthBetween(5, 20)},
                        new String[]{randomAlphaOfLengthBetween(5, 20)});
                    break;
                case 3:
                    fetchSourceContext = new FetchSourceContext(true, includes, excludes);
                    break;
                case 4:
                    fetchSourceContext = new FetchSourceContext(true, includes, null);
                    break;
                case 5:
                    fetchSourceContext = new FetchSourceContext(true, new String[] {randomAlphaOfLengthBetween(5, 20)}, null);
                    break;
                default:
                    throw new IllegalStateException();
            }
            builder.fetchSource(fetchSourceContext);
        }
        if (randomBoolean()) {
            int size = randomIntBetween(0, 20);
            List<String> statsGroups = new ArrayList<>(size);
            for (int i = 0; i < size; i++) {
                statsGroups.add(randomAlphaOfLengthBetween(5, 20));
            }
            builder.stats(statsGroups);
        }
        if (randomBoolean()) {
            int indexBoostSize = randomIntBetween(1, 10);
            for (int i = 0; i < indexBoostSize; i++) {
                builder.indexBoost(randomAlphaOfLengthBetween(5, 20), randomFloat() * 10);
            }
        }
        if (randomBoolean()) {
            builder.query(QueryBuilders.termQuery(randomAlphaOfLengthBetween(5, 20), randomAlphaOfLengthBetween(5, 20)));
        }
        if (randomBoolean()) {
            builder.postFilter(QueryBuilders.termQuery(randomAlphaOfLengthBetween(5, 20), randomAlphaOfLengthBetween(5, 20)));
        }
        if (randomBoolean()) {
            int numSorts = randomIntBetween(1, 5);
            for (int i = 0; i < numSorts; i++) {
                int branch = randomInt(5);
                switch (branch) {
                    case 0:
                        builder.sort(SortBuilders.fieldSort(randomAlphaOfLengthBetween(5, 20)).order(randomFrom(SortOrder.values())));
                        break;
                    case 1:
                        builder.sort(SortBuilders.geoDistanceSort(randomAlphaOfLengthBetween(5, 20),
                                AbstractQueryTestCase.randomGeohash(1, 12)).order(randomFrom(SortOrder.values())));
                        break;
                    case 2:
                        builder.sort(SortBuilders.scoreSort().order(randomFrom(SortOrder.values())));
                        break;
                    case 3:
                        builder.sort(SortBuilders
                                .scriptSort(
                                        new Script(ScriptType.INLINE, Script.DEFAULT_SCRIPT_LANG, ""foo"", emptyMap()),
                                        ScriptSortBuilder.ScriptSortType.NUMBER)
                                .order(randomFrom(SortOrder.values())));
                        break;
                    case 4:
                        builder.sort(randomAlphaOfLengthBetween(5, 20));
                        break;
                    case 5:
                        builder.sort(randomAlphaOfLengthBetween(5, 20), randomFrom(SortOrder.values()));
                        break;
                }
            }
        }

        if (randomBoolean()) {
            int numSearchFrom = randomIntBetween(1, 5);
            try {
                // We build a json version of the search_from first in order to
                // ensure that every number type remain the same before/after xcontent (de)serialization.
                // This is not a problem because the final type of each field value is extracted from associated sort field.
                // This little trick ensure that equals and hashcode are the same when using the xcontent serialization.
                XContentBuilder jsonBuilder = XContentFactory.jsonBuilder();
                jsonBuilder.startObject();
                jsonBuilder.startArray(""search_from"");
                for (int i = 0; i < numSearchFrom; i++) {
                    int branch = randomInt(8);
                    switch (branch) {
                        case 0:
                            jsonBuilder.value(randomInt());
                            break;
                        case 1:
                            jsonBuilder.value(randomFloat());
                            break;
                        case 2:
                            jsonBuilder.value(randomLong());
                            break;
                        case 3:
                            jsonBuilder.value(randomDouble());
                            break;
                        case 4:
                            jsonBuilder.value(randomAlphaOfLengthBetween(5, 20));
                            break;
                        case 5:
                            jsonBuilder.value(randomBoolean());
                            break;
                        case 6:
                            jsonBuilder.value(randomByte());
                            break;
                        case 7:
                            jsonBuilder.value(randomShort());
                            break;
                        case 8:
                            jsonBuilder.value(new Text(randomAlphaOfLengthBetween(5, 20)));
                            break;
                    }
                }
                jsonBuilder.endArray();
                jsonBuilder.endObject();
                XContentParser parser = XContentFactory.xContent(XContentType.JSON)
                    .createParser(NamedXContentRegistry.EMPTY, DeprecationHandler.THROW_UNSUPPORTED_OPERATION,
                        BytesReference.bytes(jsonBuilder).streamInput());
                parser.nextToken();
                parser.nextToken();
                parser.nextToken();
                builder.searchAfter(SearchAfterBuilder.fromXContent(parser).getSortValues());
            } catch (IOException e) {
                throw new RuntimeException(""Error building search_from"", e);
            }
        }
        if (randomBoolean()) {
            builder.highlighter(randomHighlightBuilder.get());
        }
        if (randomBoolean()) {
            builder.suggest(randomSuggestBuilder.get());
        }
        if (randomBoolean()) {
            int numRescores = randomIntBetween(1, 5);
            for (int i = 0; i < numRescores; i++) {
                builder.addRescorer(randomRescoreBuilder.get());
            }
        }
        if (randomBoolean()) {
            builder.aggregation(AggregationBuilders.avg(randomAlphaOfLengthBetween(5, 20)).field(""foo""));
        }
        if (randomBoolean()) {
            builder.ext(randomExtBuilders.get());
        }
        if (randomBoolean()) {
            String field = randomBoolean() ? null : randomAlphaOfLengthBetween(5, 20);
            int max = between(2, 1000);
            int id = randomInt(max-1);
            if (field == null) {
                builder.slice(new SliceBuilder(id, max));
            } else {
                builder.slice(new SliceBuilder(field, id, max));
            }
        }
        if (randomBoolean()) {
            builder.collapse(randomCollapseBuilder.get());
        }
        return builder;
    }","Supplier<CollapseBuilder> randomCollapseBuilder) {
        SearchSourceBuilder builder = new SearchSourceBuilder();
        if (randomBoolean()) {
            builder.from(randomIntBetween(0, 10000));
        }
        if (randomBoolean()) {
            builder.size(randomIntBetween(0, 10000));
        }
        if (randomBoolean()) {
            builder.explain(randomBoolean());
        }
        if (randomBoolean()) {
            builder.version(randomBoolean());
        }
        if (randomBoolean()) {
            builder.seqNoAndPrimaryTerm(randomBoolean());
        }
        if (randomBoolean()) {
            builder.trackScores(randomBoolean());
        }
        if (randomBoolean()) {
            builder.minScore(randomFloat() * 1000);
        }
        if (randomBoolean()) {
            builder.timeout(TimeValue.parseTimeValue(randomTimeValue(), null, ""timeout""));
        }
        if (randomBoolean()) {
            builder.terminateAfter(randomIntBetween(1, 100000));
        }
        if (randomBoolean()) {
            if (randomBoolean()) {
                builder.trackTotalHits(randomBoolean());
            } else {
                builder.trackTotalHitsUpTo(
                    randomIntBetween(SearchContext.TRACK_TOTAL_HITS_DISABLED, SearchContext.TRACK_TOTAL_HITS_ACCURATE)
                );
            }
        }

        switch(randomInt(2)) {
            case 0:
                builder.storedFields();
                break;
            case 1:
                builder.storedField(""_none_"");
                break;
            case 2:
                int fieldsSize = randomInt(25);
                List<String> fields = new ArrayList<>(fieldsSize);
                for (int i = 0; i < fieldsSize; i++) {
                    fields.add(randomAlphaOfLengthBetween(5, 50));
                }
                builder.storedFields(fields);
                break;
            default:
                throw new IllegalStateException();
        }

        if (randomBoolean()) {
            int numFields = randomInt(5);
            for (int i = 0; i < numFields; i++) {
                builder.fetchField(randomAlphaOfLengthBetween(5, 10));
            }
        }

        if (randomBoolean()) {
            int scriptFieldsSize = randomInt(25);
            for (int i = 0; i < scriptFieldsSize; i++) {
                if (randomBoolean()) {
                    builder.scriptField(randomAlphaOfLengthBetween(5, 50), mockScript(""foo""), randomBoolean());
                } else {
                    builder.scriptField(randomAlphaOfLengthBetween(5, 50), mockScript(""foo""));
                }
            }
        }
        if (randomBoolean()) {
            FetchSourceContext fetchSourceContext;
            int branch = randomInt(5);
            String[] includes = new String[randomIntBetween(0, 20)];
            for (int i = 0; i < includes.length; i++) {
                includes[i] = randomAlphaOfLengthBetween(5, 20);
            }
            String[] excludes = new String[randomIntBetween(0, 20)];
            for (int i = 0; i < excludes.length; i++) {
                excludes[i] = randomAlphaOfLengthBetween(5, 20);
            }
            switch (branch) {
                case 0:
                    fetchSourceContext = new FetchSourceContext(randomBoolean());
                    break;
                case 1:
                    fetchSourceContext = new FetchSourceContext(true, includes, excludes);
                    break;
                case 2:
                    fetchSourceContext = new FetchSourceContext(true, new String[]{randomAlphaOfLengthBetween(5, 20)},
                        new String[]{randomAlphaOfLengthBetween(5, 20)});
                    break;
                case 3:
                    fetchSourceContext = new FetchSourceContext(true, includes, excludes);
                    break;
                case 4:
                    fetchSourceContext = new FetchSourceContext(true, includes, null);
                    break;
                case 5:
                    fetchSourceContext = new FetchSourceContext(true, new String[] {randomAlphaOfLengthBetween(5, 20)}, null);
                    break;
                default:
                    throw new IllegalStateException();
            }
            builder.fetchSource(fetchSourceContext);
        }
        if (randomBoolean()) {
            int size = randomIntBetween(0, 20);
            List<String> statsGroups = new ArrayList<>(size);
            for (int i = 0; i < size; i++) {
                statsGroups.add(randomAlphaOfLengthBetween(5, 20));
            }
            builder.stats(statsGroups);
        }
        if (randomBoolean()) {
            int indexBoostSize = randomIntBetween(1, 10);
            for (int i = 0; i < indexBoostSize; i++) {
                builder.indexBoost(randomAlphaOfLengthBetween(5, 20), randomFloat() * 10);
            }
        }
        if (randomBoolean()) {
            builder.query(QueryBuilders.termQuery(randomAlphaOfLengthBetween(5, 20), randomAlphaOfLengthBetween(5, 20)));
        }
        if (randomBoolean()) {
            builder.postFilter(QueryBuilders.termQuery(randomAlphaOfLengthBetween(5, 20), randomAlphaOfLengthBetween(5, 20)));
        }
        if (randomBoolean()) {
            int numSorts = randomIntBetween(1, 5);
            for (int i = 0; i < numSorts; i++) {
                int branch = randomInt(5);
                switch (branch) {
                    case 0:
                        builder.sort(SortBuilders.fieldSort(randomAlphaOfLengthBetween(5, 20)).order(randomFrom(SortOrder.values())));
                        break;
                    case 1:
                        builder.sort(SortBuilders.geoDistanceSort(randomAlphaOfLengthBetween(5, 20),
                                AbstractQueryTestCase.randomGeohash(1, 12)).order(randomFrom(SortOrder.values())));
                        break;
                    case 2:
                        builder.sort(SortBuilders.scoreSort().order(randomFrom(SortOrder.values())));
                        break;
                    case 3:
                        builder.sort(SortBuilders
                                .scriptSort(
                                        new Script(ScriptType.INLINE, Script.DEFAULT_SCRIPT_LANG, ""foo"", emptyMap()),
                                        ScriptSortBuilder.ScriptSortType.NUMBER)
                                .order(randomFrom(SortOrder.values())));
                        break;
                    case 4:
                        builder.sort(randomAlphaOfLengthBetween(5, 20));
                        break;
                    case 5:
                        builder.sort(randomAlphaOfLengthBetween(5, 20), randomFrom(SortOrder.values()));
                        break;
                }
            }
        }

        if (randomBoolean()) {
            int numSearchFrom = randomIntBetween(1, 5);
            try {
                // We build a json version of the search_from first in order to
                // ensure that every number type remain the same before/after xcontent (de)serialization.
                // This is not a problem because the final type of each field value is extracted from associated sort field.
                // This little trick ensure that equals and hashcode are the same when using the xcontent serialization.
                XContentBuilder jsonBuilder = XContentFactory.jsonBuilder();
                jsonBuilder.startObject();
                jsonBuilder.startArray(""search_from"");
                for (int i = 0; i < numSearchFrom; i++) {
                    int branch = randomInt(8);
                    switch (branch) {
                        case 0:
                            jsonBuilder.value(randomInt());
                            break;
                        case 1:
                            jsonBuilder.value(randomFloat());
                            break;
                        case 2:
                            jsonBuilder.value(randomLong());
                            break;
                        case 3:
                            jsonBuilder.value(randomDouble());
                            break;
                        case 4:
                            jsonBuilder.value(randomAlphaOfLengthBetween(5, 20));
                            break;
                        case 5:
                            jsonBuilder.value(randomBoolean());
                            break;
                        case 6:
                            jsonBuilder.value(randomByte());
                            break;
                        case 7:
                            jsonBuilder.value(randomShort());
                            break;
                        case 8:
                            jsonBuilder.value(new Text(randomAlphaOfLengthBetween(5, 20)));
                            break;
                    }
                }
                jsonBuilder.endArray();
                jsonBuilder.endObject();
                XContentParser parser = XContentFactory.xContent(XContentType.JSON)
                    .createParser(NamedXContentRegistry.EMPTY, DeprecationHandler.THROW_UNSUPPORTED_OPERATION,
                        BytesReference.bytes(jsonBuilder).streamInput());
                parser.nextToken();
                parser.nextToken();
                parser.nextToken();
                builder.searchAfter(SearchAfterBuilder.fromXContent(parser).getSortValues());
            } catch (IOException e) {
                throw new RuntimeException(""Error building search_from"", e);
            }
        }
        if (randomBoolean()) {
            builder.highlighter(randomHighlightBuilder.get());
        }
        if (randomBoolean()) {
            builder.suggest(randomSuggestBuilder.get());
        }
        if (randomBoolean()) {
            int numRescores = randomIntBetween(1, 5);
            for (int i = 0; i < numRescores; i++) {
                builder.addRescorer(randomRescoreBuilder.get());
            }
        }
        if (randomBoolean()) {
            builder.aggregation(AggregationBuilders.avg(randomAlphaOfLengthBetween(5, 20)).field(""foo""));
        }
        if (randomBoolean()) {
            builder.ext(randomExtBuilders.get());
        }
        if (randomBoolean()) {
            String field = randomBoolean() ? null : randomAlphaOfLengthBetween(5, 20);
            int max = between(2, 1000);
            int id = randomInt(max-1);
            if (field == null) {
                builder.slice(new SliceBuilder(id, max));
            } else {
                builder.slice(new SliceBuilder(field, id, max));
            }
        }
        if (randomBoolean()) {
            builder.collapse(randomCollapseBuilder.get());
        }
        if (randomBoolean()) {
            builder.pointInTimeBuilder(new SearchSourceBuilder.PointInTimeBuilder(randomAlphaOfLengthBetween(3, 10),
                TimeValue.timeValueMinutes(randomIntBetween(1, 60))));
        }
        return builder;
    }",/test/framework/src/main/java/org/elasticsearch/search/RandomSearchRequestGenerator.java
357aac806641b3807dcbbc70c33676228a33f627,563,214,"public void testRotateKey() throws Exception {
        TokenService tokenService = new TokenService(tokenServiceEnabledSettings, systemUTC(), client, securityIndex, clusterService);
        Authentication authentication = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null);
        PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
        tokenService.createUserToken(authentication, authentication, tokenFuture, Collections.emptyMap(), true);
        final UserToken token = tokenFuture.get().v1();
        assertNotNull(token);
        mockGetTokenFromId(token, false);
        authentication = token.getAuthentication();

        ThreadContext requestContext = new ThreadContext(Settings.EMPTY);
        requestContext.putHeader(""Authorization"", ""Bearer "" + getDeprecatedAccessTokenString(tokenService, token));

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertAuthentication(authentication, serialized.getAuthentication());
        }
        rotateKeys(tokenService);

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertAuthentication(authentication, serialized.getAuthentication());
        }

        PlainActionFuture<Tuple<UserToken, String>> newTokenFuture = new PlainActionFuture<>();
        tokenService.createUserToken(authentication, authentication, newTokenFuture, Collections.emptyMap(), true);
        final UserToken newToken = newTokenFuture.get().v1();
        assertNotNull(newToken);
        assertNotEquals(getDeprecatedAccessTokenString(tokenService, newToken), getDeprecatedAccessTokenString(tokenService, token));

        requestContext = new ThreadContext(Settings.EMPTY);
        requestContext.putHeader(""Authorization"", ""Bearer "" + getDeprecatedAccessTokenString(tokenService, newToken));
        mockGetTokenFromId(newToken, false);

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertAuthentication(authentication, serialized.getAuthentication());
        }
    }","public void testRotateKey() throws Exception {
        TokenService tokenService = new TokenService(tokenServiceEnabledSettings, systemUTC(), client, securityIndex, clusterService);
        Authentication authentication = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null);
        PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
        tokenService.createOAuth2Tokens(authentication, authentication, Collections.emptyMap(), true, tokenFuture);
        final UserToken token = tokenFuture.get().v1();
        assertNotNull(token);
        mockGetTokenFromId(token, false);
        authentication = token.getAuthentication();

        ThreadContext requestContext = new ThreadContext(Settings.EMPTY);
        requestContext.putHeader(""Authorization"", ""Bearer "" + getDeprecatedAccessTokenString(tokenService, token));

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertAuthentication(authentication, serialized.getAuthentication());
        }
        rotateKeys(tokenService);

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertAuthentication(authentication, serialized.getAuthentication());
        }

        PlainActionFuture<Tuple<UserToken, String>> newTokenFuture = new PlainActionFuture<>();
        tokenService.createOAuth2Tokens(authentication, authentication, Collections.emptyMap(), true, newTokenFuture);
        final UserToken newToken = newTokenFuture.get().v1();
        assertNotNull(newToken);
        assertNotEquals(getDeprecatedAccessTokenString(tokenService, newToken), getDeprecatedAccessTokenString(tokenService, token));

        requestContext = new ThreadContext(Settings.EMPTY);
        requestContext.putHeader(""Authorization"", ""Bearer "" + getDeprecatedAccessTokenString(tokenService, newToken));
        mockGetTokenFromId(newToken, false);

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertAuthentication(authentication, serialized.getAuthentication());
        }
    }",/x-pack/plugin/security/src/test/java/org/elasticsearch/xpack/security/authc/TokenServiceTests.java
357aac806641b3807dcbbc70c33676228a33f627,563,345,"public void testPruneKeys() throws Exception {
        TokenService tokenService = new TokenService(tokenServiceEnabledSettings, systemUTC(), client, securityIndex, clusterService);
        Authentication authentication = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null);
        PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
        tokenService.createUserToken(authentication, authentication, tokenFuture, Collections.emptyMap(), true);
        final UserToken token = tokenFuture.get().v1();
        assertNotNull(token);
        mockGetTokenFromId(token, false);
        authentication = token.getAuthentication();

        ThreadContext requestContext = new ThreadContext(Settings.EMPTY);
        requestContext.putHeader(""Authorization"", ""Bearer "" + getDeprecatedAccessTokenString(tokenService, token));

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertAuthentication(authentication, serialized.getAuthentication());
        }
        TokenMetaData metaData = tokenService.pruneKeys(randomIntBetween(0, 100));
        tokenService.refreshMetaData(metaData);

        int numIterations = scaledRandomIntBetween(1, 5);
        for (int i = 0; i < numIterations; i++) {
            rotateKeys(tokenService);
        }

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertAuthentication(authentication, serialized.getAuthentication());
        }

        PlainActionFuture<Tuple<UserToken, String>> newTokenFuture = new PlainActionFuture<>();
        tokenService.createUserToken(authentication, authentication, newTokenFuture, Collections.emptyMap(), true);
        final UserToken newToken = newTokenFuture.get().v1();
        assertNotNull(newToken);
        assertNotEquals(getDeprecatedAccessTokenString(tokenService, newToken), getDeprecatedAccessTokenString(tokenService, token));

        metaData = tokenService.pruneKeys(1);
        tokenService.refreshMetaData(metaData);

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertNull(serialized);
        }

        requestContext = new ThreadContext(Settings.EMPTY);
        requestContext.putHeader(""Authorization"", ""Bearer "" + getDeprecatedAccessTokenString(tokenService, newToken));
        mockGetTokenFromId(newToken, false);
        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertAuthentication(authentication, serialized.getAuthentication());
        }

    }","public void testPruneKeys() throws Exception {
        TokenService tokenService = new TokenService(tokenServiceEnabledSettings, systemUTC(), client, securityIndex, clusterService);
        Authentication authentication = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null);
        PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
        tokenService.createOAuth2Tokens(authentication, authentication, Collections.emptyMap(), true, tokenFuture);
        final UserToken token = tokenFuture.get().v1();
        assertNotNull(token);
        mockGetTokenFromId(token, false);
        authentication = token.getAuthentication();

        ThreadContext requestContext = new ThreadContext(Settings.EMPTY);
        requestContext.putHeader(""Authorization"", ""Bearer "" + getDeprecatedAccessTokenString(tokenService, token));

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertAuthentication(authentication, serialized.getAuthentication());
        }
        TokenMetaData metaData = tokenService.pruneKeys(randomIntBetween(0, 100));
        tokenService.refreshMetaData(metaData);

        int numIterations = scaledRandomIntBetween(1, 5);
        for (int i = 0; i < numIterations; i++) {
            rotateKeys(tokenService);
        }

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertAuthentication(authentication, serialized.getAuthentication());
        }

        PlainActionFuture<Tuple<UserToken, String>> newTokenFuture = new PlainActionFuture<>();
        tokenService.createOAuth2Tokens(authentication, authentication, Collections.emptyMap(), true, newTokenFuture);
        final UserToken newToken = newTokenFuture.get().v1();
        assertNotNull(newToken);
        assertNotEquals(getDeprecatedAccessTokenString(tokenService, newToken), getDeprecatedAccessTokenString(tokenService, token));

        metaData = tokenService.pruneKeys(1);
        tokenService.refreshMetaData(metaData);

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertNull(serialized);
        }

        requestContext = new ThreadContext(Settings.EMPTY);
        requestContext.putHeader(""Authorization"", ""Bearer "" + getDeprecatedAccessTokenString(tokenService, newToken));
        mockGetTokenFromId(newToken, false);
        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertAuthentication(authentication, serialized.getAuthentication());
        }

    }",/x-pack/plugin/security/src/test/java/org/elasticsearch/xpack/security/authc/TokenServiceTests.java
357aac806641b3807dcbbc70c33676228a33f627,563,284,"public void testKeyExchange() throws Exception {
        TokenService tokenService = new TokenService(tokenServiceEnabledSettings, systemUTC(), client, securityIndex, clusterService);
        int numRotations = randomIntBetween(1, 5);
        for (int i = 0; i < numRotations; i++) {
            rotateKeys(tokenService);
        }
        TokenService otherTokenService = new TokenService(tokenServiceEnabledSettings, systemUTC(), client, securityIndex,
            clusterService);
        otherTokenService.refreshMetaData(tokenService.getTokenMetaData());
        Authentication authentication = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null);
        PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
        tokenService.createUserToken(authentication, authentication, tokenFuture, Collections.emptyMap(), true);
        final UserToken token = tokenFuture.get().v1();
        assertNotNull(token);
        mockGetTokenFromId(token, false);
        authentication = token.getAuthentication();

        ThreadContext requestContext = new ThreadContext(Settings.EMPTY);
        requestContext.putHeader(""Authorization"", ""Bearer "" + getDeprecatedAccessTokenString(tokenService, token));
        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            otherTokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertAuthentication(authentication, serialized.getAuthentication());
        }

        rotateKeys(tokenService);

        otherTokenService.refreshMetaData(tokenService.getTokenMetaData());

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            otherTokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertEquals(authentication, serialized.getAuthentication());
        }
    }","public void testKeyExchange() throws Exception {
        TokenService tokenService = new TokenService(tokenServiceEnabledSettings, systemUTC(), client, securityIndex, clusterService);
        int numRotations = randomIntBetween(1, 5);
        for (int i = 0; i < numRotations; i++) {
            rotateKeys(tokenService);
        }
        TokenService otherTokenService = new TokenService(tokenServiceEnabledSettings, systemUTC(), client, securityIndex, clusterService);
        otherTokenService.refreshMetaData(tokenService.getTokenMetaData());
        Authentication authentication = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null);
        PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
        tokenService.createOAuth2Tokens(authentication, authentication, Collections.emptyMap(), true, tokenFuture);
        final UserToken token = tokenFuture.get().v1();
        assertNotNull(token);
        mockGetTokenFromId(token, false);
        authentication = token.getAuthentication();

        ThreadContext requestContext = new ThreadContext(Settings.EMPTY);
        requestContext.putHeader(""Authorization"", ""Bearer "" + getDeprecatedAccessTokenString(tokenService, token));
        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            otherTokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertAuthentication(authentication, serialized.getAuthentication());
        }

        rotateKeys(tokenService);

        otherTokenService.refreshMetaData(tokenService.getTokenMetaData());

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            otherTokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertEquals(authentication, serialized.getAuthentication());
        }
    }",/x-pack/plugin/security/src/test/java/org/elasticsearch/xpack/security/authc/TokenServiceTests.java
357aac806641b3807dcbbc70c33676228a33f627,563,174,"public void testAttachAndGetToken() throws Exception {
        TokenService tokenService = new TokenService(tokenServiceEnabledSettings, systemUTC(), client, securityIndex, clusterService);
        Authentication authentication = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null);
        PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
        tokenService.createUserToken(authentication, authentication, tokenFuture, Collections.emptyMap(), true);
        final UserToken token = tokenFuture.get().v1();
        assertNotNull(token);
        mockGetTokenFromId(token, false);
        authentication = token.getAuthentication();

        ThreadContext requestContext = new ThreadContext(Settings.EMPTY);
        requestContext.putHeader(""Authorization"", randomFrom(""Bearer "", ""BEARER "", ""bearer "") + tokenService.getAccessTokenAsString(token));

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertAuthentication(authentication, serialized.getAuthentication());
        }

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            // verify a second separate token service with its own salt can also verify
            TokenService anotherService = new TokenService(tokenServiceEnabledSettings, systemUTC(), client, securityIndex
                    , clusterService);
            anotherService.refreshMetaData(tokenService.getTokenMetaData());
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            anotherService.getAndValidateToken(requestContext, future);
            UserToken fromOtherService = future.get();
            assertAuthentication(authentication, fromOtherService.getAuthentication());
        }
    }","public void testAttachAndGetToken() throws Exception {
        TokenService tokenService = new TokenService(tokenServiceEnabledSettings, systemUTC(), client, securityIndex, clusterService);
        Authentication authentication = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null);
        PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
        tokenService.createOAuth2Tokens(authentication, authentication, Collections.emptyMap(), true, tokenFuture);
        final UserToken token = tokenFuture.get().v1();
        assertNotNull(token);
        mockGetTokenFromId(token, false);
        authentication = token.getAuthentication();

        ThreadContext requestContext = new ThreadContext(Settings.EMPTY);
        requestContext.putHeader(""Authorization"", randomFrom(""Bearer "", ""BEARER "", ""bearer "") + tokenService.getAccessTokenAsString(token));

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertAuthentication(authentication, serialized.getAuthentication());
        }

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            // verify a second separate token service with its own salt can also verify
            TokenService anotherService = new TokenService(tokenServiceEnabledSettings, systemUTC(), client, securityIndex
                    , clusterService);
            anotherService.refreshMetaData(tokenService.getTokenMetaData());
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            anotherService.getAndValidateToken(requestContext, future);
            UserToken fromOtherService = future.get();
            assertAuthentication(authentication, fromOtherService.getAuthentication());
        }
    }",/x-pack/plugin/security/src/test/java/org/elasticsearch/xpack/security/authc/TokenServiceTests.java
357aac806641b3807dcbbc70c33676228a33f627,563,482,"public void testTokenExpiry() throws Exception {
        ClockMock clock = ClockMock.frozen();
        TokenService tokenService = new TokenService(tokenServiceEnabledSettings, clock, client, securityIndex, clusterService);
        Authentication authentication = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null);
        PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
        tokenService.createUserToken(authentication, authentication, tokenFuture, Collections.emptyMap(), true);
        final UserToken token = tokenFuture.get().v1();
        mockGetTokenFromId(token, false);
        authentication = token.getAuthentication();

        ThreadContext requestContext = new ThreadContext(Settings.EMPTY);
        requestContext.putHeader(""Authorization"", ""Bearer "" + tokenService.getAccessTokenAsString(token));

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            // the clock is still frozen, so the cookie should be valid
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            assertAuthentication(authentication, future.get().getAuthentication());
        }

        final TimeValue defaultExpiration = TokenService.TOKEN_EXPIRATION.get(Settings.EMPTY);
        final int fastForwardAmount = randomIntBetween(1, Math.toIntExact(defaultExpiration.getSeconds()) - 5);
        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            // move the clock forward but don't go to expiry
            clock.fastForwardSeconds(fastForwardAmount);
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            assertAuthentication(authentication, future.get().getAuthentication());
        }

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            // move to expiry
            clock.fastForwardSeconds(Math.toIntExact(defaultExpiration.getSeconds()) - fastForwardAmount);
            clock.rewind(TimeValue.timeValueNanos(clock.instant().getNano())); // trim off nanoseconds since don't store them in the index
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            assertAuthentication(authentication, future.get().getAuthentication());
        }

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            // move one second past expiry
            clock.fastForwardSeconds(1);
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            ElasticsearchSecurityException e = expectThrows(ElasticsearchSecurityException.class, future::actionGet);
            final String headerValue = e.getHeader(""WWW-Authenticate"").get(0);
            assertThat(headerValue, containsString(""Bearer realm=""));
            assertThat(headerValue, containsString(""expired""));
        }
    }","public void testTokenExpiry() throws Exception {
        ClockMock clock = ClockMock.frozen();
        TokenService tokenService = new TokenService(tokenServiceEnabledSettings, clock, client, securityIndex, clusterService);
        Authentication authentication = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null);
        PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
        tokenService.createOAuth2Tokens(authentication, authentication, Collections.emptyMap(), true, tokenFuture);
        final UserToken token = tokenFuture.get().v1();
        mockGetTokenFromId(token, false);
        authentication = token.getAuthentication();

        ThreadContext requestContext = new ThreadContext(Settings.EMPTY);
        requestContext.putHeader(""Authorization"", ""Bearer "" + tokenService.getAccessTokenAsString(token));

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            // the clock is still frozen, so the cookie should be valid
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            assertAuthentication(authentication, future.get().getAuthentication());
        }

        final TimeValue defaultExpiration = TokenService.TOKEN_EXPIRATION.get(Settings.EMPTY);
        final int fastForwardAmount = randomIntBetween(1, Math.toIntExact(defaultExpiration.getSeconds()) - 5);
        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            // move the clock forward but don't go to expiry
            clock.fastForwardSeconds(fastForwardAmount);
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            assertAuthentication(authentication, future.get().getAuthentication());
        }

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            // move to expiry
            clock.fastForwardSeconds(Math.toIntExact(defaultExpiration.getSeconds()) - fastForwardAmount);
            clock.rewind(TimeValue.timeValueNanos(clock.instant().getNano())); // trim off nanoseconds since don't store them in the index
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            assertAuthentication(authentication, future.get().getAuthentication());
        }

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            // move one second past expiry
            clock.fastForwardSeconds(1);
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            ElasticsearchSecurityException e = expectThrows(ElasticsearchSecurityException.class, future::actionGet);
            final String headerValue = e.getHeader(""WWW-Authenticate"").get(0);
            assertThat(headerValue, containsString(""Bearer realm=""));
            assertThat(headerValue, containsString(""expired""));
        }
    }",/x-pack/plugin/security/src/test/java/org/elasticsearch/xpack/security/authc/TokenServiceTests.java
357aac806641b3807dcbbc70c33676228a33f627,563,1194,"public void testExpiredToken() throws Exception {
        when(securityIndex.isAvailable()).thenReturn(true);
        when(securityIndex.indexExists()).thenReturn(true);
        User user = new User(""_username"", ""r1"");
        final Authentication expected = new Authentication(user, new RealmRef(""realm"", ""custom"", ""node""), null);
        PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
        try (ThreadContext.StoredContext ctx = threadContext.stashContext()) {
            Authentication originatingAuth = new Authentication(new User(""creator""), new RealmRef(""test"", ""test"", ""test""), null);
            tokenService.createUserToken(expected, originatingAuth, tokenFuture, Collections.emptyMap(), true);
        }
        String token = tokenService.getAccessTokenAsString(tokenFuture.get().v1());
        mockGetTokenFromId(tokenFuture.get().v1(), true, client);
        doAnswer(invocationOnMock -> {
            ((Runnable) invocationOnMock.getArguments()[1]).run();
            return null;
        }).when(securityIndex).prepareIndexIfNeededThenExecute(any(Consumer.class), any(Runnable.class));

        try (ThreadContext.StoredContext ignore = threadContext.stashContext()) {
            threadContext.putHeader(""Authorization"", ""Bearer "" + token);
            ElasticsearchSecurityException e =
                    expectThrows(ElasticsearchSecurityException.class, () -> authenticateBlocking(""_action"", message, null));
            assertEquals(RestStatus.UNAUTHORIZED, e.status());
            assertEquals(""token expired"", e.getMessage());
        }
    }","public void testExpiredToken() throws Exception {
        when(securityIndex.isAvailable()).thenReturn(true);
        when(securityIndex.indexExists()).thenReturn(true);
        User user = new User(""_username"", ""r1"");
        final Authentication expected = new Authentication(user, new RealmRef(""realm"", ""custom"", ""node""), null);
        PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
        try (ThreadContext.StoredContext ctx = threadContext.stashContext()) {
            Authentication originatingAuth = new Authentication(new User(""creator""), new RealmRef(""test"", ""test"", ""test""), null);
            tokenService.createOAuth2Tokens(expected, originatingAuth, Collections.emptyMap(), true, tokenFuture);
        }
        String token = tokenService.getAccessTokenAsString(tokenFuture.get().v1());
        mockGetTokenFromId(tokenFuture.get().v1(), true, client);
        doAnswer(invocationOnMock -> {
            ((Runnable) invocationOnMock.getArguments()[1]).run();
            return null;
        }).when(securityIndex).prepareIndexIfNeededThenExecute(any(Consumer.class), any(Runnable.class));

        try (ThreadContext.StoredContext ignore = threadContext.stashContext()) {
            threadContext.putHeader(""Authorization"", ""Bearer "" + token);
            ElasticsearchSecurityException e =
                    expectThrows(ElasticsearchSecurityException.class, () -> authenticateBlocking(""_action"", message, null));
            assertEquals(RestStatus.UNAUTHORIZED, e.status());
            assertEquals(""token expired"", e.getMessage());
        }
    }",/x-pack/plugin/security/src/test/java/org/elasticsearch/xpack/security/authc/AuthenticationServiceTests.java
357aac806641b3807dcbbc70c33676228a33f627,563,411,"public void testInvalidatedToken() throws Exception {
        when(securityIndex.indexExists()).thenReturn(true);
        TokenService tokenService =
            new TokenService(tokenServiceEnabledSettings, systemUTC(), client, securityIndex, clusterService);
        Authentication authentication = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null);
        PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
        tokenService.createUserToken(authentication, authentication, tokenFuture, Collections.emptyMap(), true);
        final UserToken token = tokenFuture.get().v1();
        assertNotNull(token);
        mockGetTokenFromId(token, true);

        ThreadContext requestContext = new ThreadContext(Settings.EMPTY);
        requestContext.putHeader(""Authorization"", ""Bearer "" + tokenService.getAccessTokenAsString(token));

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            ElasticsearchSecurityException e = expectThrows(ElasticsearchSecurityException.class, future::actionGet);
            final String headerValue = e.getHeader(""WWW-Authenticate"").get(0);
            assertThat(headerValue, containsString(""Bearer realm=""));
            assertThat(headerValue, containsString(""expired""));
        }
    }","public void testInvalidatedToken() throws Exception {
        when(securityIndex.indexExists()).thenReturn(true);
        TokenService tokenService =
            new TokenService(tokenServiceEnabledSettings, systemUTC(), client, securityIndex, clusterService);
        Authentication authentication = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null);
        PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
        tokenService.createOAuth2Tokens(authentication, authentication, Collections.emptyMap(), true, tokenFuture);
        final UserToken token = tokenFuture.get().v1();
        assertNotNull(token);
        mockGetTokenFromId(token, true);

        ThreadContext requestContext = new ThreadContext(Settings.EMPTY);
        requestContext.putHeader(""Authorization"", ""Bearer "" + tokenService.getAccessTokenAsString(token));

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            ElasticsearchSecurityException e = expectThrows(ElasticsearchSecurityException.class, future::actionGet);
            final String headerValue = e.getHeader(""WWW-Authenticate"").get(0);
            assertThat(headerValue, containsString(""Bearer realm=""));
            assertThat(headerValue, containsString(""expired""));
        }
    }",/x-pack/plugin/security/src/test/java/org/elasticsearch/xpack/security/authc/TokenServiceTests.java
357aac806641b3807dcbbc70c33676228a33f627,563,1111,"public void testAuthenticateWithToken() throws Exception {
        User user = new User(""_username"", ""r1"");
        final AtomicBoolean completed = new AtomicBoolean(false);
        final Authentication expected = new Authentication(user, new RealmRef(""realm"", ""custom"", ""node""), null);
        PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
        try (ThreadContext.StoredContext ctx = threadContext.stashContext()) {
            Authentication originatingAuth = new Authentication(new User(""creator""), new RealmRef(""test"", ""test"", ""test""), null);
            tokenService.createUserToken(expected, originatingAuth, tokenFuture, Collections.emptyMap(), true);
        }
        String token = tokenService.getAccessTokenAsString(tokenFuture.get().v1());
        when(client.prepareMultiGet()).thenReturn(new MultiGetRequestBuilder(client, MultiGetAction.INSTANCE));
        mockGetTokenFromId(tokenFuture.get().v1(), false, client);
        when(securityIndex.isAvailable()).thenReturn(true);
        when(securityIndex.indexExists()).thenReturn(true);
        try (ThreadContext.StoredContext ignore = threadContext.stashContext()) {
            threadContext.putHeader(""Authorization"", ""Bearer "" + token);
            service.authenticate(""_action"", message, (User)null, ActionListener.wrap(result -> {
                assertThat(result, notNullValue());
                assertThat(result.getUser(), is(user));
                assertThat(result.getLookedUpBy(), is(nullValue()));
                assertThat(result.getAuthenticatedBy(), is(notNullValue()));
                assertThat(result.getAuthenticationType(), is(AuthenticationType.TOKEN));
                setCompletedToTrue(completed);
            }, this::logAndFail));
        }
        assertTrue(completed.get());
        verify(auditTrail).authenticationSuccess(anyString(), eq(""realm""), eq(user), eq(""_action""), same(message));
        verifyNoMoreInteractions(auditTrail);
    }","public void testAuthenticateWithToken() throws Exception {
        User user = new User(""_username"", ""r1"");
        final AtomicBoolean completed = new AtomicBoolean(false);
        final Authentication expected = new Authentication(user, new RealmRef(""realm"", ""custom"", ""node""), null);
        PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
        try (ThreadContext.StoredContext ctx = threadContext.stashContext()) {
            Authentication originatingAuth = new Authentication(new User(""creator""), new RealmRef(""test"", ""test"", ""test""), null);
            tokenService.createOAuth2Tokens(expected, originatingAuth, Collections.emptyMap(), true, tokenFuture);
        }
        String token = tokenService.getAccessTokenAsString(tokenFuture.get().v1());
        when(client.prepareMultiGet()).thenReturn(new MultiGetRequestBuilder(client, MultiGetAction.INSTANCE));
        mockGetTokenFromId(tokenFuture.get().v1(), false, client);
        when(securityIndex.isAvailable()).thenReturn(true);
        when(securityIndex.indexExists()).thenReturn(true);
        try (ThreadContext.StoredContext ignore = threadContext.stashContext()) {
            threadContext.putHeader(""Authorization"", ""Bearer "" + token);
            service.authenticate(""_action"", message, (User)null, ActionListener.wrap(result -> {
                assertThat(result, notNullValue());
                assertThat(result.getUser(), is(user));
                assertThat(result.getLookedUpBy(), is(nullValue()));
                assertThat(result.getAuthenticatedBy(), is(notNullValue()));
                assertThat(result.getAuthenticationType(), is(AuthenticationType.TOKEN));
                setCompletedToTrue(completed);
            }, this::logAndFail));
        }
        assertTrue(completed.get());
        verify(auditTrail).authenticationSuccess(anyString(), eq(""realm""), eq(user), eq(""_action""), same(message));
        verifyNoMoreInteractions(auditTrail);
    }",/x-pack/plugin/security/src/test/java/org/elasticsearch/xpack/security/authc/AuthenticationServiceTests.java
357aac806641b3807dcbbc70c33676228a33f627,563,374,"public void testPassphraseWorks() throws Exception {
        TokenService tokenService = new TokenService(tokenServiceEnabledSettings, systemUTC(), client, securityIndex, clusterService);
        Authentication authentication = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null);
        PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
        tokenService.createUserToken(authentication, authentication, tokenFuture, Collections.emptyMap(), true);
        final UserToken token = tokenFuture.get().v1();
        assertNotNull(token);
        mockGetTokenFromId(token, false);
        authentication = token.getAuthentication();

        ThreadContext requestContext = new ThreadContext(Settings.EMPTY);
        requestContext.putHeader(""Authorization"", ""Bearer "" + getDeprecatedAccessTokenString(tokenService, token));

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertAuthentication(authentication, serialized.getAuthentication());
        }

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            // verify a second separate token service with its own passphrase cannot verify
            TokenService anotherService = new TokenService(tokenServiceEnabledSettings, systemUTC(), client, securityIndex,
                clusterService);
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            anotherService.getAndValidateToken(requestContext, future);
            assertNull(future.get());
        }
    }","public void testPassphraseWorks() throws Exception {
        TokenService tokenService = new TokenService(tokenServiceEnabledSettings, systemUTC(), client, securityIndex, clusterService);
        Authentication authentication = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null);
        PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
        tokenService.createOAuth2Tokens(authentication, authentication, Collections.emptyMap(), true, tokenFuture);
        final UserToken token = tokenFuture.get().v1();
        assertNotNull(token);
        mockGetTokenFromId(token, false);
        authentication = token.getAuthentication();

        ThreadContext requestContext = new ThreadContext(Settings.EMPTY);
        requestContext.putHeader(""Authorization"", ""Bearer "" + getDeprecatedAccessTokenString(tokenService, token));

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            UserToken serialized = future.get();
            assertAuthentication(authentication, serialized.getAuthentication());
        }

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            // verify a second separate token service with its own passphrase cannot verify
            TokenService anotherService = new TokenService(tokenServiceEnabledSettings, systemUTC(), client, securityIndex,
                clusterService);
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            anotherService.getAndValidateToken(requestContext, future);
            assertNull(future.get());
        }
    }",/x-pack/plugin/security/src/test/java/org/elasticsearch/xpack/security/authc/TokenServiceTests.java
357aac806641b3807dcbbc70c33676228a33f627,690,1006,"private Optional<ElasticsearchSecurityException> checkTokenDocForRefresh(Map<String, Object> source, Authentication clientAuth) {
        final Map<String, Object> refreshTokenSrc = (Map<String, Object>) source.get(""refresh_token"");
        final Map<String, Object> accessTokenSrc = (Map<String, Object>) source.get(""access_token"");
        if (refreshTokenSrc == null || refreshTokenSrc.isEmpty()) {
            return Optional.of(invalidGrantException(""token document is missing the refresh_token object""));
        } else if (accessTokenSrc == null || accessTokenSrc.isEmpty()) {
            return Optional.of(invalidGrantException(""token document is missing the access_token object""));
        } else {
            final Boolean refreshed = (Boolean) refreshTokenSrc.get(""refreshed"");
            final Boolean invalidated = (Boolean) refreshTokenSrc.get(""invalidated"");
            final Long creationEpochMilli = (Long) source.get(""creation_time"");
            final Instant creationTime = creationEpochMilli == null ? null : Instant.ofEpochMilli(creationEpochMilli);
            final Map<String, Object> userTokenSrc = (Map<String, Object>) accessTokenSrc.get(""user_token"");
            if (refreshed == null) {
                return Optional.of(invalidGrantException(""token document is missing refreshed value""));
            } else if (invalidated == null) {
                return Optional.of(invalidGrantException(""token document is missing invalidated value""));
            } else if (creationEpochMilli == null) {
                return Optional.of(invalidGrantException(""token document is missing creation time value""));
            } else if (invalidated) {
                return Optional.of(invalidGrantException(""token has been invalidated""));
            } else if (clock.instant().isAfter(creationTime.plus(24L, ChronoUnit.HOURS))) {
                return Optional.of(invalidGrantException(""refresh token is expired""));
            } else if (userTokenSrc == null || userTokenSrc.isEmpty()) {
                return Optional.of(invalidGrantException(""token document is missing the user token info""));
            } else if (userTokenSrc.get(""authentication"") == null) {
                return Optional.of(invalidGrantException(""token is missing authentication info""));
            } else if (userTokenSrc.get(""version"") == null) {
                return Optional.of(invalidGrantException(""token is missing version value""));
            } else if (userTokenSrc.get(""metadata"") == null) {
                return Optional.of(invalidGrantException(""token is missing metadata""));
            } else {
                return checkLenientlyIfTokenAlreadyRefreshed(source, clientAuth);
            }
        }
    }","Authentication clientAuthentication) {
        if (clientAuthentication.getUser().principal().equals(refreshToken.getAssociatedUser()) == false) {
            logger.warn(""Token was originally created by [{}] but [{}] attempted to refresh it"", refreshToken.getAssociatedUser(),
                    clientAuthentication.getUser().principal());
            return Optional.of(invalidGrantException(""tokens must be refreshed by the creating client""));
        } else if (clientAuthentication.getAuthenticatedBy().getName().equals(refreshToken.getAssociatedRealm()) == false) {
            logger.warn(""[{}] created the refresh token while authenticated by [{}] but is now authenticated by [{}]"",
                    refreshToken.getAssociatedUser(), refreshToken.getAssociatedRealm(),
                    clientAuthentication.getAuthenticatedBy().getName());
            return Optional.of(invalidGrantException(""tokens must be refreshed by the creating client""));
        } else {
            return Optional.empty();
        }
    }",/x-pack/plugin/security/src/main/java/org/elasticsearch/xpack/security/authc/TokenService.java
357aac806641b3807dcbbc70c33676228a33f627,563,581,"public void testIndexNotAvailable() throws Exception {
        TokenService tokenService =
            new TokenService(tokenServiceEnabledSettings, systemUTC(), client, securityIndex, clusterService);
        Authentication authentication = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null);
        PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
        tokenService.createUserToken(authentication, authentication, tokenFuture, Collections.emptyMap(), true);
        final UserToken token = tokenFuture.get().v1();
        assertNotNull(token);
        //mockGetTokenFromId(token, false);

        ThreadContext requestContext = new ThreadContext(Settings.EMPTY);
        requestContext.putHeader(""Authorization"", ""Bearer "" + tokenService.getAccessTokenAsString(token));

        doAnswer(invocationOnMock -> {
            ActionListener<GetResponse> listener = (ActionListener<GetResponse>) invocationOnMock.getArguments()[1];
            listener.onFailure(new NoShardAvailableActionException(new ShardId(new Index(""foo"", ""uuid""), 0), ""shard oh shard""));
            return Void.TYPE;
        }).when(client).get(any(GetRequest.class), any(ActionListener.class));

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            assertNull(future.get());

            when(securityIndex.isAvailable()).thenReturn(false);
            when(securityIndex.indexExists()).thenReturn(true);
            future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            assertNull(future.get());

            when(securityIndex.indexExists()).thenReturn(false);
            future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            assertNull(future.get());

            when(securityIndex.isAvailable()).thenReturn(true);
            when(securityIndex.indexExists()).thenReturn(true);
            mockGetTokenFromId(token, false);
            future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            assertEquals(token.getAuthentication(), future.get().getAuthentication());
        }
    }","public void testIndexNotAvailable() throws Exception {
        TokenService tokenService =
            new TokenService(tokenServiceEnabledSettings, systemUTC(), client, securityIndex, clusterService);
        Authentication authentication = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null);
        PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
        tokenService.createOAuth2Tokens(authentication, authentication, Collections.emptyMap(), true, tokenFuture);
        final UserToken token = tokenFuture.get().v1();
        assertNotNull(token);
        //mockGetTokenFromId(token, false);

        ThreadContext requestContext = new ThreadContext(Settings.EMPTY);
        requestContext.putHeader(""Authorization"", ""Bearer "" + tokenService.getAccessTokenAsString(token));

        doAnswer(invocationOnMock -> {
            ActionListener<GetResponse> listener = (ActionListener<GetResponse>) invocationOnMock.getArguments()[1];
            listener.onFailure(new NoShardAvailableActionException(new ShardId(new Index(""foo"", ""uuid""), 0), ""shard oh shard""));
            return Void.TYPE;
        }).when(client).get(any(GetRequest.class), any(ActionListener.class));

        try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
            PlainActionFuture<UserToken> future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            assertNull(future.get());

            when(securityIndex.isAvailable()).thenReturn(false);
            when(securityIndex.indexExists()).thenReturn(true);
            future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            assertNull(future.get());

            when(securityIndex.indexExists()).thenReturn(false);
            future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            assertNull(future.get());

            when(securityIndex.isAvailable()).thenReturn(true);
            when(securityIndex.indexExists()).thenReturn(true);
            mockGetTokenFromId(token, false);
            future = new PlainActionFuture<>();
            tokenService.getAndValidateToken(requestContext, future);
            assertEquals(token.getAuthentication(), future.get().getAuthentication());
        }
    }",/x-pack/plugin/security/src/test/java/org/elasticsearch/xpack/security/authc/TokenServiceTests.java
286120cdbaa44f2f87e2d22b3e19b43400d797ca,570,442,"private static Coordinate[] coordinates(Edge component, Coordinate[] coordinates, double[] partitionPoint) {
        for (int i = 0; i < coordinates.length; i++) {
            coordinates[i] = (component = component.next).coordinate;
        }
        // First and last coordinates must be equal
        if (coordinates[0].equals(coordinates[coordinates.length - 1]) == false) {
            if (partitionPoint[2] == Double.NaN) {
                throw new InvalidShapeException(""Self-intersection at or near point [""
                    + partitionPoint[0] + "","" + partitionPoint[1] + ""]"");
            } else {
                throw new InvalidShapeException(""Self-intersection at or near point [""
                    + partitionPoint[0] + "","" + partitionPoint[1] + "","" + partitionPoint[2] + ""]"");
            }
        }
        return coordinates;
    }","private static Coordinate[] coordinates(Edge component, Coordinate[] coordinates, double[] partitionPoint) {
        for (int i = 0; i < coordinates.length; i++) {
            coordinates[i] = (component = component.next).coordinate;
        }
        // First and last coordinates must be equal
        if (coordinates[0].equals(coordinates[coordinates.length - 1]) == false) {
            if (Double.isNaN(partitionPoint[2])) {
                throw new InvalidShapeException(""Self-intersection at or near point [""
                    + partitionPoint[0] + "","" + partitionPoint[1] + ""]"");
            } else {
                throw new InvalidShapeException(""Self-intersection at or near point [""
                    + partitionPoint[0] + "","" + partitionPoint[1] + "","" + partitionPoint[2] + ""]"");
            }
        }
        return coordinates;
    }",/server/src/main/java/org/elasticsearch/common/geo/builders/PolygonBuilder.java
286120cdbaa44f2f87e2d22b3e19b43400d797ca,570,582,"private static Point[] coordinates(Edge component, Point[] coordinates, double[] partitionPoint) {
        for (int i = 0; i < coordinates.length; i++) {
            coordinates[i] = (component = component.next).coordinate;
        }
        // First and last coordinates must be equal
        if (coordinates[0].equals(coordinates[coordinates.length - 1]) == false) {
            if (partitionPoint[2] == Double.NaN) {
                throw new InvalidShapeException(""Self-intersection at or near point [""
                    + partitionPoint[0] + "","" + partitionPoint[1] + ""]"");
            } else {
                throw new InvalidShapeException(""Self-intersection at or near point [""
                    + partitionPoint[0] + "","" + partitionPoint[1] + "","" + partitionPoint[2] + ""]"");
            }
        }
        return coordinates;
    }","private static Point[] coordinates(Edge component, Point[] coordinates, double[] partitionPoint) {
        for (int i = 0; i < coordinates.length; i++) {
            coordinates[i] = (component = component.next).coordinate;
        }
        // First and last coordinates must be equal
        if (coordinates[0].equals(coordinates[coordinates.length - 1]) == false) {
            if (Double.isNaN(partitionPoint[2])) {
                throw new InvalidShapeException(""Self-intersection at or near point [""
                    + partitionPoint[0] + "","" + partitionPoint[1] + ""]"");
            } else {
                throw new InvalidShapeException(""Self-intersection at or near point [""
                    + partitionPoint[0] + "","" + partitionPoint[1] + "","" + partitionPoint[2] + ""]"");
            }
        }
        return coordinates;
    }",/server/src/main/java/org/elasticsearch/common/geo/GeoPolygonDecomposer.java
86500ae6681ddb3b306631fee04f24fee9cad43a,688,232,"ParseContext context) {
        Mapper.TypeParser.ParserContext parserContext = context.parserContext(dateFormatter);
        parserContext = parserContext.createDynamicTemplateFieldContext(parserContext);
        Mapper.TypeParser typeParser = parserContext.typeParser(mappingType);
        if (typeParser == null) {
            throw new MapperParsingException(""failed to find type parsed ["" + mappingType + ""] for ["" + name + ""]"");
        }
        return typeParser.parse(name, mapping, parserContext);
    }","ParseContext context) {
        Mapper.TypeParser.ParserContext parserContext = context.dynamicTemplateParserContext(dateFormatter);
        Mapper.TypeParser typeParser = parserContext.typeParser(mappingType);
        if (typeParser == null) {
            throw new MapperParsingException(""failed to find type parsed ["" + mappingType + ""] for ["" + name + ""]"");
        }
        return typeParser.parse(name, mapping, parserContext);
    }",/server/src/main/java/org/elasticsearch/index/mapper/DynamicFieldsBuilder.java
86500ae6681ddb3b306631fee04f24fee9cad43a,688,214,"private static TestMapper fromMapping(String mapping, Version version, boolean fromDynamicTemplate) {
        MapperService mapperService = mock(MapperService.class);
        IndexAnalyzers indexAnalyzers = new IndexAnalyzers(
            Map.of(""_standard"", Lucene.STANDARD_ANALYZER,
                ""_keyword"", Lucene.KEYWORD_ANALYZER,
                ""default"", new NamedAnalyzer(""default"", AnalyzerScope.INDEX, new StandardAnalyzer())),
            Collections.emptyMap(), Collections.emptyMap());
        when(mapperService.getIndexAnalyzers()).thenReturn(indexAnalyzers);
        Mapper.TypeParser.ParserContext pc = new Mapper.TypeParser.ParserContext(s -> null, s -> {
            if (Objects.equals(""keyword"", s)) {
                return KeywordFieldMapper.PARSER;
            }
            if (Objects.equals(""binary"", s)) {
                return BinaryFieldMapper.PARSER;
            }
            return null;
        }, name -> null, version, () -> null, null, ScriptCompiler.NONE,
            mapperService.getIndexAnalyzers(), mapperService.getIndexSettings(), () -> {
            throw new UnsupportedOperationException();
        });
        if (fromDynamicTemplate) {
            pc = pc.createDynamicTemplateFieldContext(pc);
        }
        return (TestMapper) new TypeParser()
            .parse(""field"", XContentHelper.convertToMap(JsonXContent.jsonXContent, mapping, true), pc)
            .build(new ContentPath());
    }","private static TestMapper fromMapping(String mapping, Version version, boolean fromDynamicTemplate) {
        MapperService mapperService = mock(MapperService.class);
        IndexAnalyzers indexAnalyzers = new IndexAnalyzers(
            Map.of(""_standard"", Lucene.STANDARD_ANALYZER,
                ""_keyword"", Lucene.KEYWORD_ANALYZER,
                ""default"", new NamedAnalyzer(""default"", AnalyzerScope.INDEX, new StandardAnalyzer())),
            Collections.emptyMap(), Collections.emptyMap());
        when(mapperService.getIndexAnalyzers()).thenReturn(indexAnalyzers);
        Mapper.TypeParser.ParserContext pc = new Mapper.TypeParser.ParserContext(s -> null, s -> {
            if (Objects.equals(""keyword"", s)) {
                return KeywordFieldMapper.PARSER;
            }
            if (Objects.equals(""binary"", s)) {
                return BinaryFieldMapper.PARSER;
            }
            return null;
        }, name -> null, version, () -> null, null, ScriptCompiler.NONE,
            mapperService.getIndexAnalyzers(), mapperService.getIndexSettings(), () -> {
            throw new UnsupportedOperationException();
        });
        if (fromDynamicTemplate) {
            pc = pc.createDynamicTemplateFieldContext();
        }
        return (TestMapper) new TypeParser()
            .parse(""field"", XContentHelper.convertToMap(JsonXContent.jsonXContent, mapping, true), pc)
            .build(new ContentPath());
    }",/server/src/test/java/org/elasticsearch/index/mapper/ParametrizedMapperTests.java
060f500346788c4c5d0b3b9c045facec5d677d3d,563,369,"public void testKeySameConstraints() {
        ZoneId zd = randomZone();
        Attribute a = key(""a"");

        Expression keyCondition = gtExpression(a);
        Expression filter = equalsExpression();

        KeyedFilter rule1 = keyedFilter(basicFilter(keyCondition), a);
        KeyedFilter rule2 = keyedFilter(basicFilter(filter), a);

        Sequence s = sequence(rule1, rule2);

        LogicalPlan result = new Optimizer.PropagateJoinKeyConstraints().apply(s);

        assertEquals(Sequence.class, result.getClass());
        Sequence seq = (Sequence) result;

        List<KeyedFilter> queries = seq.queries();
        assertEquals(rule1, queries.get(0));
        KeyedFilter query2 = queries.get(1);
        assertEquals(keyCondition, filterCondition(query2.child()));
        assertEquals(filter, filterCondition(query2.child().children().get(0)));
    }","public void testKeySameConstraints() {
        Attribute a = key(""a"");

        Expression keyCondition = gtExpression(a);
        Expression filter = equalsExpression();

        KeyedFilter rule1 = keyedFilter(basicFilter(keyCondition), a);
        KeyedFilter rule2 = keyedFilter(basicFilter(filter), a);

        Sequence s = sequence(rule1, rule2);

        LogicalPlan result = new Optimizer.PropagateJoinKeyConstraints().apply(s);

        assertEquals(Sequence.class, result.getClass());
        Sequence seq = (Sequence) result;

        List<KeyedFilter> queries = seq.queries();
        assertEquals(rule1, queries.get(0));
        KeyedFilter query2 = queries.get(1);
        assertEquals(keyCondition, filterCondition(query2.child()));
        assertEquals(filter, filterCondition(query2.child().children().get(0)));
    }",/x-pack/plugin/eql/src/test/java/org/elasticsearch/xpack/eql/optimizer/OptimizerTests.java
060f500346788c4c5d0b3b9c045facec5d677d3d,563,566,"public void testExtractKeySameFromDisjunction() {
        ZoneId zd = randomZone();
        Attribute a = key(""a"");

        Expression keyCondition = gtExpression(a);
        Expression filter = equalsExpression();

        Expression cond = new And(EMPTY, filter, keyCondition);

        KeyedFilter rule1 = keyedFilter(basicFilter(cond), a);
        KeyedFilter rule2 = keyedFilter(basicFilter(filter), a);

        Sequence s = sequence(rule1, rule2);

        LogicalPlan result = new Optimizer.PropagateJoinKeyConstraints().apply(s);

        assertEquals(Sequence.class, result.getClass());
        Sequence seq = (Sequence) result;

        List<KeyedFilter> queries = seq.queries();
        assertEquals(rule1, queries.get(0));

        KeyedFilter query2 = queries.get(1);
        LogicalPlan child2 = query2.child();

        Expression keyRuleBCondition = gtExpression(a);

        assertEquals(keyRuleBCondition, filterCondition(child2));
        assertEquals(filter, filterCondition(child2.children().get(0)));
    }","public void testExtractKeySameFromDisjunction() {
        Attribute a = key(""a"");

        Expression keyCondition = gtExpression(a);
        Expression filter = equalsExpression();

        Expression cond = new And(EMPTY, filter, keyCondition);

        KeyedFilter rule1 = keyedFilter(basicFilter(cond), a);
        KeyedFilter rule2 = keyedFilter(basicFilter(filter), a);

        Sequence s = sequence(rule1, rule2);

        LogicalPlan result = new Optimizer.PropagateJoinKeyConstraints().apply(s);

        assertEquals(Sequence.class, result.getClass());
        Sequence seq = (Sequence) result;

        List<KeyedFilter> queries = seq.queries();
        assertEquals(rule1, queries.get(0));

        KeyedFilter query2 = queries.get(1);
        LogicalPlan child2 = query2.child();

        Expression keyRuleBCondition = gtExpression(a);

        assertEquals(keyRuleBCondition, filterCondition(child2));
        assertEquals(filter, filterCondition(child2.children().get(0)));
    }",/x-pack/plugin/eql/src/test/java/org/elasticsearch/xpack/eql/optimizer/OptimizerTests.java
060f500346788c4c5d0b3b9c045facec5d677d3d,563,442,"public void testDifferentOneKeyConstraints() {
        ZoneId zd = randomZone();
        Attribute a = key(""a"");
        Attribute b = key(""b"");

        Expression keyARuleACondition = gtExpression(a);
        Expression keyBRuleACondition = gtExpression(b);

        Expression keyARuleBCondition = new Equals(EMPTY, a, TRUE);
        Expression keyBRuleBCondition = new Equals(EMPTY, b, TRUE);

        KeyedFilter rule1 = keyedFilter(basicFilter(keyARuleACondition), a);
        KeyedFilter rule2 = keyedFilter(basicFilter(keyBRuleBCondition), b);

        Sequence s = sequence(rule1, rule2);

        LogicalPlan result = new Optimizer.PropagateJoinKeyConstraints().apply(s);

        assertEquals(Sequence.class, result.getClass());
        Sequence seq = (Sequence) result;

        List<KeyedFilter> queries = seq.queries();
        KeyedFilter query1 = queries.get(0);

        assertEquals(keyARuleBCondition, filterCondition(query1.child()));
        assertEquals(keyARuleACondition, filterCondition(query1.child().children().get(0)));

        KeyedFilter query2 = queries.get(1);
        assertEquals(keyBRuleACondition, filterCondition(query2.child()));
        assertEquals(keyBRuleBCondition, filterCondition(query2.child().children().get(0)));
    }","public void testDifferentOneKeyConstraints() {
        Attribute a = key(""a"");
        Attribute b = key(""b"");

        Expression keyARuleACondition = gtExpression(a);
        Expression keyBRuleACondition = gtExpression(b);

        Expression keyARuleBCondition = new Equals(EMPTY, a, TRUE);
        Expression keyBRuleBCondition = new Equals(EMPTY, b, TRUE);

        KeyedFilter rule1 = keyedFilter(basicFilter(keyARuleACondition), a);
        KeyedFilter rule2 = keyedFilter(basicFilter(keyBRuleBCondition), b);

        Sequence s = sequence(rule1, rule2);

        LogicalPlan result = new Optimizer.PropagateJoinKeyConstraints().apply(s);

        assertEquals(Sequence.class, result.getClass());
        Sequence seq = (Sequence) result;

        List<KeyedFilter> queries = seq.queries();
        KeyedFilter query1 = queries.get(0);

        assertEquals(keyARuleBCondition, filterCondition(query1.child()));
        assertEquals(keyARuleACondition, filterCondition(query1.child().children().get(0)));

        KeyedFilter query2 = queries.get(1);
        assertEquals(keyBRuleACondition, filterCondition(query2.child()));
        assertEquals(keyBRuleBCondition, filterCondition(query2.child().children().get(0)));
    }",/x-pack/plugin/eql/src/test/java/org/elasticsearch/xpack/eql/optimizer/OptimizerTests.java
060f500346788c4c5d0b3b9c045facec5d677d3d,563,531,"public void testSkipKeySameWithDisjunctionConstraints() {
        ZoneId zd = randomZone();
        Attribute a = key(""a"");

        Expression keyCondition = gtExpression(a);
        Expression filter = equalsExpression();
        Expression cond = new Or(EMPTY, filter, keyCondition);

        KeyedFilter rule1 = keyedFilter(basicFilter(cond), a);
        KeyedFilter rule2 = keyedFilter(basicFilter(filter), a);

        Sequence s = sequence(rule1, rule2);

        LogicalPlan result = new Optimizer.PropagateJoinKeyConstraints().apply(s);

        assertEquals(Sequence.class, result.getClass());
        Sequence seq = (Sequence) result;

        List<KeyedFilter> queries = seq.queries();
        assertEquals(rule1, queries.get(0));
        assertEquals(rule2, queries.get(1));
    }","public void testSkipKeySameWithDisjunctionConstraints() {
        Attribute a = key(""a"");

        Expression keyCondition = gtExpression(a);
        Expression filter = equalsExpression();
        Expression cond = new Or(EMPTY, filter, keyCondition);

        KeyedFilter rule1 = keyedFilter(basicFilter(cond), a);
        KeyedFilter rule2 = keyedFilter(basicFilter(filter), a);

        Sequence s = sequence(rule1, rule2);

        LogicalPlan result = new Optimizer.PropagateJoinKeyConstraints().apply(s);

        assertEquals(Sequence.class, result.getClass());
        Sequence seq = (Sequence) result;

        List<KeyedFilter> queries = seq.queries();
        assertEquals(rule1, queries.get(0));
        assertEquals(rule2, queries.get(1));
    }",/x-pack/plugin/eql/src/test/java/org/elasticsearch/xpack/eql/optimizer/OptimizerTests.java
8b8c0c0b4daaa3c3aa7e406a493a778dc07b04ab,684,329,"public void testToFilterDeprecationMessage() throws IOException {
        Directory dir = new RAMDirectory();
        try (IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())))) {
            writer.commit();
        }
        QueryShardContext context = mock(QueryShardContext.class);
        try (IndexReader reader = DirectoryReader.open(dir)) {
            MappedFieldType fieldType = new MappedFieldType() {
                @Override
                public MappedFieldType clone() {
                    return null;
                }

                @Override
                public String typeName() {
                    return null;
                }

                @Override
                public Query termQuery(Object value, @Nullable QueryShardContext context) {
                    return null;
                }

                public Query existsQuery(QueryShardContext context) {
                    return null;
                }
            };
            fieldType.setName(""_uid"");
            fieldType.setHasDocValues(false);
            when(context.fieldMapper(""_uid"")).thenReturn(fieldType);
            when(context.getIndexReader()).thenReturn(reader);
            Settings settings = Settings.builder()
                    .put(IndexMetaData.SETTING_VERSION_CREATED, Version.V_6_3_0)
                    .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 2)
                    .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0)
                    .build();
            IndexMetaData indexState = IndexMetaData.builder(""index"").settings(settings).build();
            IndexSettings indexSettings = new IndexSettings(indexState, Settings.EMPTY);
            when(context.getIndexSettings()).thenReturn(indexSettings);
            SliceBuilder builder = new SliceBuilder(""_uid"", 5, 10);
            Query query = builder.toFilter(context, 0, 1);
            assertThat(query, instanceOf(TermsSliceQuery.class));
            assertThat(builder.toFilter(context, 0, 1), equalTo(query));
            assertWarnings(""Computing slices on the [_uid] field is deprecated for 6.x indices, use [_id] instead"");
        }

    }","public void testInvalidArguments() throws Exception {
        Exception e = expectThrows(IllegalArgumentException.class, () -> new SliceBuilder(""field"", -1, 10));
        assertEquals(""id must be greater than or equal to 0"", e.getMessage());

        e = expectThrows(IllegalArgumentException.class, () -> new SliceBuilder(""field"", 10, -1));
        assertEquals(""max must be greater than 1"", e.getMessage());

        e = expectThrows(IllegalArgumentException.class, () -> new SliceBuilder(""field"", 10, 0));
        assertEquals(""max must be greater than 1"", e.getMessage());

        e = expectThrows(IllegalArgumentException.class, () -> new SliceBuilder(""field"", 10, 5));
        assertEquals(""max must be greater than id"", e.getMessage());

        e = expectThrows(IllegalArgumentException.class, () -> new SliceBuilder(""field"", 1000, 1000));
        assertEquals(""max must be greater than id"", e.getMessage());
        e = expectThrows(IllegalArgumentException.class, () -> new SliceBuilder(""field"", 1001, 1000));
        assertEquals(""max must be greater than id"", e.getMessage());
    }",/server/src/test/java/org/elasticsearch/search/slice/SliceBuilderTests.java
8b8c0c0b4daaa3c3aa7e406a493a778dc07b04ab,690,200,"public boolean equals(Object other) {
        if (!(other instanceof SliceBuilder)) {
            return false;
        }

        SliceBuilder o = (SliceBuilder) other;
        return ((field == null && o.field == null) || field.equals(o.field))
            && id == o.id && o.max == max;
    }","public static SliceBuilder fromXContent(XContentParser parser) throws IOException {
        SliceBuilder builder = PARSER.parse(parser, new SliceBuilder(), null);
        return builder;
    }",/server/src/main/java/org/elasticsearch/search/slice/SliceBuilder.java
8b8c0c0b4daaa3c3aa7e406a493a778dc07b04ab,684,191,"public void testToFilter() throws IOException {
        Directory dir = new RAMDirectory();
        try (IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())))) {
            writer.commit();
        }
        QueryShardContext context = mock(QueryShardContext.class);
        try (IndexReader reader = DirectoryReader.open(dir)) {
            MappedFieldType fieldType = new MappedFieldType() {
                @Override
                public MappedFieldType clone() {
                    return null;
                }

                @Override
                public String typeName() {
                    return null;
                }

                @Override
                public Query termQuery(Object value, @Nullable QueryShardContext context) {
                    return null;
                }

                public Query existsQuery(QueryShardContext context) {
                    return null;
                }
            };
            fieldType.setName(IdFieldMapper.NAME);
            fieldType.setHasDocValues(false);
            when(context.fieldMapper(IdFieldMapper.NAME)).thenReturn(fieldType);
            when(context.getIndexReader()).thenReturn(reader);
            Settings settings = Settings.builder()
                    .put(IndexMetaData.SETTING_VERSION_CREATED, Version.CURRENT)
                    .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 2)
                    .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0)
                    .build();
            IndexMetaData indexState = IndexMetaData.builder(""index"").settings(settings).build();
            IndexSettings indexSettings = new IndexSettings(indexState, Settings.EMPTY);
            when(context.getIndexSettings()).thenReturn(indexSettings);
            SliceBuilder builder = new SliceBuilder(5, 10);
            Query query = builder.toFilter(context, 0, 1);
            assertThat(query, instanceOf(TermsSliceQuery.class));

            assertThat(builder.toFilter(context, 0, 1), equalTo(query));
            try (IndexReader newReader = DirectoryReader.open(dir)) {
                when(context.getIndexReader()).thenReturn(newReader);
                assertThat(builder.toFilter(context, 0, 1), equalTo(query));
            }
        }

        try (IndexReader reader = DirectoryReader.open(dir)) {
            MappedFieldType fieldType = new MappedFieldType() {
                @Override
                public MappedFieldType clone() {
                    return null;
                }

                @Override
                public String typeName() {
                    return null;
                }

                @Override
                public Query termQuery(Object value, @Nullable QueryShardContext context) {
                    return null;
                }

                public Query existsQuery(QueryShardContext context) {
                    return null;
                }
            };
            fieldType.setName(""field_doc_values"");
            fieldType.setHasDocValues(true);
            fieldType.setDocValuesType(DocValuesType.SORTED_NUMERIC);
            when(context.fieldMapper(""field_doc_values"")).thenReturn(fieldType);
            when(context.getIndexReader()).thenReturn(reader);
            IndexNumericFieldData fd = mock(IndexNumericFieldData.class);
            when(context.getForField(fieldType)).thenReturn(fd);
            SliceBuilder builder = new SliceBuilder(""field_doc_values"", 5, 10);
            Query query = builder.toFilter(context, 0, 1);
            assertThat(query, instanceOf(DocValuesSliceQuery.class));

            assertThat(builder.toFilter(context, 0, 1), equalTo(query));
            try (IndexReader newReader = DirectoryReader.open(dir)) {
                when(context.getIndexReader()).thenReturn(newReader);
                assertThat(builder.toFilter(context, 0, 1), equalTo(query));
            }

            // numSlices > numShards
            int numSlices = randomIntBetween(10, 100);
            int numShards = randomIntBetween(1, 9);
            Map<Integer, AtomicInteger> numSliceMap = new HashMap<>();
            for (int i = 0; i < numSlices; i++) {
                for (int j = 0; j < numShards; j++) {
                    SliceBuilder slice = new SliceBuilder(""_id"", i, numSlices);
                    Query q = slice.toFilter(context, j, numShards);
                    if (q instanceof TermsSliceQuery || q instanceof MatchAllDocsQuery) {
                        AtomicInteger count = numSliceMap.get(j);
                        if (count == null) {
                            count = new AtomicInteger(0);
                            numSliceMap.put(j, count);
                        }
                        count.incrementAndGet();
                        if (q instanceof MatchAllDocsQuery) {
                            assertThat(count.get(), equalTo(1));
                        }
                    } else {
                        assertThat(q, instanceOf(MatchNoDocsQuery.class));
                    }
                }
            }
            int total = 0;
            for (Map.Entry<Integer, AtomicInteger> e : numSliceMap.entrySet()) {
                total += e.getValue().get();
            }
            assertThat(total, equalTo(numSlices));

            // numShards > numSlices
            numShards = randomIntBetween(4, 100);
            numSlices = randomIntBetween(2, numShards-1);
            List<Integer> targetShards = new ArrayList<>();
            for (int i = 0; i < numSlices; i++) {
                for (int j = 0; j < numShards; j++) {
                    SliceBuilder slice = new SliceBuilder(""_id"", i, numSlices);
                    Query q = slice.toFilter(context, j, numShards);
                    if (q instanceof MatchNoDocsQuery == false) {
                        assertThat(q, instanceOf(MatchAllDocsQuery.class));
                        targetShards.add(j);
                    }
                }
            }
            assertThat(targetShards.size(), equalTo(numShards));
            assertThat(new HashSet<>(targetShards).size(), equalTo(numShards));

            // numShards == numSlices
            numShards = randomIntBetween(2, 10);
            numSlices = numShards;
            for (int i = 0; i < numSlices; i++) {
                for (int j = 0; j < numShards; j++) {
                    SliceBuilder slice = new SliceBuilder(""_id"", i, numSlices);
                    Query q = slice.toFilter(context, j, numShards);
                    if (i == j) {
                        assertThat(q, instanceOf(MatchAllDocsQuery.class));
                    } else {
                        assertThat(q, instanceOf(MatchNoDocsQuery.class));
                    }
                }
            }
        }

        try (IndexReader reader = DirectoryReader.open(dir)) {
            MappedFieldType fieldType = new MappedFieldType() {
                @Override
                public MappedFieldType clone() {
                    return null;
                }

                @Override
                public String typeName() {
                    return null;
                }

                @Override
                public Query termQuery(Object value, @Nullable QueryShardContext context) {
                    return null;
                }

                public Query existsQuery(QueryShardContext context) {
                    return null;
                }
            };
            fieldType.setName(""field_without_doc_values"");
            when(context.fieldMapper(""field_without_doc_values"")).thenReturn(fieldType);
            when(context.getIndexReader()).thenReturn(reader);
            SliceBuilder builder = new SliceBuilder(""field_without_doc_values"", 5, 10);
            IllegalArgumentException exc =
                expectThrows(IllegalArgumentException.class, () -> builder.toFilter(context, 0, 1));
            assertThat(exc.getMessage(), containsString(""cannot load numeric doc values""));
        }
    }","public void setProfile(boolean profile) {

        }",/server/src/test/java/org/elasticsearch/search/slice/SliceBuilderTests.java
dce5a65f471049c00d62ed2409cdcaf6be29ae8b,125,84,"protected void doWriteTo(StreamOutput out) throws IOException {
        out.writeOptionalWriteable(reduceScript);
        if (out.getVersion().before(Version.V_7_8_0)) {
            if (aggregations.size() > 0) {
                /*
                 * I *believe* that this situation can only happen in cross
                 * cluster search right now. Thus the message. But computers
                 * are hard.
                 */
                throw new IllegalArgumentException(""scripted_metric doesn't support cross cluster search until 7.8.0"");
            }
            out.writeGenericValue(aggregations.get(0));
        } else {
            out.writeCollection(aggregations, StreamOutput::writeGenericValue);
        }
    }","protected void doWriteTo(StreamOutput out) throws IOException {
        out.writeOptionalWriteable(reduceScript);
        if (out.getVersion().before(Version.V_7_8_0)) {
            if (aggregations.size() > 1) {
                /*
                 * If aggregations has more than one entry we're trying to
                 * serialize an unreduced aggregation. This *should* only
                 * happen when we're returning a scripted_metric over cross
                 * cluster search.
                 */
                throw new IllegalArgumentException(""scripted_metric doesn't support cross cluster search until 7.8.0"");
            }
            out.writeGenericValue(aggregations.get(0));
        } else {
            out.writeCollection(aggregations, StreamOutput::writeGenericValue);
        }
    }",/server/src/main/java/org/elasticsearch/search/aggregations/metrics/InternalScriptedMetric.java
babfd8a18117731b1143d1f60d21e269b2b219f9,682,1053,"private void assertBucketContents(Histogram.Bucket actual, Double expectedCount, Double expectedValue) {
        // This is a gap bucket
        SimpleValue countMovAvg = actual.getAggregations().get(""movavg_counts"");
        if (expectedCount == null) {
            assertThat(""[_count] movavg is not null"", countMovAvg, nullValue());
        } else {
            assertThat(""[_count] movavg is null"", countMovAvg, notNullValue());
            assertThat(""[_count] movavg does not match expected [""+countMovAvg.value()+"" vs ""+expectedCount+""]"",
                    Math.abs(countMovAvg.value() - expectedCount) <= 0.000001, equalTo(true));
        }

        // This is a gap bucket
        SimpleValue valuesMovAvg = actual.getAggregations().get(""movavg_values"");
        if (expectedValue == null) {
            assertThat(""[value] movavg is not null"", valuesMovAvg, Matchers.nullValue());
        } else {
            assertThat(""[value] movavg is null"", valuesMovAvg, notNullValue());
            assertThat(""[value] movavg does not match expected [""+valuesMovAvg.value()+"" vs ""+expectedValue+""]"", Math.abs(valuesMovAvg.value() - expectedValue) <= 0.000001, equalTo(true));
        }
    }","private MovAvgModelBuilder randomModelBuilder() {
        int rand = randomIntBetween(0,3);

        switch (rand) {
            case 0:
                return new SimpleModel.SimpleModelBuilder();
            case 1:
                return new LinearModel.LinearModelBuilder();
            case 2:
                return new SingleExpModel.SingleExpModelBuilder().alpha(alpha);
            case 3:
                return new DoubleExpModel.DoubleExpModelBuilder().alpha(alpha).beta(beta);
            default:
                return new SimpleModel.SimpleModelBuilder();
        }
    }",/src/test/java/org/elasticsearch/search/aggregations/reducers/moving/avg/MovAvgTests.java
300f010c0b18ed0f10a41d5e1606466ba0a3088f,547,302,"public void testMathFolding() {
        assertEquals(7, foldFunction(new Abs(EMPTY, L(7))));
        assertEquals(0d, (double) foldFunction(new ACos(EMPTY, ONE)), 0.01d);
        assertEquals(1.57076d, (double) foldFunction(new ASin(EMPTY, ONE)), 0.01d);
        assertEquals(0.78539d, (double) foldFunction(new ATan(EMPTY, ONE)), 0.01d);
        assertEquals(7, foldFunction(new Floor(EMPTY, L(7))));
        assertEquals(Math.E, foldFunction(new E(EMPTY)));
    }","public void testConstantFoldingIn_LeftValueIsNull() {
        In in = new In(EMPTY, NULL, Arrays.asList(ONE, TWO, THREE));
        Literal result= (Literal) new ConstantFolding().rule(in);
        assertNull(result.value());
    }",/x-pack/plugin/sql/src/test/java/org/elasticsearch/xpack/sql/optimizer/OptimizerTests.java
300f010c0b18ed0f10a41d5e1606466ba0a3088f,571,758,"private static boolean findExistingRange(Range main, List<Range> ranges, boolean conjunctive) {
            if (!main.lower().foldable() && !main.upper().foldable()) {
                return false;
            }
            // NB: the loop modifies the list (hence why the int is used)
            for (int i = 0; i < ranges.size(); i++) {
                Range other = ranges.get(i);

                if (main.value().semanticEquals(other.value())) {

                    // make sure the comparison was done
                    boolean compared = false;

                    boolean lower = false;
                    boolean upper = false;
                    // boundary equality (useful to differentiate whether a range is included or not)
                    // and thus whether it should be preserved or ignored
                    boolean lowerEq = false;
                    boolean upperEq = false;

                    // evaluate lower
                    if (main.lower().foldable() && other.lower().foldable()) {
                        compared = true;

                        Integer comp = BinaryComparison.compare(main.lower().fold(), other.lower().fold());
                        // values are comparable
                        if (comp != null) {
                            // boundary equality
                            lowerEq = comp == 0 && main.includeLower() == other.includeLower();
                            // AND
                            if (conjunctive) {
                                // (2 < a < 3) AND (1 < a < 3) -> (2 < a < 3)
                                lower = comp > 0 ||
                                // (2 < a < 3) AND (2 <= a < 3) -> (2 < a < 3)
                                        (comp == 0 && !main.includeLower() && other.includeLower());
                            }
                            // OR
                            else {
                                // (1 < a < 3) OR (2 < a < 3) -> (1 < a < 3)
                                lower = comp < 0 ||
                                // (2 <= a < 3) OR (2 < a < 3) -> (2 <= a < 3)
                                        (comp == 0 && main.includeLower() && !other.includeLower()) || lowerEq;
                            }
                        }
                    }
                    // evaluate upper
                    if (main.upper().foldable() && other.upper().foldable()) {
                        compared = true;

                        Integer comp = BinaryComparison.compare(main.upper().fold(), other.upper().fold());
                        // values are comparable
                        if (comp != null) {
                            // boundary equality
                            upperEq = comp == 0 && main.includeUpper() == other.includeUpper();

                            // AND
                            if (conjunctive) {
                                // (1 < a < 2) AND (1 < a < 3) -> (1 < a < 2)
                                upper = comp < 0 ||
                                // (1 < a < 2) AND (1 < a <= 2) -> (1 < a < 2)
                                        (comp == 0 && !main.includeUpper() && other.includeUpper());
                            }
                            // OR
                            else {
                                // (1 < a < 3) OR (1 < a < 2) -> (1 < a < 3)
                                upper = comp > 0 ||
                                // (1 < a <= 3) OR (1 < a < 3) -> (2 < a < 3)
                                        (comp == 0 && main.includeUpper() && !other.includeUpper()) || upperEq;
                            }
                        }
                    }

                    // AND - at least one of lower or upper
                    if (conjunctive) {
                        // can tighten range
                        if (lower || upper) {
                            ranges.remove(i);
                            ranges.add(i,
                                    new Range(main.source(), main.value(),
                                            lower ? main.lower() : other.lower(),
                                            lower ? main.includeLower() : other.includeLower(),
                                            upper ? main.upper() : other.upper(),
                                            upper ? main.includeUpper() : other.includeUpper()));
                        }

                        // range was comparable
                        return compared;
                    }
                    // OR - needs both upper and lower to loosen range
                    else {
                        // can loosen range
                        if (lower && upper) {
                            ranges.remove(i);
                            ranges.add(i,
                                    new Range(main.source(), main.value(),
                                            lower ? main.lower() : other.lower(),
                                            lower ? main.includeLower() : other.includeLower(),
                                            upper ? main.upper() : other.upper(),
                                            upper ? main.includeUpper() : other.includeUpper()));
                            return true;
                        }

                        // if the range in included, no need to add it
                        return compared && (!((lower && !lowerEq) || (upper && !upperEq)));
                    }
                }
            }
            return false;
        }","private static boolean findExistingRange(Range main, List<Range> ranges, boolean conjunctive) {
            if (!main.lower().foldable() && !main.upper().foldable()) {
                return false;
            }
            // NB: the loop modifies the list (hence why the int is used)
            for (int i = 0; i < ranges.size(); i++) {
                Range other = ranges.get(i);

                if (main.value().semanticEquals(other.value())) {

                    // make sure the comparison was done
                    boolean compared = false;

                    boolean lower = false;
                    boolean upper = false;
                    // boundary equality (useful to differentiate whether a range is included or not)
                    // and thus whether it should be preserved or ignored
                    boolean lowerEq = false;
                    boolean upperEq = false;

                    // evaluate lower
                    if (main.lower().foldable() && other.lower().foldable()) {
                        compared = true;

                        Integer comp = BinaryComparison.compare(main.lower().fold(), other.lower().fold());
                        // values are comparable
                        if (comp != null) {
                            // boundary equality
                            lowerEq = comp == 0 && main.includeLower() == other.includeLower();
                            // AND
                            if (conjunctive) {
                                // (2 < a < 3) AND (1 < a < 3) -> (2 < a < 3)
                                lower = comp > 0 ||
                                // (2 < a < 3) AND (2 <= a < 3) -> (2 < a < 3)
                                        (comp == 0 && !main.includeLower() && other.includeLower());
                            }
                            // OR
                            else {
                                // (1 < a < 3) OR (2 < a < 3) -> (1 < a < 3)
                                lower = comp < 0 ||
                                // (2 <= a < 3) OR (2 < a < 3) -> (2 <= a < 3)
                                        (comp == 0 && main.includeLower() && !other.includeLower()) || lowerEq;
                            }
                        }
                    }
                    // evaluate upper
                    if (main.upper().foldable() && other.upper().foldable()) {
                        compared = true;

                        Integer comp = BinaryComparison.compare(main.upper().fold(), other.upper().fold());
                        // values are comparable
                        if (comp != null) {
                            // boundary equality
                            upperEq = comp == 0 && main.includeUpper() == other.includeUpper();

                            // AND
                            if (conjunctive) {
                                // (1 < a < 2) AND (1 < a < 3) -> (1 < a < 2)
                                upper = comp < 0 ||
                                // (1 < a < 2) AND (1 < a <= 2) -> (1 < a < 2)
                                        (comp == 0 && !main.includeUpper() && other.includeUpper());
                            }
                            // OR
                            else {
                                // (1 < a < 3) OR (1 < a < 2) -> (1 < a < 3)
                                upper = comp > 0 ||
                                // (1 < a <= 3) OR (1 < a < 3) -> (2 < a < 3)
                                        (comp == 0 && main.includeUpper() && !other.includeUpper()) || upperEq;
                            }
                        }
                    }

                    // AND - at least one of lower or upper
                    if (conjunctive) {
                        // can tighten range
                        if (lower || upper) {
                            ranges.remove(i);
                            ranges.add(i,
                                    new Range(main.source(), main.value(),
                                            lower ? main.lower() : other.lower(),
                                            lower ? main.includeLower() : other.includeLower(),
                                            upper ? main.upper() : other.upper(),
                                            upper ? main.includeUpper() : other.includeUpper(),
                                            main.zoneId()));
                        }

                        // range was comparable
                        return compared;
                    }
                    // OR - needs both upper and lower to loosen range
                    else {
                        // can loosen range
                        if (lower && upper) {
                            ranges.remove(i);
                            ranges.add(i,
                                    new Range(main.source(), main.value(),
                                            lower ? main.lower() : other.lower(),
                                            lower ? main.includeLower() : other.includeLower(),
                                            upper ? main.upper() : other.upper(),
                                            upper ? main.includeUpper() : other.includeUpper(),
                                            main.zoneId()));
                            return true;
                        }

                        // if the range in included, no need to add it
                        return compared && (!((lower && !lowerEq) || (upper && !upperEq)));
                    }
                }
            }
            return false;
        }",/x-pack/plugin/ql/src/main/java/org/elasticsearch/xpack/ql/optimizer/OptimizerRules.java
300f010c0b18ed0f10a41d5e1606466ba0a3088f,570,113,"BiFunction<AstBuilder, ParserRuleContext, T> visitor) {
        try {
            SqlBaseLexer lexer = new SqlBaseLexer(new CaseInsensitiveStream(sql));

            lexer.removeErrorListeners();
            lexer.addErrorListener(ERROR_LISTENER);

            Map<Token, SqlTypedParamValue> paramTokens = new HashMap<>();
            TokenSource tokenSource = new ParametrizedTokenSource(lexer, paramTokens, params);

            CommonTokenStream tokenStream = new CommonTokenStream(tokenSource);
            SqlBaseParser parser = new SqlBaseParser(tokenStream);

            parser.addParseListener(new PostProcessor(Arrays.asList(parser.getRuleNames())));

            parser.removeErrorListeners();
            parser.addErrorListener(ERROR_LISTENER);

            parser.getInterpreter().setPredictionMode(PredictionMode.SLL);

            if (DEBUG) {
                debug(parser);
                tokenStream.fill();

                for (Token t : tokenStream.getTokens()) {
                    String symbolicName = SqlBaseLexer.VOCABULARY.getSymbolicName(t.getType());
                    String literalName = SqlBaseLexer.VOCABULARY.getLiteralName(t.getType());
                    log.info(format(Locale.ROOT, ""  %-15s '%s'"",
                        symbolicName == null ? literalName : symbolicName,
                        t.getText()));
                }
            }

            ParserRuleContext tree = parseFunction.apply(parser);

            if (DEBUG) {
                log.info(""Parse tree {} "" + tree.toStringTree());
            }

            return visitor.apply(new AstBuilder(paramTokens), tree);
        } catch (StackOverflowError e) {
            throw new ParsingException(""SQL statement is too large, "" +
                ""causing stack overflow when generating the parsing tree: [{}]"", sql);
        }
    }","BiFunction<AstBuilder, ParserRuleContext, T> visitor) {
        try {
            SqlBaseLexer lexer = new SqlBaseLexer(new CaseInsensitiveStream(sql));

            lexer.removeErrorListeners();
            lexer.addErrorListener(ERROR_LISTENER);

            Map<Token, SqlTypedParamValue> paramTokens = new HashMap<>();
            TokenSource tokenSource = new ParametrizedTokenSource(lexer, paramTokens, params);

            CommonTokenStream tokenStream = new CommonTokenStream(tokenSource);
            SqlBaseParser parser = new SqlBaseParser(tokenStream);

            parser.addParseListener(new PostProcessor(Arrays.asList(parser.getRuleNames())));

            parser.removeErrorListeners();
            parser.addErrorListener(ERROR_LISTENER);

            parser.getInterpreter().setPredictionMode(PredictionMode.SLL);

            if (DEBUG) {
                debug(parser);
                tokenStream.fill();

                for (Token t : tokenStream.getTokens()) {
                    String symbolicName = SqlBaseLexer.VOCABULARY.getSymbolicName(t.getType());
                    String literalName = SqlBaseLexer.VOCABULARY.getLiteralName(t.getType());
                    log.info(format(Locale.ROOT, ""  %-15s '%s'"",
                        symbolicName == null ? literalName : symbolicName,
                        t.getText()));
                }
            }

            ParserRuleContext tree = parseFunction.apply(parser);

            if (DEBUG) {
                log.info(""Parse tree {} "" + tree.toStringTree());
            }

            return visitor.apply(new AstBuilder(paramTokens, zoneId), tree);
        } catch (StackOverflowError e) {
            throw new ParsingException(""SQL statement is too large, "" +
                ""causing stack overflow when generating the parsing tree: [{}]"", sql);
        }
    }",/x-pack/plugin/sql/src/main/java/org/elasticsearch/xpack/sql/parser/SqlParser.java
300f010c0b18ed0f10a41d5e1606466ba0a3088f,563,1811,"public void testHavingWithLiteralImplicitGrouping() {
        PhysicalPlan p = optimizeAndPlan(""SELECT 1 FROM test HAVING COUNT(*) > 0"");
        assertEquals(EsQueryExec.class, p.getClass());
        EsQueryExec eqe = (EsQueryExec) p;
        assertTrue(""Should be tracking hits"", eqe.queryContainer().shouldTrackHits());
        assertEquals(1, eqe.output().size());
        String query = eqe.queryContainer().toString().replaceAll(""\\s+"", """");
        assertThat(eqe.queryContainer().toString().replaceAll(""\\s+"", """"), containsString(""\""size\"":0""));
    }","public void testFieldCountDoesNotTrackHits() {
        PhysicalPlan p = optimizeAndPlan(""SELECT COUNT(int) FROM test"");
        assertEquals(EsQueryExec.class, p.getClass());
        EsQueryExec eqe = (EsQueryExec) p;
        assertFalse(""Should NOT be tracking hits"", eqe.queryContainer().shouldTrackHits());
    }",/x-pack/plugin/sql/src/test/java/org/elasticsearch/xpack/sql/planner/QueryTranslatorTests.java
379e8470488b30a96c9f80eb64d5ab3b9b239aa1,563,1575,"final boolean refresh(String source, SearcherScope scope, boolean block) throws EngineException {
        // we obtain a read lock here, since we don't want a flush to happen while we are refreshing
        // since it flushes the index as well (though, in terms of concurrency, we are allowed to do it)
        // both refresh types will result in an internal refresh but only the external will also
        // pass the new reader reference to the external reader manager.
        final long localCheckpointBeforeRefresh = localCheckpointTracker.getProcessedCheckpoint();
        boolean refreshed;
        try (ReleasableLock lock = readLock.acquire()) {
            ensureOpen();
            if (store.tryIncRef()) {
                // increment the ref just to ensure nobody closes the store during a refresh
                try {
                    // even though we maintain 2 managers we really do the heavy-lifting only once.
                    // the second refresh will only do the extra work we have to do for warming caches etc.
                    ReferenceManager<ElasticsearchDirectoryReader> referenceManager = getReferenceManager(scope);
                    // it is intentional that we never refresh both internal / external together
                    if (block) {
                        referenceManager.maybeRefreshBlocking();
                        refreshed = true;
                    } else {
                        refreshed = referenceManager.maybeRefresh();
                    }
                } finally {
                    store.decRef();
                }
                if (refreshed) {
                    lastRefreshedCheckpointListener.updateRefreshedCheckpoint(localCheckpointBeforeRefresh);
                }
            } else {
                refreshed = false;
            }
        } catch (AlreadyClosedException e) {
            failOnTragicEvent(e);
            throw e;
        } catch (Exception e) {
            try {
                failEngine(""refresh failed source["" + source + ""]"", e);
            } catch (Exception inner) {
                e.addSuppressed(inner);
            }
            throw new RefreshFailedEngineException(shardId, e);
        }
        assert refreshed == false || lastRefreshedCheckpoint() >= localCheckpointBeforeRefresh : ""refresh checkpoint was not advanced; "" +
            ""local_checkpoint="" + localCheckpointBeforeRefresh + "" refresh_checkpoint="" + lastRefreshedCheckpoint();
        // TODO: maybe we should just put a scheduled job in threadPool?
        // We check for pruning in each delete request, but we also prune here e.g. in case a delete burst comes in and then no more deletes
        // for a long time:
        maybePruneDeletes();
        mergeScheduler.refreshConfig();
        return refreshed;
    }","final boolean refresh(String source, SearcherScope scope, boolean block) throws EngineException {
        // both refresh types will result in an internal refresh but only the external will also
        // pass the new reader reference to the external reader manager.
        final long localCheckpointBeforeRefresh = localCheckpointTracker.getProcessedCheckpoint();
        boolean refreshed;
        try {
            // refresh does not need to hold readLock as ReferenceManager can handle correctly if the engine is closed in mid-way.
            if (store.tryIncRef()) {
                // increment the ref just to ensure nobody closes the store during a refresh
                try {
                    // even though we maintain 2 managers we really do the heavy-lifting only once.
                    // the second refresh will only do the extra work we have to do for warming caches etc.
                    ReferenceManager<ElasticsearchDirectoryReader> referenceManager = getReferenceManager(scope);
                    // it is intentional that we never refresh both internal / external together
                    if (block) {
                        referenceManager.maybeRefreshBlocking();
                        refreshed = true;
                    } else {
                        refreshed = referenceManager.maybeRefresh();
                    }
                } finally {
                    store.decRef();
                }
                if (refreshed) {
                    lastRefreshedCheckpointListener.updateRefreshedCheckpoint(localCheckpointBeforeRefresh);
                }
            } else {
                refreshed = false;
            }
        } catch (AlreadyClosedException e) {
            failOnTragicEvent(e);
            throw e;
        } catch (Exception e) {
            try {
                failEngine(""refresh failed source["" + source + ""]"", e);
            } catch (Exception inner) {
                e.addSuppressed(inner);
            }
            throw new RefreshFailedEngineException(shardId, e);
        }
        assert refreshed == false || lastRefreshedCheckpoint() >= localCheckpointBeforeRefresh : ""refresh checkpoint was not advanced; "" +
            ""local_checkpoint="" + localCheckpointBeforeRefresh + "" refresh_checkpoint="" + lastRefreshedCheckpoint();
        // TODO: maybe we should just put a scheduled job in threadPool?
        // We check for pruning in each delete request, but we also prune here e.g. in case a delete burst comes in and then no more deletes
        // for a long time:
        maybePruneDeletes();
        mergeScheduler.refreshConfig();
        return refreshed;
    }",/server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
5921ead04518ea56f035341bedf6e83ed683b16e,563,396,"public static Client wrapClient(Client client, Map<String, String> headers) {
        if (headers.isEmpty()) {
            return client;
        } else {
            final ThreadContext threadContext = client.threadPool().getThreadContext();
            Map<String, String> filteredHeaders = headers.entrySet().stream()
                .filter(e -> ShardFollowTask.HEADER_FILTERS.contains(e.getKey()))
                .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
            return new FilterClient(client) {
                @Override
                protected <Request extends ActionRequest, Response extends ActionResponse>
                void doExecute(ActionType<Response> action, Request request, ActionListener<Response> listener) {
                    final Supplier<ThreadContext.StoredContext> supplier = threadContext.newRestorableContext(false);
                    try (ThreadContext.StoredContext ignore = stashWithHeaders(threadContext, filteredHeaders)) {
                        super.doExecute(action, request, new ContextPreservingActionListener<>(supplier, listener));
                    }
                }
            };
        }
    }","public static Client wrapClient(Client client, Map<String, String> headers) {
        if (headers.isEmpty()) {
            return client;
        } else {
            Map<String, String> filteredHeaders = ClientHelper.filterSecurityHeaders(headers);
            if (filteredHeaders.isEmpty()) {
                return client;
            }
            return new FilterClient(client) {
                @Override
                protected <Request extends ActionRequest, Response extends ActionResponse>
                void doExecute(ActionType<Response> action, Request request, ActionListener<Response> listener) {
                    ClientHelper.executeWithHeadersAsync(filteredHeaders, null, client, action, request, listener);
                }
            };
        }
    }",/x-pack/plugin/ccr/src/main/java/org/elasticsearch/xpack/ccr/CcrLicenseChecker.java
9ba5e168e41e0955f8412f4ba78fe8c5b3cbf169,476,131,"private static void createTestContainer(String containerName) throws Exception {
        // It could happen that we run this test really close to a previous one
        // so we might need some time to be able to create the container
        assertBusy(() -> {
            azureStorageService.createContainer(""default"", LocationMode.PRIMARY_ONLY, containerName);
        }, 30, TimeUnit.SECONDS);
    }","private static void createTestContainer(String containerName) throws Exception {
        // It could happen that we run this test really close to a previous one
        // so we might need some time to be able to create the container
        assertBusy(() -> {
            getAzureStorageService().createContainer(""default"", LocationMode.PRIMARY_ONLY, containerName);
        }, 30, TimeUnit.SECONDS);
    }",/plugins/repository-azure/src/test/java/org/elasticsearch/repositories/azure/AzureSnapshotRestoreTests.java
22ccc8631058325d7285eb24fe34aeaf3cf1064e,570,416,"private void runIfShardMarkedAsEvictedInCache(ShardEviction shardEviction, Runnable runnable) {
        try (Releasable ignored = shardsEvictionLock.acquire(shardEviction)) {
            boolean success = false;
            try {
                if (evictedShards.remove(shardEviction)) {
                    runnable.run();
                }
                success = true;
            } finally {
                assert success : ""shard eviction should be successful: "" + shardEviction;
                if (success == false) {
                    final boolean added = evictedShards.add(shardEviction);
                    assert added : shardEviction;
                }
            }
        }
    }","private void runIfShardMarkedAsEvictedInCache(ShardEviction shardEviction, Runnable runnable) {
        try (Releasable ignored = shardsEvictionLock.acquire(shardEviction)) {
            boolean success = false;
            try {
                if (evictedShards.remove(shardEviction)) {
                    runnable.run();
                }
                success = true;
            } finally {
                if (success == false) {
                    final boolean added = evictedShards.add(shardEviction);
                    assert added : shardEviction;
                }
            }
        }
    }",/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java
a01aff6243674234aec4b3b34fac6e30dcfa6009,563,194,") {
        // Process the missing repositories
        final Map<String, ElasticsearchException> failures = new HashMap<>();
        for (String missingRepo : repositoriesResult.missing()) {
            failures.put(missingRepo, new RepositoryMissingException(missingRepo));
        }

        // short-circuit if there are no repos, because we can not create GroupedActionListener of size 0
        if (repositoriesResult.metadata().isEmpty()) {
            listener.onResponse(new GetSnapshotsResponse(List.of(), failures, null, 0, 0));
            return;
        }
        List<RepositoryMetadata> repositories = maybeFilterRepositories(repositoriesResult.metadata(), sortBy, order, fromSortValue);
        final GroupedActionListener<Tuple<Tuple<String, ElasticsearchException>, SnapshotsInRepo>> groupedActionListener =
            new GroupedActionListener<>(repositories.size(), listener.map(responses -> {
                assert repositories.size() == responses.size();
                final List<SnapshotInfo> allSnapshots = responses.stream()
                    .map(Tuple::v2)
                    .filter(Objects::nonNull)
                    .flatMap(snapshotsInRepo -> snapshotsInRepo.snapshotInfos.stream())
                    .toList();

                responses.stream().map(Tuple::v1).filter(Objects::nonNull).forEach(tuple -> failures.put(tuple.v1(), tuple.v2()));
                final SnapshotsInRepo snInfos = sortSnapshots(allSnapshots, sortBy, after, offset, size, order);
                final List<SnapshotInfo> snapshotInfos = snInfos.snapshotInfos;
                final int remaining = snInfos.remaining + responses.stream()
                    .map(Tuple::v2)
                    .filter(Objects::nonNull)
                    .mapToInt(s -> s.remaining)
                    .sum();
                return new GetSnapshotsResponse(
                    indices ? snapshotInfos : snapshotInfos.stream().map(SnapshotInfo::withoutIndices).toList(),
                    failures,
                    remaining > 0
                        ? GetSnapshotsRequest.After.from(snapshotInfos.get(snapshotInfos.size() - 1), sortBy).asQueryParam()
                        : null,
                    responses.stream().map(Tuple::v2).filter(Objects::nonNull).mapToInt(s -> s.totalCount).sum(),
                    remaining
                );
            }));

        for (final RepositoryMetadata repository : repositories) {
            final String repoName = repository.name();
            getSingleRepoSnapshotInfo(
                snapshotsInProgress,
                repoName,
                snapshots,
                predicates,
                ignoreUnavailable,
                verbose,
                cancellableTask,
                sortBy,
                after,
                order,
                groupedActionListener.delegateResponse((groupedListener, e) -> {
                    if (isMultiRepoRequest && e instanceof ElasticsearchException) {
                        groupedListener.onResponse(Tuple.tuple(Tuple.tuple(repoName, (ElasticsearchException) e), null));
                    } else {
                        groupedListener.onFailure(e);
                    }
                }).map(snInfos -> Tuple.tuple(null, snInfos))
            );
        }
    }",") {
        // Process the missing repositories
        final Map<String, ElasticsearchException> failures = ConcurrentCollections.newConcurrentMap();
        for (String missingRepo : repositoriesResult.missing()) {
            failures.put(missingRepo, new RepositoryMissingException(missingRepo));
        }

        final Queue<List<SnapshotInfo>> allSnapshotInfos = ConcurrentCollections.newQueue();
        final var remaining = new AtomicInteger();
        final var totalCount = new AtomicInteger();

        List<RepositoryMetadata> repositories = maybeFilterRepositories(repositoriesResult.metadata(), sortBy, order, fromSortValue);
        try (var listeners = new RefCountingListener(listener.map(ignored -> {
            cancellableTask.ensureNotCancelled();
            final var sortedSnapshotsInRepos = sortSnapshots(
                allSnapshotInfos.stream().flatMap(Collection::stream),
                totalCount.get(),
                sortBy,
                after,
                offset,
                size,
                order
            );
            final var snapshotInfos = sortedSnapshotsInRepos.snapshotInfos();
            final int finalRemaining = sortedSnapshotsInRepos.remaining() + remaining.get();
            return new GetSnapshotsResponse(
                indices ? snapshotInfos : snapshotInfos.stream().map(SnapshotInfo::withoutIndices).toList(),
                failures,
                finalRemaining > 0
                    ? GetSnapshotsRequest.After.from(snapshotInfos.get(snapshotInfos.size() - 1), sortBy).asQueryParam()
                    : null,
                totalCount.get(),
                finalRemaining
            );
        }))) {
            for (final RepositoryMetadata repository : repositories) {
                final String repoName = repository.name();
                getSingleRepoSnapshotInfo(
                    snapshotsInProgress,
                    repoName,
                    snapshots,
                    predicates,
                    ignoreUnavailable,
                    verbose,
                    cancellableTask,
                    sortBy,
                    after,
                    order,
                    listeners.acquire((SnapshotsInRepo snapshotsInRepo) -> {
                        allSnapshotInfos.add(snapshotsInRepo.snapshotInfos());
                        remaining.addAndGet(snapshotsInRepo.remaining());
                        totalCount.addAndGet(snapshotsInRepo.totalCount());
                    }).delegateResponse((l, e) -> {
                        if (isMultiRepoRequest && e instanceof ElasticsearchException elasticsearchException) {
                            failures.put(repoName, elasticsearchException);
                            l.onResponse(SnapshotsInRepo.EMPTY);
                        } else {
                            l.onFailure(e);
                        }
                    })
                );
            }
        }
    }",/server/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/get/TransportGetSnapshotsAction.java
a5aeee27f69b50d4424781604ff9bc5080a89a67,563,84,"public ClusterState performAction(Index index, ClusterState clusterState) {
        IndexMetadata indexMetadata = clusterState.metadata().index(index);
        if (indexMetadata == null) {
            // Index must have been since deleted, ignore it
            logger.debug(""[{}] lifecycle action for index [{}] executed but index no longer exists"", getKey().getAction(), index.getName());
            return clusterState;
        }
        // get target index
        LifecycleExecutionState lifecycleState = LifecycleExecutionState.fromIndexMetadata(indexMetadata);
        String targetIndexName = targetIndexNameSupplier.apply(index.getName(), lifecycleState);
        IndexMetadata targetIndexMetadata = clusterState.metadata().index(targetIndexName);

        if (targetIndexMetadata == null) {
            logger.warn(""[{}] index [{}] unable to copy execution state to target index [{}] as target index does not exist"",
                getKey().getAction(), index.getName(), targetIndexName);
            throw new IllegalStateException(""unable to copy execution state from ["" + index.getName() +
                ""] to ["" + targetIndexName + ""] as target index does not exist"");
        }

        String phase = targetNextStepKey.getPhase();
        String action = targetNextStepKey.getAction();
        String step = targetNextStepKey.getName();
        long lifecycleDate = lifecycleState.getLifecycleDate();

        LifecycleExecutionState.Builder relevantTargetCustomData = LifecycleExecutionState.builder(lifecycleState);
        // Override the phase, action, and step for the target next StepKey
        relevantTargetCustomData.setPhase(phase);
        relevantTargetCustomData.setAction(action);
        relevantTargetCustomData.setStep(step);

        Metadata.Builder newMetadata = Metadata.builder(clusterState.getMetadata())
            .put(IndexMetadata.builder(targetIndexMetadata)
                .putCustom(ILM_CUSTOM_METADATA_KEY, relevantTargetCustomData.build().asMap()));

        return ClusterState.builder(clusterState).metadata(newMetadata).build();
    }","public ClusterState performAction(Index index, ClusterState clusterState) {
        IndexMetadata indexMetadata = clusterState.metadata().index(index);
        if (indexMetadata == null) {
            // Index must have been since deleted, ignore it
            logger.debug(""[{}] lifecycle action for index [{}] executed but index no longer exists"", getKey().getAction(), index.getName());
            return clusterState;
        }
        // get target index
        LifecycleExecutionState lifecycleState = LifecycleExecutionState.fromIndexMetadata(indexMetadata);
        String targetIndexName = targetIndexNameSupplier.apply(index.getName(), lifecycleState);
        IndexMetadata targetIndexMetadata = clusterState.metadata().index(targetIndexName);

        if (targetIndexMetadata == null) {
            logger.warn(""[{}] index [{}] unable to copy execution state to target index [{}] as target index does not exist"",
                getKey().getAction(), index.getName(), targetIndexName);
            throw new IllegalStateException(""unable to copy execution state from ["" + index.getName() +
                ""] to ["" + targetIndexName + ""] as target index does not exist"");
        }

        String phase = targetNextStepKey.getPhase();
        String action = targetNextStepKey.getAction();
        String step = targetNextStepKey.getName();

        LifecycleExecutionState.Builder relevantTargetCustomData = LifecycleExecutionState.builder(lifecycleState);
        // Override the phase, action, and step for the target next StepKey
        relevantTargetCustomData.setPhase(phase);
        relevantTargetCustomData.setAction(action);
        relevantTargetCustomData.setStep(step);

        Metadata.Builder newMetadata = Metadata.builder(clusterState.getMetadata())
            .put(IndexMetadata.builder(targetIndexMetadata)
                .putCustom(ILM_CUSTOM_METADATA_KEY, relevantTargetCustomData.build().asMap()));

        return ClusterState.builder(clusterState).metadata(newMetadata).build();
    }",/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ilm/CopyExecutionStateStep.java
5812753dbcbac645c2fc8a5ed460178b3e5b60a9,393,211,"public static void copyIndex(final ESLogger logger, final Path src, final String indexName, final Path... dests) throws IOException {
        for (Path dest : dests) {
            Path indexDir = dest.resolve(indexName);
            assertFalse(Files.exists(indexDir));
            Files.createDirectories(indexDir);
        }
        Files.walkFileTree(src, new SimpleFileVisitor<Path>() {
            @Override
            public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException {
                Path relativeDir = src.relativize(dir);
                for (Path dest : dests) {
                    Path destDir = dest.resolve(indexName).resolve(relativeDir);
                    Files.createDirectories(destDir);
                }
                return FileVisitResult.CONTINUE;
            }
            @Override
            public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {
                if (file.getFileName().toString().equals(IndexWriter.WRITE_LOCK_NAME)) {
                    // skip lock file, we don't need it
                    logger.trace(""Skipping lock file: "" + file.toString());
                    return FileVisitResult.CONTINUE;
                }

                Path relativeFile = src.relativize(file);
                Path destFile = dests[randomInt(dests.length - 1)].resolve(indexName).resolve(relativeFile);
                logger.trace(""--> Moving "" + relativeFile.toString() + "" to "" + destFile.toString());
                Files.move(file, destFile);
                assertFalse(Files.exists(file));
                assertTrue(Files.exists(destFile));
                return FileVisitResult.CONTINUE;
            }
        });
    }","public static void copyIndex(final ESLogger logger, final Path src, final String indexName, final Path... dests) throws IOException {
        for (Path dest : dests) {
            Path indexDir = dest.resolve(indexName);
            assertFalse(Files.exists(indexDir));
            Files.createDirectories(indexDir);
        }
        Files.walkFileTree(src, new SimpleFileVisitor<Path>() {
            @Override
            public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException {
                Path relativeDir = src.relativize(dir);
                for (Path dest : dests) {
                    Path destDir = dest.resolve(indexName).resolve(relativeDir);
                    Files.createDirectories(destDir);
                }
                return FileVisitResult.CONTINUE;
            }

            @Override
            public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {
                if (file.getFileName().toString().equals(IndexWriter.WRITE_LOCK_NAME)) {
                    // skip lock file, we don't need it
                    logger.trace(""Skipping lock file: "" + file.toString());
                    return FileVisitResult.CONTINUE;
                }

                Path relativeFile = src.relativize(file);
                Path destFile = dests[randomInt(dests.length - 1)].resolve(indexName).resolve(relativeFile);
                logger.trace(""--> Moving "" + relativeFile.toString() + "" to "" + destFile.toString());
                Files.move(file, destFile);
                assertFalse(Files.exists(file));
                assertTrue(Files.exists(destFile));
                return FileVisitResult.CONTINUE;
            }
        });
    }",/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityTests.java
165cec275743cc3a30059b5b37e68a0725afcff8,628,300,"public final boolean equals(Object obj) {
        if (this == obj) {
            return true;
        }
        if (obj == null || getClass() != obj.getClass()) {
            return false;
        }
        RatedRequest other = (RatedRequest) obj;
        return Objects.equals(specId, other.specId) &&
                Objects.equals(testRequest, other.testRequest) &&
                Objects.equals(indices, other.indices) &&
                Objects.equals(types, other.types) &&
                Objects.equals(summaryFields, summaryFields) &&
                Objects.equals(ratedDocs, other.ratedDocs) &&
                Objects.equals(params, other.params);
    }","public final boolean equals(Object obj) {
        if (this == obj) {
            return true;
        }
        if (obj == null || getClass() != obj.getClass()) {
            return false;
        }

        RatedRequest other = (RatedRequest) obj;
        
        return Objects.equals(specId, other.specId) &&
                Objects.equals(testRequest, other.testRequest) &&
                Objects.equals(indices, other.indices) &&
                Objects.equals(types, other.types) &&
                Objects.equals(summaryFields, other.summaryFields) &&
                Objects.equals(ratedDocs, other.ratedDocs) &&
                Objects.equals(params, other.params);
    }",/modules/rank-eval/src/main/java/org/elasticsearch/index/rankeval/RatedRequest.java
6e4defd3c511583aeeccc3deafff138d682ef9cf,561,177,"ThreadPool threadPool) {
        new ActionRunnable<PrimaryResult<BulkShardRequest, BulkShardResponse>>(listener) {

            private final Executor executor = threadPool.executor(ThreadPool.Names.WRITE);

            private final BulkPrimaryExecutionContext context = new BulkPrimaryExecutionContext(request, primary);

            @Override
            protected void doRun() {
                while (context.hasMoreOperationsToExecute()) {
                    if (executeBulkItemRequest(context, updateHelper, nowInMillisSupplier, mappingUpdater, waitForMappingUpdate,
                        ActionListener.wrap(v -> executor.execute(this), this::onRejection)) == false) {
                        // We are waiting for a mapping update on another thread, that will invoke this action again once its done
                        // so we just break out here.
                        return;
                    }
                    assert context.isInitial(); // either completed and moved to next or reset
                }
                // We're done, there's no more operations to execute so we resolve the wrapped listener
                finishRequest();
            }

            @Override
            public void onFailure(Exception e) {
                assert false : ""All exceptions should be handled by #executeBulkItemRequest"";
                onRejection(e);
            }

            @Override
            public void onRejection(Exception e) {
                // Fail all operations after a bulk rejection hit an action that waited for a mapping update and finish the request
                while (context.hasMoreOperationsToExecute()) {
                    context.setRequestToExecute(context.getCurrent());
                    final DocWriteRequest<?> docWriteRequest = context.getRequestToExecute();
                    onComplete(
                        exceptionToResult(
                            e, primary, docWriteRequest.opType() == DocWriteRequest.OpType.DELETE, docWriteRequest.version()),
                        context, null);
                }
                finishRequest();
            }

            private void finishRequest() {
                listener.onResponse(
                    new WritePrimaryResult<>(context.getBulkShardRequest(), context.buildShardResponse(), context.getLocationToSync(),
                        null, context.getPrimary(), logger));
            }

        }.run();
    }","ThreadPool threadPool) {
        new ActionRunnable<>(listener) {

            private final Executor executor = threadPool.executor(ThreadPool.Names.WRITE);

            private final BulkPrimaryExecutionContext context = new BulkPrimaryExecutionContext(request, primary);

            @Override
            protected void doRun() {
                while (context.hasMoreOperationsToExecute()) {
                    if (executeBulkItemRequest(context, updateHelper, nowInMillisSupplier, mappingUpdater, waitForMappingUpdate,
                        ActionListener.wrap(v -> executor.execute(this), this::onRejection)) == false) {
                        // We are waiting for a mapping update on another thread, that will invoke this action again once its done
                        // so we just break out here.
                        return;
                    }
                    assert context.isInitial(); // either completed and moved to next or reset
                }
                // We're done, there's no more operations to execute so we resolve the wrapped listener
                finishRequest();
            }

            @Override
            public void onFailure(Exception e) {
                assert false : ""All exceptions should be handled by #executeBulkItemRequest"";
                onRejection(e);
            }

            @Override
            public void onRejection(Exception e) {
                // Fail all operations after a bulk rejection hit an action that waited for a mapping update and finish the request
                while (context.hasMoreOperationsToExecute()) {
                    context.setRequestToExecute(context.getCurrent());
                    final DocWriteRequest<?> docWriteRequest = context.getRequestToExecute();
                    onComplete(
                        exceptionToResult(
                            e, primary, docWriteRequest.opType() == DocWriteRequest.OpType.DELETE, docWriteRequest.version()),
                        context, null);
                }
                finishRequest();
            }

            private void finishRequest() {
                ActionListener.completeWith(listener,
                    () -> new WritePrimaryResult<>(
                        context.getBulkShardRequest(), context.buildShardResponse(), context.getLocationToSync(), null,
                        context.getPrimary(), logger));
            }
        }.run();
    }",/server/src/main/java/org/elasticsearch/action/bulk/TransportShardBulkAction.java
bc5c849d296d2e4d114ed5c40432b64519776f62,570,827,"private void ensureFullStateWritten() {
            assert fullStateWritten : ""Need to write full state first before doing incremental writes"";
            // noinspection ConstantConditions to catch this even if assertions are disabled
            if (fullStateWritten == false) {
                logger.error(""cannot write incremental state"");
                throw new IllegalStateException(""cannot write incremental state"");
            }
        }","throws IOException {
            ensureOpen();
            ensureFullStateWritten();

            try {
                final long startTimeMillis = relativeTimeMillisSupplier.getAsLong();

                for (MetadataIndexWriter metadataIndexWriter : metadataIndexWriters) {
                    metadataIndexWriter.startWrite();
                }

                final WriterStats stats = updateMetadata(previousClusterState.metadata(), clusterState.metadata());
                commit(currentTerm, clusterState.version(), clusterState.metadata().oldestIndexVersion());
                final long durationMillis = relativeTimeMillisSupplier.getAsLong() - startTimeMillis;
                final TimeValue finalSlowWriteLoggingThreshold = slowWriteLoggingThresholdSupplier.get();
                if (durationMillis >= finalSlowWriteLoggingThreshold.getMillis()) {
                    logger.warn(
                        ""writing cluster state took [{}ms] which is above the warn threshold of [{}]; {}"",
                        durationMillis,
                        finalSlowWriteLoggingThreshold,
                        stats
                    );
                } else {
                    logger.debug(""writing cluster state took [{}ms]; {}"", durationMillis, stats);
                }
            } finally {
                closeIfAnyIndexWriterHasTragedyOrIsClosed();
            }
        }",/server/src/main/java/org/elasticsearch/gateway/PersistedClusterStateService.java
d4771b993f669a359ce75ba7bf2faaae8939450f,686,572,"<T> void runTasksForExecutor(ClusterStateTaskExecutor<T> executor) {
        final ArrayList<UpdateTask<T>> toExecute = new ArrayList<>();
        final Map<String, ArrayList<T>> processTasksBySource = new HashMap<>();
        synchronized (updateTasksPerExecutor) {
            List<UpdateTask> pending = updateTasksPerExecutor.remove(executor);
            if (pending != null) {
                for (UpdateTask<T> task : pending) {
                    if (task.processed.getAndSet(true) == false) {
                        logger.trace(""will process [{}[{}]]"", task.source, task.task);
                        toExecute.add(task);
                        processTasksBySource.computeIfAbsent(task.source, s -> new ArrayList<>()).add(task.task);
                    } else {
                        logger.trace(""skipping [{}[{}]], already processed"", task.source, task.task);
                    }
                }
            }
        }
        if (toExecute.isEmpty()) {
            return;
        }
        final String tasksSummary = processTasksBySource.entrySet().stream().map(entry -> {
            String tasks = executor.describeTasks(entry.getValue());
            return tasks.isEmpty() ? entry.getKey() : entry.getKey() + ""["" + tasks + ""]"";
        }).reduce((s1, s2) -> s1 + "", "" + s2).orElse("""");

        if (!lifecycle.started()) {
            logger.debug(""processing [{}]: ignoring, cluster_service not started"", tasksSummary);
            return;
        }
        logger.debug(""processing [{}]: execute"", tasksSummary);
        ClusterState previousClusterState = clusterState;
        if (!previousClusterState.nodes().isLocalNodeElectedMaster() && executor.runOnlyOnMaster()) {
            logger.debug(""failing [{}]: local node is no longer master"", tasksSummary);
            toExecute.stream().forEach(task -> task.listener.onNoLongerMaster(task.source));
            return;
        }
        ClusterStateTaskExecutor.BatchResult<T> batchResult;
        long startTimeNS = currentTimeInNanos();
        try {
            List<T> inputs = toExecute.stream().map(tUpdateTask -> tUpdateTask.task).collect(Collectors.toList());
            batchResult = executor.execute(previousClusterState, inputs);
        } catch (Exception e) {
            TimeValue executionTime = TimeValue.timeValueMillis(Math.max(0, TimeValue.nsecToMSec(currentTimeInNanos() - startTimeNS)));
            if (logger.isTraceEnabled()) {
                logger.trace(""failed to execute cluster state update in [{}], state:\nversion [{}], source [{}]\n{}{}{}"", e, executionTime,
                        previousClusterState.version(), tasksSummary, previousClusterState.nodes().prettyPrint(),
                        previousClusterState.routingTable().prettyPrint(), previousClusterState.getRoutingNodes().prettyPrint());
            }
            warnAboutSlowTaskIfNeeded(executionTime, tasksSummary);
            batchResult = ClusterStateTaskExecutor.BatchResult.<T>builder()
                    .failures(toExecute.stream().map(updateTask -> updateTask.task)::iterator, e)
                    .build(previousClusterState);
        }

        assert batchResult.executionResults != null;
        assert batchResult.executionResults.size() == toExecute.size()
                : String.format(Locale.ROOT, ""expected [%d] task result%s but was [%d]"", toExecute.size(),
                toExecute.size() == 1 ? """" : ""s"", batchResult.executionResults.size());
        boolean assertsEnabled = false;
        assert (assertsEnabled = true);
        if (assertsEnabled) {
            for (UpdateTask<T> updateTask : toExecute) {
                assert batchResult.executionResults.containsKey(updateTask.task) : ""missing task result for ["" + updateTask.task + ""]"";
            }
        }

        ClusterState newClusterState = batchResult.resultingState;
        final ArrayList<UpdateTask<T>> proccessedListeners = new ArrayList<>();
        // fail all tasks that have failed and extract those that are waiting for results
        for (UpdateTask<T> updateTask : toExecute) {
            assert batchResult.executionResults.containsKey(updateTask.task) : ""missing "" + updateTask.task.toString();
            final ClusterStateTaskExecutor.TaskResult executionResult =
                    batchResult.executionResults.get(updateTask.task);
            executionResult.handle(
                    () -> proccessedListeners.add(updateTask),
                    ex -> {
                        logger.debug(""cluster state update task [{}] failed"", ex, updateTask.source);
                        updateTask.listener.onFailure(updateTask.source, ex);
                    }
            );
        }

        if (previousClusterState == newClusterState) {
            for (UpdateTask<T> task : proccessedListeners) {
                if (task.listener instanceof AckedClusterStateTaskListener) {
                    //no need to wait for ack if nothing changed, the update can be counted as acknowledged
                    ((AckedClusterStateTaskListener) task.listener).onAllNodesAcked(null);
                }
                task.listener.clusterStateProcessed(task.source, previousClusterState, newClusterState);
            }
            TimeValue executionTime = TimeValue.timeValueMillis(Math.max(0, TimeValue.nsecToMSec(currentTimeInNanos() - startTimeNS)));
            logger.debug(""processing [{}]: took [{}] no change in cluster_state"", tasksSummary, executionTime);
            warnAboutSlowTaskIfNeeded(executionTime, tasksSummary);
            return;
        }

        try {
            ArrayList<Discovery.AckListener> ackListeners = new ArrayList<>();
            if (newClusterState.nodes().isLocalNodeElectedMaster()) {
                // only the master controls the version numbers
                Builder builder = ClusterState.builder(newClusterState).incrementVersion();
                if (previousClusterState.routingTable() != newClusterState.routingTable()) {
                    builder.routingTable(RoutingTable.builder(newClusterState.routingTable())
                            .version(newClusterState.routingTable().version() + 1).build());
                }
                if (previousClusterState.metaData() != newClusterState.metaData()) {
                    builder.metaData(MetaData.builder(newClusterState.metaData()).version(newClusterState.metaData().version() + 1));
                }
                newClusterState = builder.build();
                for (UpdateTask<T> task : proccessedListeners) {
                    if (task.listener instanceof AckedClusterStateTaskListener) {
                        final AckedClusterStateTaskListener ackedListener = (AckedClusterStateTaskListener) task.listener;
                        if (ackedListener.ackTimeout() == null || ackedListener.ackTimeout().millis() == 0) {
                            ackedListener.onAckTimeout();
                        } else {
                            try {
                                ackListeners.add(new AckCountDownListener(ackedListener, newClusterState.version(), newClusterState.nodes(),
                                        threadPool));
                            } catch (EsRejectedExecutionException ex) {
                                if (logger.isDebugEnabled()) {
                                    logger.debug(""Couldn't schedule timeout thread - node might be shutting down"", ex);
                                }
                                //timeout straightaway, otherwise we could wait forever as the timeout thread has not started
                                ackedListener.onAckTimeout();
                            }
                        }
                    }
                }
            }
            final Discovery.AckListener ackListener = new DelegetingAckListener(ackListeners);

            newClusterState.status(ClusterState.ClusterStateStatus.BEING_APPLIED);

            if (logger.isTraceEnabled()) {
                logger.trace(""cluster state updated, source [{}]\n{}"", tasksSummary, newClusterState.prettyPrint());
            } else if (logger.isDebugEnabled()) {
                logger.debug(""cluster state updated, version [{}], source [{}]"", newClusterState.version(), tasksSummary);
            }

            ClusterChangedEvent clusterChangedEvent = new ClusterChangedEvent(tasksSummary, newClusterState, previousClusterState);
            // new cluster state, notify all listeners
            final DiscoveryNodes.Delta nodesDelta = clusterChangedEvent.nodesDelta();
            if (nodesDelta.hasChanges() && logger.isInfoEnabled()) {
                String summary = nodesDelta.shortSummary();
                if (summary.length() > 0) {
                    logger.info(""{}, reason: {}"", summary, tasksSummary);
                }
            }

            nodeConnectionsService.connectToAddedNodes(clusterChangedEvent);

            // if we are the master, publish the new state to all nodes
            // we publish here before we send a notification to all the listeners, since if it fails
            // we don't want to notify
            if (newClusterState.nodes().isLocalNodeElectedMaster()) {
                logger.debug(""publishing cluster state version [{}]"", newClusterState.version());
                try {
                    clusterStatePublisher.accept(clusterChangedEvent, ackListener);
                } catch (Discovery.FailedToCommitClusterStateException t) {
                    logger.warn(""failing [{}]: failed to commit cluster state version [{}]"", t, tasksSummary, newClusterState.version());
                    proccessedListeners.forEach(task -> task.listener.onFailure(task.source, t));
                    return;
                }
            }

            // update the current cluster state
            clusterState = newClusterState;
            logger.debug(""set local cluster state to version {}"", newClusterState.version());
            try {
                // nothing to do until we actually recover from the gateway or any other block indicates we need to disable persistency
                if (clusterChangedEvent.state().blocks().disableStatePersistence() == false && clusterChangedEvent.metaDataChanged()) {
                    final Settings incomingSettings = clusterChangedEvent.state().metaData().settings();
                    clusterSettings.applySettings(incomingSettings);
                }
            } catch (Exception ex) {
                logger.warn(""failed to apply cluster settings"", ex);
            }
            for (ClusterStateListener listener : preAppliedListeners) {
                try {
                    listener.clusterChanged(clusterChangedEvent);
                } catch (Exception ex) {
                    logger.warn(""failed to notify ClusterStateListener"", ex);
                }
            }

            nodeConnectionsService.disconnectFromRemovedNodes(clusterChangedEvent);

            newClusterState.status(ClusterState.ClusterStateStatus.APPLIED);

            for (ClusterStateListener listener : postAppliedListeners) {
                try {
                    listener.clusterChanged(clusterChangedEvent);
                } catch (Exception ex) {
                    logger.warn(""failed to notify ClusterStateListener"", ex);
                }
            }

            //manual ack only from the master at the end of the publish
            if (newClusterState.nodes().isLocalNodeElectedMaster()) {
                try {
                    ackListener.onNodeAck(newClusterState.nodes().getLocalNode(), null);
                } catch (Exception e) {
                    logger.debug(""error while processing ack for master node [{}]"", e, newClusterState.nodes().getLocalNode());
                }
            }

            for (UpdateTask<T> task : proccessedListeners) {
                task.listener.clusterStateProcessed(task.source, previousClusterState, newClusterState);
            }

            try {
                executor.clusterStatePublished(clusterChangedEvent);
            } catch (Exception e) {
                logger.error(""exception thrown while notifying executor of new cluster state publication [{}]"", e, tasksSummary);
            }

            TimeValue executionTime = TimeValue.timeValueMillis(Math.max(0, TimeValue.nsecToMSec(currentTimeInNanos() - startTimeNS)));
            logger.debug(""processing [{}]: took [{}] done applying updated cluster_state (version: {}, uuid: {})"", tasksSummary,
                executionTime, newClusterState.version(), newClusterState.stateUUID());
            warnAboutSlowTaskIfNeeded(executionTime, tasksSummary);
        } catch (Exception e) {
            TimeValue executionTime = TimeValue.timeValueMillis(Math.max(0, TimeValue.nsecToMSec(currentTimeInNanos() - startTimeNS)));
            logger.warn(""failed to apply updated cluster state in [{}]:\nversion [{}], uuid [{}], source [{}]\n{}"", e, executionTime,
                    newClusterState.version(), newClusterState.stateUUID(), tasksSummary, newClusterState.prettyPrint());
            // TODO: do we want to call updateTask.onFailure here?
        }

    }","<T> void runTasksForExecutor(ClusterStateTaskExecutor<T> executor) {
        final ArrayList<UpdateTask<T>> toExecute = new ArrayList<>();
        final Map<String, ArrayList<T>> processTasksBySource = new HashMap<>();
        synchronized (updateTasksPerExecutor) {
            List<UpdateTask> pending = updateTasksPerExecutor.remove(executor);
            if (pending != null) {
                for (UpdateTask<T> task : pending) {
                    if (task.processed.getAndSet(true) == false) {
                        logger.trace(""will process {}"", task.toString(executor));
                        toExecute.add(task);
                        processTasksBySource.computeIfAbsent(task.source, s -> new ArrayList<>()).add(task.task);
                    } else {
                        logger.trace(""skipping {}, already processed"", task.toString(executor));
                    }
                }
            }
        }
        if (toExecute.isEmpty()) {
            return;
        }
        final String tasksSummary = processTasksBySource.entrySet().stream().map(entry -> {
            String tasks = executor.describeTasks(entry.getValue());
            return tasks.isEmpty() ? entry.getKey() : entry.getKey() + ""["" + tasks + ""]"";
        }).reduce((s1, s2) -> s1 + "", "" + s2).orElse("""");

        if (!lifecycle.started()) {
            logger.debug(""processing [{}]: ignoring, cluster_service not started"", tasksSummary);
            return;
        }
        logger.debug(""processing [{}]: execute"", tasksSummary);
        ClusterState previousClusterState = clusterState;
        if (!previousClusterState.nodes().isLocalNodeElectedMaster() && executor.runOnlyOnMaster()) {
            logger.debug(""failing [{}]: local node is no longer master"", tasksSummary);
            toExecute.stream().forEach(task -> task.listener.onNoLongerMaster(task.source));
            return;
        }
        ClusterStateTaskExecutor.BatchResult<T> batchResult;
        long startTimeNS = currentTimeInNanos();
        try {
            List<T> inputs = toExecute.stream().map(tUpdateTask -> tUpdateTask.task).collect(Collectors.toList());
            batchResult = executor.execute(previousClusterState, inputs);
        } catch (Exception e) {
            TimeValue executionTime = TimeValue.timeValueMillis(Math.max(0, TimeValue.nsecToMSec(currentTimeInNanos() - startTimeNS)));
            if (logger.isTraceEnabled()) {
                logger.trace(""failed to execute cluster state update in [{}], state:\nversion [{}], source [{}]\n{}{}{}"", e, executionTime,
                        previousClusterState.version(), tasksSummary, previousClusterState.nodes().prettyPrint(),
                        previousClusterState.routingTable().prettyPrint(), previousClusterState.getRoutingNodes().prettyPrint());
            }
            warnAboutSlowTaskIfNeeded(executionTime, tasksSummary);
            batchResult = ClusterStateTaskExecutor.BatchResult.<T>builder()
                    .failures(toExecute.stream().map(updateTask -> updateTask.task)::iterator, e)
                    .build(previousClusterState);
        }

        assert batchResult.executionResults != null;
        assert batchResult.executionResults.size() == toExecute.size()
                : String.format(Locale.ROOT, ""expected [%d] task result%s but was [%d]"", toExecute.size(),
                toExecute.size() == 1 ? """" : ""s"", batchResult.executionResults.size());
        boolean assertsEnabled = false;
        assert (assertsEnabled = true);
        if (assertsEnabled) {
            for (UpdateTask<T> updateTask : toExecute) {
                assert batchResult.executionResults.containsKey(updateTask.task) :
                    ""missing task result for "" + updateTask.toString(executor);
            }
        }

        ClusterState newClusterState = batchResult.resultingState;
        final ArrayList<UpdateTask<T>> proccessedListeners = new ArrayList<>();
        // fail all tasks that have failed and extract those that are waiting for results
        for (UpdateTask<T> updateTask : toExecute) {
            assert batchResult.executionResults.containsKey(updateTask.task) : ""missing "" + updateTask.toString(executor);
            final ClusterStateTaskExecutor.TaskResult executionResult =
                    batchResult.executionResults.get(updateTask.task);
            executionResult.handle(
                    () -> proccessedListeners.add(updateTask),
                    ex -> {
                        logger.debug(""cluster state update task {} failed"", ex, updateTask.toString(executor));
                        updateTask.listener.onFailure(updateTask.source, ex);
                    }
            );
        }

        if (previousClusterState == newClusterState) {
            for (UpdateTask<T> task : proccessedListeners) {
                if (task.listener instanceof AckedClusterStateTaskListener) {
                    //no need to wait for ack if nothing changed, the update can be counted as acknowledged
                    ((AckedClusterStateTaskListener) task.listener).onAllNodesAcked(null);
                }
                task.listener.clusterStateProcessed(task.source, previousClusterState, newClusterState);
            }
            TimeValue executionTime = TimeValue.timeValueMillis(Math.max(0, TimeValue.nsecToMSec(currentTimeInNanos() - startTimeNS)));
            logger.debug(""processing [{}]: took [{}] no change in cluster_state"", tasksSummary, executionTime);
            warnAboutSlowTaskIfNeeded(executionTime, tasksSummary);
            return;
        }

        try {
            ArrayList<Discovery.AckListener> ackListeners = new ArrayList<>();
            if (newClusterState.nodes().isLocalNodeElectedMaster()) {
                // only the master controls the version numbers
                Builder builder = ClusterState.builder(newClusterState).incrementVersion();
                if (previousClusterState.routingTable() != newClusterState.routingTable()) {
                    builder.routingTable(RoutingTable.builder(newClusterState.routingTable())
                            .version(newClusterState.routingTable().version() + 1).build());
                }
                if (previousClusterState.metaData() != newClusterState.metaData()) {
                    builder.metaData(MetaData.builder(newClusterState.metaData()).version(newClusterState.metaData().version() + 1));
                }
                newClusterState = builder.build();
                for (UpdateTask<T> task : proccessedListeners) {
                    if (task.listener instanceof AckedClusterStateTaskListener) {
                        final AckedClusterStateTaskListener ackedListener = (AckedClusterStateTaskListener) task.listener;
                        if (ackedListener.ackTimeout() == null || ackedListener.ackTimeout().millis() == 0) {
                            ackedListener.onAckTimeout();
                        } else {
                            try {
                                ackListeners.add(new AckCountDownListener(ackedListener, newClusterState.version(), newClusterState.nodes(),
                                        threadPool));
                            } catch (EsRejectedExecutionException ex) {
                                if (logger.isDebugEnabled()) {
                                    logger.debug(""Couldn't schedule timeout thread - node might be shutting down"", ex);
                                }
                                //timeout straightaway, otherwise we could wait forever as the timeout thread has not started
                                ackedListener.onAckTimeout();
                            }
                        }
                    }
                }
            }
            final Discovery.AckListener ackListener = new DelegetingAckListener(ackListeners);

            newClusterState.status(ClusterState.ClusterStateStatus.BEING_APPLIED);

            if (logger.isTraceEnabled()) {
                logger.trace(""cluster state updated, source [{}]\n{}"", tasksSummary, newClusterState.prettyPrint());
            } else if (logger.isDebugEnabled()) {
                logger.debug(""cluster state updated, version [{}], source [{}]"", newClusterState.version(), tasksSummary);
            }

            ClusterChangedEvent clusterChangedEvent = new ClusterChangedEvent(tasksSummary, newClusterState, previousClusterState);
            // new cluster state, notify all listeners
            final DiscoveryNodes.Delta nodesDelta = clusterChangedEvent.nodesDelta();
            if (nodesDelta.hasChanges() && logger.isInfoEnabled()) {
                String summary = nodesDelta.shortSummary();
                if (summary.length() > 0) {
                    logger.info(""{}, reason: {}"", summary, tasksSummary);
                }
            }

            nodeConnectionsService.connectToAddedNodes(clusterChangedEvent);

            // if we are the master, publish the new state to all nodes
            // we publish here before we send a notification to all the listeners, since if it fails
            // we don't want to notify
            if (newClusterState.nodes().isLocalNodeElectedMaster()) {
                logger.debug(""publishing cluster state version [{}]"", newClusterState.version());
                try {
                    clusterStatePublisher.accept(clusterChangedEvent, ackListener);
                } catch (Discovery.FailedToCommitClusterStateException t) {
                    logger.warn(""failing [{}]: failed to commit cluster state version [{}]"", t, tasksSummary, newClusterState.version());
                    proccessedListeners.forEach(task -> task.listener.onFailure(task.source, t));
                    return;
                }
            }

            // update the current cluster state
            clusterState = newClusterState;
            logger.debug(""set local cluster state to version {}"", newClusterState.version());
            try {
                // nothing to do until we actually recover from the gateway or any other block indicates we need to disable persistency
                if (clusterChangedEvent.state().blocks().disableStatePersistence() == false && clusterChangedEvent.metaDataChanged()) {
                    final Settings incomingSettings = clusterChangedEvent.state().metaData().settings();
                    clusterSettings.applySettings(incomingSettings);
                }
            } catch (Exception ex) {
                logger.warn(""failed to apply cluster settings"", ex);
            }
            for (ClusterStateListener listener : preAppliedListeners) {
                try {
                    listener.clusterChanged(clusterChangedEvent);
                } catch (Exception ex) {
                    logger.warn(""failed to notify ClusterStateListener"", ex);
                }
            }

            nodeConnectionsService.disconnectFromRemovedNodes(clusterChangedEvent);

            newClusterState.status(ClusterState.ClusterStateStatus.APPLIED);

            for (ClusterStateListener listener : postAppliedListeners) {
                try {
                    listener.clusterChanged(clusterChangedEvent);
                } catch (Exception ex) {
                    logger.warn(""failed to notify ClusterStateListener"", ex);
                }
            }

            //manual ack only from the master at the end of the publish
            if (newClusterState.nodes().isLocalNodeElectedMaster()) {
                try {
                    ackListener.onNodeAck(newClusterState.nodes().getLocalNode(), null);
                } catch (Exception e) {
                    logger.debug(""error while processing ack for master node [{}]"", e, newClusterState.nodes().getLocalNode());
                }
            }

            for (UpdateTask<T> task : proccessedListeners) {
                task.listener.clusterStateProcessed(task.source, previousClusterState, newClusterState);
            }

            try {
                executor.clusterStatePublished(clusterChangedEvent);
            } catch (Exception e) {
                logger.error(""exception thrown while notifying executor of new cluster state publication [{}]"", e, tasksSummary);
            }

            TimeValue executionTime = TimeValue.timeValueMillis(Math.max(0, TimeValue.nsecToMSec(currentTimeInNanos() - startTimeNS)));
            logger.debug(""processing [{}]: took [{}] done applying updated cluster_state (version: {}, uuid: {})"", tasksSummary,
                executionTime, newClusterState.version(), newClusterState.stateUUID());
            warnAboutSlowTaskIfNeeded(executionTime, tasksSummary);
        } catch (Exception e) {
            TimeValue executionTime = TimeValue.timeValueMillis(Math.max(0, TimeValue.nsecToMSec(currentTimeInNanos() - startTimeNS)));
            logger.warn(""failed to apply updated cluster state in [{}]:\nversion [{}], uuid [{}], source [{}]\n{}"", e, executionTime,
                    newClusterState.version(), newClusterState.stateUUID(), tasksSummary, newClusterState.prettyPrint());
            // TODO: do we want to call updateTask.onFailure here?
        }

    }",/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java
15ccb110d71d0dcb1d02d9ceba0203e93c51919c,563,343,"public PhysicalOperation plan(PhysicalPlan node, LocalExecutionPlanContext context) {
        if (node instanceof AggregateExec aggregate) {
            PhysicalOperation source = plan(aggregate.child(), context);
            Map<Object, Integer> layout = new HashMap<>();
            OperatorFactory operatorFactory = null;

            if (aggregate.groupings().isEmpty()) {
                // not grouping
                for (NamedExpression e : aggregate.aggregates()) {
                    if (e instanceof Alias alias && alias.child()instanceof AggregateFunction aggregateFunction) {
                        AggregatorFunctionFactory aggregatorFunc;
                        if (aggregateFunction instanceof Avg avg) {
                            aggregatorFunc = avg.dataType().isRational() ? AggregatorFunction.doubleAvg : AggregatorFunction.longAvg;
                        } else if (aggregateFunction instanceof Count) {
                            aggregatorFunc = AggregatorFunction.count;
                        } else {
                            throw new UnsupportedOperationException(""unsupported aggregate function:"" + aggregateFunction);
                        }

                        if (aggregate.getMode() == AggregateExec.Mode.PARTIAL) {
                            operatorFactory = new AggregationOperatorFactory(
                                List.of(
                                    new AggregatorFactory(
                                        aggregatorFunc,
                                        AggregatorMode.INITIAL,
                                        source.layout.get(Expressions.attribute(aggregateFunction.field()).id())
                                    )
                                ),
                                AggregatorMode.INITIAL
                            );
                            layout.put(alias.id(), 0);
                        } else if (aggregate.getMode() == AggregateExec.Mode.FINAL) {
                            operatorFactory = new AggregationOperatorFactory(
                                List.of(new AggregatorFactory(aggregatorFunc, AggregatorMode.FINAL, source.layout.get(alias.id()))),
                                AggregatorMode.FINAL
                            );
                            layout.put(alias.id(), 0);
                        } else {
                            throw new UnsupportedOperationException();
                        }
                    } else {
                        throw new UnsupportedOperationException();
                    }
                }
            } else {
                // grouping
                AttributeSet groups = Expressions.references(aggregate.groupings());
                if (groups.size() != 1) {
                    throw new UnsupportedOperationException(""just one group, for now"");
                }
                Attribute grpAttrib = groups.iterator().next();
                layout.put(grpAttrib.id(), 0);

                for (NamedExpression e : aggregate.aggregates()) {
                    if (e instanceof Alias alias && alias.child()instanceof AggregateFunction aggregateFunction) {
                        GroupingAggregatorFunctionFactory aggregatorFunc;
                        if (aggregateFunction instanceof Avg) {
                            aggregatorFunc = GroupingAggregatorFunction.avg;
                        } else if (aggregateFunction instanceof Count) {
                            aggregatorFunc = GroupingAggregatorFunction.count;
                        } else {
                            throw new UnsupportedOperationException(""unsupported aggregate function:"" + aggregateFunction);
                        }

                        final Supplier<BlockHash> blockHash;
                        if (grpAttrib.dataType() == DataTypes.KEYWORD) {
                            blockHash = () -> BlockHash.newBytesRefHash(BigArrays.NON_RECYCLING_INSTANCE);
                        } else {
                            blockHash = () -> BlockHash.newLongHash(BigArrays.NON_RECYCLING_INSTANCE);
                        }
                        if (aggregate.getMode() == AggregateExec.Mode.PARTIAL) {
                            operatorFactory = new HashAggregationOperatorFactory(
                                source.layout.get(grpAttrib.id()),
                                List.of(
                                    new GroupingAggregatorFactory(
                                        aggregatorFunc,
                                        AggregatorMode.INITIAL,
                                        source.layout.get(Expressions.attribute(aggregateFunction.field()).id())
                                    )
                                ),
                                blockHash,
                                AggregatorMode.INITIAL
                            );
                            layout.put(alias.id(), 1);  // <<<< TODO: this one looks suspicious
                        } else if (aggregate.getMode() == AggregateExec.Mode.FINAL) {
                            operatorFactory = new HashAggregationOperatorFactory(
                                source.layout.get(grpAttrib.id()),
                                List.of(new GroupingAggregatorFactory(aggregatorFunc, AggregatorMode.FINAL, source.layout.get(alias.id()))),
                                blockHash,
                                AggregatorMode.FINAL
                            );
                            layout.put(alias.id(), 1);
                        } else {
                            throw new UnsupportedOperationException();
                        }
                    } else {
                        throw new UnsupportedOperationException();
                    }
                }

            }
            if (operatorFactory != null) {
                return new PhysicalOperation(operatorFactory, layout, source);
            }
            throw new UnsupportedOperationException();
        } else if (node instanceof EsQueryExec esQuery) {
            return planEsQueryNode(esQuery, context);
        } else if (node instanceof FieldExtractExec fieldExtractExec) {
            return planFieldExtractNode(context, fieldExtractExec);
        } else if (node instanceof OutputExec outputExec) {
            PhysicalOperation source = plan(outputExec.child(), context);
            if (outputExec.output().size() != source.layout.size()) {
                throw new IllegalStateException(
                    ""expected layout:""
                        + outputExec.output()
                        + "": ""
                        + outputExec.output().stream().map(NamedExpression::id).collect(Collectors.toList())
                        + "", source.layout:""
                        + source.layout
                );
            }
            return new PhysicalOperation(
                new OutputOperatorFactory(Expressions.names(outputExec.output()), outputExec.getPageConsumer()),
                source.layout,
                source
            );
        } else if (node instanceof ExchangeExec exchangeExec) {
            DriverParallelism parallelism = exchangeExec.getType() == ExchangeExec.Type.GATHER
                ? DriverParallelism.SINGLE
                : new DriverParallelism(DriverParallelism.Type.TASK_LEVEL_PARALLELISM, taskConcurrency);
            context.driverParallelism(parallelism);
            Exchange ex = new Exchange(parallelism.instanceCount(), exchangeExec.getPartitioning().toExchange(), bufferMaxPages);

            LocalExecutionPlanContext subContext = context.createSubContext();
            PhysicalOperation source = plan(exchangeExec.child(), subContext);
            Map<Object, Integer> layout = source.layout;
            PhysicalOperation physicalOperation = new PhysicalOperation(new ExchangeSinkOperatorFactory(ex), source.layout, source);
            context.addDriverFactory(new DriverFactory(new DriverSupplier(physicalOperation), subContext.driverParallelism()));
            return new PhysicalOperation(new ExchangeSourceOperatorFactory(ex), layout);
        } else if (node instanceof TopNExec topNExec) {
            PhysicalOperation source = plan(topNExec.child(), context);
            if (topNExec.order().size() != 1) {
                throw new UnsupportedOperationException();
            }
            Order order = topNExec.order().get(0);
            int sortByChannel;
            if (order.child()instanceof Attribute a) {
                sortByChannel = source.layout.get(a.id());
            } else {
                throw new UnsupportedOperationException();
            }
            int limit;
            if (topNExec.getLimit()instanceof Literal literal) {
                limit = Integer.parseInt(literal.value().toString());
            } else {
                throw new UnsupportedOperationException();
            }

            return new PhysicalOperation(
                new TopNOperatorFactory(sortByChannel, order.direction() == Order.OrderDirection.ASC, limit),
                source.layout,
                source
            );
        } else if (node instanceof EvalExec eval) {
            PhysicalOperation source = plan(eval.child(), context);
            if (eval.fields().size() != 1) {
                throw new UnsupportedOperationException();
            }
            NamedExpression namedExpression = eval.fields().get(0);
            ExpressionEvaluator evaluator;
            if (namedExpression instanceof Alias alias) {
                evaluator = toEvaluator(alias.child(), source.layout);
            } else {
                throw new UnsupportedOperationException();
            }
            Map<Object, Integer> layout = new HashMap<>();
            layout.putAll(source.layout);
            layout.put(namedExpression.toAttribute().id(), layout.size());
            return new PhysicalOperation(
                new EvalOperatorFactory(evaluator, namedExpression.dataType().isRational() ? Double.TYPE : Long.TYPE),
                layout,
                source
            );
        } else if (node instanceof RowExec row) {
            List<Object> obj = row.fields().stream().map(f -> {
                if (f instanceof Alias) {
                    return ((Alias) f).child().fold();
                } else {
                    return f.fold();
                }
            }).toList();
            Map<Object, Integer> layout = new HashMap<>();
            var output = row.output();
            for (int i = 0; i < output.size(); i++) {
                layout.put(output.get(i).id(), i);
            }
            return new PhysicalOperation(new RowOperatorFactory(obj), layout);
        } else if (node instanceof ProjectExec project) {
            var source = plan(project.child(), context);
            Map<Object, Integer> layout = new HashMap<>();
            var output = project.output();

            var outputSet = project.outputSet();
            var input = project.child().output();
            var mask = new BitSet(input.size());
            int layoutPos = 0;
            for (int i = 0; i < input.size(); i++) {
                var element = input.get(i);
                var id = element.id();
                var maskPosition = source.layout.get(id);
                var keepColumn = outputSet.contains(element);
                mask.set(maskPosition, keepColumn);
                if (keepColumn) {
                    layout.put(id, layoutPos++);
                }
            }
            return new PhysicalOperation(new ProjectOperatorFactory(mask), layout, source);
        } else if (node instanceof FilterExec filter) {
            PhysicalOperation source = plan(filter.child(), context);
            return new PhysicalOperation(new FilterOperatorFactory(toEvaluator(filter.condition(), source.layout)), source.layout, source);
        }
        throw new UnsupportedOperationException(node.nodeName());
    }","public PhysicalOperation plan(PhysicalPlan node, LocalExecutionPlanContext context) {
        if (node instanceof AggregateExec aggregate) {
            PhysicalOperation source = plan(aggregate.child(), context);
            Map<Object, Integer> layout = new HashMap<>();
            OperatorFactory operatorFactory = null;

            if (aggregate.groupings().isEmpty()) {
                // not grouping
                for (NamedExpression e : aggregate.aggregates()) {
                    if (e instanceof Alias alias && alias.child()instanceof AggregateFunction aggregateFunction) {
                        AggregatorFunctionFactory aggregatorFunc;
                        if (aggregateFunction instanceof Avg avg) {
                            aggregatorFunc = avg.dataType().isRational() ? AggregatorFunction.doubleAvg : AggregatorFunction.longAvg;
                        } else if (aggregateFunction instanceof Count) {
                            aggregatorFunc = AggregatorFunction.count;
                        } else {
                            throw new UnsupportedOperationException(""unsupported aggregate function:"" + aggregateFunction);
                        }

                        if (aggregate.getMode() == AggregateExec.Mode.PARTIAL) {
                            operatorFactory = new AggregationOperatorFactory(
                                List.of(
                                    new AggregatorFactory(
                                        aggregatorFunc,
                                        AggregatorMode.INITIAL,
                                        source.layout.get(Expressions.attribute(aggregateFunction.field()).id())
                                    )
                                ),
                                AggregatorMode.INITIAL
                            );
                            layout.put(alias.id(), 0);
                        } else if (aggregate.getMode() == AggregateExec.Mode.FINAL) {
                            operatorFactory = new AggregationOperatorFactory(
                                List.of(new AggregatorFactory(aggregatorFunc, AggregatorMode.FINAL, source.layout.get(alias.id()))),
                                AggregatorMode.FINAL
                            );
                            layout.put(alias.id(), 0);
                        } else {
                            throw new UnsupportedOperationException();
                        }
                    } else {
                        throw new UnsupportedOperationException();
                    }
                }
            } else {
                // grouping
                AttributeSet groups = Expressions.references(aggregate.groupings());
                if (groups.size() != 1) {
                    throw new UnsupportedOperationException(""just one group, for now"");
                }
                Attribute grpAttrib = groups.iterator().next();
                layout.put(grpAttrib.id(), 0);

                for (NamedExpression e : aggregate.aggregates()) {
                    if (e instanceof Alias alias && alias.child()instanceof AggregateFunction aggregateFunction) {
                        GroupingAggregatorFunctionFactory aggregatorFunc;
                        if (aggregateFunction instanceof Avg) {
                            aggregatorFunc = GroupingAggregatorFunction.avg;
                        } else if (aggregateFunction instanceof Count) {
                            aggregatorFunc = GroupingAggregatorFunction.count;
                        } else {
                            throw new UnsupportedOperationException(""unsupported aggregate function:"" + aggregateFunction);
                        }

                        final Supplier<BlockHash> blockHash;
                        if (grpAttrib.dataType() == DataTypes.KEYWORD) {
                            blockHash = () -> BlockHash.newBytesRefHash(BigArrays.NON_RECYCLING_INSTANCE);
                        } else {
                            blockHash = () -> BlockHash.newLongHash(BigArrays.NON_RECYCLING_INSTANCE);
                        }
                        if (aggregate.getMode() == AggregateExec.Mode.PARTIAL) {
                            operatorFactory = new HashAggregationOperatorFactory(
                                source.layout.get(grpAttrib.id()),
                                List.of(
                                    new GroupingAggregatorFactory(
                                        aggregatorFunc,
                                        AggregatorMode.INITIAL,
                                        source.layout.get(Expressions.attribute(aggregateFunction.field()).id())
                                    )
                                ),
                                blockHash,
                                AggregatorMode.INITIAL
                            );
                            layout.put(alias.id(), 1);  // <<<< TODO: this one looks suspicious
                        } else if (aggregate.getMode() == AggregateExec.Mode.FINAL) {
                            operatorFactory = new HashAggregationOperatorFactory(
                                source.layout.get(grpAttrib.id()),
                                List.of(new GroupingAggregatorFactory(aggregatorFunc, AggregatorMode.FINAL, source.layout.get(alias.id()))),
                                blockHash,
                                AggregatorMode.FINAL
                            );
                            layout.put(alias.id(), 1);
                        } else {
                            throw new UnsupportedOperationException();
                        }
                    } else {
                        throw new UnsupportedOperationException();
                    }
                }

            }
            if (operatorFactory != null) {
                return new PhysicalOperation(operatorFactory, layout, source);
            }
            throw new UnsupportedOperationException();
        } else if (node instanceof EsQueryExec esQuery) {
            return planEsQueryNode(esQuery, context);
        } else if (node instanceof FieldExtractExec fieldExtractExec) {
            return planFieldExtractNode(context, fieldExtractExec);
        } else if (node instanceof OutputExec outputExec) {
            PhysicalOperation source = plan(outputExec.child(), context);
            var output = outputExec.output();
            if (output.size() != source.layout.size()) {
                throw new IllegalStateException(
                    ""expected layout:""
                        + output
                        + "": ""
                        + output.stream().map(NamedExpression::id).collect(Collectors.toList())
                        + "", source.layout:""
                        + source.layout
                );
            }
            // align the page layout with the operator output
            // extraction order - the list ordinal is the same as the column one
            // while the value represents the position in the original page
            final int[] mappedPosition = new int[output.size()];
            int index = -1;
            boolean transformRequired = false;
            for (var attribute : output) {
                mappedPosition[++index] = source.layout.get(attribute.id());
                if (transformRequired == false) {
                    transformRequired = mappedPosition[index] != index;
                }
            }
            Function<Page, Page> mapper = transformRequired ? p -> {
                var blocks = new Block[p.getBlockCount()];
                for (int i = 0; i < blocks.length; i++) {
                    blocks[i] = p.getBlock(mappedPosition[i]);
                }
                return new Page(blocks);
            } : Function.identity();

            return new PhysicalOperation(
                new OutputOperatorFactory(Expressions.names(outputExec.output()), mapper, outputExec.getPageConsumer()),
                source.layout,
                source
            );
        } else if (node instanceof ExchangeExec exchangeExec) {
            DriverParallelism parallelism = exchangeExec.getType() == ExchangeExec.Type.GATHER
                ? DriverParallelism.SINGLE
                : new DriverParallelism(DriverParallelism.Type.TASK_LEVEL_PARALLELISM, taskConcurrency);
            context.driverParallelism(parallelism);
            Exchange ex = new Exchange(parallelism.instanceCount(), exchangeExec.getPartitioning().toExchange(), bufferMaxPages);

            LocalExecutionPlanContext subContext = context.createSubContext();
            PhysicalOperation source = plan(exchangeExec.child(), subContext);
            Map<Object, Integer> layout = source.layout;
            PhysicalOperation physicalOperation = new PhysicalOperation(new ExchangeSinkOperatorFactory(ex), source.layout, source);
            context.addDriverFactory(new DriverFactory(new DriverSupplier(physicalOperation), subContext.driverParallelism()));
            return new PhysicalOperation(new ExchangeSourceOperatorFactory(ex), layout);
        } else if (node instanceof TopNExec topNExec) {
            PhysicalOperation source = plan(topNExec.child(), context);
            if (topNExec.order().size() != 1) {
                throw new UnsupportedOperationException();
            }
            Order order = topNExec.order().get(0);
            int sortByChannel;
            if (order.child()instanceof Attribute a) {
                sortByChannel = source.layout.get(a.id());
            } else {
                throw new UnsupportedOperationException();
            }
            int limit;
            if (topNExec.getLimit()instanceof Literal literal) {
                limit = Integer.parseInt(literal.value().toString());
            } else {
                throw new UnsupportedOperationException();
            }

            return new PhysicalOperation(
                new TopNOperatorFactory(sortByChannel, order.direction() == Order.OrderDirection.ASC, limit),
                source.layout,
                source
            );
        } else if (node instanceof EvalExec eval) {
            PhysicalOperation source = plan(eval.child(), context);
            if (eval.fields().size() != 1) {
                throw new UnsupportedOperationException();
            }
            NamedExpression namedExpression = eval.fields().get(0);
            ExpressionEvaluator evaluator;
            if (namedExpression instanceof Alias alias) {
                evaluator = toEvaluator(alias.child(), source.layout);
            } else {
                throw new UnsupportedOperationException();
            }
            Map<Object, Integer> layout = new HashMap<>();
            layout.putAll(source.layout);
            layout.put(namedExpression.toAttribute().id(), layout.size());
            return new PhysicalOperation(
                new EvalOperatorFactory(evaluator, namedExpression.dataType().isRational() ? Double.TYPE : Long.TYPE),
                layout,
                source
            );
        } else if (node instanceof RowExec row) {
            List<Object> obj = row.fields().stream().map(f -> {
                if (f instanceof Alias) {
                    return ((Alias) f).child().fold();
                } else {
                    return f.fold();
                }
            }).toList();
            Map<Object, Integer> layout = new HashMap<>();
            var output = row.output();
            for (int i = 0; i < output.size(); i++) {
                layout.put(output.get(i).id(), i);
            }
            return new PhysicalOperation(new RowOperatorFactory(obj), layout);
        } else if (node instanceof ProjectExec project) {
            var source = plan(project.child(), context);
            Map<Object, Integer> layout = new HashMap<>();

            var outputSet = project.outputSet();
            var input = project.child().output();
            var mask = new BitSet(input.size());
            int layoutPos = 0;
            for (Attribute element : input) {
                var id = element.id();
                var maskPosition = source.layout.get(id);
                var keepColumn = outputSet.contains(element);
                mask.set(maskPosition, keepColumn);
                if (keepColumn) {
                    layout.put(id, layoutPos++);
                }
            }
            return new PhysicalOperation(new ProjectOperatorFactory(mask), layout, source);
        } else if (node instanceof FilterExec filter) {
            PhysicalOperation source = plan(filter.child(), context);
            return new PhysicalOperation(new FilterOperatorFactory(toEvaluator(filter.condition(), source.layout)), source.layout, source);
        }
        throw new UnsupportedOperationException(node.nodeName());
    }",/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/planner/LocalExecutionPlanner.java
6fac5a45e342c01ccc2737f328c65405517de7ac,662,93,"public Releasable forceRefreshes() {
        synchronized (this) {
            assert refreshForcers >= 0;
            refreshForcers += 1;
        }
        final RunOnce runOnce = new RunOnce(() -> {
            synchronized (RefreshListeners.this) {
                assert refreshForcers > 0;
                refreshForcers -= 1;
            }
        });
        if (refreshNeeded()) {
            try {
                forceRefresh.run();
            } catch (Exception e) {
                runOnce.run();
                throw e;
            }
        }
        assert refreshListeners == null;
        return () -> runOnce.run();
    }","public Releasable forceRefreshes() {
        synchronized (this) {
            assert refreshForcers >= 0;
            refreshForcers += 1;
        }
        final Releasable releaseOnce = Releasables.releaseOnce(() -> {
            synchronized (RefreshListeners.this) {
                assert refreshForcers > 0;
                refreshForcers -= 1;
            }
        });
        if (refreshNeeded()) {
            try {
                forceRefresh.run();
            } catch (Exception e) {
                releaseOnce.close();
                throw e;
            }
        }
        assert refreshListeners == null;
        return releaseOnce;
    }",/server/src/main/java/org/elasticsearch/index/shard/RefreshListeners.java
6fac5a45e342c01ccc2737f328c65405517de7ac,662,136,"private Releasable acquireAll(final long timeout, final TimeUnit timeUnit) throws InterruptedException, TimeoutException {
        if (Assertions.ENABLED) {
            // since delayed is not volatile, we have to synchronize even here for visibility
            synchronized (this) {
                assert queuedBlockOperations > 0;
            }
        }
        if (semaphore.tryAcquire(TOTAL_PERMITS, timeout, timeUnit)) {
            final RunOnce release = new RunOnce(() -> {
                assert semaphore.availablePermits() == 0;
                semaphore.release(TOTAL_PERMITS);
            });
            return release::run;
        } else {
            throw new TimeoutException(""timeout while blocking operations"");
        }
    }","private Releasable acquireAll(final long timeout, final TimeUnit timeUnit) throws InterruptedException, TimeoutException {
        if (Assertions.ENABLED) {
            // since delayed is not volatile, we have to synchronize even here for visibility
            synchronized (this) {
                assert queuedBlockOperations > 0;
            }
        }
        if (semaphore.tryAcquire(TOTAL_PERMITS, timeout, timeUnit)) {
            final Releasable release = Releasables.releaseOnce(() -> {
                assert semaphore.availablePermits() == 0;
                semaphore.release(TOTAL_PERMITS);
            });
            return release;
        } else {
            throw new TimeoutException(""timeout while blocking operations"");
        }
    }",/server/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java
6fac5a45e342c01ccc2737f328c65405517de7ac,391,144,"private Releasable interceptVerifyShardBeforeCloseActions(final String indexPattern, final Runnable onIntercept) {
        final MockTransportService mockTransportService = (MockTransportService) internalCluster()
            .getInstance(TransportService.class, internalCluster().getMasterName());

        final CountDownLatch release = new CountDownLatch(1);
        for (DiscoveryNode node : internalCluster().clusterService().state().getNodes()) {
            mockTransportService.addSendBehavior(internalCluster().getInstance(TransportService.class, node.getName()),
                (connection, requestId, action, request, options) -> {
                    if (action.startsWith(TransportVerifyShardBeforeCloseAction.NAME)) {
                        if (request instanceof TransportVerifyShardBeforeCloseAction.ShardRequest) {
                            final String index = ((TransportVerifyShardBeforeCloseAction.ShardRequest) request).shardId().getIndexName();
                            if (Glob.globMatch(indexPattern, index)) {
                                logger.info(""request {} intercepted for index {}"", requestId, index);
                                onIntercept.run();
                                try {
                                    release.await();
                                    logger.info(""request {} released for index {}"", requestId, index);
                                } catch (final InterruptedException e) {
                                    throw new AssertionError(e);
                                }
                            }
                        }

                    }
                    connection.sendRequest(requestId, action, request, options);
                });
        }
        final RunOnce releaseOnce = new RunOnce(release::countDown);
        return releaseOnce::run;
    }","private Releasable interceptVerifyShardBeforeCloseActions(final String indexPattern, final Runnable onIntercept) {
        final MockTransportService mockTransportService = (MockTransportService) internalCluster()
            .getInstance(TransportService.class, internalCluster().getMasterName());

        final CountDownLatch release = new CountDownLatch(1);
        for (DiscoveryNode node : internalCluster().clusterService().state().getNodes()) {
            mockTransportService.addSendBehavior(internalCluster().getInstance(TransportService.class, node.getName()),
                (connection, requestId, action, request, options) -> {
                    if (action.startsWith(TransportVerifyShardBeforeCloseAction.NAME)) {
                        if (request instanceof TransportVerifyShardBeforeCloseAction.ShardRequest) {
                            final String index = ((TransportVerifyShardBeforeCloseAction.ShardRequest) request).shardId().getIndexName();
                            if (Glob.globMatch(indexPattern, index)) {
                                logger.info(""request {} intercepted for index {}"", requestId, index);
                                onIntercept.run();
                                try {
                                    release.await();
                                    logger.info(""request {} released for index {}"", requestId, index);
                                } catch (final InterruptedException e) {
                                    throw new AssertionError(e);
                                }
                            }
                        }

                    }
                    connection.sendRequest(requestId, action, request, options);
                });
        }
        return Releasables.releaseOnce(release::countDown);
    }",/server/src/internalClusterTest/java/org/elasticsearch/indices/state/ReopenWhileClosingIT.java
217ba2cc7e147796cc1a6f4f688a8a22308a4df0,563,285,"public void testRestoreWithPersistedFileSettings() throws Exception {
        createRepository(""test-repo"", ""fs"");

        logger.info(""--> set some persistent cluster settings"");
        assertAcked(
            clusterAdmin().prepareUpdateSettings()
                .setPersistentSettings(
                    Settings.builder()
                        .put(InternalClusterInfoService.INTERNAL_CLUSTER_INFO_TIMEOUT_SETTING.getKey(), TimeValue.timeValueSeconds(25))
                        .build()
                )
        );

        ensureGreen();

        String masterNode = internalCluster().getMasterName();

        var savedClusterState = setupClusterStateListener(masterNode);
        FileSettingsService fs = internalCluster().getInstance(FileSettingsService.class, masterNode);

        logger.info(""--> write some file based settings, putting some reserved state"");
        writeJSONFile(masterNode, testFileSettingsJSON);
        final ClusterStateResponse savedStateResponse = assertClusterStateSaveOK(savedClusterState.v1(), savedClusterState.v2());
        assertThat(
            savedStateResponse.getState().metadata().persistentSettings().get(INDICES_RECOVERY_MAX_BYTES_PER_SEC_SETTING.getKey()),
            equalTo(""50mb"")
        );

        logger.info(""--> create full snapshot"");
        createFullSnapshot(""test-repo"", ""test-snap"");
        assertThat(getSnapshot(""test-repo"", ""test-snap"").state(), equalTo(SnapshotState.SUCCESS));

        assertAcked(
            clusterAdmin().prepareUpdateSettings()
                .setPersistentSettings(
                    Settings.builder()
                        .put(InternalClusterInfoService.INTERNAL_CLUSTER_INFO_TIMEOUT_SETTING.getKey(), TimeValue.timeValueSeconds(55))
                        .build()
                )
        );

        logger.info(""--> restore global state from the snapshot"");
        var removedReservedState = removedReservedClusterStateListener(masterNode);

        clusterAdmin().prepareRestoreSnapshot(""test-repo"", ""test-snap"").setRestoreGlobalState(true).setWaitForCompletion(true).get();

        ensureGreen();

        // When the target cluster of a restore has an existing operator file, we don't un-reserve the reserved
        // cluster state for file based settings, but instead we reset the version to 0 and 'touch' the operator file
        // so that it gets re-processed.
        logger.info(""--> reserved state version will be reset to 0, because of snapshot restore"");
        // double timeout, we restore snapshot then apply the file
        assertTrue(removedReservedState.v1().await(40, TimeUnit.SECONDS));

        logger.info(""--> reserved state would be restored to non-zero version"");

        final ClusterStateResponse clusterStateResponse = clusterAdmin().state(
            new ClusterStateRequest().metadata(true).waitForMetadataVersion(removedReservedState.v2().get())
        ).actionGet();

        assertNotNull(clusterStateResponse.getState().metadata().reservedStateMetadata().get(FileSettingsService.NAMESPACE));

        final ClusterGetSettingsAction.Response getSettingsResponse = clusterAdmin().execute(
            ClusterGetSettingsAction.INSTANCE,
            new ClusterGetSettingsAction.Request()
        ).actionGet();

        assertThat(
            getSettingsResponse.persistentSettings().get(InternalClusterInfoService.INTERNAL_CLUSTER_INFO_TIMEOUT_SETTING.getKey()),
            equalTo(""25s"")
        );

        // we need to remove the reserved state, so that clean-up can happen
        var cleanupReservedState = cleanedClusterStateListener(masterNode);

        logger.info(""--> clear the file based settings"");
        writeJSONFile(masterNode, emptyFileSettingsJSON);
        assertClusterStateSaveOK(cleanupReservedState.v1(), cleanupReservedState.v2());
        // cleanup
        assertAcked(
            clusterAdmin().prepareUpdateSettings()
                .setPersistentSettings(
                    Settings.builder()
                        .put(InternalClusterInfoService.INTERNAL_CLUSTER_INFO_TIMEOUT_SETTING.getKey(), (String) null)
                        .put(""indices.recovery.max_bytes_per_sec"", (String) null)
                        .build()
                )
        );
    }","public void testRestoreWithPersistedFileSettings() throws Exception {
        createRepository(""test-repo"", ""fs"");

        logger.info(""--> set some persistent cluster settings"");
        assertAcked(
            clusterAdmin().prepareUpdateSettings()
                .setPersistentSettings(
                    Settings.builder()
                        .put(InternalClusterInfoService.INTERNAL_CLUSTER_INFO_TIMEOUT_SETTING.getKey(), TimeValue.timeValueSeconds(25))
                        .build()
                )
        );

        ensureGreen();

        String masterNode = internalCluster().getMasterName();

        var savedClusterState = setupClusterStateListener(masterNode);

        logger.info(""--> write some file based settings, putting some reserved state"");
        writeJSONFile(masterNode, testFileSettingsJSON);
        final ClusterStateResponse savedStateResponse = assertClusterStateSaveOK(savedClusterState.v1(), savedClusterState.v2());
        assertThat(
            savedStateResponse.getState().metadata().persistentSettings().get(INDICES_RECOVERY_MAX_BYTES_PER_SEC_SETTING.getKey()),
            equalTo(""50mb"")
        );

        logger.info(""--> create full snapshot"");
        createFullSnapshot(""test-repo"", ""test-snap"");
        assertThat(getSnapshot(""test-repo"", ""test-snap"").state(), equalTo(SnapshotState.SUCCESS));

        assertAcked(
            clusterAdmin().prepareUpdateSettings()
                .setPersistentSettings(
                    Settings.builder()
                        .put(InternalClusterInfoService.INTERNAL_CLUSTER_INFO_TIMEOUT_SETTING.getKey(), TimeValue.timeValueSeconds(55))
                        .build()
                )
        );

        logger.info(""--> restore global state from the snapshot"");
        var removedReservedState = removedReservedClusterStateListener(masterNode);

        clusterAdmin().prepareRestoreSnapshot(""test-repo"", ""test-snap"").setRestoreGlobalState(true).setWaitForCompletion(true).get();

        ensureGreen();

        // When the target cluster of a restore has an existing operator file, we don't un-reserve the reserved
        // cluster state for file based settings, but instead we reset the version to 0 and 'touch' the operator file
        // so that it gets re-processed.
        logger.info(""--> reserved state version will be reset to 0, because of snapshot restore"");
        // double timeout, we restore snapshot then apply the file
        assertTrue(removedReservedState.v1().await(40, TimeUnit.SECONDS));

        logger.info(""--> reserved state would be restored to non-zero version"");

        final ClusterStateResponse clusterStateResponse = clusterAdmin().state(
            new ClusterStateRequest().metadata(true).waitForMetadataVersion(removedReservedState.v2().get())
        ).actionGet();

        assertNotNull(clusterStateResponse.getState().metadata().reservedStateMetadata().get(FileSettingsService.NAMESPACE));

        final ClusterGetSettingsAction.Response getSettingsResponse = clusterAdmin().execute(
            ClusterGetSettingsAction.INSTANCE,
            new ClusterGetSettingsAction.Request()
        ).actionGet();

        assertThat(
            getSettingsResponse.persistentSettings().get(InternalClusterInfoService.INTERNAL_CLUSTER_INFO_TIMEOUT_SETTING.getKey()),
            equalTo(""25s"")
        );

        // we need to remove the reserved state, so that clean-up can happen
        var cleanupReservedState = cleanedClusterStateListener(masterNode);

        logger.info(""--> clear the file based settings"");
        writeJSONFile(masterNode, emptyFileSettingsJSON);
        assertClusterStateSaveOK(cleanupReservedState.v1(), cleanupReservedState.v2());
        // cleanup
        assertAcked(
            clusterAdmin().prepareUpdateSettings()
                .setPersistentSettings(
                    Settings.builder()
                        .put(InternalClusterInfoService.INTERNAL_CLUSTER_INFO_TIMEOUT_SETTING.getKey(), (String) null)
                        .put(""indices.recovery.max_bytes_per_sec"", (String) null)
                        .build()
                )
        );
    }",/server/src/internalClusterTest/java/org/elasticsearch/reservedstate/service/SnapshotsAndFileSettingsIT.java
ac94253dce99f12742085e02ed891dc397ba2272,662,219,"public void acquire(final ActionListener<Releasable> onAcquired, final String executorOnDelay, final boolean forceExecution) {
        if (closed) {
            onAcquired.onFailure(new IndexShardClosedException(shardId));
            return;
        }
        final Releasable releasable;
        try {
            synchronized (this) {
                if (delayed) {
                    final Supplier<StoredContext> contextSupplier = threadPool.getThreadContext().newRestorableContext(false);
                    if (executorOnDelay != null) {
                        delayedOperations.add(
                                new ThreadedActionListener<>(logger, threadPool, executorOnDelay,
                                        new ContextPreservingActionListener<>(contextSupplier, onAcquired), forceExecution));
                    } else {
                        delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired));
                    }
                    return;
                } else {
                    releasable = tryAcquire();
                    assert releasable != null;
                }
            }
        } catch (final InterruptedException e) {
            onAcquired.onFailure(e);
            return;
        }
        // execute this outside the synchronized block!
        onAcquired.onResponse(releasable);
    }","public void acquire(final ActionListener<Releasable> onAcquired, final String executorOnDelay, final boolean forceExecution) {
        if (closed) {
            onAcquired.onFailure(new IndexShardClosedException(shardId));
            return;
        }
        final Releasable releasable;
        try {
            synchronized (this) {
                if (delayed) {
                    final Supplier<StoredContext> contextSupplier = threadPool.getThreadContext().newRestorableContext(false);
                    if (executorOnDelay != null) {
                        delayedOperations.add(
                                new ThreadedActionListener<>(logger, threadPool, executorOnDelay,
                                        new ContextPreservingActionListener<>(contextSupplier, onAcquired), forceExecution));
                    } else {
                        delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired));
                    }
                    return;
                } else {
                    releasable = acquire();
                }
            }
        } catch (final InterruptedException e) {
            onAcquired.onFailure(e);
            return;
        }
        // execute this outside the synchronized block!
        onAcquired.onResponse(releasable);
    }",/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java
03241037373a727444cd7fda2ab23825a6eb84d6,486,612,"public static Class<?> TypeToClass(Type type) {
        if (def.class.getSimpleName().equals(type.struct.name)) {
            return ObjectClassTodefClass(type.clazz);
        }

        return type.clazz;
    }","public Type ClassToType(Class<?> clazz) {
        if (clazz == null) {
            return null;
        } else if (clazz.isArray()) {
            Class<?> component = clazz.getComponentType();
            int dimensions = 1;

            while (component.isArray()) {
                component = component.getComponentType();
                ++dimensions;
            }

            if (component == def.class) {
                return getType(structsMap.get(def.class.getSimpleName()), dimensions);
            } else {
                return getType(structsMap.get(ClassToName(component)), dimensions);
            }
        } else if (clazz == def.class) {
            return getType(structsMap.get(def.class.getSimpleName()), 0);
        }

        return getType(structsMap.get(ClassToName(clazz)), 0);
    }",/modules/lang-painless/src/main/java/org/elasticsearch/painless/Definition.java
03241037373a727444cd7fda2ab23825a6eb84d6,628,1342,"private Type getTypeInternal(String name) {
        // simple types (e.g. 0 array dimensions) are a simple hash lookup for speed
        Type simple = simpleTypesMap.get(name);

        if (simple != null) {
            return simple;
        }

        int dimensions = getDimensions(name);
        String structstr = dimensions == 0 ? name : name.substring(0, name.indexOf('['));
        Struct struct = structsMap.get(structstr);

        if (struct == null) {
            throw new IllegalArgumentException(""The struct with name ["" + name + ""] has not been defined."");
        }

        return getTypeInternal(struct, dimensions);
    }","private Method computeFunctionalInterfaceMethod(Struct clazz) {
        if (!clazz.clazz.isInterface()) {
            return null;
        }
        // if its marked with this annotation, we fail if the conditions don't hold (means whitelist bug)
        // otherwise, this annotation is pretty useless.
        boolean hasAnnotation = clazz.clazz.isAnnotationPresent(FunctionalInterface.class);
        List<java.lang.reflect.Method> methods = new ArrayList<>();
        for (java.lang.reflect.Method m : clazz.clazz.getMethods()) {
            // default interface methods don't count
            if (m.isDefault()) {
                continue;
            }
            // static methods don't count
            if (Modifier.isStatic(m.getModifiers())) {
                continue;
            }
            // if its from Object, it doesn't count
            try {
                Object.class.getMethod(m.getName(), m.getParameterTypes());
                continue;
            } catch (ReflectiveOperationException e) {
                // it counts
            }
            methods.add(m);
        }
        if (methods.size() != 1) {
            if (hasAnnotation) {
                throw new IllegalArgumentException(""Class: "" + clazz.name +
                    "" is marked with FunctionalInterface but doesn't fit the bill: "" + methods);
            }
            return null;
        }
        // inspect the one method found from the reflection API, it should match the whitelist!
        java.lang.reflect.Method oneMethod = methods.get(0);
        Method painless = clazz.methods.get(new Definition.MethodKey(oneMethod.getName(), oneMethod.getParameterCount()));
        if (painless == null || painless.method.equals(org.objectweb.asm.commons.Method.getMethod(oneMethod)) == false) {
            throw new IllegalArgumentException(""Class: "" + clazz.name + "" is functional but the functional "" +
                ""method is not whitelisted!"");
        }
        return painless;
    }",/modules/lang-painless/src/main/java/org/elasticsearch/painless/Definition.java
03241037373a727444cd7fda2ab23825a6eb84d6,690,348,"throws Throwable {
         final FunctionRef ref;
         if (""this"".equals(type)) {
             // user written method
             Method interfaceMethod = clazz.struct.functionalMethod;
             if (interfaceMethod == null) {
                 throw new IllegalArgumentException(""Cannot convert function reference ["" + type + ""::"" + call + ""] "" +
                                                    ""to ["" + clazz.name + ""], not a functional interface"");
             }
             int arity = interfaceMethod.arguments.size() + captures.length;
             final MethodHandle handle;
             try {
                 MethodHandle accessor = lookup.findStaticGetter(lookup.lookupClass(),
                                                                 getUserFunctionHandleFieldName(call, arity),
                                                                 MethodHandle.class);
                 handle = (MethodHandle)accessor.invokeExact();
             } catch (NoSuchFieldException | IllegalAccessException e) {
                 // is it a synthetic method? If we generated the method ourselves, be more helpful. It can only fail
                 // because the arity does not match the expected interface type.
                 if (call.contains(""$"")) {
                     throw new IllegalArgumentException(""Incorrect number of parameters for ["" + interfaceMethod.name +
                                                        ""] in ["" + clazz.clazz + ""]"");
                 }
                 throw new IllegalArgumentException(""Unknown call ["" + call + ""] with ["" + arity + ""] arguments."");
             }
             ref = new FunctionRef(clazz.clazz, interfaceMethod, call, handle.type(), captures.length);
         } else {
             // whitelist lookup
             ref = new FunctionRef(definition, clazz.clazz, type, call, captures.length);
         }
         final CallSite callSite = LambdaBootstrap.lambdaBootstrap(
             lookup,
             ref.interfaceMethodName,
             ref.factoryMethodType,
             ref.interfaceMethodType,
             ref.delegateClassName,
             ref.delegateInvokeType,
             ref.delegateMethodName,
             ref.delegateMethodType
         );
         return callSite.dynamicInvoker().asType(MethodType.methodType(clazz.clazz, captures));
     }","throws Throwable {
         final FunctionRef ref;
         if (""this"".equals(type)) {
             // user written method
             Method interfaceMethod = clazz.struct.functionalMethod;
             if (interfaceMethod == null) {
                 throw new IllegalArgumentException(""Cannot convert function reference ["" + type + ""::"" + call + ""] "" +
                                                    ""to ["" + clazz.name + ""], not a functional interface"");
             }
             int arity = interfaceMethod.arguments.size() + captures.length;
             final MethodHandle handle;
             try {
                 MethodHandle accessor = lookup.findStaticGetter(lookup.lookupClass(),
                                                                 getUserFunctionHandleFieldName(call, arity),
                                                                 MethodHandle.class);
                 handle = (MethodHandle)accessor.invokeExact();
             } catch (NoSuchFieldException | IllegalAccessException e) {
                 // is it a synthetic method? If we generated the method ourselves, be more helpful. It can only fail
                 // because the arity does not match the expected interface type.
                 if (call.contains(""$"")) {
                     throw new IllegalArgumentException(""Incorrect number of parameters for ["" + interfaceMethod.name +
                                                        ""] in ["" + clazz.clazz + ""]"");
                 }
                 throw new IllegalArgumentException(""Unknown call ["" + call + ""] with ["" + arity + ""] arguments."");
             }
             ref = new FunctionRef(clazz.clazz, interfaceMethod, call, handle.type(), captures.length);
         } else {
             // whitelist lookup
             ref = new FunctionRef(definition, clazz.clazz, type, call, captures.length);
         }
         final CallSite callSite = LambdaBootstrap.lambdaBootstrap(
             lookup,
             ref.interfaceMethodName,
             ref.factoryMethodType,
             ref.interfaceMethodType,
             ref.delegateClassName,
             ref.delegateInvokeType,
             ref.delegateMethodName,
             ref.delegateMethodType,
             ref.isDelegateInterface ? 1 : 0
         );
         return callSite.dynamicInvoker().asType(MethodType.methodType(clazz.clazz, captures));
     }",/modules/lang-painless/src/main/java/org/elasticsearch/painless/Def.java
758e5aaf13d6c350d020fb2e5d32343ef1782a0b,570,321,"public void testAllIsNotAllowedInShardLevelRequests() {
        ShardSearchRequest request = mock(ShardSearchRequest.class);
        if (randomBoolean()) {
            when(request.indices()).thenReturn(new String[]{""_all""});
        } else {
            if (randomBoolean()) {
                when(request.indices()).thenReturn(Strings.EMPTY_ARRAY);
            } else {
                when(request.indices()).thenReturn(null);
            }
        }
        IllegalStateException illegalStateException = expectThrows(IllegalStateException.class,
                () -> resolveIndices(request, buildAuthorizedIndices(userDashIndices, SearchAction.NAME))
                        .getLocal());
        assertEquals(""There are no external requests known to support wildcards that don't support replacing their indices"",
                illegalStateException.getMessage());
    }","public void testWildcardsAreNotAllowedInShardLevelRequests() {
        ShardSearchRequest request = mock(ShardSearchRequest.class);
        when(request.indices()).thenReturn(new String[]{""index*""});
        IllegalArgumentException exception = expectThrows(
            IllegalArgumentException.class,
            () -> resolveIndices(SearchAction.NAME + ""[s]"", request, buildAuthorizedIndices(userDashIndices, SearchAction.NAME)).getLocal()
        );
        assertThat(
            exception,
            throwableWithMessage(
                ""the action indices:data/read/search[s] does not support wildcards;""
                    + "" the provided index expression(s) [index*] are not allowed""
            )
        );
    }",/x-pack/plugin/security/src/test/java/org/elasticsearch/xpack/security/authz/IndicesAndAliasesResolverTests.java
31a79952e68fd8efc2fd7f5a7e6f77bc19a45a24,391,123,"public void testPreferCopyCanPerformNoopRecovery() throws Exception {
        String indexName = ""test"";
        String nodeWithPrimary = internalCluster().startNode();

        updateClusterSettings(
            Settings.builder().put(CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), EnableAllocationDecider.Rebalance.NONE)
        );

        assertAcked(
            indicesAdmin().prepareCreate(indexName)
                .setSettings(
                    indexSettings(1, 1).put(IndexSettings.FILE_BASED_RECOVERY_THRESHOLD_SETTING.getKey(), 1.0f)
                        .put(IndexService.RETENTION_LEASE_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(IndexService.GLOBAL_CHECKPOINT_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), ""1ms"")
                )
        );
        String nodeWithReplica = internalCluster().startDataOnlyNode();
        Settings nodeWithReplicaSettings = internalCluster().dataPathSettings(nodeWithReplica);
        ensureGreen(indexName);
        indexRandom(
            randomBoolean(),
            randomBoolean(),
            randomBoolean(),
            IntStream.range(0, between(100, 500)).mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v"")).toList()
        );
        indicesAdmin().prepareFlush(indexName).get();
        if (randomBoolean()) {
            indexRandom(
                randomBoolean(),
                false,
                randomBoolean(),
                IntStream.range(0, between(0, 80)).mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v"")).toList()
            );
        }
        ensureActivePeerRecoveryRetentionLeasesAdvanced(indexName);
        internalCluster().stopNode(nodeWithReplica);
        if (randomBoolean()) {
            indicesAdmin().prepareForceMerge(indexName).setFlush(true).get();
        }
        CountDownLatch blockRecovery = new CountDownLatch(1);
        CountDownLatch recoveryStarted = new CountDownLatch(1);
        MockTransportService transportServiceOnPrimary = (MockTransportService) internalCluster().getInstance(
            TransportService.class,
            nodeWithPrimary
        );
        transportServiceOnPrimary.addSendBehavior((connection, requestId, action, request, options) -> {
            if (PeerRecoveryTargetService.Actions.FILES_INFO.equals(action)) {
                recoveryStarted.countDown();
                try {
                    blockRecovery.await();
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                    throw new AssertionError(e);
                }
            }
            connection.sendRequest(requestId, action, request, options);
        });
        internalCluster().startDataOnlyNode();
        recoveryStarted.await();
        nodeWithReplica = internalCluster().startDataOnlyNode(nodeWithReplicaSettings);
        // AllocationService only calls GatewayAllocator if there are unassigned shards
        assertAcked(indicesAdmin().prepareCreate(""dummy-index"").setWaitForActiveShards(0));
        ensureGreen(indexName);
        assertThat(internalCluster().nodesInclude(indexName), containsInAnyOrder(nodeWithPrimary, nodeWithReplica));
        assertNoOpRecoveries(indexName);
        blockRecovery.countDown();
        transportServiceOnPrimary.clearAllRules();
    }","public void testPreferCopyCanPerformNoopRecovery() throws Exception {
        String indexName = ""test"";
        String nodeWithPrimary = internalCluster().startNode();

        updateClusterSettings(
            Settings.builder().put(CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), EnableAllocationDecider.Rebalance.NONE)
        );

        assertAcked(
            indicesAdmin().prepareCreate(indexName)
                .setSettings(
                    indexSettings(1, 1).put(IndexSettings.FILE_BASED_RECOVERY_THRESHOLD_SETTING.getKey(), 1.0f)
                        .put(IndexService.RETENTION_LEASE_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(IndexService.GLOBAL_CHECKPOINT_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), ""1ms"")
                )
        );
        String nodeWithReplica = internalCluster().startDataOnlyNode();
        Settings nodeWithReplicaSettings = internalCluster().dataPathSettings(nodeWithReplica);
        ensureGreen(indexName);
        indexRandom(
            randomBoolean(),
            randomBoolean(),
            randomBoolean(),
            IntStream.range(0, between(100, 500)).mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v"")).toList()
        );
        indicesAdmin().prepareFlush(indexName).get();
        if (randomBoolean()) {
            indexRandom(
                randomBoolean(),
                false,
                randomBoolean(),
                IntStream.range(0, between(0, 80)).mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v"")).toList()
            );
        }
        ensureActivePeerRecoveryRetentionLeasesAdvanced(indexName);
        internalCluster().stopNode(nodeWithReplica);
        if (randomBoolean()) {
            indicesAdmin().prepareForceMerge(indexName).setFlush(true).get();
        }
        CountDownLatch blockRecovery = new CountDownLatch(1);
        CountDownLatch recoveryStarted = new CountDownLatch(1);
        MockTransportService transportServiceOnPrimary = (MockTransportService) internalCluster().getInstance(
            TransportService.class,
            nodeWithPrimary
        );
        transportServiceOnPrimary.addSendBehavior((connection, requestId, action, request, options) -> {
            if (PeerRecoveryTargetService.Actions.FILES_INFO.equals(action)) {
                recoveryStarted.countDown();
                safeAwait(blockRecovery);
            }
            connection.sendRequest(requestId, action, request, options);
        });
        internalCluster().startDataOnlyNode();
        safeAwait(recoveryStarted);
        nodeWithReplica = internalCluster().startDataOnlyNode(nodeWithReplicaSettings);
        // AllocationService only calls GatewayAllocator if there are unassigned shards
        assertAcked(indicesAdmin().prepareCreate(""dummy-index"").setWaitForActiveShards(0));
        ensureGreen(indexName);
        assertThat(internalCluster().nodesInclude(indexName), containsInAnyOrder(nodeWithPrimary, nodeWithReplica));
        assertNoOpRecoveries(indexName);
        blockRecovery.countDown();
        transportServiceOnPrimary.clearAllRules();
    }",/server/src/internalClusterTest/java/org/elasticsearch/gateway/ReplicaShardAllocatorIT.java
31a79952e68fd8efc2fd7f5a7e6f77bc19a45a24,391,370,"public void testDoNotCancelRecoveryForBrokenNode() throws Exception {
        internalCluster().startMasterOnlyNode();
        String nodeWithPrimary = internalCluster().startDataOnlyNode();
        String indexName = ""test"";
        assertAcked(
            indicesAdmin().prepareCreate(indexName)
                .setSettings(
                    indexSettings(1, 0).put(IndexService.GLOBAL_CHECKPOINT_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(IndexService.RETENTION_LEASE_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                )
        );
        indexRandom(
            randomBoolean(),
            randomBoolean(),
            randomBoolean(),
            IntStream.range(0, between(200, 500)).mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v"")).toList()
        );
        indicesAdmin().prepareFlush(indexName).get();
        String brokenNode = internalCluster().startDataOnlyNode();
        MockTransportService transportService = (MockTransportService) internalCluster().getInstance(
            TransportService.class,
            nodeWithPrimary
        );
        CountDownLatch newNodeStarted = new CountDownLatch(1);
        transportService.addSendBehavior((connection, requestId, action, request, options) -> {
            if (action.equals(PeerRecoveryTargetService.Actions.TRANSLOG_OPS)) {
                if (brokenNode.equals(connection.getNode().getName())) {
                    try {
                        newNodeStarted.await();
                    } catch (InterruptedException e) {
                        throw new AssertionError(e);
                    }
                    throw new CircuitBreakingException(""not enough memory for indexing"", 100, 50, CircuitBreaker.Durability.TRANSIENT);
                }
            }
            connection.sendRequest(requestId, action, request, options);
        });
        setReplicaCount(1, indexName);
        internalCluster().startDataOnlyNode();
        newNodeStarted.countDown();

        var allocator = internalCluster().getInstance(ShardsAllocator.class);
        if (allocator instanceof BalancedShardsAllocator) {
            // BalancedShardsAllocator will try other node once retries are exhausted
            ensureGreen(indexName);
        } else if (allocator instanceof DesiredBalanceShardsAllocator) {
            // DesiredBalanceShardsAllocator will keep shard in the error state if it could not be allocated on the desired node
            ensureYellow(indexName);
        } else {
            fail(""Unknown allocator used"");
        }

        transportService.clearAllRules();
    }","public void testDoNotCancelRecoveryForBrokenNode() throws Exception {
        internalCluster().startMasterOnlyNode();
        String nodeWithPrimary = internalCluster().startDataOnlyNode();
        String indexName = ""test"";
        assertAcked(
            indicesAdmin().prepareCreate(indexName)
                .setSettings(
                    indexSettings(1, 0).put(IndexService.GLOBAL_CHECKPOINT_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(IndexService.RETENTION_LEASE_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                )
        );
        indexRandom(
            randomBoolean(),
            randomBoolean(),
            randomBoolean(),
            IntStream.range(0, between(200, 500)).mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v"")).toList()
        );
        indicesAdmin().prepareFlush(indexName).get();
        String brokenNode = internalCluster().startDataOnlyNode();
        MockTransportService transportService = (MockTransportService) internalCluster().getInstance(
            TransportService.class,
            nodeWithPrimary
        );
        CountDownLatch newNodeStarted = new CountDownLatch(1);
        transportService.addSendBehavior((connection, requestId, action, request, options) -> {
            if (action.equals(PeerRecoveryTargetService.Actions.TRANSLOG_OPS)) {
                if (brokenNode.equals(connection.getNode().getName())) {
                    safeAwait(newNodeStarted);
                    throw new CircuitBreakingException(""not enough memory for indexing"", 100, 50, CircuitBreaker.Durability.TRANSIENT);
                }
            }
            connection.sendRequest(requestId, action, request, options);
        });
        setReplicaCount(1, indexName);
        internalCluster().startDataOnlyNode();
        newNodeStarted.countDown();

        var allocator = internalCluster().getInstance(ShardsAllocator.class);
        if (allocator instanceof BalancedShardsAllocator) {
            // BalancedShardsAllocator will try other node once retries are exhausted
            ensureGreen(indexName);
        } else if (allocator instanceof DesiredBalanceShardsAllocator) {
            // DesiredBalanceShardsAllocator will keep shard in the error state if it could not be allocated on the desired node
            ensureYellow(indexName);
        } else {
            fail(""Unknown allocator used"");
        }

        transportService.clearAllRules();
    }",/server/src/internalClusterTest/java/org/elasticsearch/gateway/ReplicaShardAllocatorIT.java
31a79952e68fd8efc2fd7f5a7e6f77bc19a45a24,391,202,"public void testPreferCopyCanPerformNoopRecovery() throws Exception {
        String indexName = ""test"";
        String nodeWithPrimary = internalCluster().startNode();

        updateClusterSettings(
            Settings.builder().put(CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), EnableAllocationDecider.Rebalance.NONE)
        );
        assertAcked(
            indicesAdmin().prepareCreate(indexName)
                .setSettings(
                    indexSettings(1, 1)
                        // expire PRRLs quickly
                        .put(IndexSettings.INDEX_SOFT_DELETES_RETENTION_LEASE_PERIOD_SETTING.getKey(), ""1ms"")
                        .put(IndexService.RETENTION_LEASE_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(IndexService.GLOBAL_CHECKPOINT_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), ""1ms"")
                )
        );
        String nodeWithReplica = internalCluster().startDataOnlyNode();
        Settings nodeWithReplicaSettings = internalCluster().dataPathSettings(nodeWithReplica);
        ensureGreen(indexName);
        indexRandom(
            randomBoolean(),
            randomBoolean(),
            randomBoolean(),
            IntStream.range(0, between(100, 500)).mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v"")).toList()
        );
        if (randomBoolean()) {
            indicesAdmin().prepareFlush(indexName).get();
        }
        ensureGlobalCheckpointAdvancedAndSynced(indexName);
        syncFlush(indexName);
        internalCluster().stopNode(nodeWithReplica);
        // Wait until the peer recovery retention leases of the offline node are expired
        assertBusy(() -> {
            for (ShardStats shardStats : indicesAdmin().prepareStats(indexName).get().getShards()) {
                assertThat(shardStats.getRetentionLeaseStats().retentionLeases().leases(), hasSize(1));
            }
        });
        CountDownLatch blockRecovery = new CountDownLatch(1);
        CountDownLatch recoveryStarted = new CountDownLatch(1);
        MockTransportService transportServiceOnPrimary = (MockTransportService) internalCluster().getInstance(
            TransportService.class,
            nodeWithPrimary
        );
        transportServiceOnPrimary.addSendBehavior((connection, requestId, action, request, options) -> {
            if (PeerRecoveryTargetService.Actions.FILES_INFO.equals(action)) {
                recoveryStarted.countDown();
                try {
                    blockRecovery.await();
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                    throw new AssertionError(e);
                }
            }
            connection.sendRequest(requestId, action, request, options);
        });
        internalCluster().startDataOnlyNode();
        recoveryStarted.await();
        nodeWithReplica = internalCluster().startDataOnlyNode(nodeWithReplicaSettings);
        // AllocationService only calls GatewayAllocator if there are unassigned shards
        assertAcked(indicesAdmin().prepareCreate(""dummy-index"").setWaitForActiveShards(0));
        ensureGreen(indexName);
        assertThat(internalCluster().nodesInclude(indexName), containsInAnyOrder(nodeWithPrimary, nodeWithReplica));
        assertNoOpRecoveries(indexName);
        blockRecovery.countDown();
        transportServiceOnPrimary.clearAllRules();
    }","public void testPreferCopyCanPerformNoopRecovery() throws Exception {
        String indexName = ""test"";
        String nodeWithPrimary = internalCluster().startNode();

        updateClusterSettings(
            Settings.builder().put(CLUSTER_ROUTING_REBALANCE_ENABLE_SETTING.getKey(), EnableAllocationDecider.Rebalance.NONE)
        );
        assertAcked(
            indicesAdmin().prepareCreate(indexName)
                .setSettings(
                    indexSettings(1, 1)
                        // expire PRRLs quickly
                        .put(IndexSettings.INDEX_SOFT_DELETES_RETENTION_LEASE_PERIOD_SETTING.getKey(), ""1ms"")
                        .put(IndexService.RETENTION_LEASE_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(IndexService.GLOBAL_CHECKPOINT_SYNC_INTERVAL_SETTING.getKey(), ""100ms"")
                        .put(UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), ""1ms"")
                )
        );
        String nodeWithReplica = internalCluster().startDataOnlyNode();
        Settings nodeWithReplicaSettings = internalCluster().dataPathSettings(nodeWithReplica);
        ensureGreen(indexName);
        indexRandom(
            randomBoolean(),
            randomBoolean(),
            randomBoolean(),
            IntStream.range(0, between(100, 500)).mapToObj(n -> client().prepareIndex(indexName).setSource(""f"", ""v"")).toList()
        );
        if (randomBoolean()) {
            indicesAdmin().prepareFlush(indexName).get();
        }
        ensureGlobalCheckpointAdvancedAndSynced(indexName);
        syncFlush(indexName);
        internalCluster().stopNode(nodeWithReplica);
        // Wait until the peer recovery retention leases of the offline node are expired
        assertBusy(() -> {
            for (ShardStats shardStats : indicesAdmin().prepareStats(indexName).get().getShards()) {
                assertThat(shardStats.getRetentionLeaseStats().retentionLeases().leases(), hasSize(1));
            }
        });
        CountDownLatch blockRecovery = new CountDownLatch(1);
        CountDownLatch recoveryStarted = new CountDownLatch(1);
        MockTransportService transportServiceOnPrimary = (MockTransportService) internalCluster().getInstance(
            TransportService.class,
            nodeWithPrimary
        );
        transportServiceOnPrimary.addSendBehavior((connection, requestId, action, request, options) -> {
            if (PeerRecoveryTargetService.Actions.FILES_INFO.equals(action)) {
                recoveryStarted.countDown();
                safeAwait(blockRecovery);
            }
            connection.sendRequest(requestId, action, request, options);
        });
        internalCluster().startDataOnlyNode();
        recoveryStarted.await();
        nodeWithReplica = internalCluster().startDataOnlyNode(nodeWithReplicaSettings);
        // AllocationService only calls GatewayAllocator if there are unassigned shards
        assertAcked(indicesAdmin().prepareCreate(""dummy-index"").setWaitForActiveShards(0));
        ensureGreen(indexName);
        assertThat(internalCluster().nodesInclude(indexName), containsInAnyOrder(nodeWithPrimary, nodeWithReplica));
        assertNoOpRecoveries(indexName);
        blockRecovery.countDown();
        transportServiceOnPrimary.clearAllRules();
    }",/server/src/internalClusterTest/java/org/elasticsearch/gateway/ReplicaShardAllocatorSyncIdIT.java
31a79952e68fd8efc2fd7f5a7e6f77bc19a45a24,391,262,"public void testCancelFailedSearchWhenPartialResultDisallowed() throws Exception {
        int numberOfShards = between(2, 5);
        createIndex(""test"", numberOfShards, 0);
        indexTestData();

        // Define (but don't run) the search request, expecting a partial shard failure. We will run it later.
        Thread searchThread = new Thread(() -> {
            SearchPhaseExecutionException e = expectThrows(
                SearchPhaseExecutionException.class,
                () -> client().prepareSearch(""test"")
                    .setSearchType(SearchType.QUERY_THEN_FETCH)
                    .setQuery(scriptQuery(new Script(ScriptType.INLINE, ""mockscript"", SEARCH_BLOCK_SCRIPT_NAME, Collections.emptyMap())))
                    .setAllowPartialSearchResults(false)
                    .setSize(1000)
                    .get()
            );
            assertThat(e.getMessage(), containsString(""Partial shards failure""));
        });

        // When the search request executes, block all shards except 1.
        final List<SearchShardBlockingPlugin> searchShardBlockingPlugins = initSearchShardBlockingPlugin();
        AtomicBoolean letOneShardProceed = new AtomicBoolean();
        CountDownLatch shardTaskLatch = new CountDownLatch(1);
        for (SearchShardBlockingPlugin plugin : searchShardBlockingPlugins) {
            plugin.setRunOnNewReaderContext((ReaderContext c) -> {
                if (letOneShardProceed.compareAndSet(false, true)) {
                    // Let one shard continue.
                } else {
                    try {
                        shardTaskLatch.await(); // Bock the other shards.
                    } catch (InterruptedException e) {
                        throw new AssertionError(e);
                    }
                }
            });
        }

        // For the shard that was allowed to proceed, have a single query-execution thread throw an exception.
        final List<ScriptedBlockPlugin> plugins = initBlockFactory();
        AtomicBoolean oneThreadWillError = new AtomicBoolean();
        for (ScriptedBlockPlugin plugin : plugins) {
            plugin.disableBlock();
            plugin.setBeforeExecution(() -> {
                if (oneThreadWillError.compareAndSet(false, true)) {
                    throw new IllegalStateException(""This will cancel the ContextIndexSearcher.search task"");
                }
            });
        }

        // Now run the search request.
        searchThread.start();

        try {
            assertBusy(() -> {
                final List<SearchTask> coordinatorSearchTask = getCoordinatorSearchTasks();
                assertThat(""The Coordinator should have one SearchTask."", coordinatorSearchTask, hasSize(1));
                assertTrue(""The SearchTask should be cancelled."", coordinatorSearchTask.get(0).isCancelled());
                for (var shardQueryTask : getShardQueryTasks()) {
                    assertTrue(""All SearchShardTasks should then be cancelled"", shardQueryTask.isCancelled());
                }
            }, 30, TimeUnit.SECONDS);
            shardTaskLatch.countDown(); // unblock the shardTasks, allowing the test to conclude.
        } finally {
            searchThread.join();
            for (ScriptedBlockPlugin plugin : plugins) {
                plugin.setBeforeExecution(() -> {});
            }
        }
    }","public void testCancelFailedSearchWhenPartialResultDisallowed() throws Exception {
        int numberOfShards = between(2, 5);
        createIndex(""test"", numberOfShards, 0);
        indexTestData();

        // Define (but don't run) the search request, expecting a partial shard failure. We will run it later.
        Thread searchThread = new Thread(() -> {
            SearchPhaseExecutionException e = expectThrows(
                SearchPhaseExecutionException.class,
                () -> client().prepareSearch(""test"")
                    .setSearchType(SearchType.QUERY_THEN_FETCH)
                    .setQuery(scriptQuery(new Script(ScriptType.INLINE, ""mockscript"", SEARCH_BLOCK_SCRIPT_NAME, Collections.emptyMap())))
                    .setAllowPartialSearchResults(false)
                    .setSize(1000)
                    .get()
            );
            assertThat(e.getMessage(), containsString(""Partial shards failure""));
        });

        // When the search request executes, block all shards except 1.
        final List<SearchShardBlockingPlugin> searchShardBlockingPlugins = initSearchShardBlockingPlugin();
        AtomicBoolean letOneShardProceed = new AtomicBoolean();
        CountDownLatch shardTaskLatch = new CountDownLatch(1);
        for (SearchShardBlockingPlugin plugin : searchShardBlockingPlugins) {
            plugin.setRunOnNewReaderContext((ReaderContext c) -> {
                if (letOneShardProceed.compareAndSet(false, true)) {
                    // Let one shard continue.
                } else {
                    safeAwait(shardTaskLatch); // Block the other shards.
                }
            });
        }

        // For the shard that was allowed to proceed, have a single query-execution thread throw an exception.
        final List<ScriptedBlockPlugin> plugins = initBlockFactory();
        AtomicBoolean oneThreadWillError = new AtomicBoolean();
        for (ScriptedBlockPlugin plugin : plugins) {
            plugin.disableBlock();
            plugin.setBeforeExecution(() -> {
                if (oneThreadWillError.compareAndSet(false, true)) {
                    throw new IllegalStateException(""This will cancel the ContextIndexSearcher.search task"");
                }
            });
        }

        // Now run the search request.
        searchThread.start();

        try {
            assertBusy(() -> {
                final List<SearchTask> coordinatorSearchTask = getCoordinatorSearchTasks();
                assertThat(""The Coordinator should have one SearchTask."", coordinatorSearchTask, hasSize(1));
                assertTrue(""The SearchTask should be cancelled."", coordinatorSearchTask.get(0).isCancelled());
                for (var shardQueryTask : getShardQueryTasks()) {
                    assertTrue(""All SearchShardTasks should then be cancelled"", shardQueryTask.isCancelled());
                }
            }, 30, TimeUnit.SECONDS);
            shardTaskLatch.countDown(); // unblock the shardTasks, allowing the test to conclude.
        } finally {
            searchThread.join();
            for (ScriptedBlockPlugin plugin : plugins) {
                plugin.setBeforeExecution(() -> {});
            }
        }
    }",/server/src/internalClusterTest/java/org/elasticsearch/search/SearchCancellationIT.java
31a79952e68fd8efc2fd7f5a7e6f77bc19a45a24,391,244,"public void testQuicklySkipUnavailableClusters() throws Exception {
        Settings remoteSettings = Settings.builder().put(ClusterName.CLUSTER_NAME_SETTING.getKey(), ""foo_bar_cluster"").build();
        try (
            MockTransportService remoteTransport = startTransport(
                ""remote_node"",
                Collections.emptyList(),
                VersionInformation.CURRENT,
                TransportVersion.current(),
                threadPool,
                remoteSettings
            )
        ) {
            DiscoveryNode remoteNode = remoteTransport.getLocalDiscoNode();

            Settings localSettings = Settings.builder()
                .put(onlyRole(DiscoveryNodeRole.REMOTE_CLUSTER_CLIENT_ROLE))
                .put(""cluster.remote.test.seeds"", remoteNode.getAddress().getAddress() + "":"" + remoteNode.getAddress().getPort())
                .put(""cluster.remote.test.skip_unavailable"", true)
                .put(""cluster.remote.initial_connect_timeout"", ""0s"")
                .build();
            try (
                MockTransportService service = MockTransportService.createNewService(
                    localSettings,
                    VersionInformation.CURRENT,
                    TransportVersion.current(),
                    threadPool,
                    null
                )
            ) {
                CountDownLatch latch = new CountDownLatch(1);
                service.addConnectBehavior(remoteTransport, (transport, discoveryNode, profile, listener) -> {
                    try {
                        latch.await();
                    } catch (InterruptedException e) {
                        throw new AssertionError(e);
                    }
                    listener.onFailure(new ConnectTransportException(discoveryNode, ""simulated""));
                });
                service.start();
                service.acceptIncomingRequests();
                RemoteClusterService remoteClusterService = service.getRemoteClusterService();
                Client client = remoteClusterService.getRemoteClusterClient(threadPool, ""test"", EsExecutors.DIRECT_EXECUTOR_SERVICE);

                try {
                    assertFalse(remoteClusterService.isRemoteNodeConnected(""test"", remoteNode));

                    // check that we quickly fail
                    expectThrows(
                        NoSuchRemoteClusterException.class,
                        () -> client.admin().cluster().prepareState().get(TimeValue.timeValueSeconds(10))
                    );
                } finally {
                    service.clearAllRules();
                    latch.countDown();
                }

                assertBusy(() -> {
                    try {
                        client.admin().cluster().prepareState().get();
                    } catch (NoSuchRemoteClusterException e) {
                        // keep retrying on this exception, the goal is to check that we eventually reconnect
                        throw new AssertionError(e);
                    }
                });
                assertTrue(remoteClusterService.isRemoteNodeConnected(""test"", remoteNode));
            }
        }
    }","public void testQuicklySkipUnavailableClusters() throws Exception {
        Settings remoteSettings = Settings.builder().put(ClusterName.CLUSTER_NAME_SETTING.getKey(), ""foo_bar_cluster"").build();
        try (
            MockTransportService remoteTransport = startTransport(
                ""remote_node"",
                Collections.emptyList(),
                VersionInformation.CURRENT,
                TransportVersion.current(),
                threadPool,
                remoteSettings
            )
        ) {
            DiscoveryNode remoteNode = remoteTransport.getLocalDiscoNode();

            Settings localSettings = Settings.builder()
                .put(onlyRole(DiscoveryNodeRole.REMOTE_CLUSTER_CLIENT_ROLE))
                .put(""cluster.remote.test.seeds"", remoteNode.getAddress().getAddress() + "":"" + remoteNode.getAddress().getPort())
                .put(""cluster.remote.test.skip_unavailable"", true)
                .put(""cluster.remote.initial_connect_timeout"", ""0s"")
                .build();
            try (
                MockTransportService service = MockTransportService.createNewService(
                    localSettings,
                    VersionInformation.CURRENT,
                    TransportVersion.current(),
                    threadPool,
                    null
                )
            ) {
                CountDownLatch latch = new CountDownLatch(1);
                service.addConnectBehavior(remoteTransport, (transport, discoveryNode, profile, listener) -> {
                    safeAwait(latch);
                    listener.onFailure(new ConnectTransportException(discoveryNode, ""simulated""));
                });
                service.start();
                service.acceptIncomingRequests();
                RemoteClusterService remoteClusterService = service.getRemoteClusterService();
                Client client = remoteClusterService.getRemoteClusterClient(threadPool, ""test"", EsExecutors.DIRECT_EXECUTOR_SERVICE);

                try {
                    assertFalse(remoteClusterService.isRemoteNodeConnected(""test"", remoteNode));

                    // check that we quickly fail
                    expectThrows(
                        NoSuchRemoteClusterException.class,
                        () -> client.admin().cluster().prepareState().get(TimeValue.timeValueSeconds(10))
                    );
                } finally {
                    service.clearAllRules();
                    latch.countDown();
                }

                assertBusy(() -> {
                    try {
                        client.admin().cluster().prepareState().get();
                    } catch (NoSuchRemoteClusterException e) {
                        // keep retrying on this exception, the goal is to check that we eventually reconnect
                        throw new AssertionError(e);
                    }
                });
                assertTrue(remoteClusterService.isRemoteNodeConnected(""test"", remoteNode));
            }
        }
    }",/server/src/test/java/org/elasticsearch/transport/RemoteClusterClientTests.java
31a79952e68fd8efc2fd7f5a7e6f77bc19a45a24,391,225,"public void testRetryOnStoppedTransportService() throws Exception {
        internalCluster().startMasterOnlyNodes(2);
        String primary = internalCluster().startDataOnlyNode();
        assertAcked(
            prepareCreate(""test"").setSettings(
                Settings.builder()
                    .put(indexSettings())
                    .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)
                    .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1)
            )
        );

        String replica = internalCluster().startDataOnlyNode();
        String coordinator = internalCluster().startCoordinatingOnlyNode(Settings.EMPTY);
        ensureGreen(""test"");

        TestPlugin primaryTestPlugin = getTestPlugin(primary);
        // this test only provoked an issue for the primary action, but for completeness, we pick the action randomly
        primaryTestPlugin.testActionName = TestAction.ACTION_NAME + (randomBoolean() ? ""[p]"" : ""[r]"");
        logger.info(""--> Test action {}, primary {}, replica {}"", primaryTestPlugin.testActionName, primary, replica);

        AtomicReference<Object> response = new AtomicReference<>();
        CountDownLatch doneLatch = new CountDownLatch(1);
        client(coordinator).execute(
            TestAction.TYPE,
            new Request(new ShardId(resolveIndex(""test""), 0)),
            ActionListener.runAfter(
                ActionListener.wrap(r -> assertTrue(response.compareAndSet(null, r)), e -> assertTrue(response.compareAndSet(null, e))),
                doneLatch::countDown
            )
        );

        assertTrue(primaryTestPlugin.actionRunningLatch.await(10, TimeUnit.SECONDS));

        MockTransportService primaryTransportService = (MockTransportService) internalCluster().getInstance(
            TransportService.class,
            primary
        );
        // we pause node after TransportService has moved to stopped, but before closing connections, since if connections are closed
        // we would not hit the transport service closed case.
        primaryTransportService.addOnStopListener(() -> {
            primaryTestPlugin.actionWaitLatch.countDown();
            try {
                assertTrue(doneLatch.await(10, TimeUnit.SECONDS));
            } catch (InterruptedException e) {
                throw new AssertionError(e);
            }
        });
        internalCluster().stopNode(primary);

        assertTrue(doneLatch.await(10, TimeUnit.SECONDS));
        if (response.get() instanceof Exception) {
            throw new AssertionError(response.get());
        }
    }","public void testRetryOnStoppedTransportService() throws Exception {
        internalCluster().startMasterOnlyNodes(2);
        String primary = internalCluster().startDataOnlyNode();
        assertAcked(
            prepareCreate(""test"").setSettings(
                Settings.builder()
                    .put(indexSettings())
                    .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)
                    .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1)
            )
        );

        String replica = internalCluster().startDataOnlyNode();
        String coordinator = internalCluster().startCoordinatingOnlyNode(Settings.EMPTY);
        ensureGreen(""test"");

        TestPlugin primaryTestPlugin = getTestPlugin(primary);
        // this test only provoked an issue for the primary action, but for completeness, we pick the action randomly
        primaryTestPlugin.testActionName = TestAction.ACTION_NAME + (randomBoolean() ? ""[p]"" : ""[r]"");
        logger.info(""--> Test action {}, primary {}, replica {}"", primaryTestPlugin.testActionName, primary, replica);

        AtomicReference<Object> response = new AtomicReference<>();
        CountDownLatch doneLatch = new CountDownLatch(1);
        client(coordinator).execute(
            TestAction.TYPE,
            new Request(new ShardId(resolveIndex(""test""), 0)),
            ActionListener.runAfter(
                ActionListener.wrap(r -> assertTrue(response.compareAndSet(null, r)), e -> assertTrue(response.compareAndSet(null, e))),
                doneLatch::countDown
            )
        );

        assertTrue(primaryTestPlugin.actionRunningLatch.await(10, TimeUnit.SECONDS));

        MockTransportService primaryTransportService = (MockTransportService) internalCluster().getInstance(
            TransportService.class,
            primary
        );
        // we pause node after TransportService has moved to stopped, but before closing connections, since if connections are closed
        // we would not hit the transport service closed case.
        primaryTransportService.addOnStopListener(() -> {
            primaryTestPlugin.actionWaitLatch.countDown();
            safeAwait(doneLatch);
        });
        internalCluster().stopNode(primary);

        assertTrue(doneLatch.await(10, TimeUnit.SECONDS));
        if (response.get() instanceof Exception) {
            throw new AssertionError(response.get());
        }
    }",/server/src/internalClusterTest/java/org/elasticsearch/action/support/replication/TransportReplicationActionRetryOnClosedNodeIT.java
31a79952e68fd8efc2fd7f5a7e6f77bc19a45a24,391,122,"public void testResolvesAddressesInBackgroundAndIgnoresConcurrentCalls() throws Exception {
        final AtomicReference<List<TransportAddress>> resolvedAddressesRef = new AtomicReference<>();
        final CountDownLatch startLatch = new CountDownLatch(1);
        final CountDownLatch endLatch = new CountDownLatch(1);

        final int addressCount = randomIntBetween(0, 5);
        for (int i = 0; i < addressCount; i++) {
            transportAddresses.add(buildNewFakeTransportAddress());
        }

        seedHostsResolver.resolveConfiguredHosts(resolvedAddresses -> {
            try {
                assertTrue(startLatch.await(30, TimeUnit.SECONDS));
            } catch (InterruptedException e) {
                throw new AssertionError(e);
            }
            resolvedAddressesRef.set(resolvedAddresses);
            endLatch.countDown();
        });

        seedHostsResolver.resolveConfiguredHosts(resolvedAddresses -> { throw new AssertionError(""unexpected concurrent resolution""); });

        assertThat(resolvedAddressesRef.get(), nullValue());
        startLatch.countDown();
        assertTrue(endLatch.await(30, TimeUnit.SECONDS));
        assertThat(resolvedAddressesRef.get(), equalTo(transportAddresses));
    }","public void testResolvesAddressesInBackgroundAndIgnoresConcurrentCalls() throws Exception {
        final AtomicReference<List<TransportAddress>> resolvedAddressesRef = new AtomicReference<>();
        final CountDownLatch startLatch = new CountDownLatch(1);
        final CountDownLatch endLatch = new CountDownLatch(1);

        final int addressCount = randomIntBetween(0, 5);
        for (int i = 0; i < addressCount; i++) {
            transportAddresses.add(buildNewFakeTransportAddress());
        }

        seedHostsResolver.resolveConfiguredHosts(resolvedAddresses -> {
            safeAwait(startLatch);
            resolvedAddressesRef.set(resolvedAddresses);
            endLatch.countDown();
        });

        seedHostsResolver.resolveConfiguredHosts(resolvedAddresses -> { throw new AssertionError(""unexpected concurrent resolution""); });

        assertThat(resolvedAddressesRef.get(), nullValue());
        startLatch.countDown();
        assertTrue(endLatch.await(30, TimeUnit.SECONDS));
        assertThat(resolvedAddressesRef.get(), equalTo(transportAddresses));
    }",/server/src/test/java/org/elasticsearch/discovery/SeedHostsResolverTests.java
a0279bc069fbf5024a2bd36b93df9fed706700f7,563,1244,"public final void messageReceived(BytesReference reference, TcpChannel channel) throws IOException {
        String profileName = channel.getProfile();
        InetSocketAddress remoteAddress = channel.getRemoteAddress();
        int messageLengthBytes = reference.length();
        final int totalMessageSize = messageLengthBytes + TcpHeader.MARKER_BYTES_SIZE + TcpHeader.MESSAGE_LENGTH_SIZE;
        readBytesMetric.inc(totalMessageSize);
        // we have additional bytes to read, outside of the header
        boolean hasMessageBytesToRead = (totalMessageSize - TcpHeader.HEADER_SIZE) > 0;
        StreamInput streamIn = reference.streamInput();
        boolean success = false;
        try (ThreadContext.StoredContext tCtx = threadPool.getThreadContext().stashContext()) {
            long requestId = streamIn.readLong();
            byte status = streamIn.readByte();
            Version version = Version.fromId(streamIn.readInt());
            if (TransportStatus.isCompress(status) && hasMessageBytesToRead && streamIn.available() > 0) {
                Compressor compressor;
                try {
                    final int bytesConsumed = TcpHeader.REQUEST_ID_SIZE + TcpHeader.STATUS_SIZE + TcpHeader.VERSION_ID_SIZE;
                    compressor = CompressorFactory.compressor(reference.slice(bytesConsumed, reference.length() - bytesConsumed));
                } catch (NotCompressedException ex) {
                    int maxToRead = Math.min(reference.length(), 10);
                    StringBuilder sb = new StringBuilder(""stream marked as compressed, but no compressor found, first ["").append(maxToRead)
                        .append(""] content bytes out of ["").append(reference.length())
                        .append(""] readable bytes with message size ["").append(messageLengthBytes).append(""] "").append(""] are ["");
                    for (int i = 0; i < maxToRead; i++) {
                        sb.append(reference.get(i)).append("","");
                    }
                    sb.append(""]"");
                    throw new IllegalStateException(sb.toString());
                }
                streamIn = compressor.streamInput(streamIn);
            }
            final boolean isHandshake = TransportStatus.isHandshake(status);
            ensureVersionCompatibility(version, getCurrentVersion(), isHandshake);
            streamIn = new NamedWriteableAwareStreamInput(streamIn, namedWriteableRegistry);
            streamIn.setVersion(version);
            threadPool.getThreadContext().readHeaders(streamIn);
            threadPool.getThreadContext().putTransient(""_remote_address"", remoteAddress);
            if (TransportStatus.isRequest(status)) {
                handleRequest(channel, profileName, streamIn, requestId, messageLengthBytes, version, remoteAddress, status);
            } else {
                final TransportResponseHandler<?> handler;
                if (isHandshake) {
                    handler = pendingHandshakes.remove(requestId);
                } else {
                    TransportResponseHandler theHandler = responseHandlers.onResponseReceived(requestId, messageListener);
                    if (theHandler == null && TransportStatus.isError(status)) {
                        handler = pendingHandshakes.remove(requestId);
                    } else {
                        handler = theHandler;
                    }
                }
                // ignore if its null, the service logs it
                if (handler != null) {
                    if (TransportStatus.isError(status)) {
                        handlerResponseError(streamIn, handler);
                    } else {
                        handleResponse(remoteAddress, streamIn, handler);
                    }
                    // Check the entire message has been read
                    final int nextByte = streamIn.read();
                    // calling read() is useful to make sure the message is fully read, even if there is an EOS marker
                    if (nextByte != -1) {
                        throw new IllegalStateException(""Message not fully read (response) for requestId ["" + requestId + ""], handler [""
                            + handler + ""], error ["" + TransportStatus.isError(status) + ""]; resetting"");
                    }
                }
            }
            success = true;
        } finally {
            if (success) {
                IOUtils.close(streamIn);
            } else {
                IOUtils.closeWhileHandlingException(streamIn);
            }
        }
    }","public final void messageReceived(BytesReference reference, TcpChannel channel) throws IOException {
        String profileName = channel.getProfile();
        InetSocketAddress remoteAddress = channel.getRemoteAddress();
        int messageLengthBytes = reference.length();
        final int totalMessageSize = messageLengthBytes + TcpHeader.MARKER_BYTES_SIZE + TcpHeader.MESSAGE_LENGTH_SIZE;
        readBytesMetric.inc(totalMessageSize);
        // we have additional bytes to read, outside of the header
        boolean hasMessageBytesToRead = (totalMessageSize - TcpHeader.HEADER_SIZE) > 0;
        StreamInput streamIn = reference.streamInput();
        boolean success = false;
        try (ThreadContext.StoredContext tCtx = threadPool.getThreadContext().stashContext()) {
            long requestId = streamIn.readLong();
            byte status = streamIn.readByte();
            Version version = Version.fromId(streamIn.readInt());
            if (TransportStatus.isCompress(status) && hasMessageBytesToRead && streamIn.available() > 0) {
                Compressor compressor;
                try {
                    final int bytesConsumed = TcpHeader.REQUEST_ID_SIZE + TcpHeader.STATUS_SIZE + TcpHeader.VERSION_ID_SIZE;
                    compressor = CompressorFactory.compressor(reference.slice(bytesConsumed, reference.length() - bytesConsumed));
                } catch (NotCompressedException ex) {
                    int maxToRead = Math.min(reference.length(), 10);
                    StringBuilder sb = new StringBuilder(""stream marked as compressed, but no compressor found, first ["").append(maxToRead)
                        .append(""] content bytes out of ["").append(reference.length())
                        .append(""] readable bytes with message size ["").append(messageLengthBytes).append(""] "").append(""] are ["");
                    for (int i = 0; i < maxToRead; i++) {
                        sb.append(reference.get(i)).append("","");
                    }
                    sb.append(""]"");
                    throw new IllegalStateException(sb.toString());
                }
                streamIn = compressor.streamInput(streamIn);
            }
            final boolean isHandshake = TransportStatus.isHandshake(status);
            ensureVersionCompatibility(version, getCurrentVersion(), isHandshake);
            streamIn = new NamedWriteableAwareStreamInput(streamIn, namedWriteableRegistry);
            streamIn.setVersion(version);
            threadPool.getThreadContext().readHeaders(streamIn);
            threadPool.getThreadContext().putTransient(""_remote_address"", remoteAddress);
            if (TransportStatus.isRequest(status)) {
                handleRequest(channel, profileName, streamIn, requestId, messageLengthBytes, version, remoteAddress, status);
            } else {
                final TransportResponseHandler<?> handler;
                if (isHandshake) {
                    handler = pendingHandshakes.remove(requestId);
                } else {
                    TransportResponseHandler<? extends TransportResponse> theHandler =
                        responseHandlers.onResponseReceived(requestId, messageListener);
                    if (theHandler == null && TransportStatus.isError(status)) {
                        handler = pendingHandshakes.remove(requestId);
                    } else {
                        handler = theHandler;
                    }
                }
                // ignore if its null, the service logs it
                if (handler != null) {
                    if (TransportStatus.isError(status)) {
                        handlerResponseError(streamIn, handler);
                    } else {
                        handleResponse(remoteAddress, streamIn, handler);
                    }
                    // Check the entire message has been read
                    final int nextByte = streamIn.read();
                    // calling read() is useful to make sure the message is fully read, even if there is an EOS marker
                    if (nextByte != -1) {
                        throw new IllegalStateException(""Message not fully read (response) for requestId ["" + requestId + ""], handler [""
                            + handler + ""], error ["" + TransportStatus.isError(status) + ""]; resetting"");
                    }
                }
            }
            success = true;
        } finally {
            if (success) {
                IOUtils.close(streamIn);
            } else {
                IOUtils.closeWhileHandlingException(streamIn);
            }
        }
    }",/server/src/main/java/org/elasticsearch/transport/TcpTransport.java
a0279bc069fbf5024a2bd36b93df9fed706700f7,567,255,"public void run() {
            if (!running()) {
                return;
            }
            final TransportRequestOptions options = TransportRequestOptions.builder().withType(TransportRequestOptions.Type.PING)
                .withTimeout(pingRetryTimeout).build();
            transportService.sendRequest(node, PING_ACTION_NAME, newPingRequest(), options, new TransportResponseHandler<PingResponse>() {
                        @Override
                        public PingResponse newInstance() {
                            return new PingResponse();
                        }

                        @Override
                        public void handleResponse(PingResponse response) {
                            if (!running()) {
                                return;
                            }
                            retryCount = 0;
                            threadPool.schedule(pingInterval, ThreadPool.Names.SAME, NodeFD.this);
                        }

                        @Override
                        public void handleException(TransportException exp) {
                            if (!running()) {
                                return;
                            }
                            if (exp instanceof ConnectTransportException || exp.getCause() instanceof ConnectTransportException) {
                                handleTransportDisconnect(node);
                                return;
                            }

                            retryCount++;
                            logger.trace( () -> new ParameterizedMessage(
                                    ""[node  ] failed to ping [{}], retry [{}] out of [{}]"", node, retryCount, pingRetryCount), exp);
                            if (retryCount >= pingRetryCount) {
                                logger.debug(""[node  ] failed to ping [{}], tried [{}] times, each with  maximum [{}] timeout"", node,
                                    pingRetryCount, pingRetryTimeout);
                                // not good, failure
                                if (nodesFD.remove(node, NodeFD.this)) {
                                    notifyNodeFailure(node, ""failed to ping, tried ["" + pingRetryCount + ""] times, each with maximum [""
                                        + pingRetryTimeout + ""] timeout"");
                                }
                            } else {
                                // resend the request, not reschedule, rely on send timeout
                                transportService.sendRequest(node, PING_ACTION_NAME, newPingRequest(), options, this);
                            }
                        }

                        @Override
                        public String executor() {
                            return ThreadPool.Names.SAME;
                        }
                    }
            );
        }","public void run() {
            if (!running()) {
                return;
            }
            final TransportRequestOptions options = TransportRequestOptions.builder().withType(TransportRequestOptions.Type.PING)
                .withTimeout(pingRetryTimeout).build();
            transportService.sendRequest(node, PING_ACTION_NAME, newPingRequest(), options, new TransportResponseHandler<PingResponse>() {
                        @Override
                        public PingResponse read(StreamInput in) throws IOException {
                            return new PingResponse(in);
                        }

                        @Override
                        public void handleResponse(PingResponse response) {
                            if (!running()) {
                                return;
                            }
                            retryCount = 0;
                            threadPool.schedule(pingInterval, ThreadPool.Names.SAME, NodeFD.this);
                        }

                        @Override
                        public void handleException(TransportException exp) {
                            if (!running()) {
                                return;
                            }
                            if (exp instanceof ConnectTransportException || exp.getCause() instanceof ConnectTransportException) {
                                handleTransportDisconnect(node);
                                return;
                            }

                            retryCount++;
                            logger.trace( () -> new ParameterizedMessage(
                                    ""[node  ] failed to ping [{}], retry [{}] out of [{}]"", node, retryCount, pingRetryCount), exp);
                            if (retryCount >= pingRetryCount) {
                                logger.debug(""[node  ] failed to ping [{}], tried [{}] times, each with  maximum [{}] timeout"", node,
                                    pingRetryCount, pingRetryTimeout);
                                // not good, failure
                                if (nodesFD.remove(node, NodeFD.this)) {
                                    notifyNodeFailure(node, ""failed to ping, tried ["" + pingRetryCount + ""] times, each with maximum [""
                                        + pingRetryTimeout + ""] timeout"");
                                }
                            } else {
                                // resend the request, not reschedule, rely on send timeout
                                transportService.sendRequest(node, PING_ACTION_NAME, newPingRequest(), options, this);
                            }
                        }

                        @Override
                        public String executor() {
                            return ThreadPool.Names.SAME;
                        }
                    }
            );
        }",/server/src/main/java/org/elasticsearch/discovery/zen/NodesFaultDetection.java
a0279bc069fbf5024a2bd36b93df9fed706700f7,457,2644,"public void testProfilesIncludesDefault() {
        Set<TcpTransport.ProfileSettings> profileSettings = TcpTransport.getProfileSettings(Settings.EMPTY);
        assertEquals(1, profileSettings.size());
        assertEquals(TcpTransport.DEFAULT_PROFILE, profileSettings.stream().findAny().get().profileName);

        profileSettings = TcpTransport.getProfileSettings(Settings.builder()
            .put(""transport.profiles.test.port"", ""0"")
            .build());
        assertEquals(2, profileSettings.size());
        assertEquals(new HashSet<>(Arrays.asList(""default"", ""test"")), profileSettings.stream().map(s -> s.profileName).collect(Collectors
            .toSet()));

        profileSettings = TcpTransport.getProfileSettings(Settings.builder()
            .put(""transport.profiles.test.port"", ""0"")
            .put(""transport.profiles.default.port"", ""0"")
            .build());
        assertEquals(2, profileSettings.size());
        assertEquals(new HashSet<>(Arrays.asList(""default"", ""test"")), profileSettings.stream().map(s -> s.profileName).collect(Collectors
            .toSet()));
    }","public void testProfileSettings() {
        boolean enable = randomBoolean();
        Settings globalSettings = Settings.builder()
            .put(""network.tcp.no_delay"", enable)
            .put(""network.tcp.keep_alive"", enable)
            .put(""network.tcp.reuse_address"", enable)
            .put(""network.tcp.send_buffer_size"", ""43000b"")
            .put(""network.tcp.receive_buffer_size"", ""42000b"")
            .put(""network.publish_host"", ""the_publish_host"")
            .put(""network.bind_host"", ""the_bind_host"")
            .build();

        Settings globalSettings2 = Settings.builder()
            .put(""network.tcp.no_delay"", !enable)
            .put(""network.tcp.keep_alive"", !enable)
            .put(""network.tcp.reuse_address"", !enable)
            .put(""network.tcp.send_buffer_size"", ""4b"")
            .put(""network.tcp.receive_buffer_size"", ""3b"")
            .put(""network.publish_host"", ""another_publish_host"")
            .put(""network.bind_host"", ""another_bind_host"")
            .build();

        Settings transportSettings = Settings.builder()
            .put(""transport.tcp_no_delay"", enable)
            .put(""transport.tcp.keep_alive"", enable)
            .put(""transport.tcp.reuse_address"", enable)
            .put(""transport.tcp.send_buffer_size"", ""43000b"")
            .put(""transport.tcp.receive_buffer_size"", ""42000b"")
            .put(""transport.publish_host"", ""the_publish_host"")
            .put(""transport.tcp.port"", ""9700-9800"")
            .put(""transport.bind_host"", ""the_bind_host"")
            .put(globalSettings2)
            .build();

        Settings transportSettings2 = Settings.builder()
            .put(""transport.tcp_no_delay"", !enable)
            .put(""transport.tcp.keep_alive"", !enable)
            .put(""transport.tcp.reuse_address"", !enable)
            .put(""transport.tcp.send_buffer_size"", ""5b"")
            .put(""transport.tcp.receive_buffer_size"", ""6b"")
            .put(""transport.publish_host"", ""another_publish_host"")
            .put(""transport.tcp.port"", ""9702-9802"")
            .put(""transport.bind_host"", ""another_bind_host"")
            .put(globalSettings2)
            .build();
        Settings defaultProfileSettings = Settings.builder()
            .put(""transport.profiles.default.tcp_no_delay"", enable)
            .put(""transport.profiles.default.tcp_keep_alive"", enable)
            .put(""transport.profiles.default.reuse_address"", enable)
            .put(""transport.profiles.default.send_buffer_size"", ""43000b"")
            .put(""transport.profiles.default.receive_buffer_size"", ""42000b"")
            .put(""transport.profiles.default.port"", ""9700-9800"")
            .put(""transport.profiles.default.publish_host"", ""the_publish_host"")
            .put(""transport.profiles.default.bind_host"", ""the_bind_host"")
            .put(""transport.profiles.default.publish_port"", 42)
            .put(randomBoolean() ? transportSettings2 : globalSettings2) // ensure that we have profile precedence
            .build();

        Settings profileSettings = Settings.builder()
            .put(""transport.profiles.some_profile.tcp_no_delay"", enable)
            .put(""transport.profiles.some_profile.tcp_keep_alive"", enable)
            .put(""transport.profiles.some_profile.reuse_address"", enable)
            .put(""transport.profiles.some_profile.send_buffer_size"", ""43000b"")
            .put(""transport.profiles.some_profile.receive_buffer_size"", ""42000b"")
            .put(""transport.profiles.some_profile.port"", ""9700-9800"")
            .put(""transport.profiles.some_profile.publish_host"", ""the_publish_host"")
            .put(""transport.profiles.some_profile.bind_host"", ""the_bind_host"")
            .put(""transport.profiles.some_profile.publish_port"", 42)
            .put(randomBoolean() ? transportSettings2 : globalSettings2) // ensure that we have profile precedence
            .put(randomBoolean() ? defaultProfileSettings : Settings.EMPTY)
            .build();

        Settings randomSettings = randomFrom(random(), globalSettings, transportSettings, profileSettings);
        ClusterSettings clusterSettings = new ClusterSettings(randomSettings, ClusterSettings
            .BUILT_IN_CLUSTER_SETTINGS);
        clusterSettings.validate(randomSettings, false);
        TcpTransport.ProfileSettings settings = new TcpTransport.ProfileSettings(
            Settings.builder().put(randomSettings).put(""transport.profiles.some_profile.port"", ""9700-9800"").build(), // port is required
            ""some_profile"");

        assertEquals(enable, settings.tcpNoDelay);
        assertEquals(enable, settings.tcpKeepAlive);
        assertEquals(enable, settings.reuseAddress);
        assertEquals(43000, settings.sendBufferSize.getBytes());
        assertEquals(42000, settings.receiveBufferSize.getBytes());
        if (randomSettings == profileSettings) {
            assertEquals(42, settings.publishPort);
        } else {
            assertEquals(-1, settings.publishPort);
        }

        if (randomSettings == globalSettings) { // publish host has no global fallback for the profile since we later resolve it based on
            // the bound address
            assertEquals(Collections.emptyList(), settings.publishHosts);
        } else {
            assertEquals(Collections.singletonList(""the_publish_host""), settings.publishHosts);
        }
        assertEquals(""9700-9800"", settings.portOrRange);
        assertEquals(Collections.singletonList(""the_bind_host""), settings.bindHosts);
    }",/test/framework/src/main/java/org/elasticsearch/transport/AbstractSimpleTransportTestCase.java
22415fa2de1d7d07cea7dd5e7263eb1ed4270503,571,137,"CharsetMatch findCharset(List<String> explanation, InputStream inputStream) throws Exception {

        // We need an input stream that supports mark and reset, so wrap the argument
        // in a BufferedInputStream if it doesn't already support this feature
        if (inputStream.markSupported() == false) {
            inputStream = new BufferedInputStream(inputStream, BUFFER_SIZE);
        }

        // This is from ICU4J
        CharsetDetector charsetDetector = new CharsetDetector().setText(inputStream);
        CharsetMatch[] charsetMatches = charsetDetector.detectAll();

        // Determine some extra characteristics of the input to compensate for some deficiencies of ICU4J
        boolean pureAscii = true;
        boolean containsZeroBytes = false;
        inputStream.mark(BUFFER_SIZE);
        byte[] workspace = new byte[BUFFER_SIZE];
        int remainingLength = BUFFER_SIZE;
        do {
            int bytesRead = inputStream.read(workspace, 0, remainingLength);
            if (bytesRead <= 0) {
                break;
            }
            for (int i = 0; i < bytesRead && containsZeroBytes == false; ++i) {
                if (workspace[i] == 0) {
                    containsZeroBytes = true;
                    pureAscii = false;
                } else {
                    pureAscii = pureAscii && workspace[i] > 0 && workspace[i] < 128;
                }
            }
            remainingLength -= bytesRead;
        } while (containsZeroBytes == false && remainingLength > 0);
        inputStream.reset();

        if (pureAscii) {
            // If the input is pure ASCII then many single byte character sets will match.  We want to favour
            // UTF-8 in this case, as it avoids putting a bold declaration of a dubious character set choice
            // in the config files.
            Optional<CharsetMatch> utf8CharsetMatch = Arrays.stream(charsetMatches)
                .filter(charsetMatch -> StandardCharsets.UTF_8.name().equals(charsetMatch.getName())).findFirst();
            if (utf8CharsetMatch.isPresent()) {
                explanation.add(""Using character encoding ["" + StandardCharsets.UTF_8.name() +
                    ""], which matched the input with ["" + utf8CharsetMatch.get().getConfidence() + ""%] confidence - first ["" +
                    (BUFFER_SIZE / 1024) + ""kB] of input was pure ASCII"");
                return utf8CharsetMatch.get();
            }
        }

        // Input wasn't pure ASCII, so use the best matching character set that's supported by both Java and Go.
        // Additionally, if the input contains zero bytes then avoid single byte character sets, as ICU4J will
        // suggest these for binary files but then
        for (CharsetMatch charsetMatch : charsetMatches) {
            String name = charsetMatch.getName();
            if (Charset.isSupported(name) && FILEBEAT_SUPPORTED_ENCODINGS.contains(name.toLowerCase(Locale.ROOT))) {

                // This extra test is to avoid trying to read binary files as text.  Running the log config
                // deduction algorithms on binary files is very slow as the binary files generally appear to
                // have very long lines.
                boolean spaceEncodingContainsZeroByte = false;
                byte[] spaceBytes = "" "".getBytes(name);
                for (int i = 0; i < spaceBytes.length && spaceEncodingContainsZeroByte == false; ++i) {
                    spaceEncodingContainsZeroByte = (spaceBytes[i] == 0);
                }
                if (containsZeroBytes && spaceEncodingContainsZeroByte == false) {
                    explanation.add(""Character encoding ["" + name + ""] matched the input with ["" + charsetMatch.getConfidence() +
                        ""%] confidence but was rejected as the input contains zero bytes and the ["" + name + ""] encoding does not"");
                } else {
                    explanation.add(""Using character encoding ["" + name + ""], which matched the input with ["" +
                        charsetMatch.getConfidence() + ""%] confidence"");
                    return charsetMatch;
                }
            } else {
                explanation.add(""Character encoding ["" + name + ""] matched the input with ["" + charsetMatch.getConfidence() +
                    ""%] confidence but was rejected as it is not supported by ["" +
                    (Charset.isSupported(name) ? ""Filebeat"" : ""the JVM"") + ""]"");
            }
        }

        throw new IllegalArgumentException(""Could not determine a usable character encoding for the input"" +
            (containsZeroBytes ? "" - could it be binary data?"" : """"));
    }","CharsetMatch findCharset(List<String> explanation, InputStream inputStream) throws Exception {

        // We need an input stream that supports mark and reset, so wrap the argument
        // in a BufferedInputStream if it doesn't already support this feature
        if (inputStream.markSupported() == false) {
            inputStream = new BufferedInputStream(inputStream, BUFFER_SIZE);
        }

        // This is from ICU4J
        CharsetDetector charsetDetector = new CharsetDetector().setText(inputStream);
        CharsetMatch[] charsetMatches = charsetDetector.detectAll();

        // Determine some extra characteristics of the input to compensate for some deficiencies of ICU4J
        boolean pureAscii = true;
        boolean containsZeroBytes = false;
        inputStream.mark(BUFFER_SIZE);
        byte[] workspace = new byte[BUFFER_SIZE];
        int remainingLength = BUFFER_SIZE;
        do {
            int bytesRead = inputStream.read(workspace, 0, remainingLength);
            if (bytesRead <= 0) {
                break;
            }
            for (int i = 0; i < bytesRead && containsZeroBytes == false; ++i) {
                if (workspace[i] == 0) {
                    containsZeroBytes = true;
                    pureAscii = false;
                } else {
                    pureAscii = pureAscii && workspace[i] > 0 && workspace[i] < 128;
                }
            }
            remainingLength -= bytesRead;
        } while (containsZeroBytes == false && remainingLength > 0);
        inputStream.reset();

        if (pureAscii) {
            // If the input is pure ASCII then many single byte character sets will match.  We want to favour
            // UTF-8 in this case, as it avoids putting a bold declaration of a dubious character set choice
            // in the config files.
            Optional<CharsetMatch> utf8CharsetMatch = Arrays.stream(charsetMatches)
                .filter(charsetMatch -> StandardCharsets.UTF_8.name().equals(charsetMatch.getName())).findFirst();
            if (utf8CharsetMatch.isPresent()) {
                explanation.add(""Using character encoding ["" + StandardCharsets.UTF_8.name() +
                    ""], which matched the input with ["" + utf8CharsetMatch.get().getConfidence() + ""%] confidence - first ["" +
                    (BUFFER_SIZE / 1024) + ""kB] of input was pure ASCII"");
                return utf8CharsetMatch.get();
            }
        }

        // Input wasn't pure ASCII, so use the best matching character set that's supported by both Java and Go.
        // Additionally, if the input contains zero bytes then avoid single byte character sets, as ICU4J will
        // suggest these for binary files but then
        for (CharsetMatch charsetMatch : charsetMatches) {
            String name = charsetMatch.getName();
            if (Charset.isSupported(name) && FILEBEAT_SUPPORTED_ENCODINGS.contains(name.toLowerCase(Locale.ROOT))) {

                // This extra test is to avoid trying to read binary files as text.  Running the log config
                // deduction algorithms on binary files is very slow as the binary files generally appear to
                // have very long lines.
                boolean spaceEncodingContainsZeroByte = false;
                Charset charset = Charset.forName(name);
                // Some character sets cannot be encoded.  These are extremely rare so it's likely that
                // they've been chosen based on incorrectly provided binary data.  Therefore, err on
                // the side of rejecting binary data.
                if (charset.canEncode()) {
                    byte[] spaceBytes = "" "".getBytes(charset);
                    for (int i = 0; i < spaceBytes.length && spaceEncodingContainsZeroByte == false; ++i) {
                        spaceEncodingContainsZeroByte = (spaceBytes[i] == 0);
                    }
                }
                if (containsZeroBytes && spaceEncodingContainsZeroByte == false) {
                    explanation.add(""Character encoding ["" + name + ""] matched the input with ["" + charsetMatch.getConfidence() +
                        ""%] confidence but was rejected as the input contains zero bytes and the ["" + name + ""] encoding does not"");
                } else {
                    explanation.add(""Using character encoding ["" + name + ""], which matched the input with ["" +
                        charsetMatch.getConfidence() + ""%] confidence"");
                    return charsetMatch;
                }
            } else {
                explanation.add(""Character encoding ["" + name + ""] matched the input with ["" + charsetMatch.getConfidence() +
                    ""%] confidence but was rejected as it is not supported by ["" +
                    (Charset.isSupported(name) ? ""Filebeat"" : ""the JVM"") + ""]"");
            }
        }

        throw new IllegalArgumentException(""Could not determine a usable character encoding for the input"" +
            (containsZeroBytes ? "" - could it be binary data?"" : """"));
    }",/x-pack/plugin/ml/log-structure-finder/src/main/java/org/elasticsearch/xpack/ml/logstructurefinder/LogStructureFinderManager.java
55c8e805320c1ab51288396e005cffaf14adc008,571,569,"public void testToQueryFuzzyQueryAutoFuziness() throws Exception {
        assumeTrue(""test runs only when at least a type is registered"", getCurrentTypes().length > 0);

        int length = randomIntBetween(1, 10);
        StringBuilder queryString = new StringBuilder();
        for (int i = 0; i < length; i++) {
            queryString.append(""a"");
        }
        queryString.append(""~"");

        int expectedEdits;
        if (length <= 2) {
            expectedEdits = 0;
        } else if (3 <= length && length <= 5) {
            expectedEdits = 1;
        } else {
            expectedEdits = 2;
        }

        Query query = queryStringQuery(queryString.toString()).defaultField(STRING_FIELD_NAME).fuzziness(Fuzziness.AUTO)
            .toQuery(createShardContext());
        assertThat(query, instanceOf(FuzzyQuery.class));
        FuzzyQuery fuzzyQuery = (FuzzyQuery) query;
        assertEquals(expectedEdits, fuzzyQuery.getMaxEdits());
    }","public void testToQueryWilcardQueryWithSynonyms() throws Exception {
        assumeTrue(""test runs only when at least a type is registered"", getCurrentTypes().length > 0);
        for (Operator op : Operator.values()) {
            BooleanClause.Occur defaultOp = op.toBooleanClauseOccur();
            QueryStringQueryParser queryParser = new QueryStringQueryParser(createShardContext(), STRING_FIELD_NAME);
            queryParser.setAnalyzeWildcard(true);
            queryParser.setMultiTermRewriteMethod(MultiTermQuery.CONSTANT_SCORE_REWRITE);
            queryParser.setDefaultOperator(op.toQueryParserOperator());
            queryParser.setForceAnalyzer(new MockRepeatAnalyzer());
            Query query = queryParser.parse(""first foo-bar-foobar* last"");

            Query expectedQuery = new BooleanQuery.Builder()
                .add(new BooleanClause(new SynonymQuery(new Term(STRING_FIELD_NAME, ""first""),
                    new Term(STRING_FIELD_NAME, ""first"")), defaultOp))
                .add(new BooleanQuery.Builder()
                    .add(new BooleanClause(new SynonymQuery(new Term(STRING_FIELD_NAME, ""foo""),
                        new Term(STRING_FIELD_NAME, ""foo"")), defaultOp))
                    .add(new BooleanClause(new SynonymQuery(new Term(STRING_FIELD_NAME, ""bar""),
                        new Term(STRING_FIELD_NAME, ""bar"")), defaultOp))
                    .add(new BooleanQuery.Builder()
                        .add(new BooleanClause(new PrefixQuery(new Term(STRING_FIELD_NAME, ""foobar"")),
                            BooleanClause.Occur.SHOULD))
                        .add(new BooleanClause(new PrefixQuery(new Term(STRING_FIELD_NAME, ""foobar"")),
                            BooleanClause.Occur.SHOULD))
                        .build(), defaultOp)
                    .build(), defaultOp)
                .add(new BooleanClause(new SynonymQuery(new Term(STRING_FIELD_NAME, ""last""),
                    new Term(STRING_FIELD_NAME, ""last"")), defaultOp))
                .build();
            assertThat(query, Matchers.equalTo(expectedQuery));
        }
    }",/server/src/test/java/org/elasticsearch/index/query/QueryStringQueryBuilderTests.java
55c8e805320c1ab51288396e005cffaf14adc008,690,892,"protected boolean doEquals(QueryStringQueryBuilder other) {
        return Objects.equals(queryString, other.queryString) &&
                Objects.equals(defaultField, other.defaultField) &&
                Objects.equals(fieldsAndWeights, other.fieldsAndWeights) &&
                Objects.equals(defaultOperator, other.defaultOperator) &&
                Objects.equals(analyzer, other.analyzer) &&
                Objects.equals(quoteAnalyzer, other.quoteAnalyzer) &&
                Objects.equals(quoteFieldSuffix, other.quoteFieldSuffix) &&
                Objects.equals(allowLeadingWildcard, other.allowLeadingWildcard) &&
                Objects.equals(enablePositionIncrements, other.enablePositionIncrements) &&
                Objects.equals(analyzeWildcard, other.analyzeWildcard) &&
                Objects.equals(fuzziness, other.fuzziness) &&
                Objects.equals(fuzzyPrefixLength, other.fuzzyPrefixLength) &&
                Objects.equals(fuzzyMaxExpansions, other.fuzzyMaxExpansions) &&
                Objects.equals(fuzzyRewrite, other.fuzzyRewrite) &&
                Objects.equals(phraseSlop, other.phraseSlop) &&
                Objects.equals(type, other.type) &&
                Objects.equals(tieBreaker, other.tieBreaker) &&
                Objects.equals(rewrite, other.rewrite) &&
                Objects.equals(minimumShouldMatch, other.minimumShouldMatch) &&
                Objects.equals(lenient, other.lenient) &&
                timeZone == null ? other.timeZone == null : other.timeZone != null &&
                Objects.equals(timeZone.getID(), other.timeZone.getID()) &&
                Objects.equals(escape, other.escape) &&
                Objects.equals(maxDeterminizedStates, other.maxDeterminizedStates) &&
                Objects.equals(autoGenerateSynonymsPhraseQuery, other.autoGenerateSynonymsPhraseQuery) &&
                Objects.equals(fuzzyTranspositions, other.fuzzyTranspositions);
    }","protected boolean doEquals(QueryStringQueryBuilder other) {
        return Objects.equals(queryString, other.queryString) &&
                Objects.equals(defaultField, other.defaultField) &&
                Objects.equals(fieldsAndWeights, other.fieldsAndWeights) &&
                Objects.equals(defaultOperator, other.defaultOperator) &&
                Objects.equals(analyzer, other.analyzer) &&
                Objects.equals(quoteAnalyzer, other.quoteAnalyzer) &&
                Objects.equals(quoteFieldSuffix, other.quoteFieldSuffix) &&
                Objects.equals(allowLeadingWildcard, other.allowLeadingWildcard) &&
                Objects.equals(enablePositionIncrements, other.enablePositionIncrements) &&
                Objects.equals(analyzeWildcard, other.analyzeWildcard) &&
                Objects.equals(fuzziness, other.fuzziness) &&
                Objects.equals(fuzzyPrefixLength, other.fuzzyPrefixLength) &&
                Objects.equals(fuzzyMaxExpansions, other.fuzzyMaxExpansions) &&
                Objects.equals(fuzzyRewrite, other.fuzzyRewrite) &&
                Objects.equals(phraseSlop, other.phraseSlop) &&
                Objects.equals(type, other.type) &&
                Objects.equals(tieBreaker, other.tieBreaker) &&
                Objects.equals(rewrite, other.rewrite) &&
                Objects.equals(minimumShouldMatch, other.minimumShouldMatch) &&
                Objects.equals(lenient, other.lenient) && 
                Objects.equals(
                        timeZone == null ? null : timeZone.getID(), 
                        other.timeZone == null ? null : other.timeZone.getID()) &&
                Objects.equals(escape, other.escape) &&
                Objects.equals(maxDeterminizedStates, other.maxDeterminizedStates) &&
                Objects.equals(autoGenerateSynonymsPhraseQuery, other.autoGenerateSynonymsPhraseQuery) &&
                Objects.equals(fuzzyTranspositions, other.fuzzyTranspositions);
    }",/server/src/main/java/org/elasticsearch/index/query/QueryStringQueryBuilder.java
22c77f9fdbca096850a1146d2da1010f8f180541,125,115,"public void testParseFileNotExists() throws IllegalAccessException, IOException {
        Logger logger = CapturingLogger.newCapturingLogger(Level.TRACE, null);
        final List<String> events = CapturingLogger.output(logger.getName(), Level.TRACE);
        events.clear();
        final Map<String, char[]> tokenHashes =
            FileServiceAccountTokenStore.parseFile(getDataPath(""service_tokens"").getParent().resolve(""does-not-exist""), logger);
        assertThat(tokenHashes.isEmpty(), is(true));
        assertThat(events.size(), equalTo(2));
        assertThat(events.get(1), containsString(""does not exist""));
    }","public void testParseFileNotExists() throws IllegalAccessException, IOException {
        Logger logger = CapturingLogger.newCapturingLogger(Level.TRACE, null);
        final List<String> events = CapturingLogger.output(logger.getName(), Level.TRACE);
        events.clear();
        final Map<String, char[]> tokenHashes =
            FileServiceAccountTokenStore.parseFile(getDataPath(""service_tokens"").getParent().resolve(""does-not-exist""), logger);
        assertThat(tokenHashes.isEmpty(), is(true));
        assertThat(events, hasSize(2));
        assertThat(events.get(1), containsString(""does not exist""));
    }",/x-pack/plugin/security/src/test/java/org/elasticsearch/xpack/security/authc/service/FileServiceAccountTokenStoreTests.java
154dcf007e655cd9637ebfac7e2af5af09b15b7c,628,48,"public static void decodeQueryString(String queryString, int fromIndex, Map<String, String> params) {
        if (fromIndex < 0) {
            return;
        }
        if (fromIndex >= queryString.length()) {
            return;
        }
        int toIndex;
        while ((toIndex = queryString.indexOf('&', fromIndex)) >= 0) {
            int idx = queryString.indexOf('=', fromIndex);
            if (idx < 0) {
                continue;
            }
            params.put(decodeComponent(queryString.substring(fromIndex, idx)), decodeComponent(queryString.substring(idx + 1, toIndex)));
            fromIndex = toIndex + 1;
        }
        int idx = queryString.indexOf('=', fromIndex);
        if (idx < 0) {
            return;
        }
        params.put(decodeComponent(queryString.substring(fromIndex, idx)), decodeComponent(queryString.substring(idx + 1)));
    }","public static void decodeQueryString(String queryString, int fromIndex, Map<String, String> params) {
        if (fromIndex < 0) {
            return;
        }
        if (fromIndex >= queryString.length()) {
            return;
        }
        int toIndex;
        while ((toIndex = queryString.indexOf('&', fromIndex)) >= 0) {
            int idx = queryString.indexOf('=', fromIndex);
            if (fromIndex < idx && idx < toIndex) {
                params.put(decodeComponent(queryString.substring(fromIndex, idx)), decodeComponent(queryString.substring(idx + 1, toIndex)));
            }
            fromIndex = toIndex + 1;
        }
        int idx = queryString.indexOf('=', fromIndex);
        if (idx < 0) {
            return;
        }
        params.put(decodeComponent(queryString.substring(fromIndex, idx)), decodeComponent(queryString.substring(idx + 1)));
    }",/modules/elasticsearch/src/main/java/org/elasticsearch/rest/support/RestUtils.java
b50b81e9740842c43b757c5de4c0332a810a8857,570,496,"private Store.MetadataSnapshot generateRandomTargetState(Store store) throws IOException {
        final Store.MetadataSnapshot targetMetadataSnapshot;
        if (randomBoolean()) {
            // The target can share some files with the source
            writeRandomDocs(store, randomIntBetween(20, 50));
            targetMetadataSnapshot = store.getMetadata(null);
        } else {
            if (randomBoolean()) {
                targetMetadataSnapshot = Store.MetadataSnapshot.EMPTY;
            } else {
                // None of the files in the target would match
                final int filesInTargetCount = randomIntBetween(1, 20);
                Map<String, StoreFileMetadata> filesInTarget = IntStream.range(0, filesInTargetCount)
                    .mapToObj(i -> randomStoreFileMetadata())
                    .collect(Collectors.toMap(StoreFileMetadata::name, Function.identity()));
                targetMetadataSnapshot = new Store.MetadataSnapshot(filesInTarget, Collections.emptyMap(), 0);
            }
        }
        return targetMetadataSnapshot;
    }","Store.MetadataSnapshot sourceMetadataSnapshot) {
        for (StoreFileMetadata sourceFile : shardRecoveryPlan.getSourceFilesToRecover()) {
            final StoreFileMetadata actual = sourceMetadataSnapshot.get(sourceFile.name());
            assertThat(actual, is(notNullValue()));
            assertThat(actual.isSame(sourceFile), is(equalTo(true)));
        }
    }",/server/src/test/java/org/elasticsearch/indices/recovery/plan/SnapshotsRecoveryPlannerServiceTests.java
b50b81e9740842c43b757c5de4c0332a810a8857,570,1433,"private static List<Translog.Operation> generateOperations(int numOps) {
        final List<Translog.Operation> operations = new ArrayList<>(numOps);
        final byte[] source = ""{}"".getBytes(StandardCharsets.UTF_8);
        final Set<Long> seqNos = new HashSet<>();
        for (int i = 0; i < numOps; i++) {
            final long seqNo = randomValueOtherThanMany(n -> seqNos.add(n) == false, ESTestCase::randomNonNegativeLong);
            final Translog.Operation op;
            if (randomBoolean()) {
                op = new Translog.Index(""id"", seqNo, randomNonNegativeLong(), randomNonNegativeLong(), source, null, -1);
            } else if (randomBoolean()) {
                op = new Translog.Delete(""id"", seqNo, randomNonNegativeLong(), randomNonNegativeLong());
            } else {
                op = new Translog.NoOp(seqNo, randomNonNegativeLong(), ""test"");
            }
            operations.add(op);
        }
        return operations;
    }","private ShardRecoveryPlan createShardRecoveryPlan(Store store, int sourceFileCount, int snapshotFileCount) throws Exception {
        List<StoreFileMetadata> sourceFiles = generateFiles(store, snapshotFileCount + sourceFileCount, () -> randomIntBetween(1, 100));
        Store.MetadataSnapshot metadata = new Store.MetadataSnapshot(
            sourceFiles.stream().collect(Collectors.toMap(StoreFileMetadata::name, Function.identity())),
            emptyMap(),
            0
        );

        ByteSizeValue partSize = new ByteSizeValue(Long.MAX_VALUE, ByteSizeUnit.BYTES);

        List<StoreFileMetadata> filesToRecoverFromSource = sourceFiles.subList(0, sourceFileCount);
        List<StoreFileMetadata> filesToRecoverFromSnapshot = sourceFiles.subList(sourceFileCount, sourceFiles.size());

        List<BlobStoreIndexShardSnapshot.FileInfo> snapshotFiles = new ArrayList<>(snapshotFileCount);
        for (StoreFileMetadata storeFileMetadata : filesToRecoverFromSnapshot) {
            snapshotFiles.add(new BlobStoreIndexShardSnapshot.FileInfo(storeFileMetadata.name(), storeFileMetadata, partSize));
        }

        IndexId indexId = new IndexId(""index"", ""id"");
        String repository = ""repo"";
        ShardRecoveryPlan.SnapshotFilesToRecover snapshotFilesToRecover = new ShardRecoveryPlan.SnapshotFilesToRecover(indexId,
            repository,
            snapshotFiles
        );

        return new ShardRecoveryPlan(snapshotFilesToRecover,
            filesToRecoverFromSource,
            emptyList(),
            0,
            0,
            metadata
        );
    }",/server/src/test/java/org/elasticsearch/indices/recovery/RecoverySourceHandlerTests.java
b50b81e9740842c43b757c5de4c0332a810a8857,670,734,"private long getSnapshotSizeForIndex(String repository, String snapshot, String index) {
        GetSnapshotsResponse getSnapshotsResponse =
            client().admin().cluster().prepareGetSnapshots(repository).addSnapshots(snapshot).get();
        for (SnapshotInfo snapshotInfo : getSnapshotsResponse.getSnapshots()) {
            SnapshotInfo.IndexSnapshotDetails indexSnapshotDetails = snapshotInfo.indexSnapshotDetails().get(index);
            assertThat(indexSnapshotDetails, is(notNullValue()));
            return indexSnapshotDetails.getSize().getBytes();
        }

        return -1;
    }","public void testRecoveryConcurrentlyWithIndexing() throws Exception {
        internalCluster().startDataOnlyNode();
        String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);
        createIndex(indexName,
            Settings.builder()
                .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)
                .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)
                .put(MergePolicyConfig.INDEX_MERGE_ENABLED, false)
                .put(IndexService.GLOBAL_CHECKPOINT_SYNC_INTERVAL_SETTING.getKey(), ""1s"")
                .build()
        );

        AtomicInteger numDocs = new AtomicInteger(randomIntBetween(1, 1000));
        indexDocs(indexName, 0, numDocs.get());

        String repoName = ""repo"";
        createRepo(repoName, TestRepositoryPlugin.INSTRUMENTED_TYPE);
        createSnapshot(repoName, ""snap"", Collections.singletonList(indexName));

        long snapshotSizeForIndex = getSnapshotSizeForIndex(repoName, ""snap"", indexName);

        assertAcked(
            client().admin().indices().prepareUpdateSettings(indexName)
                .setSettings(Settings.builder()
                    .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1))
        );

        boolean waitForSnapshotDownloadToStart = randomBoolean();
        if (waitForSnapshotDownloadToStart) {
            // wait for the snapshot download to start.
            assertBusy(() -> {
                RecoveryState recoveryState = getLatestPeerRecoveryStateForShard(indexName, 0);
                assertThat(recoveryState.getIndex().recoveredBytes(), greaterThan(0L));
            });
        }

        // busy wait to complete and add a bit of indexing.
        assertBusy(() -> {
            if (randomBoolean()) {
                int moreDocs = between(1, 5);
                indexDocs(indexName, numDocs.getAndAdd(moreDocs), moreDocs);
            }
            RecoveryState recoveryState = getLatestPeerRecoveryStateForShard(indexName, 0);
            assertThat(recoveryState.getStage(), equalTo(RecoveryState.Stage.DONE));
        });

        ensureGreen(indexName);

        if (waitForSnapshotDownloadToStart) {
            // must complete using snapshots alone.
            RecoveryState recoveryState = getLatestPeerRecoveryStateForShard(indexName, 0);
            assertThat(recoveryState.getIndex().recoveredFromSnapshotBytes(), equalTo(snapshotSizeForIndex));
        }

        assertDocumentsAreEqual(indexName, numDocs.get());
    }",/server/src/internalClusterTest/java/org/elasticsearch/indices/recovery/SnapshotBasedIndexRecoveryIT.java
6484f812c05dd537d5bbbd6a7907efa5971e13a6,628,296,"public void testEquals_GivenSameReference() {
        AnalysisConfig config = createFullyPopulatedConfig();
        assertTrue(config.equals(config));
    }","public void testBuild_GivenNestedFieldOverlapsNonNested() {
        Detector.Builder detector1 = new Detector.Builder();
        detector1.setFunction(""count"");
        detector1.setByFieldName(""a"");
        Detector.Builder detector2 = new Detector.Builder();
        detector2.setFunction(""count"");
        detector2.setPartitionFieldName(""a.b"");
        AnalysisConfig.Builder ac = new AnalysisConfig.Builder(Arrays.asList(detector1.build(), detector2.build()));

        ElasticsearchException e = expectThrows(ElasticsearchException.class, ac::build);
        assertThat(e.getMessage(), equalTo(""Fields a and a.b cannot both be used in the same analysis_config""));
    }",/plugin/src/test/java/org/elasticsearch/xpack/ml/job/config/AnalysisConfigTests.java
6484f812c05dd537d5bbbd6a7907efa5971e13a6,570,535,"public void testVerify_OverlappingBuckets() {
        List<Detector> detectors;
        Detector detector;

        boolean onByDefault = false;

        // Uncomment this when overlappingBuckets turned on by default
        if (onByDefault) {
            // Test overlappingBuckets unset
            AnalysisConfig.Builder analysisConfig = createValidConfig();
            analysisConfig.setBucketSpan(TimeValue.timeValueSeconds(5000L));
            detectors = new ArrayList<>();
            detector = new Detector.Builder(""count"", null).build();
            detectors.add(detector);
            detector = new Detector.Builder(""mean"", ""value"").build();
            detectors.add(detector);
            analysisConfig.setDetectors(detectors);
            AnalysisConfig ac = analysisConfig.build();
            assertTrue(ac.getOverlappingBuckets());

            // Test overlappingBuckets unset
            analysisConfig = createValidConfig();
            analysisConfig.setBucketSpan(TimeValue.timeValueSeconds(5000L));
            detectors = new ArrayList<>();
            detector = new Detector.Builder(""count"", null).build();
            detectors.add(detector);
            detector = new Detector.Builder(""rare"", ""value"").build();
            detectors.add(detector);
            analysisConfig.setDetectors(detectors);
            ac = analysisConfig.build();
            assertFalse(ac.getOverlappingBuckets());

            // Test overlappingBuckets unset
            analysisConfig = createValidConfig();
            analysisConfig.setBucketSpan(TimeValue.timeValueSeconds(5000L));
            detectors = new ArrayList<>();
            detector = new Detector.Builder(""count"", null).build();
            detectors.add(detector);
            detector = new Detector.Builder(""min"", ""value"").build();
            detectors.add(detector);
            detector = new Detector.Builder(""max"", ""value"").build();
            detectors.add(detector);
            analysisConfig.setDetectors(detectors);
            ac = analysisConfig.build();
            assertFalse(ac.getOverlappingBuckets());
        }

        // Test overlappingBuckets set
        AnalysisConfig.Builder analysisConfig = createValidConfig();
        analysisConfig.setBucketSpan(TimeValue.timeValueSeconds(5000L));
        detectors = new ArrayList<>();
        detector = new Detector.Builder(""count"", null).build();
        detectors.add(detector);
        Detector.Builder builder = new Detector.Builder(""rare"", null);
        builder.setByFieldName(""value"");
        detectors.add(builder.build());
        analysisConfig.setOverlappingBuckets(false);
        analysisConfig.setDetectors(detectors);
        assertFalse(analysisConfig.build().getOverlappingBuckets());

        // Test overlappingBuckets set
        analysisConfig = createValidConfig();
        analysisConfig.setBucketSpan(TimeValue.timeValueSeconds(5000L));
        analysisConfig.setOverlappingBuckets(true);
        detectors = new ArrayList<>();
        detector = new Detector.Builder(""count"", null).build();
        detectors.add(detector);
        builder = new Detector.Builder(""rare"", null);
        builder.setByFieldName(""value"");
        detectors.add(builder.build());
        analysisConfig.setDetectors(detectors);
        IllegalArgumentException e = ESTestCase.expectThrows(IllegalArgumentException.class, analysisConfig::build);
        assertEquals(""Overlapping buckets cannot be used with function '[rare]'"", e.getMessage());

        // Test overlappingBuckets set
        analysisConfig = createValidConfig();
        analysisConfig.setBucketSpan(TimeValue.timeValueSeconds(5000L));
        analysisConfig.setOverlappingBuckets(false);
        detectors = new ArrayList<>();
        detector = new Detector.Builder(""count"", null).build();
        detectors.add(detector);
        detector = new Detector.Builder(""mean"", ""value"").build();
        detectors.add(detector);
        analysisConfig.setDetectors(detectors);
        AnalysisConfig ac = analysisConfig.build();
        assertFalse(ac.getOverlappingBuckets());
    }","public void testVerify_GivenNegativeLatency() {
        AnalysisConfig.Builder analysisConfig = createValidConfig();
        analysisConfig.setLatency(TimeValue.timeValueSeconds(-1));

        IllegalArgumentException e = ESTestCase.expectThrows(IllegalArgumentException.class, analysisConfig::build);

        assertEquals(""latency cannot be less than 0. Value = -1"", e.getMessage());
    }",/plugin/src/test/java/org/elasticsearch/xpack/ml/job/config/AnalysisConfigTests.java
6484f812c05dd537d5bbbd6a7907efa5971e13a6,1024,300,"public void testEquals_GivenDifferentClass() {
        assertFalse(createFullyPopulatedConfig().equals(""a string""));
    }","public void testBuild_GivenNestedFieldOverlapsNonNested() {
        Detector.Builder detector1 = new Detector.Builder();
        detector1.setFunction(""count"");
        detector1.setByFieldName(""a"");
        Detector.Builder detector2 = new Detector.Builder();
        detector2.setFunction(""count"");
        detector2.setPartitionFieldName(""a.b"");
        AnalysisConfig.Builder ac = new AnalysisConfig.Builder(Arrays.asList(detector1.build(), detector2.build()));

        ElasticsearchException e = expectThrows(ElasticsearchException.class, ac::build);
        assertThat(e.getMessage(), equalTo(""Fields a and a.b cannot both be used in the same analysis_config""));
    }",/plugin/src/test/java/org/elasticsearch/xpack/ml/job/config/AnalysisConfigTests.java
6484f812c05dd537d5bbbd6a7907efa5971e13a6,563,472,"public void testVerify_throws() {
        // count works with no fields
        Detector d = new Detector.Builder(""count"", null).build();
        new AnalysisConfig.Builder(Collections.singletonList(d)).build();

        try {
            d = new Detector.Builder(""distinct_count"", null).build();
            new AnalysisConfig.Builder(Collections.singletonList(d)).build();
            assertTrue(false); // shouldn't get here
        } catch (IllegalArgumentException e) {
            assertEquals(""Unless the function is 'count' one of field_name, by_field_name or over_field_name must be set"", e.getMessage());
        }

        // should work now
        Detector.Builder builder = new Detector.Builder(""distinct_count"", ""somefield"");
        builder.setOverFieldName(""over_field"");
        new AnalysisConfig.Builder(Collections.singletonList(builder.build())).build();

        builder = new Detector.Builder(""info_content"", ""somefield"");
        builder.setOverFieldName(""over_field"");
        d = builder.build();
        new AnalysisConfig.Builder(Collections.singletonList(builder.build())).build();

        builder.setByFieldName(""by_field"");
        new AnalysisConfig.Builder(Collections.singletonList(builder.build())).build();

        try {
            builder = new Detector.Builder(""made_up_function"", ""somefield"");
            builder.setOverFieldName(""over_field"");
            new AnalysisConfig.Builder(Collections.singletonList(builder.build())).build();
            assertTrue(false); // shouldn't get here
        } catch (IllegalArgumentException e) {
            assertEquals(""Unknown function 'made_up_function'"", e.getMessage());
        }
    }","private static AnalysisConfig createFullyPopulatedConfig() {
        Detector.Builder detector = new Detector.Builder(""min"", ""count"");
        detector.setOverFieldName(""mlcategory"");
        AnalysisConfig.Builder builder = new AnalysisConfig.Builder(
                Collections.singletonList(detector.build()));
        builder.setBucketSpan(TimeValue.timeValueHours(1));
        builder.setCategorizationFieldName(""cat"");
        builder.setCategorizationFilters(Collections.singletonList(""foo""));
        builder.setInfluencers(Collections.singletonList(""myInfluencer""));
        builder.setLatency(TimeValue.timeValueSeconds(3600));
        builder.setSummaryCountFieldName(""sumCount"");
        return builder.build();
    }",/plugin/src/test/java/org/elasticsearch/xpack/ml/job/config/AnalysisConfigTests.java
95eac4e806b2be2f85d2748df1b7211c73d5e339,682,201,"private static void checkGrouped(String prefix, String grouping, String op, AggregationType aggType, Page page) {
        switch (grouping) {
            case LONGS -> {
                LongBlock groups = page.getBlock(0);
                for (int g = 0; g < GROUPS; g++) {
                    if (groups.getLong(g) != (long) g) {
                        throw new AssertionError(prefix + ""bad group expected ["" + g + ""] but was ["" + groups.getLong(g) + ""]"");
                    }
                }
            }
            case INTS -> {
                IntBlock groups = page.getBlock(0);
                for (int g = 0; g < GROUPS; g++) {
                    if (groups.getInt(g) != g) {
                        throw new AssertionError(prefix + ""bad group expected ["" + g + ""] but was ["" + groups.getInt(g) + ""]"");
                    }
                }
            }
            case DOUBLES -> {
                DoubleBlock groups = page.getBlock(0);
                for (int g = 0; g < GROUPS; g++) {
                    if (groups.getDouble(g) != (double) g) {
                        throw new AssertionError(prefix + ""bad group expected ["" + (double) g + ""] but was ["" + groups.getDouble(g) + ""]"");
                    }
                }
            }
            case BOOLEANS -> {
                BooleanBlock groups = page.getBlock(0);
                if (groups.getBoolean(0) != false) {
                    throw new AssertionError(prefix + ""bad group expected [false] but was ["" + groups.getBoolean(0) + ""]"");
                }
                if (groups.getBoolean(1) != true) {
                    throw new AssertionError(prefix + ""bad group expected [true] but was ["" + groups.getBoolean(1) + ""]"");
                }
            }
            case BYTES_REFS -> {
                BytesRefBlock groups = page.getBlock(0);
                for (int g = 0; g < GROUPS; g++) {
                    if (false == groups.getBytesRef(g, new BytesRef()).equals(bytesGroup(g))) {
                        throw new AssertionError(
                            prefix + ""bad group expected ["" + bytesGroup(g) + ""] but was ["" + groups.getBytesRef(g, new BytesRef()) + ""]""
                        );
                    }
                }
            }
            default -> throw new IllegalArgumentException(""bad grouping ["" + grouping + ""]"");
        }
        Block values = page.getBlock(1);
        int groups = switch (grouping) {
            case BOOLEANS -> 2;
            default -> GROUPS;
        };
        switch (op) {
            case AVG -> {
                DoubleBlock dValues = (DoubleBlock) values;
                for (int g = 0; g < groups; g++) {
                    long group = g;
                    long sum = LongStream.range(0, BLOCK_LENGTH).filter(l -> l % groups == group).sum();
                    long count = LongStream.range(0, BLOCK_LENGTH).filter(l -> l % groups == group).count();
                    double expected = (double) sum / count;
                    if (dValues.getDouble(g) != expected) {
                        throw new AssertionError(prefix + ""expected ["" + expected + ""] but was ["" + dValues.getDouble(g) + ""]"");
                    }
                }
            }
            case COUNT -> {
                LongBlock lValues = (LongBlock) values;
                for (int g = 0; g < groups; g++) {
                    long group = g;
                    long expected = LongStream.range(0, BLOCK_LENGTH).filter(l -> l % groups == group).count() * 1024;
                    if (lValues.getLong(g) != expected) {
                        throw new AssertionError(prefix + ""expected ["" + expected + ""] but was ["" + lValues.getLong(g) + ""]"");
                    }
                }
            }
            case MIN -> {
                switch (aggType) {
                    case longs -> {
                        LongBlock lValues = (LongBlock) values;
                        for (int g = 0; g < groups; g++) {
                            if (lValues.getLong(g) != (long) g) {
                                throw new AssertionError(prefix + ""expected ["" + g + ""] but was ["" + lValues.getLong(g) + ""]"");
                            }
                        }
                    }
                    case doubles -> {
                        DoubleBlock dValues = (DoubleBlock) values;
                        for (int g = 0; g < groups; g++) {
                            if (dValues.getDouble(g) != (long) g) {
                                throw new AssertionError(prefix + ""expected ["" + g + ""] but was ["" + dValues.getDouble(g) + ""]"");
                            }
                        }
                    }
                }
            }
            case MAX -> {
                switch (aggType) {
                    case longs -> {
                        LongBlock lValues = (LongBlock) values;
                        for (int g = 0; g < groups; g++) {
                            long group = g;
                            long expected = LongStream.range(0, BLOCK_LENGTH).filter(l -> l % groups == group).max().getAsLong();
                            if (lValues.getLong(g) != expected) {
                                throw new AssertionError(prefix + ""expected ["" + expected + ""] but was ["" + lValues.getLong(g) + ""]"");
                            }
                        }
                    }
                    case doubles -> {
                        DoubleBlock dValues = (DoubleBlock) values;
                        for (int g = 0; g < groups; g++) {
                            long group = g;
                            long expected = LongStream.range(0, BLOCK_LENGTH).filter(l -> l % groups == group).max().getAsLong();
                            if (dValues.getDouble(g) != expected) {
                                throw new AssertionError(prefix + ""expected ["" + expected + ""] but was ["" + dValues.getDouble(g) + ""]"");
                            }
                        }
                    }
                }
            }
            case SUM -> {
                switch (aggType) {
                    case longs -> {
                        LongBlock lValues = (LongBlock) values;
                        for (int g = 0; g < groups; g++) {
                            long group = g;
                            long expected = LongStream.range(0, BLOCK_LENGTH).filter(l -> l % groups == group).sum() * 1024;
                            if (lValues.getLong(g) != expected) {
                                throw new AssertionError(prefix + ""expected ["" + expected + ""] but was ["" + lValues.getLong(g) + ""]"");
                            }
                        }
                    }
                    case doubles -> {
                        DoubleBlock dValues = (DoubleBlock) values;
                        for (int g = 0; g < groups; g++) {
                            long group = g;
                            long expected = LongStream.range(0, BLOCK_LENGTH).filter(l -> l % groups == group).sum() * 1024;
                            if (dValues.getDouble(g) != expected) {
                                throw new AssertionError(prefix + ""expected ["" + expected + ""] but was ["" + dValues.getDouble(g) + ""]"");
                            }
                        }
                    }
                }
            }
            default -> throw new IllegalArgumentException(""bad op "" + op);
        }
    }","private static void checkGrouped(String prefix, String grouping, String op, AggregationType aggType, Page page) {
        switch (grouping) {
            case TWO_LONGS -> {
                checkGroupingBlock(prefix, LONGS, page.getBlock(0));
                checkGroupingBlock(prefix, LONGS, page.getBlock(1));
            }
            case LONGS_AND_BYTES_REFS -> {
                checkGroupingBlock(prefix, LONGS, page.getBlock(0));
                checkGroupingBlock(prefix, BYTES_REFS, page.getBlock(1));
            }
            default -> checkGroupingBlock(prefix, grouping, page.getBlock(0));
        }
        Block values = page.getBlock(page.getBlockCount() - 1);
        int groups = switch (grouping) {
            case BOOLEANS -> 2;
            default -> GROUPS;
        };
        switch (op) {
            case AVG -> {
                DoubleBlock dValues = (DoubleBlock) values;
                for (int g = 0; g < groups; g++) {
                    long group = g;
                    long sum = LongStream.range(0, BLOCK_LENGTH).filter(l -> l % groups == group).sum();
                    long count = LongStream.range(0, BLOCK_LENGTH).filter(l -> l % groups == group).count();
                    double expected = (double) sum / count;
                    if (dValues.getDouble(g) != expected) {
                        throw new AssertionError(prefix + ""expected ["" + expected + ""] but was ["" + dValues.getDouble(g) + ""]"");
                    }
                }
            }
            case COUNT -> {
                LongBlock lValues = (LongBlock) values;
                for (int g = 0; g < groups; g++) {
                    long group = g;
                    long expected = LongStream.range(0, BLOCK_LENGTH).filter(l -> l % groups == group).count() * 1024;
                    if (lValues.getLong(g) != expected) {
                        throw new AssertionError(prefix + ""expected ["" + expected + ""] but was ["" + lValues.getLong(g) + ""]"");
                    }
                }
            }
            case MIN -> {
                switch (aggType) {
                    case longs -> {
                        LongBlock lValues = (LongBlock) values;
                        for (int g = 0; g < groups; g++) {
                            if (lValues.getLong(g) != (long) g) {
                                throw new AssertionError(prefix + ""expected ["" + g + ""] but was ["" + lValues.getLong(g) + ""]"");
                            }
                        }
                    }
                    case doubles -> {
                        DoubleBlock dValues = (DoubleBlock) values;
                        for (int g = 0; g < groups; g++) {
                            if (dValues.getDouble(g) != (long) g) {
                                throw new AssertionError(prefix + ""expected ["" + g + ""] but was ["" + dValues.getDouble(g) + ""]"");
                            }
                        }
                    }
                }
            }
            case MAX -> {
                switch (aggType) {
                    case longs -> {
                        LongBlock lValues = (LongBlock) values;
                        for (int g = 0; g < groups; g++) {
                            long group = g;
                            long expected = LongStream.range(0, BLOCK_LENGTH).filter(l -> l % groups == group).max().getAsLong();
                            if (lValues.getLong(g) != expected) {
                                throw new AssertionError(prefix + ""expected ["" + expected + ""] but was ["" + lValues.getLong(g) + ""]"");
                            }
                        }
                    }
                    case doubles -> {
                        DoubleBlock dValues = (DoubleBlock) values;
                        for (int g = 0; g < groups; g++) {
                            long group = g;
                            long expected = LongStream.range(0, BLOCK_LENGTH).filter(l -> l % groups == group).max().getAsLong();
                            if (dValues.getDouble(g) != expected) {
                                throw new AssertionError(prefix + ""expected ["" + expected + ""] but was ["" + dValues.getDouble(g) + ""]"");
                            }
                        }
                    }
                }
            }
            case SUM -> {
                switch (aggType) {
                    case longs -> {
                        LongBlock lValues = (LongBlock) values;
                        for (int g = 0; g < groups; g++) {
                            long group = g;
                            long expected = LongStream.range(0, BLOCK_LENGTH).filter(l -> l % groups == group).sum() * 1024;
                            if (lValues.getLong(g) != expected) {
                                throw new AssertionError(prefix + ""expected ["" + expected + ""] but was ["" + lValues.getLong(g) + ""]"");
                            }
                        }
                    }
                    case doubles -> {
                        DoubleBlock dValues = (DoubleBlock) values;
                        for (int g = 0; g < groups; g++) {
                            long group = g;
                            long expected = LongStream.range(0, BLOCK_LENGTH).filter(l -> l % groups == group).sum() * 1024;
                            if (dValues.getDouble(g) != expected) {
                                throw new AssertionError(prefix + ""expected ["" + expected + ""] but was ["" + dValues.getDouble(g) + ""]"");
                            }
                        }
                    }
                }
            }
            default -> throw new IllegalArgumentException(""bad op "" + op);
        }
    }",/benchmarks/src/main/java/org/elasticsearch/benchmark/compute/operation/AggregatorBenchmark.java
95eac4e806b2be2f85d2748df1b7211c73d5e339,682,293,"private static void checkUngrouped(String prefix, String op, AggregationType aggType, Page page) {
        Block block = page.getBlock(0);
        switch (op) {
            case AVG -> {
                DoubleBlock dBlock = (DoubleBlock) block;
                if (dBlock.getDouble(0) != (BLOCK_LENGTH - 1) / 2.0) {
                    throw new AssertionError(
                        prefix + ""expected ["" + ((BLOCK_LENGTH - 1) / 2.0) + ""] but was ["" + dBlock.getDouble(0) + ""]""
                    );
                }
            }
            case COUNT -> {
                LongBlock lBlock = (LongBlock) block;
                if (lBlock.getLong(0) != BLOCK_LENGTH * 1024) {
                    throw new AssertionError(prefix + ""expected ["" + (BLOCK_LENGTH * 1024) + ""] but was ["" + lBlock.getLong(0) + ""]"");
                }
            }
            case MIN -> {
                long expected = 0L;
                var val = switch (aggType) {
                    case longs -> ((LongBlock) block).getLong(0);
                    case doubles -> ((DoubleBlock) block).getDouble(0);
                    default -> throw new IllegalStateException(""Unexpected aggregation type: "" + aggType);
                };
                if (val != expected) {
                    throw new AssertionError(prefix + ""expected ["" + expected + ""] but was ["" + val + ""]"");
                }
            }
            case MAX -> {
                long expected = BLOCK_LENGTH - 1;
                var val = switch (aggType) {
                    case longs -> ((LongBlock) block).getLong(0);
                    case doubles -> ((DoubleBlock) block).getDouble(0);
                    default -> throw new IllegalStateException(""Unexpected aggregation type: "" + aggType);
                };
                if (val != expected) {
                    throw new AssertionError(prefix + ""expected ["" + expected + ""] but was ["" + val + ""]"");
                }
            }
            case SUM -> {
                long expected = (BLOCK_LENGTH * (BLOCK_LENGTH - 1L)) * 1024L / 2;
                var val = switch (aggType) {
                    case longs -> ((LongBlock) block).getLong(0);
                    case doubles -> ((DoubleBlock) block).getDouble(0);
                    default -> throw new IllegalStateException(""Unexpected aggregation type: "" + aggType);
                };
                if (val != expected) {
                    throw new AssertionError(prefix + ""expected ["" + expected + ""] but was ["" + val + ""]"");
                }
            }
            default -> throw new IllegalArgumentException(""bad op "" + op);
        }
    }","private static void checkGroupingBlock(String prefix, String grouping, Block block) {
        switch (grouping) {
            case LONGS -> {
                LongBlock groups = (LongBlock) block;
                for (int g = 0; g < GROUPS; g++) {
                    if (groups.getLong(g) != (long) g) {
                        throw new AssertionError(prefix + ""bad group expected ["" + g + ""] but was ["" + groups.getLong(g) + ""]"");
                    }
                }
            }
            case INTS -> {
                IntBlock groups = (IntBlock) block;
                for (int g = 0; g < GROUPS; g++) {
                    if (groups.getInt(g) != g) {
                        throw new AssertionError(prefix + ""bad group expected ["" + g + ""] but was ["" + groups.getInt(g) + ""]"");
                    }
                }
            }
            case DOUBLES -> {
                DoubleBlock groups = (DoubleBlock) block;
                for (int g = 0; g < GROUPS; g++) {
                    if (groups.getDouble(g) != (double) g) {
                        throw new AssertionError(prefix + ""bad group expected ["" + (double) g + ""] but was ["" + groups.getDouble(g) + ""]"");
                    }
                }
            }
            case BOOLEANS -> {
                BooleanBlock groups = (BooleanBlock) block;
                if (groups.getBoolean(0) != false) {
                    throw new AssertionError(prefix + ""bad group expected [false] but was ["" + groups.getBoolean(0) + ""]"");
                }
                if (groups.getBoolean(1) != true) {
                    throw new AssertionError(prefix + ""bad group expected [true] but was ["" + groups.getBoolean(1) + ""]"");
                }
            }
            case BYTES_REFS -> {
                BytesRefBlock groups = (BytesRefBlock) block;
                for (int g = 0; g < GROUPS; g++) {
                    if (false == groups.getBytesRef(g, new BytesRef()).equals(bytesGroup(g))) {
                        throw new AssertionError(
                            prefix + ""bad group expected ["" + bytesGroup(g) + ""] but was ["" + groups.getBytesRef(g, new BytesRef()) + ""]""
                        );
                    }
                }
            }
            default -> throw new IllegalArgumentException(""bad grouping ["" + grouping + ""]"");
        }
    }",/benchmarks/src/main/java/org/elasticsearch/benchmark/compute/operation/AggregatorBenchmark.java
95eac4e806b2be2f85d2748df1b7211c73d5e339,561,125,"private static Operator operator(String grouping, AggregationName aggName, AggregationType aggType) {
        if (grouping.equals(""none"")) {
            AggregatorFunction.Factory factory = AggregatorFunction.of(aggName, aggType);
            return new AggregationOperator(List.of(new Aggregator(factory, AggregatorMode.SINGLE, 0)));
        }
        List<HashAggregationOperator.GroupSpec> groups = switch (grouping) {
            case LONGS -> List.of(new HashAggregationOperator.GroupSpec(0, ElementType.LONG));
            case INTS -> List.of(new HashAggregationOperator.GroupSpec(0, ElementType.INT));
            case DOUBLES -> List.of(new HashAggregationOperator.GroupSpec(0, ElementType.DOUBLE));
            case BOOLEANS -> List.of(new HashAggregationOperator.GroupSpec(0, ElementType.BOOLEAN));
            case BYTES_REFS -> List.of(new HashAggregationOperator.GroupSpec(0, ElementType.BYTES_REF));
            default -> throw new IllegalArgumentException(""unsupported grouping ["" + grouping + ""]"");
        };
        GroupingAggregatorFunction.Factory factory = GroupingAggregatorFunction.of(aggName, aggType);
        return new HashAggregationOperator(
            List.of(new GroupingAggregator.GroupingAggregatorFactory(BIG_ARRAYS, factory, AggregatorMode.SINGLE, groups.size())),
            () -> BlockHash.build(groups, BIG_ARRAYS)
        );
    }","private static Operator operator(String grouping, AggregationName aggName, AggregationType aggType) {
        if (grouping.equals(""none"")) {
            AggregatorFunction.Factory factory = AggregatorFunction.of(aggName, aggType);
            return new AggregationOperator(List.of(new Aggregator(factory, AggregatorMode.SINGLE, 0)));
        }
        List<HashAggregationOperator.GroupSpec> groups = switch (grouping) {
            case LONGS -> List.of(new HashAggregationOperator.GroupSpec(0, ElementType.LONG));
            case INTS -> List.of(new HashAggregationOperator.GroupSpec(0, ElementType.INT));
            case DOUBLES -> List.of(new HashAggregationOperator.GroupSpec(0, ElementType.DOUBLE));
            case BOOLEANS -> List.of(new HashAggregationOperator.GroupSpec(0, ElementType.BOOLEAN));
            case BYTES_REFS -> List.of(new HashAggregationOperator.GroupSpec(0, ElementType.BYTES_REF));
            case TWO_LONGS -> List.of(
                new HashAggregationOperator.GroupSpec(0, ElementType.LONG),
                new HashAggregationOperator.GroupSpec(1, ElementType.LONG)
            );
            case LONGS_AND_BYTES_REFS -> List.of(
                new HashAggregationOperator.GroupSpec(0, ElementType.LONG),
                new HashAggregationOperator.GroupSpec(1, ElementType.BYTES_REF)
            );
            default -> throw new IllegalArgumentException(""unsupported grouping ["" + grouping + ""]"");
        };
        GroupingAggregatorFunction.Factory factory = GroupingAggregatorFunction.of(aggName, aggType);
        return new HashAggregationOperator(
            List.of(new GroupingAggregator.GroupingAggregatorFactory(BIG_ARRAYS, factory, AggregatorMode.SINGLE, groups.size())),
            () -> BlockHash.build(groups, BIG_ARRAYS)
        );
    }",/benchmarks/src/main/java/org/elasticsearch/benchmark/compute/operation/AggregatorBenchmark.java
dfdb89c94554af10c757cb03dac1e65d4b0387e4,690,677,"private void indexModelSnapshotFromCurrentJobStats(String jobId) throws IOException {
        JobStats jobStats = getJobStats(jobId);
        DataCounts dataCounts = jobStats.getDataCounts();

        ModelSnapshot modelSnapshot = new ModelSnapshot.Builder(jobId)
            .setLatestResultTimeStamp(dataCounts.getLatestRecordTimeStamp())
            .setLatestRecordTimeStamp(dataCounts.getLatestRecordTimeStamp())
            .setMinVersion(Version.CURRENT)
            .setSnapshotId(jobId + ""_mock_snapshot"")
            .setTimestamp(new Date())
            .setModelSizeStats(new ModelSizeStats.Builder(jobId).build())
            .build();

        try (XContentBuilder xContentBuilder = JsonXContent.contentBuilder()) {
            modelSnapshot.toXContent(xContentBuilder, ToXContent.EMPTY_PARAMS);
            IndexRequest indexRequest = new IndexRequest(AnomalyDetectorsIndex.jobResultsAliasedName(jobId));
            indexRequest.setRefreshPolicy(WriteRequest.RefreshPolicy.IMMEDIATE);
            indexRequest.id(ModelSnapshot.documentId(modelSnapshot));
            indexRequest.source(xContentBuilder);
            client().index(indexRequest).actionGet();
        }

        JobUpdate jobUpdate = new JobUpdate.Builder(jobId).setModelSnapshotId(modelSnapshot.getSnapshotId()).build();
        client().execute(UpdateJobAction.INSTANCE, new UpdateJobAction.Request(jobId, jobUpdate)).actionGet();
    }","private void waitForJobClosed(String jobId) throws Exception {
        assertBusy(() -> {
            JobStats jobStats = getJobStats(jobId);
            assertEquals(jobStats.getState(), JobState.CLOSED);
        }, 30, TimeUnit.SECONDS);
    }",/x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/MlDistributedFailureIT.java
eb50f47440abfb7878c11a6d945305ee36f8b960,595,245,"static Map<String, long[]> extractIndexCheckPoints(ShardStats[] shards, Set<String> userIndices) {
        Map<String, TreeMap<Integer, Long>> checkpointsByIndex = new TreeMap<>();

        for (ShardStats shard : shards) {
            String indexName = shard.getShardRouting().getIndexName();
            if (userIndices.contains(indexName)) {
                SeqNoStats seqNoStats = shard.getSeqNoStats();
                // SeqNoStats could be `null`. This indicates that an `AlreadyClosed` exception was thrown somewhere down the stack
                // Indicates that the index COULD be closed, or at least that the shard is not fully recovered yet.
                if (seqNoStats == null) {
                    logger.warn(""failure gathering checkpoint information for index [{}] as seq_no_stats were null. Shard Stats [{}]"",
                        indexName,
                        Strings.toString(shard));
                    throw new CheckpointException(
                        ""Unable to gather checkpoint information for index ["" + indexName + ""]. seq_no_stats are missing."");
                }
                if (checkpointsByIndex.containsKey(indexName)) {
                    // we have already seen this index, just check/add shards
                    TreeMap<Integer, Long> checkpoints = checkpointsByIndex.get(indexName);
                    if (checkpoints.containsKey(shard.getShardRouting().getId())) {
                        // there is already a checkpoint entry for this index/shard combination, check if they match
                        if (checkpoints.get(shard.getShardRouting().getId()) != shard.getSeqNoStats().getGlobalCheckpoint()) {
                            throw new CheckpointException(""Global checkpoints mismatch for index ["" + indexName + ""] between shards of id [""
                                    + shard.getShardRouting().getId() + ""]"");
                        }
                    } else {
                        // 1st time we see this shard for this index, add the entry for the shard
                        checkpoints.put(shard.getShardRouting().getId(), shard.getSeqNoStats().getGlobalCheckpoint());
                    }
                } else {
                    // 1st time we see this index, create an entry for the index and add the shard checkpoint
                    checkpointsByIndex.put(indexName, new TreeMap<>());
                    checkpointsByIndex.get(indexName).put(shard.getShardRouting().getId(), shard.getSeqNoStats().getGlobalCheckpoint());
                }
            }
        }

        // create the final structure
        Map<String, long[]> checkpointsByIndexReduced = new TreeMap<>();

        checkpointsByIndex.forEach((indexName, checkpoints) -> {
            checkpointsByIndexReduced.put(indexName, checkpoints.values().stream().mapToLong(l -> l).toArray());
        });

        return checkpointsByIndexReduced;
    }","static Map<String, long[]> extractIndexCheckPoints(ShardStats[] shards, Set<String> userIndices) {
        Map<String, TreeMap<Integer, Long>> checkpointsByIndex = new TreeMap<>();

        for (ShardStats shard : shards) {
            String indexName = shard.getShardRouting().getIndexName();

            if (userIndices.contains(indexName)) {
                // SeqNoStats could be `null`, assume the global checkpoint to be 0 in this case
                long globalCheckpoint = shard.getSeqNoStats() == null ? 0 : shard.getSeqNoStats().getGlobalCheckpoint();
                if (checkpointsByIndex.containsKey(indexName)) {
                    // we have already seen this index, just check/add shards
                    TreeMap<Integer, Long> checkpoints = checkpointsByIndex.get(indexName);
                    if (checkpoints.containsKey(shard.getShardRouting().getId())) {
                        // there is already a checkpoint entry for this index/shard combination, check if they match
                        if (checkpoints.get(shard.getShardRouting().getId()) != globalCheckpoint) {
                            throw new CheckpointException(""Global checkpoints mismatch for index ["" + indexName + ""] between shards of id [""
                                    + shard.getShardRouting().getId() + ""]"");
                        }
                    } else {
                        // 1st time we see this shard for this index, add the entry for the shard
                        checkpoints.put(shard.getShardRouting().getId(), globalCheckpoint);
                    }
                } else {
                    // 1st time we see this index, create an entry for the index and add the shard checkpoint
                    checkpointsByIndex.put(indexName, new TreeMap<>());
                    checkpointsByIndex.get(indexName).put(shard.getShardRouting().getId(), globalCheckpoint);
                }
            }
        }

        // checkpoint extraction is done in 2 steps:
        // 1. GetIndexRequest to retrieve the indices the user has access to
        // 2. IndicesStatsRequest to retrieve stats about indices
        // between 1 and 2 indices could get deleted or created
        if (logger.isDebugEnabled()) {
            Set<String> userIndicesClone = new HashSet<>(userIndices);

            userIndicesClone.removeAll(checkpointsByIndex.keySet());
            if (userIndicesClone.isEmpty() == false) {
                logger.debug(""Original set of user indices contained more indexes [{}]"", userIndicesClone);
            }
        }

        // create the final structure
        Map<String, long[]> checkpointsByIndexReduced = new TreeMap<>();

        checkpointsByIndex.forEach((indexName, checkpoints) -> {
            checkpointsByIndexReduced.put(indexName, checkpoints.values().stream().mapToLong(l -> l).toArray());
        });

        return checkpointsByIndexReduced;
    }",/x-pack/plugin/data-frame/src/main/java/org/elasticsearch/xpack/dataframe/checkpoint/DataFrameTransformsCheckpointService.java
c20d3e9a3807a36f33f3a8fad401a6ba99948e7f,563,1368,"public void findActiveTokensForUser(String username, ActionListener<Collection<Tuple<UserToken, String>>> listener) {
        ensureEnabled();
        if (Strings.isNullOrEmpty(username)) {
            listener.onFailure(new IllegalArgumentException(""username is required""));
            return;
        }
        sourceIndicesWithTokensAndRun(ActionListener.wrap(indicesWithTokens -> {
            if (indicesWithTokens.isEmpty()) {
                listener.onResponse(Collections.emptyList());
            } else {
                final Instant now = clock.instant();
                final BoolQueryBuilder boolQuery = QueryBuilders.boolQuery()
                        .filter(QueryBuilders.termQuery(""doc_type"", TOKEN_DOC_TYPE))
                        .filter(QueryBuilders.boolQuery()
                                .should(QueryBuilders.boolQuery()
                                        .must(QueryBuilders.termQuery(""access_token.invalidated"", false))
                                        .must(QueryBuilders.rangeQuery(""access_token.user_token.expiration_time"").gte(now.toEpochMilli()))
                                        )
                                .should(QueryBuilders.boolQuery()
                                        .must(QueryBuilders.termQuery(""refresh_token.invalidated"", false))
                                        .must(QueryBuilders.rangeQuery(""creation_time"").gte(now.toEpochMilli()
                                                - TimeValue.timeValueHours(ExpiredTokenRemover.MAXIMUM_TOKEN_LIFETIME_HOURS).millis()))
                                        )
                                );
                final Supplier<ThreadContext.StoredContext> supplier = client.threadPool().getThreadContext().newRestorableContext(false);
                try (ThreadContext.StoredContext ignore = client.threadPool().getThreadContext().stashWithOrigin(SECURITY_ORIGIN)) {
                    final SearchRequest request = client.prepareSearch(indicesWithTokens.toArray(new String[0]))
                            .setScroll(DEFAULT_KEEPALIVE_SETTING.get(settings))
                            .setQuery(boolQuery)
                            .setVersion(false)
                            .setSize(1000)
                            .setFetchSource(true)
                            .request();
                    ScrollHelper.fetchAllByEntity(client, request, new ContextPreservingActionListener<>(supplier, listener),
                            (SearchHit hit) -> filterAndParseHit(hit, isOfUser(username)));
                }
            }
        }, listener::onFailure));
    }","ActionListener<Collection<Tuple<UserToken, String>>> listener) {
        ensureEnabled();
        if (Strings.isNullOrEmpty(realmName)) {
            listener.onFailure(new IllegalArgumentException(""realm name is required""));
            return;
        }
        sourceIndicesWithTokensAndRun(ActionListener.wrap(indicesWithTokens -> {
            if (indicesWithTokens.isEmpty()) {
                listener.onResponse(Collections.emptyList());
            } else {
                final Instant now = clock.instant();
                final BoolQueryBuilder boolQuery = QueryBuilders.boolQuery()
                        .filter(QueryBuilders.termQuery(""doc_type"", TOKEN_DOC_TYPE))
                        .filter(QueryBuilders.termQuery(""access_token.realm"", realmName))
                        .filter(QueryBuilders.boolQuery()
                                .should(QueryBuilders.boolQuery()
                                        .must(QueryBuilders.termQuery(""access_token.invalidated"", false))
                                        .must(QueryBuilders.rangeQuery(""access_token.user_token.expiration_time"").gte(now.toEpochMilli()))
                                        )
                                .should(QueryBuilders.boolQuery()
                                        .must(QueryBuilders.termQuery(""refresh_token.invalidated"", false))
                                        .must(QueryBuilders.rangeQuery(""creation_time"").gte(now.toEpochMilli()
                                                - TimeValue.timeValueHours(ExpiredTokenRemover.MAXIMUM_TOKEN_LIFETIME_HOURS).millis()))
                                        )
                                );
                final Supplier<ThreadContext.StoredContext> supplier = client.threadPool().getThreadContext().newRestorableContext(false);
                try (ThreadContext.StoredContext ignore = client.threadPool().getThreadContext().stashWithOrigin(SECURITY_ORIGIN)) {
                    final SearchRequest request = client.prepareSearch(indicesWithTokens.toArray(new String[0]))
                            .setScroll(DEFAULT_KEEPALIVE_SETTING.get(settings))
                            .setQuery(boolQuery)
                            .setVersion(false)
                            .setSize(1000)
                            .setFetchSource(true)
                            .request();
                    ScrollHelper.fetchAllByEntity(client, request, new ContextPreservingActionListener<>(supplier, listener),
                            (SearchHit hit) -> filterAndParseHit(hit, filter));
                }
            }
        }, listener::onFailure));
    }",/x-pack/plugin/security/src/main/java/org/elasticsearch/xpack/security/authc/TokenService.java
c20d3e9a3807a36f33f3a8fad401a6ba99948e7f,690,1446,"@Nullable Authentication originatingClientAuth) {
        assert refreshToken == null || originatingClientAuth != null : ""non-null refresh token "" + refreshToken
            + "" requires non-null client authn "" + originatingClientAuth;
        try (XContentBuilder builder = XContentFactory.jsonBuilder()) {
            builder.startObject();
            builder.field(""doc_type"", TOKEN_DOC_TYPE);
            builder.field(""creation_time"", getCreationTime(userToken.getExpirationTime()).toEpochMilli());
            if (refreshToken != null) {
                builder.startObject(""refresh_token"")
                    .field(""token"", refreshToken)
                    .field(""invalidated"", false)
                    .field(""refreshed"", false)
                    .startObject(""client"")
                        .field(""type"", ""unassociated_client"")
                        .field(""user"", originatingClientAuth.getUser().principal())
                        .field(""realm"", originatingClientAuth.getAuthenticatedBy().getName())
                    .endObject()
                    .endObject();
            }
            builder.startObject(""access_token"")
                    .field(""invalidated"", false)
                    .field(""user_token"", userToken)
                    .field(""realm"", userToken.getAuthentication().getAuthenticatedBy().getName())
                    .endObject();
            builder.endObject();
            return BytesReference.bytes(builder);
        } catch (IOException e) {
            throw new RuntimeException(""Unexpected exception when constructing a JSON document."", e);
        }
    }","private void sourceIndicesWithTokensAndRun(ActionListener<List<String>> listener) {
        final List<String> indicesWithTokens = new ArrayList<>(2);
        final SecurityIndexManager frozenTokensIndex = securityTokensIndex.freeze();
        if (frozenTokensIndex.indexExists()) {
            // an existing tokens index always contains tokens (if available and version allows)
            if (false == frozenTokensIndex.isAvailable()) {
                listener.onFailure(frozenTokensIndex.getUnavailableReason());
                return;
            }
            if (false == frozenTokensIndex.isIndexUpToDate()) {
                listener.onFailure(new IllegalStateException(
                        ""Index ["" + frozenTokensIndex.aliasName() + ""] is not on the current version. Features relying on the index""
                                + "" will not be available until the upgrade API is run on the index""));
                return;
            }
            indicesWithTokens.add(frozenTokensIndex.aliasName());
        }
        final SecurityIndexManager frozenMainIndex = securityMainIndex.freeze();
        if (frozenMainIndex.indexExists()) {
            // main security index _might_ contain tokens if the tokens index has been created recently
            if (false == frozenTokensIndex.indexExists() || frozenTokensIndex.getCreationTime()
                    .isAfter(clock.instant().minus(ExpiredTokenRemover.MAXIMUM_TOKEN_LIFETIME_HOURS, ChronoUnit.HOURS))) {
                if (false == frozenMainIndex.isAvailable()) {
                    listener.onFailure(frozenMainIndex.getUnavailableReason());
                    return;
                }
                if (false == frozenMainIndex.isIndexUpToDate()) {
                    listener.onFailure(new IllegalStateException(
                            ""Index ["" + frozenMainIndex.aliasName() + ""] is not on the current version. Features relying on the index""
                                    + "" will not be available until the upgrade API is run on the index""));
                    return;
                }
                indicesWithTokens.add(frozenMainIndex.aliasName());
            }
        }
        listener.onResponse(indicesWithTokens);
    }",/x-pack/plugin/security/src/main/java/org/elasticsearch/xpack/security/authc/TokenService.java
c20d3e9a3807a36f33f3a8fad401a6ba99948e7f,563,1321,"ActionListener<Collection<Tuple<UserToken, String>>> listener) {
        ensureEnabled();
        if (Strings.isNullOrEmpty(realmName)) {
            listener.onFailure(new IllegalArgumentException(""realm name is required""));
            return;
        }
        sourceIndicesWithTokensAndRun(ActionListener.wrap(indicesWithTokens -> {
            if (indicesWithTokens.isEmpty()) {
                listener.onResponse(Collections.emptyList());
            } else {
                final Instant now = clock.instant();
                final BoolQueryBuilder boolQuery = QueryBuilders.boolQuery()
                        .filter(QueryBuilders.termQuery(""doc_type"", TOKEN_DOC_TYPE))
                        .filter(QueryBuilders.termQuery(""access_token.realm"", realmName))
                        .filter(QueryBuilders.boolQuery()
                                .should(QueryBuilders.boolQuery()
                                        .must(QueryBuilders.termQuery(""access_token.invalidated"", false))
                                        .must(QueryBuilders.rangeQuery(""access_token.user_token.expiration_time"").gte(now.toEpochMilli()))
                                        )
                                .should(QueryBuilders.boolQuery()
                                        .must(QueryBuilders.termQuery(""refresh_token.invalidated"", false))
                                        .must(QueryBuilders.rangeQuery(""creation_time"").gte(now.toEpochMilli()
                                                - TimeValue.timeValueHours(ExpiredTokenRemover.MAXIMUM_TOKEN_LIFETIME_HOURS).millis()))
                                        )
                                );
                final Supplier<ThreadContext.StoredContext> supplier = client.threadPool().getThreadContext().newRestorableContext(false);
                try (ThreadContext.StoredContext ignore = client.threadPool().getThreadContext().stashWithOrigin(SECURITY_ORIGIN)) {
                    final SearchRequest request = client.prepareSearch(indicesWithTokens.toArray(new String[0]))
                            .setScroll(DEFAULT_KEEPALIVE_SETTING.get(settings))
                            .setQuery(boolQuery)
                            .setVersion(false)
                            .setSize(1000)
                            .setFetchSource(true)
                            .request();
                    ScrollHelper.fetchAllByEntity(client, request, new ContextPreservingActionListener<>(supplier, listener),
                            (SearchHit hit) -> filterAndParseHit(hit, filter));
                }
            }
        }, listener::onFailure));
    }","RefreshTokenStatus refreshTokenStatus) {
        if (refreshTokenStatus.isRefreshed()) {
            if (refreshTokenStatus.getVersion().onOrAfter(VERSION_MULTIPLE_CONCURRENT_REFRESHES)) {
                if (refreshRequested.isAfter(refreshTokenStatus.getRefreshInstant().plus(30L, ChronoUnit.SECONDS))) {
                    return Optional.of(invalidGrantException(""token has already been refreshed more than 30 seconds in the past""));
                }
                if (refreshRequested.isBefore(refreshTokenStatus.getRefreshInstant().minus(30L, ChronoUnit.SECONDS))) {
                    return Optional
                            .of(invalidGrantException(""token has been refreshed more than 30 seconds in the future, clock skew too great""));
                }
            } else {
                return Optional.of(invalidGrantException(""token has already been refreshed""));
            }
        }
        return Optional.empty();
    }",/x-pack/plugin/security/src/main/java/org/elasticsearch/xpack/security/authc/TokenService.java
d46981a7b2631f9f4bc3ba5ed304b11d74c671a0,563,86,"public void createComponents() throws Exception {
        ThreadPool tp = mockThreadPool();
        ClusterSettings clusterSettings = new ClusterSettings(
            Settings.EMPTY,
            new HashSet<>(
                Arrays.asList(
                    InferenceProcessor.MAX_INFERENCE_PROCESSORS,
                    MasterService.MASTER_SERVICE_SLOW_TASK_LOGGING_THRESHOLD_SETTING,
                    OperationRouting.USE_ADAPTIVE_REPLICA_SELECTION_SETTING,
                    ResultsPersisterService.PERSIST_RESULTS_MAX_RETRIES,
                    ClusterService.USER_DEFINED_METADATA,
                    ClusterApplierService.CLUSTER_SERVICE_SLOW_TASK_LOGGING_THRESHOLD_SETTING
                )
            )
        );
        ClusterService clusterService = new ClusterService(Settings.EMPTY, clusterSettings, tp);

        OriginSettingClient originSettingClient = new OriginSettingClient(client(), ML_ORIGIN);
        ResultsPersisterService resultsPersisterService = new ResultsPersisterService(
            tp,
            originSettingClient,
            clusterService,
            Settings.EMPTY
        );
        AnomalyDetectionAuditor auditor = new AnomalyDetectionAuditor(client(), clusterService);
        jobResultsPersister = new JobResultsPersister(originSettingClient, resultsPersisterService);
        waitForMlTemplates();
    }","public void createComponents() throws Exception {
        ThreadPool tp = mockThreadPool();
        ClusterSettings clusterSettings = new ClusterSettings(
            Settings.EMPTY,
            new HashSet<>(
                Arrays.asList(
                    InferenceProcessor.MAX_INFERENCE_PROCESSORS,
                    MasterService.MASTER_SERVICE_SLOW_TASK_LOGGING_THRESHOLD_SETTING,
                    OperationRouting.USE_ADAPTIVE_REPLICA_SELECTION_SETTING,
                    ResultsPersisterService.PERSIST_RESULTS_MAX_RETRIES,
                    ClusterService.USER_DEFINED_METADATA,
                    ClusterApplierService.CLUSTER_SERVICE_SLOW_TASK_LOGGING_THRESHOLD_SETTING
                )
            )
        );
        ClusterService clusterService = new ClusterService(Settings.EMPTY, clusterSettings, tp);

        OriginSettingClient originSettingClient = new OriginSettingClient(client(), ML_ORIGIN);
        ResultsPersisterService resultsPersisterService = new ResultsPersisterService(
            tp,
            originSettingClient,
            clusterService,
            Settings.EMPTY
        );
        jobResultsPersister = new JobResultsPersister(originSettingClient, resultsPersisterService);
        waitForMlTemplates();
    }",/x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/AnomalyJobCRUDIT.java
5e15a20844b97b6d296f24daee69b53b9fbe4f8b,662,265,"boolean hasPendingMerges() {
            return queue.isEmpty() == false || runningTask.get() != null;
        }","boolean hasFailure() {
            return failure.get() != null;
        }",/server/src/main/java/org/elasticsearch/action/search/QueryPhaseResultConsumer.java
5e15a20844b97b6d296f24daee69b53b9fbe4f8b,563,1003,"private void testReduceCase(boolean shouldFail) throws Exception {
        int expectedNumResults = randomIntBetween(20, 200);
        int bufferSize = randomIntBetween(2, expectedNumResults - 1);
        SearchRequest request = new SearchRequest();

        request.source(new SearchSourceBuilder().aggregation(AggregationBuilders.avg(""foo"")).size(0));
        request.setBatchedReduceSize(bufferSize);
        AtomicBoolean hasConsumedFailure = new AtomicBoolean();
        AssertingCircuitBreaker circuitBreaker = new AssertingCircuitBreaker(CircuitBreaker.REQUEST);
        boolean shouldFailPartial = shouldFail && randomBoolean();
        if (shouldFailPartial) {
            circuitBreaker.shouldBreak.set(true);
        }
        QueryPhaseResultConsumer consumer = searchPhaseController.newSearchPhaseResults(fixedExecutor,
            circuitBreaker, SearchProgressListener.NOOP,
            request, expectedNumResults, exc -> hasConsumedFailure.set(true));
        CountDownLatch latch = new CountDownLatch(expectedNumResults);
        Thread[] threads = new Thread[expectedNumResults];
        for (int i =  0; i < expectedNumResults; i++) {
            final int index = i;
            threads[index] = new Thread(() -> {
                QuerySearchResult result = new QuerySearchResult(new ShardSearchContextId(UUIDs.randomBase64UUID(), index),
                    new SearchShardTarget(""node"", new ShardId(""a"", ""b"", index), null, OriginalIndices.NONE),
                    null);
                result.topDocs(new TopDocsAndMaxScore(
                        new TopDocs(new TotalHits(0, TotalHits.Relation.EQUAL_TO), Lucene.EMPTY_SCORE_DOCS), Float.NaN),
                    new DocValueFormat[0]);
                InternalAggregations aggs = InternalAggregations.from(
                    Collections.singletonList(new InternalMax(""test"", 0d, DocValueFormat.RAW, Collections.emptyMap())));
                result.aggregations(aggs);
                result.setShardIndex(index);
                result.size(1);
                consumer.consumeResult(result, latch::countDown);
            });
            threads[index].start();
        }
        for (int i = 0; i < expectedNumResults; i++) {
            threads[i].join();
        }
        latch.await();
        if (shouldFail) {
            if (shouldFailPartial == false) {
                circuitBreaker.shouldBreak.set(true);
            }
            CircuitBreakingException exc = expectThrows(CircuitBreakingException.class, () -> consumer.reduce());
            assertEquals(shouldFailPartial, hasConsumedFailure.get());
            assertThat(exc.getMessage(), containsString(""<reduce_aggs>""));
            circuitBreaker.shouldBreak.set(false);
        } else {
            SearchPhaseController.ReducedQueryPhase phase = consumer.reduce();
        }
        consumer.close();
        assertThat(circuitBreaker.allocated, equalTo(0L));
    }","private void testReduceCase(boolean shouldFail) throws Exception {
        int expectedNumResults = randomIntBetween(20, 200);
        int bufferSize = randomIntBetween(2, expectedNumResults - 1);
        SearchRequest request = new SearchRequest();

        request.source(new SearchSourceBuilder().aggregation(AggregationBuilders.avg(""foo"")).size(0));
        request.setBatchedReduceSize(bufferSize);
        AtomicBoolean hasConsumedFailure = new AtomicBoolean();
        AssertingCircuitBreaker circuitBreaker = new AssertingCircuitBreaker(CircuitBreaker.REQUEST);
        boolean shouldFailPartial = shouldFail && randomBoolean();
        if (shouldFailPartial) {
            circuitBreaker.shouldBreak.set(true);
        }
        QueryPhaseResultConsumer consumer = searchPhaseController.newSearchPhaseResults(fixedExecutor,
            circuitBreaker, SearchProgressListener.NOOP,
            request, expectedNumResults, exc -> hasConsumedFailure.set(true));
        CountDownLatch latch = new CountDownLatch(expectedNumResults);
        Thread[] threads = new Thread[expectedNumResults];
        for (int i =  0; i < expectedNumResults; i++) {
            final int index = i;
            threads[index] = new Thread(() -> {
                QuerySearchResult result = new QuerySearchResult(new ShardSearchContextId(UUIDs.randomBase64UUID(), index),
                    new SearchShardTarget(""node"", new ShardId(""a"", ""b"", index), null, OriginalIndices.NONE),
                    null);
                result.topDocs(new TopDocsAndMaxScore(
                        new TopDocs(new TotalHits(0, TotalHits.Relation.EQUAL_TO), Lucene.EMPTY_SCORE_DOCS), Float.NaN),
                    new DocValueFormat[0]);
                InternalAggregations aggs = InternalAggregations.from(
                    Collections.singletonList(new InternalMax(""test"", 0d, DocValueFormat.RAW, Collections.emptyMap()))
                );
                result.aggregations(aggs);
                result.setShardIndex(index);
                result.size(1);
                consumer.consumeResult(result, latch::countDown);
            });
            threads[index].start();
        }
        for (int i = 0; i < expectedNumResults; i++) {
            threads[i].join();
        }
        latch.await();
        if (shouldFail) {
            if (shouldFailPartial == false) {
                circuitBreaker.shouldBreak.set(true);
            }
            CircuitBreakingException exc = expectThrows(CircuitBreakingException.class, () -> consumer.reduce());
            assertEquals(shouldFailPartial, hasConsumedFailure.get());
            assertThat(exc.getMessage(), containsString(""<reduce_aggs>""));
            circuitBreaker.shouldBreak.set(false);
        } else {
            SearchPhaseController.ReducedQueryPhase phase = consumer.reduce();
        }
        consumer.close();
        assertThat(circuitBreaker.allocated, equalTo(0L));
    }",/server/src/test/java/org/elasticsearch/action/search/SearchPhaseControllerTests.java
5e15a20844b97b6d296f24daee69b53b9fbe4f8b,567,1024,"public double addEstimateBytesAndMaybeBreak(long bytes, String label) throws CircuitBreakingException {
            assert bytes >= 0;
            if (shouldBreak.get()) {
                throw new CircuitBreakingException(label, getDurability());
            }
            allocated += bytes;
            return allocated;
        }","public void testFailConsumeAggs() throws Exception {
        int expectedNumResults = randomIntBetween(20, 200);
        int bufferSize = randomIntBetween(2, expectedNumResults - 1);
        SearchRequest request = new SearchRequest();

        request.source(new SearchSourceBuilder().aggregation(AggregationBuilders.avg(""foo"")).size(0));
        request.setBatchedReduceSize(bufferSize);
        AtomicBoolean hasConsumedFailure = new AtomicBoolean();
        try (QueryPhaseResultConsumer consumer = searchPhaseController.newSearchPhaseResults(fixedExecutor,
            new NoopCircuitBreaker(CircuitBreaker.REQUEST), SearchProgressListener.NOOP,
            request, expectedNumResults, exc -> hasConsumedFailure.set(true))) {
            for (int i = 0; i < expectedNumResults; i++) {
                final int index = i;
                QuerySearchResult result = new QuerySearchResult(new ShardSearchContextId(UUIDs.randomBase64UUID(), index),
                    new SearchShardTarget(""node"", new ShardId(""a"", ""b"", index), null, OriginalIndices.NONE),
                    null);
                result.topDocs(new TopDocsAndMaxScore(
                        new TopDocs(new TotalHits(0, TotalHits.Relation.EQUAL_TO), Lucene.EMPTY_SCORE_DOCS), Float.NaN),
                    new DocValueFormat[0]);
                result.aggregations(null);
                result.setShardIndex(index);
                result.size(1);
                expectThrows(Exception.class, () -> consumer.consumeResult(result, () -> {
                }));
            }
            assertNull(consumer.reduce().aggregations);
        }
    }",/server/src/test/java/org/elasticsearch/action/search/SearchPhaseControllerTests.java
5e15a20844b97b6d296f24daee69b53b9fbe4f8b,567,1030,"public long addWithoutBreaking(long bytes) {
            allocated += bytes;
            return allocated;
        }","public void testFailConsumeAggs() throws Exception {
        int expectedNumResults = randomIntBetween(20, 200);
        int bufferSize = randomIntBetween(2, expectedNumResults - 1);
        SearchRequest request = new SearchRequest();

        request.source(new SearchSourceBuilder().aggregation(AggregationBuilders.avg(""foo"")).size(0));
        request.setBatchedReduceSize(bufferSize);
        AtomicBoolean hasConsumedFailure = new AtomicBoolean();
        try (QueryPhaseResultConsumer consumer = searchPhaseController.newSearchPhaseResults(fixedExecutor,
            new NoopCircuitBreaker(CircuitBreaker.REQUEST), SearchProgressListener.NOOP,
            request, expectedNumResults, exc -> hasConsumedFailure.set(true))) {
            for (int i = 0; i < expectedNumResults; i++) {
                final int index = i;
                QuerySearchResult result = new QuerySearchResult(new ShardSearchContextId(UUIDs.randomBase64UUID(), index),
                    new SearchShardTarget(""node"", new ShardId(""a"", ""b"", index), null, OriginalIndices.NONE),
                    null);
                result.topDocs(new TopDocsAndMaxScore(
                        new TopDocs(new TotalHits(0, TotalHits.Relation.EQUAL_TO), Lucene.EMPTY_SCORE_DOCS), Float.NaN),
                    new DocValueFormat[0]);
                result.aggregations(null);
                result.setShardIndex(index);
                result.size(1);
                expectThrows(Exception.class, () -> consumer.consumeResult(result, () -> {
                }));
            }
            assertNull(consumer.reduce().aggregations);
        }
    }",/server/src/test/java/org/elasticsearch/action/search/SearchPhaseControllerTests.java
5e15a20844b97b6d296f24daee69b53b9fbe4f8b,690,212,"int numReducePhases) {
        // ensure consistent ordering
        Arrays.sort(toConsume, Comparator.comparingInt(QuerySearchResult::getShardIndex));

        for (QuerySearchResult result : toConsume) {
            topDocsStats.add(result.topDocs(), result.searchTimedOut(), result.terminatedEarly());
        }

        final TopDocs newTopDocs;
        if (hasTopDocs) {
            List<TopDocs> topDocsList = new ArrayList<>();
            if (lastMerge != null) {
                topDocsList.add(lastMerge.reducedTopDocs);
            }
            for (QuerySearchResult result : toConsume) {
                TopDocsAndMaxScore topDocs = result.consumeTopDocs();
                setShardIndex(topDocs.topDocs, result.getShardIndex());
                topDocsList.add(topDocs.topDocs);
            }
            newTopDocs = mergeTopDocs(topDocsList,
                // we have to merge here in the same way we collect on a shard
                topNSize, 0);
        } else {
            newTopDocs = null;
        }

        final InternalAggregations newAggs;
        if (hasAggs) {
            List<InternalAggregations> aggsList = new ArrayList<>();
            if (lastMerge != null) {
                aggsList.add(lastMerge.reducedAggs);
            }
            for (QuerySearchResult result : toConsume) {
                aggsList.add(result.consumeAggs().expand());
            }
            newAggs = InternalAggregations.topLevelReduce(aggsList, aggReduceContextBuilder.forPartialReduction());
        } else {
            newAggs = null;
        }
        List<SearchShard> processedShards = new ArrayList<>(emptyResults);
        if (lastMerge != null) {
            processedShards.addAll(lastMerge.processedShards);
        }
        for (QuerySearchResult result : toConsume) {
            SearchShardTarget target = result.getSearchShardTarget();
            processedShards.add(new SearchShard(target.getClusterAlias(), target.getShardId()));
        }
        progressListener.notifyPartialReduce(processedShards, topDocsStats.getTotalHits(), newAggs, numReducePhases);
        // we leave the results un-serialized because serializing is slow but we compute the serialized
        // size as an estimate of the memory used by the newly reduced aggregations.
        long serializedSize = hasAggs ? newAggs.getSerializedSize() : 0;
        return new MergeResult(processedShards, newTopDocs, newAggs, hasAggs ? serializedSize : 0);
    }","int numReducePhases) {
        // ensure consistent ordering
        Arrays.sort(toConsume, Comparator.comparingInt(QuerySearchResult::getShardIndex));

        for (QuerySearchResult result : toConsume) {
            topDocsStats.add(result.topDocs(), result.searchTimedOut(), result.terminatedEarly());
        }

        final TopDocs newTopDocs;
        if (hasTopDocs) {
            List<TopDocs> topDocsList = new ArrayList<>();
            if (lastMerge != null) {
                topDocsList.add(lastMerge.reducedTopDocs);
            }
            for (QuerySearchResult result : toConsume) {
                TopDocsAndMaxScore topDocs = result.consumeTopDocs();
                setShardIndex(topDocs.topDocs, result.getShardIndex());
                topDocsList.add(topDocs.topDocs);
            }
            newTopDocs = mergeTopDocs(topDocsList,
                // we have to merge here in the same way we collect on a shard
                topNSize, 0);
        } else {
            newTopDocs = null;
        }

        final InternalAggregations newAggs;
        if (hasAggs) {
            List<InternalAggregations> aggsList = new ArrayList<>();
            if (lastMerge != null) {
                aggsList.add(lastMerge.reducedAggs);
            }
            for (QuerySearchResult result : toConsume) {
                aggsList.add(result.consumeAggs().expand());
            }
            newAggs = InternalAggregations.topLevelReduce(aggsList, aggReduceContextBuilder.forPartialReduction());
        } else {
            newAggs = null;
        }
        List<SearchShard> processedShards = new ArrayList<>(emptyResults);
        if (lastMerge != null) {
            processedShards.addAll(lastMerge.processedShards);
        }
        for (QuerySearchResult result : toConsume) {
            SearchShardTarget target = result.getSearchShardTarget();
            processedShards.add(new SearchShard(target.getClusterAlias(), target.getShardId()));
        }
        progressListener.notifyPartialReduce(processedShards, topDocsStats.getTotalHits(), newAggs, numReducePhases);
        // we leave the results un-serialized because serializing is slow but we compute the serialized
        // size as an estimate of the memory used by the newly reduced aggregations.
        long serializedSize = hasAggs ? DelayableWriteable.getSerializedSize(newAggs) : 0;
        return new MergeResult(processedShards, newTopDocs, newAggs, hasAggs ? serializedSize : 0);
    }",/server/src/main/java/org/elasticsearch/action/search/QueryPhaseResultConsumer.java
27f69d40f3a64794048f007f5df21fe98022650d,563,104,"private void refreshIndices(ActionListener<RefreshResponse> listener) {
        RefreshRequest refreshRequest = new RefreshRequest(
            AnomalyDetectorsIndex.jobStateIndexPattern(),
            MlStatsIndex.indexPattern(),
            config.getDest().getIndex()
        );
        refreshRequest.indicesOptions(IndicesOptions.lenientExpandOpen());

        LOGGER.debug(() -> new ParameterizedMessage(""[{}] Refreshing indices {}"", config.getId(),
            Arrays.toString(refreshRequest.indices())));

        ParentTaskAssigningClient parentTaskClient = parentTaskClient();
        try (ThreadContext.StoredContext ignore = parentTaskClient.threadPool().getThreadContext().stashWithOrigin(ML_ORIGIN)) {
            parentTaskClient.admin().indices().refresh(refreshRequest, listener);
        }
    }","private void refreshIndices(ActionListener<RefreshResponse> listener) {
        RefreshRequest refreshRequest = new RefreshRequest(
            AnomalyDetectorsIndex.jobStateIndexPattern(),
            MlStatsIndex.indexPattern(),
            config.getDest().getIndex()
        );
        refreshRequest.indicesOptions(IndicesOptions.lenientExpandOpen());

        LOGGER.debug(() -> new ParameterizedMessage(""[{}] Refreshing indices {}"", config.getId(),
            Arrays.toString(refreshRequest.indices())));

        executeAsyncWithOrigin(parentTaskClient(), ML_ORIGIN, RefreshAction.INSTANCE, refreshRequest, listener);
    }",/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/steps/FinalStep.java
497c1efb141d81b5ee7d4fc83d60e3cafce7094c,480,271,"public void testRangeQuery() throws IOException {
        Settings indexSettings = Settings.builder()
            .put(IndexMetadata.SETTING_VERSION_CREATED, Version.CURRENT)
            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)
            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1)
            .build();
        SearchExecutionContext context = new SearchExecutionContext(
            0,
            0,
            new IndexSettings(IndexMetadata.builder(""foo"").settings(indexSettings).build(), indexSettings),
            null,
            null,
            null,
            null,
            null,
            null,
            xContentRegistry(),
            writableRegistry(),
            null,
            null,
            () -> nowInMillis,
            null,
            null,
            () -> true,
            null,
            emptyMap()
        );
        MappedFieldType ft = new DateFieldType(""field"");
        String date1 = ""2015-10-12T14:10:55"";
        String date2 = ""2016-04-28T11:33:52"";
        long instant1 = DateFormatters.from(DateFieldMapper.DEFAULT_DATE_TIME_FORMATTER.parse(date1)).toInstant().toEpochMilli();
        long instant2 = DateFormatters.from(DateFieldMapper.DEFAULT_DATE_TIME_FORMATTER.parse(date2)).toInstant().toEpochMilli() + 999;
        Query expected = new IndexOrDocValuesQuery(
            LongPoint.newRangeQuery(""field"", instant1, instant2),
            SortedNumericDocValuesField.newSlowRangeQuery(""field"", instant1, instant2)
        );
        assertEquals(expected, ft.rangeQuery(date1, date2, true, true, null, null, null, context).rewrite(new MultiReader()));

        MappedFieldType ft2 = new DateFieldType(""field"", false);
        Query expected2 = SortedNumericDocValuesField.newSlowRangeQuery(""field"", instant1, instant2);
        assertEquals(expected2, ft2.rangeQuery(date1, date2, true, true, null, null, null, context).rewrite(new MultiReader()));

        instant1 = nowInMillis;
        instant2 = instant1 + 100;
        expected = new DateRangeIncludingNowQuery(
            new IndexOrDocValuesQuery(
                LongPoint.newRangeQuery(""field"", instant1, instant2),
                SortedNumericDocValuesField.newSlowRangeQuery(""field"", instant1, instant2)
            )
        );
        assertEquals(expected, ft.rangeQuery(""now"", instant2, true, true, null, null, null, context));

        expected2 = new DateRangeIncludingNowQuery(SortedNumericDocValuesField.newSlowRangeQuery(""field"", instant1, instant2));
        assertEquals(expected2, ft2.rangeQuery(""now"", instant2, true, true, null, null, null, context));

        MappedFieldType unsearchable = new DateFieldType(
            ""field"",
            false,
            false,
            false,
            DateFieldMapper.DEFAULT_DATE_TIME_FORMATTER,
            Resolution.MILLISECONDS,
            null,
            null,
            Collections.emptyMap()
        );
        IllegalArgumentException e = expectThrows(
            IllegalArgumentException.class,
            () -> unsearchable.rangeQuery(date1, date2, true, true, null, null, null, context)
        );
        assertEquals(""Cannot search on field [field] since it is not indexed nor has doc values."", e.getMessage());
    }","public void testRangeQuery() throws IOException {
        Settings indexSettings = Settings.builder()
            .put(IndexMetadata.SETTING_VERSION_CREATED, Version.CURRENT)
            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)
            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1)
            .build();
        SearchExecutionContext context = new SearchExecutionContext(
            0,
            0,
            new IndexSettings(IndexMetadata.builder(""foo"").settings(indexSettings).build(), indexSettings),
            null,
            null,
            null,
            null,
            null,
            null,
            parserConfig(),
            writableRegistry(),
            null,
            null,
            () -> nowInMillis,
            null,
            null,
            () -> true,
            null,
            emptyMap()
        );
        MappedFieldType ft = new DateFieldType(""field"");
        String date1 = ""2015-10-12T14:10:55"";
        String date2 = ""2016-04-28T11:33:52"";
        long instant1 = DateFormatters.from(DateFieldMapper.DEFAULT_DATE_TIME_FORMATTER.parse(date1)).toInstant().toEpochMilli();
        long instant2 = DateFormatters.from(DateFieldMapper.DEFAULT_DATE_TIME_FORMATTER.parse(date2)).toInstant().toEpochMilli() + 999;
        Query expected = new IndexOrDocValuesQuery(
            LongPoint.newRangeQuery(""field"", instant1, instant2),
            SortedNumericDocValuesField.newSlowRangeQuery(""field"", instant1, instant2)
        );
        assertEquals(expected, ft.rangeQuery(date1, date2, true, true, null, null, null, context).rewrite(new MultiReader()));

        MappedFieldType ft2 = new DateFieldType(""field"", false);
        Query expected2 = SortedNumericDocValuesField.newSlowRangeQuery(""field"", instant1, instant2);
        assertEquals(expected2, ft2.rangeQuery(date1, date2, true, true, null, null, null, context).rewrite(new MultiReader()));

        instant1 = nowInMillis;
        instant2 = instant1 + 100;
        expected = new DateRangeIncludingNowQuery(
            new IndexOrDocValuesQuery(
                LongPoint.newRangeQuery(""field"", instant1, instant2),
                SortedNumericDocValuesField.newSlowRangeQuery(""field"", instant1, instant2)
            )
        );
        assertEquals(expected, ft.rangeQuery(""now"", instant2, true, true, null, null, null, context));

        expected2 = new DateRangeIncludingNowQuery(SortedNumericDocValuesField.newSlowRangeQuery(""field"", instant1, instant2));
        assertEquals(expected2, ft2.rangeQuery(""now"", instant2, true, true, null, null, null, context));

        MappedFieldType unsearchable = new DateFieldType(
            ""field"",
            false,
            false,
            false,
            DateFieldMapper.DEFAULT_DATE_TIME_FORMATTER,
            Resolution.MILLISECONDS,
            null,
            null,
            Collections.emptyMap()
        );
        IllegalArgumentException e = expectThrows(
            IllegalArgumentException.class,
            () -> unsearchable.rangeQuery(date1, date2, true, true, null, null, null, context)
        );
        assertEquals(""Cannot search on field [field] since it is not indexed nor has doc values."", e.getMessage());
    }",/server/src/test/java/org/elasticsearch/index/mapper/DateFieldTypeTests.java
497c1efb141d81b5ee7d4fc83d60e3cafce7094c,662,1641,"public AliasFilter buildAliasFilter(ClusterState state, String index, Set<String> resolvedExpressions) {
        /* Being static, parseAliasFilter doesn't have access to whatever guts it needs to parse a query. Instead of passing in a bunch
         * of dependencies we pass in a function that can perform the parsing. */
        CheckedFunction<BytesReference, QueryBuilder, IOException> filterParser = bytes -> {
            try (
                InputStream inputStream = bytes.streamInput();
                XContentParser parser = XContentFactory.xContentType(inputStream)
                    .xContent()
                    .createParser(xContentRegistry, LoggingDeprecationHandler.INSTANCE, inputStream)
            ) {
                return parseInnerQueryBuilder(parser);
            }
        };
        String[] aliases = indexNameExpressionResolver.filteringAliases(state, index, resolvedExpressions);
        if (aliases == null) {
            return AliasFilter.EMPTY;
        }

        Metadata metadata = state.metadata();
        IndexAbstraction ia = state.metadata().getIndicesLookup().get(index);
        if (ia.getParentDataStream() != null) {
            List<QueryBuilder> filters = Arrays.stream(aliases).map(name -> metadata.dataStreamAliases().get(name)).map(dataStreamAlias -> {
                try {
                    return filterParser.apply(dataStreamAlias.getFilter().uncompressed());
                } catch (IOException e) {
                    throw new UncheckedIOException(e);
                }
            }).collect(Collectors.toList());
            if (filters.isEmpty()) {
                return new AliasFilter(null, aliases);
            } else {
                if (filters.size() == 1) {
                    return new AliasFilter(filters.get(0), aliases);
                } else {
                    BoolQueryBuilder bool = new BoolQueryBuilder();
                    for (QueryBuilder filter : filters) {
                        bool.should(filter);
                    }
                    return new AliasFilter(bool, aliases);
                }
            }
        } else {
            IndexMetadata indexMetadata = metadata.index(index);
            return new AliasFilter(ShardSearchRequest.parseAliasFilter(filterParser, indexMetadata, aliases), aliases);
        }
    }","public AliasFilter buildAliasFilter(ClusterState state, String index, Set<String> resolvedExpressions) {
        /* Being static, parseAliasFilter doesn't have access to whatever guts it needs to parse a query. Instead of passing in a bunch
         * of dependencies we pass in a function that can perform the parsing. */
        CheckedFunction<BytesReference, QueryBuilder, IOException> filterParser = bytes -> {
            try (
                InputStream inputStream = bytes.streamInput();
                XContentParser parser = XContentFactory.xContentType(inputStream).xContent().createParser(parserConfig, inputStream)
            ) {
                return parseInnerQueryBuilder(parser);
            }
        };
        String[] aliases = indexNameExpressionResolver.filteringAliases(state, index, resolvedExpressions);
        if (aliases == null) {
            return AliasFilter.EMPTY;
        }

        Metadata metadata = state.metadata();
        IndexAbstraction ia = state.metadata().getIndicesLookup().get(index);
        if (ia.getParentDataStream() != null) {
            List<QueryBuilder> filters = Arrays.stream(aliases).map(name -> metadata.dataStreamAliases().get(name)).map(dataStreamAlias -> {
                try {
                    return filterParser.apply(dataStreamAlias.getFilter().uncompressed());
                } catch (IOException e) {
                    throw new UncheckedIOException(e);
                }
            }).collect(Collectors.toList());
            if (filters.isEmpty()) {
                return new AliasFilter(null, aliases);
            } else {
                if (filters.size() == 1) {
                    return new AliasFilter(filters.get(0), aliases);
                } else {
                    BoolQueryBuilder bool = new BoolQueryBuilder();
                    for (QueryBuilder filter : filters) {
                        bool.should(filter);
                    }
                    return new AliasFilter(bool, aliases);
                }
            }
        } else {
            IndexMetadata indexMetadata = metadata.index(index);
            return new AliasFilter(ShardSearchRequest.parseAliasFilter(filterParser, indexMetadata, aliases), aliases);
        }
    }",/server/src/main/java/org/elasticsearch/indices/IndicesService.java
497c1efb141d81b5ee7d4fc83d60e3cafce7094c,563,97,"public Engine.Operation convertToEngineOp(Translog.Operation operation, Engine.Operation.Origin origin) {
        // If a translog op is replayed on the primary (eg. ccr), we need to use external instead of null for its version type.
        final VersionType versionType = (origin == Engine.Operation.Origin.PRIMARY) ? VersionType.EXTERNAL : null;
        switch (operation.opType()) {
            case INDEX -> {
                final Translog.Index index = (Translog.Index) operation;
                final String indexName = mapperService.index().getName();
                final Engine.Index engineIndex = IndexShard.prepareIndex(
                    mapperService,
                    new SourceToParse(index.id(), index.source(), XContentHelper.xContentType(index.source()), index.routing(), Map.of()),
                    index.seqNo(),
                    index.primaryTerm(),
                    index.version(),
                    versionType,
                    origin,
                    index.getAutoGeneratedIdTimestamp(),
                    true,
                    SequenceNumbers.UNASSIGNED_SEQ_NO,
                    SequenceNumbers.UNASSIGNED_PRIMARY_TERM
                );
                return engineIndex;
            }
            case DELETE -> {
                final Translog.Delete delete = (Translog.Delete) operation;
                return IndexShard.prepareDelete(
                    delete.id(),
                    delete.seqNo(),
                    delete.primaryTerm(),
                    delete.version(),
                    versionType,
                    origin,
                    SequenceNumbers.UNASSIGNED_SEQ_NO,
                    SequenceNumbers.UNASSIGNED_PRIMARY_TERM
                );
            }
            case NO_OP -> {
                final Translog.NoOp noOp = (Translog.NoOp) operation;
                final Engine.NoOp engineNoOp = new Engine.NoOp(noOp.seqNo(), noOp.primaryTerm(), origin, System.nanoTime(), noOp.reason());
                return engineNoOp;
            }
            default -> throw new IllegalStateException(""No operation defined for ["" + operation + ""]"");
        }
    }","public Engine.Operation convertToEngineOp(Translog.Operation operation, Engine.Operation.Origin origin) {
        // If a translog op is replayed on the primary (eg. ccr), we need to use external instead of null for its version type.
        final VersionType versionType = (origin == Engine.Operation.Origin.PRIMARY) ? VersionType.EXTERNAL : null;
        switch (operation.opType()) {
            case INDEX -> {
                final Translog.Index index = (Translog.Index) operation;
                final Engine.Index engineIndex = IndexShard.prepareIndex(
                    mapperService,
                    new SourceToParse(index.id(), index.source(), XContentHelper.xContentType(index.source()), index.routing(), Map.of()),
                    index.seqNo(),
                    index.primaryTerm(),
                    index.version(),
                    versionType,
                    origin,
                    index.getAutoGeneratedIdTimestamp(),
                    true,
                    SequenceNumbers.UNASSIGNED_SEQ_NO,
                    SequenceNumbers.UNASSIGNED_PRIMARY_TERM
                );
                return engineIndex;
            }
            case DELETE -> {
                final Translog.Delete delete = (Translog.Delete) operation;
                return IndexShard.prepareDelete(
                    delete.id(),
                    delete.seqNo(),
                    delete.primaryTerm(),
                    delete.version(),
                    versionType,
                    origin,
                    SequenceNumbers.UNASSIGNED_SEQ_NO,
                    SequenceNumbers.UNASSIGNED_PRIMARY_TERM
                );
            }
            case NO_OP -> {
                final Translog.NoOp noOp = (Translog.NoOp) operation;
                final Engine.NoOp engineNoOp = new Engine.NoOp(noOp.seqNo(), noOp.primaryTerm(), origin, System.nanoTime(), noOp.reason());
                return engineNoOp;
            }
            default -> throw new IllegalStateException(""No operation defined for ["" + operation + ""]"");
        }
    }",/test/framework/src/main/java/org/elasticsearch/index/engine/TranslogHandler.java
0c8c6191816e464c065672d1b4b9cd91b26bb0e5,563,137,"public void clusterChanged(ClusterChangedEvent event) {
        ClusterState state = event.state();
        if (state.blocks().hasGlobalBlock(GatewayService.STATE_NOT_RECOVERED_BLOCK)) {
            // wait until the gateway has recovered from disk, otherwise we think may not have the index templates,
            // while they actually do exist
            return;
        }

        if (updatesInProgress.get() > 0) {
            // we are already running some updates - skip this cluster state update
            return;
        }

        ImmutableOpenMap<String, IndexTemplateMetaData> templates = state.getMetaData().getTemplates();

        if (templates == lastTemplateMetaData) {
            // we already checked these sets of templates - no reason to check it again
            // we can do identity check here because due to cluster state diffs the actual map will not change
            // if there were no changes
            return;
        }

        if (state.nodes().isLocalNodeElectedMaster() == false) {
            return;
        }

        lastTemplateMetaData = templates;
        Optional<Tuple<Map<String, BytesReference>, Set<String>>> changes = calculateTemplateChanges(templates);
        if (changes.isPresent()) {
            if (updatesInProgress.compareAndSet(0, changes.get().v1().size() + changes.get().v2().size())) {
                logger.info(""Starting template upgrade to version {}, {} templates will be updated and {} will be removed"",
                    Version.CURRENT,
                    changes.get().v1().size(),
                    changes.get().v2().size());

                final ThreadContext threadContext = threadPool.getThreadContext();
                try (ThreadContext.StoredContext ignore = threadContext.stashContext()) {
                    threadContext.markAsSystemContext();
                    threadPool.generic().execute(() -> updateTemplates(changes.get().v1(), changes.get().v2()));
                }
            }
        }
    }","public void clusterChanged(ClusterChangedEvent event) {
        ClusterState state = event.state();
        if (state.blocks().hasGlobalBlock(GatewayService.STATE_NOT_RECOVERED_BLOCK)) {
            // wait until the gateway has recovered from disk, otherwise we think may not have the index templates,
            // while they actually do exist
            return;
        }

        if (upgradesInProgress.get() > 0) {
            // we are already running some upgrades - skip this cluster state update
            return;
        }

        ImmutableOpenMap<String, IndexTemplateMetaData> templates = state.getMetaData().getTemplates();

        if (templates == lastTemplateMetaData) {
            // we already checked these sets of templates - no reason to check it again
            // we can do identity check here because due to cluster state diffs the actual map will not change
            // if there were no changes
            return;
        }

        if (state.nodes().isLocalNodeElectedMaster() == false) {
            return;
        }

        lastTemplateMetaData = templates;
        Optional<Tuple<Map<String, BytesReference>, Set<String>>> changes = calculateTemplateChanges(templates);
        if (changes.isPresent()) {
            if (upgradesInProgress.compareAndSet(0, changes.get().v1().size() + changes.get().v2().size() + 1)) {
                logger.info(""Starting template upgrade to version {}, {} templates will be updated and {} will be removed"",
                    Version.CURRENT,
                    changes.get().v1().size(),
                    changes.get().v2().size());

                final ThreadContext threadContext = threadPool.getThreadContext();
                try (ThreadContext.StoredContext ignore = threadContext.stashContext()) {
                    threadContext.markAsSystemContext();
                    threadPool.generic().execute(() -> upgradeTemplates(changes.get().v1(), changes.get().v2()));
                }
            }
        }
    }",/server/src/main/java/org/elasticsearch/cluster/metadata/TemplateUpgradeService.java
6d6ac74a08fbe0535679bbd3d349bf20310ccf96,662,214,"public String toString() {
        return ""FollowersChecker{"" +
            ""followerCheckInterval="" + followerCheckInterval +
            "", followerCheckTimeout="" + followerCheckTimeout +
            "", followerCheckRetryCount="" + followerCheckRetryCount +
            "", followerCheckers="" + followerCheckers +
            "", faultyNodes="" + faultyNodes +
            "", fastResponseState="" + fastResponseState +
            '}';
    }","public Set<DiscoveryNode> getFaultyNodes() {
        synchronized (mutex) {
            return new HashSet<>(this.faultyNodes);
        }
    }",/server/src/main/java/org/elasticsearch/cluster/coordination/FollowersChecker.java
6d6ac74a08fbe0535679bbd3d349bf20310ccf96,567,374,"void becomeCandidate(String method) {
        assert Thread.holdsLock(mutex) : ""Coordinator mutex not held"";
        logger.debug(""{}: becoming CANDIDATE (was {}, lastKnownLeader was [{}])"", method, mode, lastKnownLeader);

        if (mode != Mode.CANDIDATE) {
            mode = Mode.CANDIDATE;
            cancelActivePublication();
            joinAccumulator.close(mode);
            joinAccumulator = joinHelper.new CandidateJoinAccumulator();

            peerFinder.activate(coordinationState.get().getLastAcceptedState().nodes());
            leaderChecker.setCurrentNodes(DiscoveryNodes.EMPTY_NODES);

            if (leaderCheckScheduler != null) {
                leaderCheckScheduler.close();
                leaderCheckScheduler = null;
            }

            followersChecker.clearCurrentNodes();
            followersChecker.updateFastResponseState(getCurrentTerm(), mode);

            if (applierState.nodes().getMasterNodeId() != null) {
                applierState = clusterStateWithNoMasterBlock(applierState);
                clusterApplier.onNewClusterState(""becoming candidate: "" + method, () -> applierState, (source, e) -> {
                });
            }
        }

        preVoteCollector.update(getPreVoteResponse(), null);
    }","void becomeCandidate(String method) {
        assert Thread.holdsLock(mutex) : ""Coordinator mutex not held"";
        logger.debug(""{}: becoming CANDIDATE (was {}, lastKnownLeader was [{}])"", method, mode, lastKnownLeader);

        if (mode != Mode.CANDIDATE) {
            mode = Mode.CANDIDATE;
            cancelActivePublication();
            joinAccumulator.close(mode);
            joinAccumulator = joinHelper.new CandidateJoinAccumulator();

            peerFinder.activate(coordinationState.get().getLastAcceptedState().nodes());
            leaderChecker.setCurrentNodes(DiscoveryNodes.EMPTY_NODES);
            leaderChecker.updateLeader(null);

            followersChecker.clearCurrentNodes();
            followersChecker.updateFastResponseState(getCurrentTerm(), mode);

            if (applierState.nodes().getMasterNodeId() != null) {
                applierState = clusterStateWithNoMasterBlock(applierState);
                clusterApplier.onNewClusterState(""becoming candidate: "" + method, () -> applierState, (source, e) -> {
                });
            }
        }

        preVoteCollector.update(getPreVoteResponse(), null);
    }",/server/src/main/java/org/elasticsearch/cluster/coordination/Coordinator.java
693c80037e11e2b56f1625bdee0d4efd8718d41b,563,162,"AllocationCommandRegistry registry) throws IOException {
        AllocationCommands commands = new AllocationCommands();

        XContentParser.Token token = parser.currentToken();
        if (token == null) {
            throw new ElasticsearchParseException(""No commands"");
        }
        if (token == XContentParser.Token.FIELD_NAME) {
            if (!parser.currentName().equals(""commands"")) {
                throw new ElasticsearchParseException(""expected field name to be named [commands], got [{}] instead"", parser.currentName());
            }
            if (!parser.currentName().equals(""commands"")) {
                throw new ElasticsearchParseException(""expected field name to be named [commands], got [{}] instead"", parser.currentName());
            }
            token = parser.nextToken();
            if (token != XContentParser.Token.START_ARRAY) {
                throw new ElasticsearchParseException(""commands should follow with an array element"");
            }
        } else if (token == XContentParser.Token.START_ARRAY) {
            // ok...
        } else {
            throw new ElasticsearchParseException(""expected either field name [commands], or start array, got [{}] instead"", token);
        }
        while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
            if (token == XContentParser.Token.START_OBJECT) {
                // move to the command name
                token = parser.nextToken();
                String commandName = parser.currentName();
                token = parser.nextToken();
                commands.add(registry.lookup(commandName, parser, parseFieldMatcher).fromXContent(parser));
                // move to the end object one
                if (parser.nextToken() != XContentParser.Token.END_OBJECT) {
                    throw new ElasticsearchParseException(""allocation command is malformed, done parsing a command, but didn't get END_OBJECT, got [{}] instead"", token);
                }
            } else {
                throw new ElasticsearchParseException(""allocation command is malformed, got [{}] instead"", token);
            }
        }
        return commands;
    }","AllocationCommandRegistry registry) throws IOException {
        AllocationCommands commands = new AllocationCommands();

        XContentParser.Token token = parser.currentToken();
        if (token == null) {
            throw new ElasticsearchParseException(""No commands"");
        }
        if (token == XContentParser.Token.FIELD_NAME) {
            if (!parser.currentName().equals(""commands"")) {
                throw new ElasticsearchParseException(""expected field name to be named [commands], got [{}] instead"", parser.currentName());
            }
            if (!parser.currentName().equals(""commands"")) {
                throw new ElasticsearchParseException(""expected field name to be named [commands], got [{}] instead"", parser.currentName());
            }
            token = parser.nextToken();
            if (token != XContentParser.Token.START_ARRAY) {
                throw new ElasticsearchParseException(""commands should follow with an array element"");
            }
        } else if (token == XContentParser.Token.START_ARRAY) {
            // ok...
        } else {
            throw new ElasticsearchParseException(""expected either field name [commands], or start array, got [{}] instead"", token);
        }
        while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
            if (token == XContentParser.Token.START_OBJECT) {
                // move to the command name
                token = parser.nextToken();
                String commandName = parser.currentName();
                token = parser.nextToken();
                commands.add(registry.lookup(commandName, parseFieldMatcher, parser.getTokenLocation()).fromXContent(parser));
                // move to the end object one
                if (parser.nextToken() != XContentParser.Token.END_OBJECT) {
                    throw new ElasticsearchParseException(""allocation command is malformed, done parsing a command, but didn't get END_OBJECT, got [{}] instead"", token);
                }
            } else {
                throw new ElasticsearchParseException(""allocation command is malformed, got [{}] instead"", token);
            }
        }
        return commands;
    }",/core/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocationCommands.java
c7285d9d19791f37693cbee5e60f60e1e567cd35,391,79,"public void testTimeoutUpdateTask() throws Exception {
        Settings settings = settingsBuilder()
                .put(""discovery.type"", ""local"")
                .build();
        internalCluster().startNode(settings);
        ClusterService clusterService1 = internalCluster().getInstance(ClusterService.class);
        final CountDownLatch block = new CountDownLatch(1);
        clusterService1.submitStateUpdateTask(""test1"", new ClusterStateUpdateTask() {
            @Override
            public ClusterState execute(ClusterState currentState) {
                try {
                    block.await();
                } catch (InterruptedException e) {
                    fail();
                }
                return currentState;
            }

            @Override
            public void onFailure(String source, Throwable t) {
                fail();
            }
        });

        final CountDownLatch timedOut = new CountDownLatch(1);
        final AtomicBoolean executeCalled = new AtomicBoolean();
        clusterService1.submitStateUpdateTask(""test2"", new TimeoutClusterStateUpdateTask() {
            @Override
            public TimeValue timeout() {
                return TimeValue.timeValueMillis(2);
            }

            @Override
            public void onFailure(String source, Throwable t) {
                timedOut.countDown();
            }

            @Override
            public ClusterState execute(ClusterState currentState) {
                executeCalled.set(true);
                return currentState;
            }

            @Override
            public void clusterStateProcessed(String source, ClusterState oldState, ClusterState newState) {
            }
        });

        assertThat(timedOut.await(500, TimeUnit.MILLISECONDS), equalTo(true));
        block.countDown();
        Thread.sleep(100); // sleep a bit to double check that execute on the timed out update task is not called...
        assertThat(executeCalled.get(), equalTo(false));
    }","public void testTimeoutUpdateTask() throws Exception {
        Settings settings = settingsBuilder()
                .put(""discovery.type"", ""local"")
                .build();
        internalCluster().startNode(settings);
        ClusterService clusterService1 = internalCluster().getInstance(ClusterService.class);
        final CountDownLatch block = new CountDownLatch(1);
        clusterService1.submitStateUpdateTask(""test1"", new ClusterStateUpdateTask() {
            @Override
            public ClusterState execute(ClusterState currentState) {
                try {
                    block.await();
                } catch (InterruptedException e) {
                    throw new RuntimeException(e);
                }
                return currentState;
            }

            @Override
            public void onFailure(String source, Throwable t) {
                throw new RuntimeException(t);
            }
        });

        final CountDownLatch timedOut = new CountDownLatch(1);
        final AtomicBoolean executeCalled = new AtomicBoolean();
        clusterService1.submitStateUpdateTask(""test2"", new TimeoutClusterStateUpdateTask() {
            @Override
            public TimeValue timeout() {
                return TimeValue.timeValueMillis(2);
            }

            @Override
            public void onFailure(String source, Throwable t) {
                timedOut.countDown();
            }

            @Override
            public ClusterState execute(ClusterState currentState) {
                executeCalled.set(true);
                return currentState;
            }

            @Override
            public void clusterStateProcessed(String source, ClusterState oldState, ClusterState newState) {
            }
        });

        timedOut.await();
        block.countDown();
        final CountDownLatch allProcessed = new CountDownLatch(1);
        clusterService1.submitStateUpdateTask(""test3"", new ClusterStateUpdateTask() {
            @Override
            public void onFailure(String source, Throwable t) {
                throw new RuntimeException(t);
            }

            @Override
            public ClusterState execute(ClusterState currentState) {
                allProcessed.countDown();
                return currentState;
            }

        });
        allProcessed.await(); // executed another task to double check that execute on the timed out update task is not called...
        assertThat(executeCalled.get(), equalTo(false));
    }",/core/src/test/java/org/elasticsearch/cluster/ClusterServiceTests.java
b6168e2f931444725268ff223c8d4f966f6f197c,563,158,"public void testCreateAndRestorePartialSearchableSnapshot() throws Exception {
        final String fsRepoName = randomAlphaOfLength(10);
        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);
        final String aliasName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);
        final String restoredIndexName = randomBoolean() ? indexName : randomAlphaOfLength(10).toLowerCase(Locale.ROOT);
        final String snapshotName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);

        createRepository(
            fsRepoName,
            ""fs"",
            Settings.builder().put(""location"", randomRepoPath()).put(""chunk_size"", randomIntBetween(100, 1000), ByteSizeUnit.BYTES)
        );

        // Peer recovery always copies .liv files but we do not permit writing to searchable snapshot directories so this doesn't work, but
        // we can bypass this by forcing soft deletes to be used. TODO this restriction can be lifted when #55142 is resolved.
        final Settings.Builder originalIndexSettings = Settings.builder().put(INDEX_SOFT_DELETES_SETTING.getKey(), true);
        if (randomBoolean()) {
            originalIndexSettings.put(IndexSettings.INDEX_CHECK_ON_STARTUP.getKey(), randomFrom(""false"", ""true"", ""checksum""));
        }
        assertAcked(prepareCreate(indexName, originalIndexSettings));
        assertAcked(client().admin().indices().prepareAliases().addAlias(indexName, aliasName));

        populateIndex(indexName, 10_000);

        final TotalHits originalAllHits = internalCluster().client()
            .prepareSearch(indexName)
            .setTrackTotalHits(true)
            .get()
            .getHits()
            .getTotalHits();
        final TotalHits originalBarHits = internalCluster().client()
            .prepareSearch(indexName)
            .setTrackTotalHits(true)
            .setQuery(matchQuery(""foo"", ""bar""))
            .get()
            .getHits()
            .getTotalHits();
        logger.info(""--> [{}] in total, of which [{}] match the query"", originalAllHits, originalBarHits);

        expectThrows(
            ResourceNotFoundException.class,
            ""Searchable snapshot stats on a non snapshot searchable index should fail"",
            () -> client().execute(SearchableSnapshotsStatsAction.INSTANCE, new SearchableSnapshotsStatsRequest()).actionGet()
        );

        final SnapshotInfo snapshotInfo = createFullSnapshot(fsRepoName, snapshotName);
        ensureGreen(indexName);

        assertShardFolders(indexName, false);

        assertThat(
            client().admin()
                .cluster()
                .prepareState()
                .clear()
                .setMetadata(true)
                .setIndices(indexName)
                .get()
                .getState()
                .metadata()
                .index(indexName)
                .getTimestampRange(),
            sameInstance(IndexLongFieldRange.UNKNOWN)
        );

        final boolean deletedBeforeMount = randomBoolean();
        if (deletedBeforeMount) {
            assertAcked(client().admin().indices().prepareDelete(indexName));
        } else {
            assertAcked(client().admin().indices().prepareClose(indexName));
        }

        logger.info(""--> restoring partial index [{}] with cache enabled"", restoredIndexName);

        Settings.Builder indexSettingsBuilder = Settings.builder().put(SearchableSnapshots.SNAPSHOT_CACHE_ENABLED_SETTING.getKey(), true);
        final List<String> nonCachedExtensions;
        if (randomBoolean()) {
            nonCachedExtensions = randomSubsetOf(Arrays.asList(""fdt"", ""fdx"", ""nvd"", ""dvd"", ""tip"", ""cfs"", ""dim""));
            indexSettingsBuilder.putList(SearchableSnapshots.SNAPSHOT_CACHE_EXCLUDED_FILE_TYPES_SETTING.getKey(), nonCachedExtensions);
        } else {
            nonCachedExtensions = Collections.emptyList();
        }
        if (randomBoolean()) {
            indexSettingsBuilder.put(
                SearchableSnapshots.SNAPSHOT_UNCACHED_CHUNK_SIZE_SETTING.getKey(),
                new ByteSizeValue(randomLongBetween(10, 100_000))
            );
        }
        final int expectedReplicas;
        if (randomBoolean()) {
            expectedReplicas = numberOfReplicas();
            indexSettingsBuilder.put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, expectedReplicas);
        } else {
            expectedReplicas = 0;
        }
        final String indexCheckOnStartup;
        if (randomBoolean()) {
            indexCheckOnStartup = randomFrom(""false"", ""true"", ""checksum"");
            indexSettingsBuilder.put(IndexSettings.INDEX_CHECK_ON_STARTUP.getKey(), indexCheckOnStartup);
        } else {
            indexCheckOnStartup = ""false"";
        }
        final String expectedDataTiersPreference;
        expectedDataTiersPreference = getDataTiersPreference(MountSearchableSnapshotRequest.Storage.SHARED_CACHE);

        indexSettingsBuilder.put(Store.INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), TimeValue.ZERO);
        final AtomicBoolean statsWatcherRunning = new AtomicBoolean(true);
        final Thread statsWatcher = new Thread(() -> {
            while (statsWatcherRunning.get()) {
                final IndicesStatsResponse indicesStatsResponse;
                try {
                    indicesStatsResponse = client().admin().indices().prepareStats(restoredIndexName).clear().setStore(true).get();
                } catch (IndexNotFoundException | IndexClosedException e) {
                    continue;
                    // ok
                }

                for (ShardStats shardStats : indicesStatsResponse.getShards()) {
                    StoreStats store = shardStats.getStats().getStore();
                    assertThat(shardStats.getShardRouting().toString(), store.getReservedSize().getBytes(), equalTo(0L));
                    assertThat(shardStats.getShardRouting().toString(), store.getSize().getBytes(), equalTo(0L));
                }
                if (indicesStatsResponse.getShards().length > 0) {
                    assertThat(indicesStatsResponse.getTotal().getStore().getReservedSize().getBytes(), equalTo(0L));
                    assertThat(indicesStatsResponse.getTotal().getStore().getSize().getBytes(), equalTo(0L));
                }
            }
        }, ""test-stats-watcher"");
        statsWatcher.start();

        final MountSearchableSnapshotRequest req = new MountSearchableSnapshotRequest(
            restoredIndexName,
            fsRepoName,
            snapshotInfo.snapshotId().getName(),
            indexName,
            indexSettingsBuilder.build(),
            Strings.EMPTY_ARRAY,
            true,
            MountSearchableSnapshotRequest.Storage.SHARED_CACHE
        );

        final RestoreSnapshotResponse restoreSnapshotResponse = client().execute(MountSearchableSnapshotAction.INSTANCE, req).get();
        assertThat(restoreSnapshotResponse.getRestoreInfo().failedShards(), equalTo(0));

        final Map<Integer, SnapshotIndexShardStatus> snapshotShards = clusterAdmin().prepareSnapshotStatus(fsRepoName)
            .setSnapshots(snapshotInfo.snapshotId().getName())
            .get()
            .getSnapshots()
            .get(0)
            .getIndices()
            .get(indexName)
            .getShards();

        ensureGreen(restoredIndexName);

        final IndicesStatsResponse indicesStatsResponse = client().admin()
            .indices()
            .prepareStats(restoredIndexName)
            .clear()
            .setStore(true)
            .get();
        assertThat(indicesStatsResponse.getShards().length, greaterThan(0));
        long totalExpectedSize = 0;
        for (ShardStats shardStats : indicesStatsResponse.getShards()) {
            StoreStats store = shardStats.getStats().getStore();

            final ShardRouting shardRouting = shardStats.getShardRouting();
            assertThat(shardRouting.toString(), store.getReservedSize().getBytes(), equalTo(0L));
            assertThat(shardRouting.toString(), store.getSize().getBytes(), equalTo(0L));

            // the original shard size from the snapshot
            final long originalSize = snapshotShards.get(shardRouting.getId()).getStats().getTotalSize();
            totalExpectedSize += originalSize;

            // an extra segments_N file is created for bootstrapping new history and associating translog. We can extract the size of this
            // extra file but we have to unwrap the in-memory directory first.
            final Directory unwrappedDir = FilterDirectory.unwrap(
                internalCluster().getInstance(IndicesService.class, getDiscoveryNodes().resolveNode(shardRouting.currentNodeId()).getName())
                    .indexServiceSafe(shardRouting.index())
                    .getShard(shardRouting.getId())
                    .store()
                    .directory()
            );
            assertThat(shardRouting.toString(), unwrappedDir, notNullValue());
            assertThat(shardRouting.toString(), unwrappedDir, instanceOf(ByteBuffersDirectory.class));

            final ByteBuffersDirectory inMemoryDir = (ByteBuffersDirectory) unwrappedDir;
            assertThat(inMemoryDir.listAll(), arrayWithSize(1));

            final String segmentsFileName = SegmentInfos.getLastCommitSegmentsFileName(inMemoryDir);
            assertThat(""Fail to find segment file name directory for "" + shardRouting.toString(), segmentsFileName, notNullValue());
            final long extraSegmentFileSize = inMemoryDir.fileLength(segmentsFileName);

            assertThat(shardRouting.toString(), store.getTotalDataSetSize().getBytes(), equalTo(originalSize + extraSegmentFileSize));
            totalExpectedSize += extraSegmentFileSize;
        }

        final StoreStats store = indicesStatsResponse.getTotal().getStore();
        assertThat(store.getTotalDataSetSize().getBytes(), equalTo(totalExpectedSize));

        statsWatcherRunning.set(false);
        statsWatcher.join();

        final Settings settings = client().admin()
            .indices()
            .prepareGetSettings(restoredIndexName)
            .get()
            .getIndexToSettings()
            .get(restoredIndexName);
        assertThat(SearchableSnapshots.SNAPSHOT_SNAPSHOT_NAME_SETTING.get(settings), equalTo(snapshotName));
        assertThat(IndexModule.INDEX_STORE_TYPE_SETTING.get(settings), equalTo(SNAPSHOT_DIRECTORY_FACTORY_KEY));
        assertThat(IndexModule.INDEX_RECOVERY_TYPE_SETTING.get(settings), equalTo(SNAPSHOT_RECOVERY_STATE_FACTORY_KEY));
        assertTrue(IndexMetadata.INDEX_BLOCKS_WRITE_SETTING.get(settings));
        assertTrue(SearchableSnapshots.SNAPSHOT_SNAPSHOT_ID_SETTING.exists(settings));
        assertTrue(SearchableSnapshots.SNAPSHOT_INDEX_ID_SETTING.exists(settings));
        assertThat(IndexMetadata.INDEX_AUTO_EXPAND_REPLICAS_SETTING.get(settings).toString(), equalTo(""false""));
        assertThat(IndexMetadata.INDEX_NUMBER_OF_REPLICAS_SETTING.get(settings), equalTo(expectedReplicas));
        assertThat(DataTierAllocationDecider.INDEX_ROUTING_PREFER_SETTING.get(settings), equalTo(expectedDataTiersPreference));
        assertTrue(SearchableSnapshotsConstants.SNAPSHOT_PARTIAL_SETTING.get(settings));
        assertTrue(DiskThresholdDecider.SETTING_IGNORE_DISK_WATERMARKS.get(settings));
        assertThat(IndexSettings.INDEX_CHECK_ON_STARTUP.get(settings), equalTo(""false""));

        checkSoftDeletesNotEagerlyLoaded(restoredIndexName);
        assertTotalHits(restoredIndexName, originalAllHits, originalBarHits);
        assertRecoveryStats(restoredIndexName, false);
        // TODO: fix
        // assertSearchableSnapshotStats(restoredIndexName, true, nonCachedExtensions);
        ensureGreen(restoredIndexName);
        assertShardFolders(restoredIndexName, true);

        assertThat(
            client().admin()
                .cluster()
                .prepareState()
                .clear()
                .setMetadata(true)
                .setIndices(restoredIndexName)
                .get()
                .getState()
                .metadata()
                .index(restoredIndexName)
                .getTimestampRange(),
            sameInstance(IndexLongFieldRange.UNKNOWN)
        );

        if (deletedBeforeMount) {
            assertThat(client().admin().indices().prepareGetAliases(aliasName).get().getAliases().size(), equalTo(0));
            assertAcked(client().admin().indices().prepareAliases().addAlias(restoredIndexName, aliasName));
        } else if (indexName.equals(restoredIndexName) == false) {
            assertThat(client().admin().indices().prepareGetAliases(aliasName).get().getAliases().size(), equalTo(1));
            assertAcked(
                client().admin()
                    .indices()
                    .prepareAliases()
                    .addAliasAction(IndicesAliasesRequest.AliasActions.remove().index(indexName).alias(aliasName).mustExist(true))
                    .addAlias(restoredIndexName, aliasName)
            );
        }
        assertThat(client().admin().indices().prepareGetAliases(aliasName).get().getAliases().size(), equalTo(1));
        assertTotalHits(aliasName, originalAllHits, originalBarHits);

        final Decision diskDeciderDecision = client().admin()
            .cluster()
            .prepareAllocationExplain()
            .setIndex(restoredIndexName)
            .setShard(0)
            .setPrimary(true)
            .setIncludeYesDecisions(true)
            .get()
            .getExplanation()
            .getShardAllocationDecision()
            .getMoveDecision()
            .getCanRemainDecision()
            .getDecisions()
            .stream()
            .filter(d -> d.label().equals(DiskThresholdDecider.NAME))
            .findFirst()
            .orElseThrow();
        assertThat(diskDeciderDecision.type(), equalTo(Decision.Type.YES));
        assertThat(
            diskDeciderDecision.getExplanation(),
            oneOf(""disk watermarks are ignored on this index"", ""there is only a single data node present"")
        );

        internalCluster().fullRestart();
        assertTotalHits(restoredIndexName, originalAllHits, originalBarHits);
        assertRecoveryStats(restoredIndexName, false);
        assertTotalHits(aliasName, originalAllHits, originalBarHits);
        // TODO: fix
        // assertSearchableSnapshotStats(restoredIndexName, false, nonCachedExtensions);

        internalCluster().ensureAtLeastNumDataNodes(2);

        final DiscoveryNode dataNode = randomFrom(
            StreamSupport.stream(
                client().admin().cluster().prepareState().get().getState().nodes().getDataNodes().values().spliterator(),
                false
            ).map(c -> c.value).toArray(DiscoveryNode[]::new)
        );

        assertAcked(
            client().admin()
                .indices()
                .prepareUpdateSettings(restoredIndexName)
                .setSettings(
                    Settings.builder()
                        .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)
                        .put(
                            IndexMetadata.INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(""_name"").getKey(),
                            dataNode.getName()
                        )
                )
        );

        assertFalse(
            client().admin()
                .cluster()
                .prepareHealth(restoredIndexName)
                .setWaitForNoRelocatingShards(true)
                .setWaitForEvents(Priority.LANGUID)
                .get()
                .isTimedOut()
        );

        assertTotalHits(restoredIndexName, originalAllHits, originalBarHits);
        assertRecoveryStats(restoredIndexName, false);
        // TODO: fix
        // assertSearchableSnapshotStats(restoredIndexName, false, nonCachedExtensions);

        assertAcked(
            client().admin()
                .indices()
                .prepareUpdateSettings(restoredIndexName)
                .setSettings(
                    Settings.builder()
                        .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1)
                        .putNull(IndexMetadata.INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(""_name"").getKey())
                )
        );

        assertTotalHits(restoredIndexName, originalAllHits, originalBarHits);
        assertRecoveryStats(restoredIndexName, false);

        final String clonedIndexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);
        assertAcked(
            client().admin()
                .indices()
                .prepareResizeIndex(restoredIndexName, clonedIndexName)
                .setResizeType(ResizeType.CLONE)
                .setSettings(
                    Settings.builder()
                        .putNull(IndexModule.INDEX_STORE_TYPE_SETTING.getKey())
                        .putNull(IndexModule.INDEX_RECOVERY_TYPE_SETTING.getKey())
                        .put(DataTierAllocationDecider.INDEX_ROUTING_PREFER, DataTier.DATA_HOT)
                        .build()
                )
        );
        ensureGreen(clonedIndexName);
        assertTotalHits(clonedIndexName, originalAllHits, originalBarHits);

        final Settings clonedIndexSettings = client().admin()
            .indices()
            .prepareGetSettings(clonedIndexName)
            .get()
            .getIndexToSettings()
            .get(clonedIndexName);
        assertFalse(clonedIndexSettings.hasValue(IndexModule.INDEX_STORE_TYPE_SETTING.getKey()));
        assertFalse(clonedIndexSettings.hasValue(SearchableSnapshots.SNAPSHOT_SNAPSHOT_NAME_SETTING.getKey()));
        assertFalse(clonedIndexSettings.hasValue(SearchableSnapshots.SNAPSHOT_SNAPSHOT_ID_SETTING.getKey()));
        assertFalse(clonedIndexSettings.hasValue(SearchableSnapshots.SNAPSHOT_INDEX_ID_SETTING.getKey()));
        assertFalse(clonedIndexSettings.hasValue(IndexModule.INDEX_RECOVERY_TYPE_SETTING.getKey()));

        assertAcked(client().admin().indices().prepareDelete(restoredIndexName));
        assertThat(client().admin().indices().prepareGetAliases(aliasName).get().getAliases().size(), equalTo(0));
        assertAcked(client().admin().indices().prepareAliases().addAlias(clonedIndexName, aliasName));
        assertTotalHits(aliasName, originalAllHits, originalBarHits);
    }","public void testCreateAndRestorePartialSearchableSnapshot() throws Exception {
        final String fsRepoName = randomAlphaOfLength(10);
        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);
        final String aliasName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);
        final String restoredIndexName = randomBoolean() ? indexName : randomAlphaOfLength(10).toLowerCase(Locale.ROOT);
        final String snapshotName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);

        createRepository(
            fsRepoName,
            ""fs"",
            Settings.builder().put(""location"", randomRepoPath()).put(""chunk_size"", randomIntBetween(100, 1000), ByteSizeUnit.BYTES)
        );

        // Peer recovery always copies .liv files but we do not permit writing to searchable snapshot directories so this doesn't work, but
        // we can bypass this by forcing soft deletes to be used. TODO this restriction can be lifted when #55142 is resolved.
        final Settings.Builder originalIndexSettings = Settings.builder().put(INDEX_SOFT_DELETES_SETTING.getKey(), true);
        if (randomBoolean()) {
            originalIndexSettings.put(IndexSettings.INDEX_CHECK_ON_STARTUP.getKey(), randomFrom(""false"", ""true"", ""checksum""));
        }
        assertAcked(prepareCreate(indexName, originalIndexSettings));
        assertAcked(client().admin().indices().prepareAliases().addAlias(indexName, aliasName));

        populateIndex(indexName, 10_000);

        final TotalHits originalAllHits = internalCluster().client()
            .prepareSearch(indexName)
            .setTrackTotalHits(true)
            .get()
            .getHits()
            .getTotalHits();
        final TotalHits originalBarHits = internalCluster().client()
            .prepareSearch(indexName)
            .setTrackTotalHits(true)
            .setQuery(matchQuery(""foo"", ""bar""))
            .get()
            .getHits()
            .getTotalHits();
        logger.info(""--> [{}] in total, of which [{}] match the query"", originalAllHits, originalBarHits);

        expectThrows(
            ResourceNotFoundException.class,
            ""Searchable snapshot stats on a non snapshot searchable index should fail"",
            () -> client().execute(SearchableSnapshotsStatsAction.INSTANCE, new SearchableSnapshotsStatsRequest()).actionGet()
        );

        final SnapshotInfo snapshotInfo = createFullSnapshot(fsRepoName, snapshotName);
        ensureGreen(indexName);

        assertShardFolders(indexName, false);

        assertThat(
            client().admin()
                .cluster()
                .prepareState()
                .clear()
                .setMetadata(true)
                .setIndices(indexName)
                .get()
                .getState()
                .metadata()
                .index(indexName)
                .getTimestampRange(),
            sameInstance(IndexLongFieldRange.UNKNOWN)
        );

        final boolean deletedBeforeMount = randomBoolean();
        if (deletedBeforeMount) {
            assertAcked(client().admin().indices().prepareDelete(indexName));
        } else {
            assertAcked(client().admin().indices().prepareClose(indexName));
        }

        logger.info(""--> restoring partial index [{}] with cache enabled"", restoredIndexName);

        Settings.Builder indexSettingsBuilder = Settings.builder().put(SearchableSnapshots.SNAPSHOT_CACHE_ENABLED_SETTING.getKey(), true);
        final List<String> nonCachedExtensions;
        if (randomBoolean()) {
            nonCachedExtensions = randomSubsetOf(Arrays.asList(""fdt"", ""fdx"", ""nvd"", ""dvd"", ""tip"", ""cfs"", ""dim""));
            indexSettingsBuilder.putList(SearchableSnapshots.SNAPSHOT_CACHE_EXCLUDED_FILE_TYPES_SETTING.getKey(), nonCachedExtensions);
        } else {
            nonCachedExtensions = Collections.emptyList();
        }
        if (randomBoolean()) {
            indexSettingsBuilder.put(
                SearchableSnapshots.SNAPSHOT_UNCACHED_CHUNK_SIZE_SETTING.getKey(),
                new ByteSizeValue(randomLongBetween(10, 100_000))
            );
        }
        final int expectedReplicas;
        if (randomBoolean()) {
            expectedReplicas = numberOfReplicas();
            indexSettingsBuilder.put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, expectedReplicas);
        } else {
            expectedReplicas = 0;
        }
        final String indexCheckOnStartup;
        if (randomBoolean()) {
            indexCheckOnStartup = randomFrom(""false"", ""true"", ""checksum"");
            indexSettingsBuilder.put(IndexSettings.INDEX_CHECK_ON_STARTUP.getKey(), indexCheckOnStartup);
        } else {
            indexCheckOnStartup = ""false"";
        }
        final String expectedDataTiersPreference;
        expectedDataTiersPreference = getDataTiersPreference(MountSearchableSnapshotRequest.Storage.SHARED_CACHE);

        indexSettingsBuilder.put(Store.INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING.getKey(), TimeValue.ZERO);
        final AtomicBoolean statsWatcherRunning = new AtomicBoolean(true);
        final Thread statsWatcher = new Thread(() -> {
            while (statsWatcherRunning.get()) {
                final IndicesStatsResponse indicesStatsResponse;
                try {
                    indicesStatsResponse = client().admin().indices().prepareStats(restoredIndexName).clear().setStore(true).get();
                } catch (IndexNotFoundException | IndexClosedException e) {
                    continue;
                    // ok
                }

                for (ShardStats shardStats : indicesStatsResponse.getShards()) {
                    StoreStats store = shardStats.getStats().getStore();
                    assertThat(shardStats.getShardRouting().toString(), store.getReservedSize().getBytes(), equalTo(0L));
                    assertThat(shardStats.getShardRouting().toString(), store.getSize().getBytes(), equalTo(0L));
                }
                if (indicesStatsResponse.getShards().length > 0) {
                    assertThat(indicesStatsResponse.getTotal().getStore().getReservedSize().getBytes(), equalTo(0L));
                    assertThat(indicesStatsResponse.getTotal().getStore().getSize().getBytes(), equalTo(0L));
                }
            }
        }, ""test-stats-watcher"");
        statsWatcher.start();

        final MountSearchableSnapshotRequest req = new MountSearchableSnapshotRequest(
            restoredIndexName,
            fsRepoName,
            snapshotInfo.snapshotId().getName(),
            indexName,
            indexSettingsBuilder.build(),
            Strings.EMPTY_ARRAY,
            true,
            MountSearchableSnapshotRequest.Storage.SHARED_CACHE
        );

        final RestoreSnapshotResponse restoreSnapshotResponse = client().execute(MountSearchableSnapshotAction.INSTANCE, req).get();
        assertThat(restoreSnapshotResponse.getRestoreInfo().failedShards(), equalTo(0));

        final Map<Integer, SnapshotIndexShardStatus> snapshotShards = clusterAdmin().prepareSnapshotStatus(fsRepoName)
            .setSnapshots(snapshotInfo.snapshotId().getName())
            .get()
            .getSnapshots()
            .get(0)
            .getIndices()
            .get(indexName)
            .getShards();

        ensureGreen(restoredIndexName);

        final IndicesStatsResponse indicesStatsResponse = client().admin()
            .indices()
            .prepareStats(restoredIndexName)
            .clear()
            .setStore(true)
            .get();
        assertThat(indicesStatsResponse.getShards().length, greaterThan(0));
        long totalExpectedSize = 0;
        for (ShardStats shardStats : indicesStatsResponse.getShards()) {
            StoreStats store = shardStats.getStats().getStore();

            final ShardRouting shardRouting = shardStats.getShardRouting();
            assertThat(shardRouting.toString(), store.getReservedSize().getBytes(), equalTo(0L));
            assertThat(shardRouting.toString(), store.getSize().getBytes(), equalTo(0L));

            // the original shard size from the snapshot
            final long originalSize = snapshotShards.get(shardRouting.getId()).getStats().getTotalSize();
            totalExpectedSize += originalSize;

            // an extra segments_N file is created for bootstrapping new history and associating translog. We can extract the size of this
            // extra file but we have to unwrap the in-memory directory first.
            final Directory unwrappedDir = FilterDirectory.unwrap(
                internalCluster().getInstance(IndicesService.class, getDiscoveryNodes().resolveNode(shardRouting.currentNodeId()).getName())
                    .indexServiceSafe(shardRouting.index())
                    .getShard(shardRouting.getId())
                    .store()
                    .directory()
            );
            assertThat(shardRouting.toString(), unwrappedDir, notNullValue());
            assertThat(shardRouting.toString(), unwrappedDir, instanceOf(ByteBuffersDirectory.class));

            final ByteBuffersDirectory inMemoryDir = (ByteBuffersDirectory) unwrappedDir;
            assertThat(inMemoryDir.listAll(), arrayWithSize(1));

            final String segmentsFileName = SegmentInfos.getLastCommitSegmentsFileName(inMemoryDir);
            assertThat(""Fail to find segment file name directory for "" + shardRouting.toString(), segmentsFileName, notNullValue());
            final long extraSegmentFileSize = inMemoryDir.fileLength(segmentsFileName);

            assertThat(shardRouting.toString(), store.getTotalDataSetSize().getBytes(), equalTo(originalSize + extraSegmentFileSize));
            totalExpectedSize += extraSegmentFileSize;
        }

        final StoreStats store = indicesStatsResponse.getTotal().getStore();
        assertThat(store.getTotalDataSetSize().getBytes(), equalTo(totalExpectedSize));

        statsWatcherRunning.set(false);
        statsWatcher.join();

        final Settings settings = client().admin()
            .indices()
            .prepareGetSettings(restoredIndexName)
            .get()
            .getIndexToSettings()
            .get(restoredIndexName);
        assertThat(SearchableSnapshots.SNAPSHOT_SNAPSHOT_NAME_SETTING.get(settings), equalTo(snapshotName));
        assertThat(IndexModule.INDEX_STORE_TYPE_SETTING.get(settings), equalTo(SNAPSHOT_DIRECTORY_FACTORY_KEY));
        assertThat(IndexModule.INDEX_RECOVERY_TYPE_SETTING.get(settings), equalTo(SNAPSHOT_RECOVERY_STATE_FACTORY_KEY));
        assertTrue(IndexMetadata.INDEX_BLOCKS_WRITE_SETTING.get(settings));
        assertTrue(SearchableSnapshots.SNAPSHOT_SNAPSHOT_ID_SETTING.exists(settings));
        assertTrue(SearchableSnapshots.SNAPSHOT_INDEX_ID_SETTING.exists(settings));
        assertThat(IndexMetadata.INDEX_AUTO_EXPAND_REPLICAS_SETTING.get(settings).toString(), equalTo(""false""));
        assertThat(IndexMetadata.INDEX_NUMBER_OF_REPLICAS_SETTING.get(settings), equalTo(expectedReplicas));
        assertThat(DataTierAllocationDecider.INDEX_ROUTING_PREFER_SETTING.get(settings), equalTo(expectedDataTiersPreference));
        assertTrue(SearchableSnapshotsConstants.SNAPSHOT_PARTIAL_SETTING.get(settings));
        assertTrue(DiskThresholdDecider.SETTING_IGNORE_DISK_WATERMARKS.get(settings));
        assertThat(IndexSettings.INDEX_CHECK_ON_STARTUP.get(settings), equalTo(indexCheckOnStartup));

        checkSoftDeletesNotEagerlyLoaded(restoredIndexName);
        assertTotalHits(restoredIndexName, originalAllHits, originalBarHits);
        assertRecoveryStats(restoredIndexName, false);
        // TODO: fix
        // assertSearchableSnapshotStats(restoredIndexName, true, nonCachedExtensions);
        ensureGreen(restoredIndexName);
        assertShardFolders(restoredIndexName, true);

        assertThat(
            client().admin()
                .cluster()
                .prepareState()
                .clear()
                .setMetadata(true)
                .setIndices(restoredIndexName)
                .get()
                .getState()
                .metadata()
                .index(restoredIndexName)
                .getTimestampRange(),
            sameInstance(IndexLongFieldRange.UNKNOWN)
        );

        if (deletedBeforeMount) {
            assertThat(client().admin().indices().prepareGetAliases(aliasName).get().getAliases().size(), equalTo(0));
            assertAcked(client().admin().indices().prepareAliases().addAlias(restoredIndexName, aliasName));
        } else if (indexName.equals(restoredIndexName) == false) {
            assertThat(client().admin().indices().prepareGetAliases(aliasName).get().getAliases().size(), equalTo(1));
            assertAcked(
                client().admin()
                    .indices()
                    .prepareAliases()
                    .addAliasAction(IndicesAliasesRequest.AliasActions.remove().index(indexName).alias(aliasName).mustExist(true))
                    .addAlias(restoredIndexName, aliasName)
            );
        }
        assertThat(client().admin().indices().prepareGetAliases(aliasName).get().getAliases().size(), equalTo(1));
        assertTotalHits(aliasName, originalAllHits, originalBarHits);

        final Decision diskDeciderDecision = client().admin()
            .cluster()
            .prepareAllocationExplain()
            .setIndex(restoredIndexName)
            .setShard(0)
            .setPrimary(true)
            .setIncludeYesDecisions(true)
            .get()
            .getExplanation()
            .getShardAllocationDecision()
            .getMoveDecision()
            .getCanRemainDecision()
            .getDecisions()
            .stream()
            .filter(d -> d.label().equals(DiskThresholdDecider.NAME))
            .findFirst()
            .orElseThrow();
        assertThat(diskDeciderDecision.type(), equalTo(Decision.Type.YES));
        assertThat(
            diskDeciderDecision.getExplanation(),
            oneOf(""disk watermarks are ignored on this index"", ""there is only a single data node present"")
        );

        internalCluster().fullRestart();
        assertTotalHits(restoredIndexName, originalAllHits, originalBarHits);
        assertRecoveryStats(restoredIndexName, false);
        assertTotalHits(aliasName, originalAllHits, originalBarHits);
        // TODO: fix
        // assertSearchableSnapshotStats(restoredIndexName, false, nonCachedExtensions);

        internalCluster().ensureAtLeastNumDataNodes(2);

        final DiscoveryNode dataNode = randomFrom(
            StreamSupport.stream(
                client().admin().cluster().prepareState().get().getState().nodes().getDataNodes().values().spliterator(),
                false
            ).map(c -> c.value).toArray(DiscoveryNode[]::new)
        );

        assertAcked(
            client().admin()
                .indices()
                .prepareUpdateSettings(restoredIndexName)
                .setSettings(
                    Settings.builder()
                        .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)
                        .put(
                            IndexMetadata.INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(""_name"").getKey(),
                            dataNode.getName()
                        )
                )
        );

        assertFalse(
            client().admin()
                .cluster()
                .prepareHealth(restoredIndexName)
                .setWaitForNoRelocatingShards(true)
                .setWaitForEvents(Priority.LANGUID)
                .get()
                .isTimedOut()
        );

        assertTotalHits(restoredIndexName, originalAllHits, originalBarHits);
        assertRecoveryStats(restoredIndexName, false);
        // TODO: fix
        // assertSearchableSnapshotStats(restoredIndexName, false, nonCachedExtensions);

        assertAcked(
            client().admin()
                .indices()
                .prepareUpdateSettings(restoredIndexName)
                .setSettings(
                    Settings.builder()
                        .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1)
                        .putNull(IndexMetadata.INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(""_name"").getKey())
                )
        );

        assertTotalHits(restoredIndexName, originalAllHits, originalBarHits);
        assertRecoveryStats(restoredIndexName, false);

        final String clonedIndexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);
        assertAcked(
            client().admin()
                .indices()
                .prepareResizeIndex(restoredIndexName, clonedIndexName)
                .setResizeType(ResizeType.CLONE)
                .setSettings(
                    Settings.builder()
                        .putNull(IndexModule.INDEX_STORE_TYPE_SETTING.getKey())
                        .putNull(IndexModule.INDEX_RECOVERY_TYPE_SETTING.getKey())
                        .put(DataTierAllocationDecider.INDEX_ROUTING_PREFER, DataTier.DATA_HOT)
                        .build()
                )
        );
        ensureGreen(clonedIndexName);
        assertTotalHits(clonedIndexName, originalAllHits, originalBarHits);

        final Settings clonedIndexSettings = client().admin()
            .indices()
            .prepareGetSettings(clonedIndexName)
            .get()
            .getIndexToSettings()
            .get(clonedIndexName);
        assertFalse(clonedIndexSettings.hasValue(IndexModule.INDEX_STORE_TYPE_SETTING.getKey()));
        assertFalse(clonedIndexSettings.hasValue(SearchableSnapshots.SNAPSHOT_SNAPSHOT_NAME_SETTING.getKey()));
        assertFalse(clonedIndexSettings.hasValue(SearchableSnapshots.SNAPSHOT_SNAPSHOT_ID_SETTING.getKey()));
        assertFalse(clonedIndexSettings.hasValue(SearchableSnapshots.SNAPSHOT_INDEX_ID_SETTING.getKey()));
        assertFalse(clonedIndexSettings.hasValue(IndexModule.INDEX_RECOVERY_TYPE_SETTING.getKey()));

        assertAcked(client().admin().indices().prepareDelete(restoredIndexName));
        assertThat(client().admin().indices().prepareGetAliases(aliasName).get().getAliases().size(), equalTo(0));
        assertAcked(client().admin().indices().prepareAliases().addAlias(clonedIndexName, aliasName));
        assertTotalHits(aliasName, originalAllHits, originalBarHits);
    }",/x-pack/plugin/searchable-snapshots/src/internalClusterTest/java/org/elasticsearch/xpack/searchablesnapshots/FrozenSearchableSnapshotsIntegTests.java
c65528b9f68701e8106ea119ec354e67246b531a,662,152,"public void clusterChanged(ClusterChangedEvent event) {
        if (event.state().blocks().hasGlobalBlock(GatewayService.STATE_NOT_RECOVERED_BLOCK) || shutDown) {
            // wait until the gateway has recovered from disk, otherwise we think may not have .watches and
            // a .triggered_watches index, but they may not have been restored from the cluster state on disk
            return;
        }

        if (Strings.isNullOrEmpty(event.state().nodes().getMasterNodeId())) {
            executor.execute(() -> this.stop(""no master node""));
            return;
        }

        if (event.state().getBlocks().hasGlobalBlock(ClusterBlockLevel.WRITE)) {
            executor.execute(() -> this.stop(""write level cluster block""));
            return;
        }

        // find out if watcher was stopped or started manually due to this cluster state change
        WatcherMetaData watcherMetaData = event.state().getMetaData().custom(WatcherMetaData.TYPE);

        if (watcherMetaData != null) {
            this.watcherMetaData = watcherMetaData;
        }

        boolean currentWatcherStopped = watcherMetaData != null && watcherMetaData.manuallyStopped() == true;
        if (currentWatcherStopped) {
            executor.execute(() -> this.stop(""watcher manually marked to shutdown by cluster state update""));
        } else {
            if (watcherService.state() == WatcherState.STARTED && event.state().nodes().getLocalNode().isDataNode()) {
                DiscoveryNode localNode = event.state().nodes().getLocalNode();
                RoutingNode routingNode = event.state().getRoutingNodes().node(localNode.getId());
                IndexMetaData watcherIndexMetaData = WatchStoreUtils.getConcreteIndex(Watch.INDEX, event.state().metaData());

                // no watcher index, time to pause, as there are for sure no shards on this node
                if (watcherIndexMetaData == null) {
                    if (previousAllocationIds.get().isEmpty() == false) {
                        previousAllocationIds.set(Collections.emptyList());
                        executor.execute(() -> watcherService.pauseExecution(""no watcher index found""));
                    }
                    return;
                }

                String watchIndex = watcherIndexMetaData.getIndex().getName();
                List<ShardRouting> localShards = routingNode.shardsWithState(watchIndex, RELOCATING, STARTED);

                // no local shards, empty out watcher and not waste resources!
                if (localShards.isEmpty()) {
                    if (previousAllocationIds.get().isEmpty() == false) {
                        executor.execute(() -> watcherService.pauseExecution(""no local watcher shards""));
                        previousAllocationIds.set(Collections.emptyList());
                    }
                    return;
                }

                List<String> currentAllocationIds = localShards.stream()
                        .map(ShardRouting::allocationId)
                        .map(AllocationId::getId)
                        .collect(Collectors.toList());
                Collections.sort(currentAllocationIds);

                if (previousAllocationIds.get().equals(currentAllocationIds) == false) {
                    previousAllocationIds.set(currentAllocationIds);
                    executor.execute(() -> watcherService.reload(event.state(), ""different shards allocated on this node""));
                }
            } else if (watcherService.state() != WatcherState.STARTED && watcherService.state() != WatcherState.STARTING) {
                IndexMetaData watcherIndexMetaData = WatchStoreUtils.getConcreteIndex(Watch.INDEX, event.state().metaData());
                IndexMetaData triggeredWatchesIndexMetaData = WatchStoreUtils.getConcreteIndex(TriggeredWatchStoreField.INDEX_NAME,
                        event.state().metaData());
                boolean isIndexInternalFormatWatchIndex = watcherIndexMetaData == null ||
                        UpgradeField.checkInternalIndexFormat(watcherIndexMetaData);
                boolean isIndexInternalFormatTriggeredWatchIndex = triggeredWatchesIndexMetaData == null ||
                        UpgradeField.checkInternalIndexFormat(triggeredWatchesIndexMetaData);
                if (isIndexInternalFormatTriggeredWatchIndex && isIndexInternalFormatWatchIndex) {
                    executor.execute(() -> start(event.state(), false));
                } else {
                    logger.warn(""not starting watcher, upgrade API run required: .watches[{}], .triggered_watches[{}]"",
                            isIndexInternalFormatWatchIndex, isIndexInternalFormatTriggeredWatchIndex);
                }
            }
        }
    }","public void clusterChanged(ClusterChangedEvent event) {
        if (event.state().blocks().hasGlobalBlock(GatewayService.STATE_NOT_RECOVERED_BLOCK) || shutDown) {
            clearAllocationIds();
            // wait until the gateway has recovered from disk, otherwise we think may not have .watches and
            // a .triggered_watches index, but they may not have been restored from the cluster state on disk
            return;
        }

        if (Strings.isNullOrEmpty(event.state().nodes().getMasterNodeId())) {
            clearAllocationIds();
            executor.execute(() -> this.stop(""no master node""));
            return;
        }

        if (event.state().getBlocks().hasGlobalBlock(ClusterBlockLevel.WRITE)) {
            clearAllocationIds();
            executor.execute(() -> this.stop(""write level cluster block""));
            return;
        }

        if (isWatcherStoppedManually(event.state())) {
            clearAllocationIds();
            executor.execute(() -> this.stop(""watcher manually marked to shutdown by cluster state update""));
        } else {
            if (watcherService.state() == WatcherState.STARTED && event.state().nodes().getLocalNode().isDataNode()) {
                checkAndSetAllocationIds(event.state(), true);
            } else if (watcherService.state() != WatcherState.STARTED && watcherService.state() != WatcherState.STARTING) {
                IndexMetaData watcherIndexMetaData = WatchStoreUtils.getConcreteIndex(Watch.INDEX, event.state().metaData());
                IndexMetaData triggeredWatchesIndexMetaData = WatchStoreUtils.getConcreteIndex(TriggeredWatchStoreField.INDEX_NAME,
                        event.state().metaData());
                boolean isIndexInternalFormatWatchIndex = watcherIndexMetaData == null ||
                        UpgradeField.checkInternalIndexFormat(watcherIndexMetaData);
                boolean isIndexInternalFormatTriggeredWatchIndex = triggeredWatchesIndexMetaData == null ||
                        UpgradeField.checkInternalIndexFormat(triggeredWatchesIndexMetaData);
                if (isIndexInternalFormatTriggeredWatchIndex && isIndexInternalFormatWatchIndex) {
                    checkAndSetAllocationIds(event.state(), false);
                    executor.execute(() -> start(event.state()));
                } else {
                    logger.warn(""not starting watcher, upgrade API run required: .watches[{}], .triggered_watches[{}]"",
                            isIndexInternalFormatWatchIndex, isIndexInternalFormatTriggeredWatchIndex);
                }
            }
        }
    }",/plugin/watcher/src/main/java/org/elasticsearch/xpack/watcher/WatcherLifeCycleService.java
2fb3d1a46521de25ca1a726dc2b6cb82647fda2d,570,459,"public void testConcurrentJoining() {
        List<DiscoveryNode> nodes = IntStream.rangeClosed(1, randomIntBetween(2, 5))
            .mapToObj(nodeId -> newNode(nodeId, true)).collect(Collectors.toList());

        VotingConfiguration votingConfiguration = new VotingConfiguration(
            randomSubsetOf(randomIntBetween(1, nodes.size()), nodes).stream().map(DiscoveryNode::getId).collect(Collectors.toSet()));

        logger.info(""Voting configuration: {}"", votingConfiguration);

        DiscoveryNode localNode = nodes.get(0);
        long initialTerm = randomLongBetween(1, 10);
        long initialVersion = randomLongBetween(1, 10);
        setupRealMasterServiceAndCoordinator(initialTerm, initialState(false, localNode, initialTerm, initialVersion, votingConfiguration));
        long newTerm = initialTerm + randomLongBetween(1, 10);

        // we need at least a quorum of voting nodes with a correct term and worse state
        List<DiscoveryNode> successfulNodes;
        do {
            successfulNodes = randomSubsetOf(nodes);
        } while (votingConfiguration.hasQuorum(successfulNodes.stream().map(DiscoveryNode::getId).collect(Collectors.toList()))
            == false);

        logger.info(""Successful voting nodes: {}"", successfulNodes);

        List<JoinRequest> correctJoinRequests = successfulNodes.stream().map(
            node -> new JoinRequest(node, Optional.of(new Join(node, localNode, newTerm, initialTerm, initialVersion))))
            .collect(Collectors.toList());

        List<DiscoveryNode> possiblyUnsuccessfulNodes = new ArrayList<>(nodes);
        possiblyUnsuccessfulNodes.removeAll(successfulNodes);

        logger.info(""Possibly unsuccessful voting nodes: {}"", possiblyUnsuccessfulNodes);

        List<JoinRequest> possiblyFailingJoinRequests = possiblyUnsuccessfulNodes.stream().map(node -> {
            if (randomBoolean()) {
                // a correct request
                return new JoinRequest(node, Optional.of(new Join(node, localNode,
                    newTerm, initialTerm, initialVersion)));
            } else if (randomBoolean()) {
                // term too low
                return new JoinRequest(node, Optional.of(new Join(node, localNode,
                    randomLongBetween(0, initialTerm), initialTerm, initialVersion)));
            } else {
                // better state
                return new JoinRequest(node, Optional.of(new Join(node, localNode,
                    newTerm, initialTerm, initialVersion + randomLongBetween(1, 10))));
            }
        }).collect(Collectors.toList());

        // duplicate some requests, which will be unsuccessful
        possiblyFailingJoinRequests.addAll(randomSubsetOf(possiblyFailingJoinRequests));

        CyclicBarrier barrier = new CyclicBarrier(correctJoinRequests.size() + possiblyFailingJoinRequests.size() + 1);
        List<Thread> threads = new ArrayList<>();
        threads.add(new Thread(() -> {
            try {
                barrier.await();
            } catch (InterruptedException | BrokenBarrierException e) {
                throw new RuntimeException(e);
            }
            for (int i = 0; i < 30; i++) {
                coordinator.invariant();
            }
        }));
        threads.addAll(correctJoinRequests.stream().map(joinRequest -> new Thread(
            () -> {
                try {
                    barrier.await();
                } catch (InterruptedException | BrokenBarrierException e) {
                    throw new RuntimeException(e);
                }
                joinNode(joinRequest);
            })).collect(Collectors.toList()));
        threads.addAll(possiblyFailingJoinRequests.stream().map(joinRequest -> new Thread(() -> {
            try {
                barrier.await();
            } catch (InterruptedException | BrokenBarrierException e) {
                throw new RuntimeException(e);
            }
            try {
                joinNode(joinRequest);
            } catch (CoordinationStateRejectedException ignore) {
                // ignore
            }
        })).collect(Collectors.toList()));

        threads.forEach(Thread::start);
        threads.forEach(t -> {
            try {
                t.join();
            } catch (InterruptedException e) {
                throw new RuntimeException(e);
            }
        });

        assertTrue(MasterServiceTests.discoveryState(masterService).nodes().isLocalNodeElectedMaster());
        successfulNodes.forEach(node -> assertTrue(clusterStateHasNode(node)));
    }","public void testConcurrentJoining() {
        List<DiscoveryNode> nodes = IntStream.rangeClosed(1, randomIntBetween(2, 5))
            .mapToObj(nodeId -> newNode(nodeId, true)).collect(Collectors.toList());

        VotingConfiguration votingConfiguration = new VotingConfiguration(
            randomSubsetOf(randomIntBetween(1, nodes.size()), nodes).stream().map(DiscoveryNode::getId).collect(Collectors.toSet()));

        logger.info(""Voting configuration: {}"", votingConfiguration);

        DiscoveryNode localNode = nodes.get(0);
        long initialTerm = randomLongBetween(1, 10);
        long initialVersion = randomLongBetween(1, 10);
        setupRealMasterServiceAndCoordinator(initialTerm, initialState(false, localNode, initialTerm, initialVersion, votingConfiguration));
        long newTerm = initialTerm + randomLongBetween(1, 10);

        // we need at least a quorum of voting nodes with a correct term and worse state
        List<DiscoveryNode> successfulNodes;
        do {
            successfulNodes = randomSubsetOf(nodes);
        } while (votingConfiguration.hasQuorum(successfulNodes.stream().map(DiscoveryNode::getId).collect(Collectors.toList()))
            == false);

        logger.info(""Successful voting nodes: {}"", successfulNodes);

        List<JoinRequest> correctJoinRequests = successfulNodes.stream().map(
            node -> new JoinRequest(node, Optional.of(new Join(node, localNode, newTerm, initialTerm, initialVersion))))
            .collect(Collectors.toList());

        List<DiscoveryNode> possiblyUnsuccessfulNodes = new ArrayList<>(nodes);
        possiblyUnsuccessfulNodes.removeAll(successfulNodes);

        logger.info(""Possibly unsuccessful voting nodes: {}"", possiblyUnsuccessfulNodes);

        List<JoinRequest> possiblyFailingJoinRequests = possiblyUnsuccessfulNodes.stream().map(node -> {
            if (randomBoolean()) {
                // a correct request
                return new JoinRequest(node, Optional.of(new Join(node, localNode,
                    newTerm, initialTerm, initialVersion)));
            } else if (randomBoolean()) {
                // term too low
                return new JoinRequest(node, Optional.of(new Join(node, localNode,
                    randomLongBetween(0, initialTerm), initialTerm, initialVersion)));
            } else {
                // better state
                return new JoinRequest(node, Optional.of(new Join(node, localNode,
                    newTerm, initialTerm, initialVersion + randomLongBetween(1, 10))));
            }
        }).collect(Collectors.toList());

        // duplicate some requests, which will be unsuccessful
        possiblyFailingJoinRequests.addAll(randomSubsetOf(possiblyFailingJoinRequests));

        CyclicBarrier barrier = new CyclicBarrier(correctJoinRequests.size() + possiblyFailingJoinRequests.size() + 1);

        final AtomicBoolean stopAsserting = new AtomicBoolean();
        final Thread assertionThread = new Thread(() -> {
            try {
                barrier.await();
            } catch (InterruptedException | BrokenBarrierException e) {
                throw new RuntimeException(e);
            }
            while (stopAsserting.get() == false) {
                coordinator.invariant();
            }
        }, ""assert invariants"");

        final List<Thread> joinThreads = Stream.concat(correctJoinRequests.stream(), possiblyFailingJoinRequests.stream())
            .map(joinRequest ->
                new Thread(() -> {
                    try {
                        barrier.await();
                    } catch (InterruptedException | BrokenBarrierException e) {
                        throw new RuntimeException(e);
                    }
                    try {
                        joinNode(joinRequest);
                    } catch (CoordinationStateRejectedException ignore) {
                        // ignore: even the ""correct"" requests may fail as a duplicate because a concurrent election may cause a node to
                        // spontaneously join.
                    }
                }, ""process "" + joinRequest)).collect(Collectors.toList());

        assertionThread.start();
        joinThreads.forEach(Thread::start);
        joinThreads.forEach(t -> {
            try {
                t.join();
            } catch (InterruptedException e) {
                throw new RuntimeException(e);
            }
        });
        stopAsserting.set(true);
        try {
            assertionThread.join();
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }

        assertTrue(MasterServiceTests.discoveryState(masterService).nodes().isLocalNodeElectedMaster());
        for (DiscoveryNode successfulNode : successfulNodes) {
            assertTrue(successfulNode.toString(), clusterStateHasNode(successfulNode));
            assertTrue(successfulNode.toString(), coordinator.hasJoinVoteFrom(successfulNode));
        }
    }",/server/src/test/java/org/elasticsearch/cluster/coordination/NodeJoinTests.java
bb033f1e0085454134d4da1cd9d9fd4238b2b529,662,125,"public void clusterChanged(final ClusterChangedEvent event) {
        if (event.state().blocks().hasGlobalBlock(GatewayService.STATE_NOT_RECOVERED_BLOCK)) {
            // wait until the gateway has recovered from disk, otherwise we think may not have .watches and
            // a .triggered_watches index, but they may not have been restored from the cluster state on disk
            return;
        }

        WatcherMetaData watcherMetaData = event.state().getMetaData().custom(WatcherMetaData.TYPE);
        if (watcherMetaData != null) {
            this.watcherMetaData = watcherMetaData;
        }

        if (!event.localNodeMaster()) {
            if (watcherService.state() != WatcherState.STARTED) {
                // to avoid unnecessary forking of threads...
                return;
            }

            // We're no longer the master so we need to stop the watcher.
            // Stopping the watcher may take a while since it will wait on the scheduler to complete shutdown,
            // so we fork here so that we don't wait too long. Other events may need to be processed and
            // other cluster state listeners may need to be executed as well for this event.
            threadPool.executor(ThreadPool.Names.GENERIC).execute(new Runnable() {
                @Override
                public void run() {
                    stop(false);
                }
            });
        } else {
            if (watcherService.state() != WatcherState.STOPPED) {
                // to avoid unnecessary forking of threads...
                return;
            }

            final ClusterState state = event.state();
            threadPool.executor(ThreadPool.Names.GENERIC).execute(new Runnable() {
                @Override
                public void run() {
                    start(state, false);
                }
            });
        }
    }","public void clusterChanged(final ClusterChangedEvent event) {
        if (event.state().blocks().hasGlobalBlock(GatewayService.STATE_NOT_RECOVERED_BLOCK)) {
            // wait until the gateway has recovered from disk, otherwise we think may not have .watches and
            // a .triggered_watches index, but they may not have been restored from the cluster state on disk
            return;
        }

        WatcherMetaData watcherMetaData = event.state().getMetaData().custom(WatcherMetaData.TYPE);
        if (watcherMetaData != null) {
            this.watcherMetaData = watcherMetaData;
        }

        if (!event.localNodeMaster()) {
            if (watcherService.state() == WatcherState.STARTED) {
                // We're no longer the master so we need to stop the watcher.
                // Stopping the watcher may take a while since it will wait on the scheduler to complete shutdown,
                // so we fork here so that we don't wait too long. Other events may need to be processed and
                // other cluster state listeners may need to be executed as well for this event.
                threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> stop(false));
            }
        } else {
            if (watcherService.state() == WatcherState.STOPPED) {
                final ClusterState state = event.state();
                threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> start(state, false));
            } else {
                boolean isWatchIndexDeleted = event.indicesDeleted().stream()
                        .filter(index -> WatchStore.INDEX.equals(index.getName()))
                        .findAny()
                        .isPresent();

                boolean isWatchIndexOpenInPreviousClusterState = event.previousState().metaData().hasIndex(WatchStore.INDEX) &&
                        event.previousState().metaData().index(WatchStore.INDEX).getState() == IndexMetaData.State.OPEN;
                boolean isWatchIndexClosedInCurrentClusterState = event.state().metaData().hasIndex(WatchStore.INDEX) &&
                        event.state().metaData().index(WatchStore.INDEX).getState() == IndexMetaData.State.CLOSE;
                boolean hasWatcherIndexBeenClosed = isWatchIndexOpenInPreviousClusterState && isWatchIndexClosedInCurrentClusterState;

                if (isWatchIndexDeleted || hasWatcherIndexBeenClosed) {
                    threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> watcherService.watchIndexDeletedOrClosed());
                }
            }
        }
    }",/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/xpack/watcher/WatcherLifeCycleService.java
7c5a954b93ee2c3b65222aee35266f3ca479512a,682,299,"protected static int intersections(double dateline, Edge[] edges) {
        int numIntersections = 0;
        assert !Double.isNaN(dateline);
        for (int i = 0; i < edges.length; i++) {
            Coordinate p1 = edges[i].coordinate;
            Coordinate p2 = edges[i].next.coordinate;
            assert !Double.isNaN(p2.x) && !Double.isNaN(p1.x);  
            edges[i].intersect = IntersectionOrder.SENTINEL;

            double position = intersection(p1, p2, dateline);
            if (!Double.isNaN(position)) {
                if (position == 1) {
                    if (Double.compare(p1.x, dateline) == Double.compare(edges[i].next.next.coordinate.x, dateline)) {
                        // Ignore the ear
                        continue;
                    }
                }
                edges[i].intersection(position);
                numIntersections++;
            }
        }
        Arrays.sort(edges, INTERSECTION_ORDER);
        return numIntersections;
    }","protected static int intersections(double dateline, Edge[] edges) {
        int numIntersections = 0;
        assert !Double.isNaN(dateline);
        for (int i = 0; i < edges.length; i++) {
            Coordinate p1 = edges[i].coordinate;
            Coordinate p2 = edges[i].next.coordinate;
            assert !Double.isNaN(p2.x) && !Double.isNaN(p1.x);  
            edges[i].intersect = IntersectionOrder.SENTINEL;

            double position = intersection(p1, p2, dateline);
            if (!Double.isNaN(position)) {
                edges[i].intersection(position);
                numIntersections++;
            }
        }
        Arrays.sort(edges, INTERSECTION_ORDER);
        return numIntersections;
    }",/src/main/java/org/elasticsearch/common/geo/builders/ShapeBuilder.java
69c7e73b665b2c87048b74b3f1e384b6c9530a5e,480,255,"public void testRangeQuery() throws IOException {
        Settings indexSettings = Settings.builder().put(IndexMetadata.SETTING_VERSION_CREATED, Version.CURRENT)
                .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1).put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1).build();
        QueryShardContext context = new QueryShardContext(0,
                new IndexSettings(IndexMetadata.builder(""foo"").settings(indexSettings).build(), indexSettings),
                BigArrays.NON_RECYCLING_INSTANCE, null, null, null, null, null, xContentRegistry(), writableRegistry(),
                null, null, () -> nowInMillis, null, null, () -> true, null);
        MappedFieldType ft = new DateFieldType(""field"");
        String date1 = ""2015-10-12T14:10:55"";
        String date2 = ""2016-04-28T11:33:52"";
        long instant1 = DateFormatters.from(DateFieldMapper.DEFAULT_DATE_TIME_FORMATTER.parse(date1)).toInstant().toEpochMilli();
        long instant2 =
            DateFormatters.from(DateFieldMapper.DEFAULT_DATE_TIME_FORMATTER.parse(date2)).toInstant().toEpochMilli() + 999;
        Query expected = new IndexOrDocValuesQuery(
                LongPoint.newRangeQuery(""field"", instant1, instant2),
                SortedNumericDocValuesField.newSlowRangeQuery(""field"", instant1, instant2));
        assertEquals(expected,
                ft.rangeQuery(date1, date2, true, true, null, null, null, context).rewrite(new MultiReader()));

        instant1 = nowInMillis;
        instant2 = instant1 + 100;
        expected = new DateRangeIncludingNowQuery(new IndexOrDocValuesQuery(
            LongPoint.newRangeQuery(""field"", instant1, instant2),
            SortedNumericDocValuesField.newSlowRangeQuery(""field"", instant1, instant2)
        ));
        assertEquals(expected,
            ft.rangeQuery(""now"", instant2, true, true, null, null, null, context));

        MappedFieldType unsearchable = new DateFieldType(""field"", false, true, DateFieldMapper.DEFAULT_DATE_TIME_FORMATTER,
            Resolution.MILLISECONDS, Collections.emptyMap());
        IllegalArgumentException e = expectThrows(IllegalArgumentException.class,
                () -> unsearchable.rangeQuery(date1, date2, true, true, null, null, null, context));
        assertEquals(""Cannot search on field [field] since it is not indexed."", e.getMessage());
    }","public void testRangeQueryWithIndexSort() {
        Settings settings = Settings.builder()
            .put(IndexMetadata.SETTING_VERSION_CREATED, Version.CURRENT)
            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)
            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1)
            .put(""index.sort.field"", ""field"")
            .build();

        IndexMetadata indexMetadata = new IndexMetadata.Builder(""index"")
            .settings(settings)
            .build();
        IndexSettings indexSettings = new IndexSettings(indexMetadata, settings);

        QueryShardContext context = new QueryShardContext(0, indexSettings,
            BigArrays.NON_RECYCLING_INSTANCE, null, null, null, null, null, xContentRegistry(), writableRegistry(),
            null, null, () -> 0L, null, null, () -> true, null);

        MappedFieldType ft = new DateFieldType(""field"");
        String date1 = ""2015-10-12T14:10:55"";
        String date2 = ""2016-04-28T11:33:52"";
        long instant1 = DateFormatters.from(DateFieldMapper.DEFAULT_DATE_TIME_FORMATTER.parse(date1)).toInstant().toEpochMilli();
        long instant2 = DateFormatters.from(DateFieldMapper.DEFAULT_DATE_TIME_FORMATTER.parse(date2)).toInstant().toEpochMilli() + 999;

        Query pointQuery = LongPoint.newRangeQuery(""field"", instant1, instant2);
        Query dvQuery = SortedNumericDocValuesField.newSlowRangeQuery(""field"", instant1, instant2);
        Query expected = new IndexSortSortedNumericDocValuesRangeQuery(""field"",  instant1, instant2,
            new IndexOrDocValuesQuery(pointQuery, dvQuery));
        assertEquals(expected, ft.rangeQuery(date1, date2, true, true, null, null, null, context));
    }",/server/src/test/java/org/elasticsearch/index/mapper/DateFieldTypeTests.java
d9a1e548a59d1f66c415e04df2ceee49f0542b4a,670,136,"public void testConcurrentConnectsAndDisconnects() throws BrokenBarrierException, InterruptedException {
        DiscoveryNode node = new DiscoveryNode("""", new TransportAddress(InetAddress.getLoopbackAddress(), 0), Version.CURRENT);
        Transport.Connection connection = new TestConnect(node);
        doAnswer(invocationOnMock -> {
            ActionListener<Transport.Connection> listener = (ActionListener<Transport.Connection>) invocationOnMock.getArguments()[2];
            if (rarely()) {
                listener.onResponse(connection);
            } if (frequently()) {
                threadPool.generic().execute(() -> listener.onResponse(connection));
            } else {
                threadPool.generic().execute(() -> listener.onFailure(new IllegalStateException(""dummy exception"")));
            }
            return null;
        }).when(transport).openConnection(eq(node), eq(connectionProfile), any(ActionListener.class));

        assertFalse(connectionManager.nodeConnected(node));

        ConnectionManager.ConnectionValidator validator = (c, p, l) -> {
            if (rarely()) {
                l.onResponse(null);
            } if (frequently()) {
                threadPool.generic().execute(() -> l.onResponse(null));
            } else {
                threadPool.generic().execute(() -> l.onFailure(new IllegalStateException(""dummy exception"")));
            }
        };

        CyclicBarrier barrier = new CyclicBarrier(11);
        List<Thread> threads = new ArrayList<>();
        AtomicInteger nodeConnectedCount = new AtomicInteger();
        AtomicInteger nodeFailureCount = new AtomicInteger();
        for (int i = 0; i < 10; i++) {
            Thread thread = new Thread(() -> {
                try {
                    barrier.await();
                } catch (InterruptedException | BrokenBarrierException e) {
                    throw new RuntimeException(e);
                }
                CountDownLatch latch = new CountDownLatch(1);
                connectionManager.connectToNode(node, connectionProfile, validator,
                    ActionListener.wrap(c -> {
                        nodeConnectedCount.incrementAndGet();
                        assert latch.getCount() == 1;
                        latch.countDown();
                    }, e -> {
                        nodeFailureCount.incrementAndGet();
                        assert latch.getCount() == 1;
                        latch.countDown();
                    }));
                try {
                    latch.await();
                } catch (InterruptedException e) {
                    throw new IllegalStateException(e);
                }
            });
            threads.add(thread);
            thread.start();
        }

        barrier.await();
        threads.forEach(t -> {
            try {
                t.join();
            } catch (InterruptedException e) {
                throw new IllegalStateException(e);
            }
        });

        assertEquals(10, nodeConnectedCount.get() + nodeFailureCount.get());
    }","public void testConcurrentConnectsAndDisconnects() throws BrokenBarrierException, InterruptedException {
        DiscoveryNode node = new DiscoveryNode("""", new TransportAddress(InetAddress.getLoopbackAddress(), 0), Version.CURRENT);
        Transport.Connection connection = new TestConnect(node);
        doAnswer(invocationOnMock -> {
            ActionListener<Transport.Connection> listener = (ActionListener<Transport.Connection>) invocationOnMock.getArguments()[2];
            if (rarely()) {
                listener.onResponse(connection);
            } else if (frequently()) {
                threadPool.generic().execute(() -> listener.onResponse(connection));
            } else {
                threadPool.generic().execute(() -> listener.onFailure(new IllegalStateException(""dummy exception"")));
            }
            return null;
        }).when(transport).openConnection(eq(node), eq(connectionProfile), any(ActionListener.class));

        assertFalse(connectionManager.nodeConnected(node));

        ConnectionManager.ConnectionValidator validator = (c, p, l) -> {
            if (rarely()) {
                l.onResponse(null);
            } else if (frequently()) {
                threadPool.generic().execute(() -> l.onResponse(null));
            } else {
                threadPool.generic().execute(() -> l.onFailure(new IllegalStateException(""dummy exception"")));
            }
        };

        CyclicBarrier barrier = new CyclicBarrier(11);
        List<Thread> threads = new ArrayList<>();
        AtomicInteger nodeConnectedCount = new AtomicInteger();
        AtomicInteger nodeFailureCount = new AtomicInteger();
        for (int i = 0; i < 10; i++) {
            Thread thread = new Thread(() -> {
                try {
                    barrier.await();
                } catch (InterruptedException | BrokenBarrierException e) {
                    throw new RuntimeException(e);
                }
                CountDownLatch latch = new CountDownLatch(1);
                connectionManager.connectToNode(node, connectionProfile, validator,
                    ActionListener.wrap(c -> {
                        nodeConnectedCount.incrementAndGet();
                        assert latch.getCount() == 1;
                        latch.countDown();
                    }, e -> {
                        nodeFailureCount.incrementAndGet();
                        assert latch.getCount() == 1;
                        latch.countDown();
                    }));
                try {
                    latch.await();
                } catch (InterruptedException e) {
                    throw new IllegalStateException(e);
                }
            });
            threads.add(thread);
            thread.start();
        }

        barrier.await();
        threads.forEach(t -> {
            try {
                t.join();
            } catch (InterruptedException e) {
                throw new IllegalStateException(e);
            }
        });

        assertEquals(10, nodeConnectedCount.get() + nodeFailureCount.get());
    }",/server/src/test/java/org/elasticsearch/transport/ConnectionManagerTests.java
c492583addfd16327b38357d141af0df0af230fe,561,947,"private void writeException(Throwable rootException, Throwable throwable, int nestedLevel) throws IOException {
        if (throwable == null) {
            writeBoolean(false);
        } else if (nestedLevel > MAX_NESTED_EXCEPTION_LEVEL) {
            assert failOnTooManyNestedExceptions(rootException);
            writeException(new IllegalStateException(""too many nested exceptions""));
        } else {
            writeBoolean(true);
            boolean writeCause = true;
            boolean writeMessage = true;
            if (throwable instanceof CorruptIndexException) {
                writeVInt(1);
                writeOptionalString(((CorruptIndexException) throwable).getOriginalMessage());
                writeOptionalString(((CorruptIndexException) throwable).getResourceDescription());
                writeMessage = false;
            } else if (throwable instanceof IndexFormatTooNewException) {
                writeVInt(2);
                writeOptionalString(((IndexFormatTooNewException) throwable).getResourceDescription());
                writeInt(((IndexFormatTooNewException) throwable).getVersion());
                writeInt(((IndexFormatTooNewException) throwable).getMinVersion());
                writeInt(((IndexFormatTooNewException) throwable).getMaxVersion());
                writeMessage = false;
                writeCause = false;
            } else if (throwable instanceof IndexFormatTooOldException t) {
                writeVInt(3);
                writeOptionalString(t.getResourceDescription());
                if (t.getVersion() == null) {
                    writeBoolean(false);
                    writeOptionalString(t.getReason());
                } else {
                    writeBoolean(true);
                    writeInt(t.getVersion());
                    writeInt(t.getMinVersion());
                    writeInt(t.getMaxVersion());
                }
                writeMessage = false;
                writeCause = false;
            } else if (throwable instanceof NullPointerException) {
                writeVInt(4);
                writeCause = false;
            } else if (throwable instanceof NumberFormatException) {
                writeVInt(5);
                writeCause = false;
            } else if (throwable instanceof IllegalArgumentException) {
                writeVInt(6);
            } else if (throwable instanceof AlreadyClosedException) {
                writeVInt(7);
            } else if (throwable instanceof EOFException) {
                writeVInt(8);
                writeCause = false;
            } else if (throwable instanceof SecurityException) {
                writeVInt(9);
            } else if (throwable instanceof StringIndexOutOfBoundsException) {
                writeVInt(10);
                writeCause = false;
            } else if (throwable instanceof ArrayIndexOutOfBoundsException) {
                writeVInt(11);
                writeCause = false;
            } else if (throwable instanceof FileNotFoundException) {
                writeVInt(12);
                writeCause = false;
            } else if (throwable instanceof FileSystemException) {
                writeVInt(13);
                if (throwable instanceof NoSuchFileException) {
                    writeVInt(0);
                } else if (throwable instanceof NotDirectoryException) {
                    writeVInt(1);
                } else if (throwable instanceof DirectoryNotEmptyException) {
                    writeVInt(2);
                } else if (throwable instanceof AtomicMoveNotSupportedException) {
                    writeVInt(3);
                } else if (throwable instanceof FileAlreadyExistsException) {
                    writeVInt(4);
                } else if (throwable instanceof AccessDeniedException) {
                    writeVInt(5);
                } else if (throwable instanceof FileSystemLoopException) {
                    writeVInt(6);
                } else {
                    writeVInt(7);
                }
                writeOptionalString(((FileSystemException) throwable).getFile());
                writeOptionalString(((FileSystemException) throwable).getOtherFile());
                writeOptionalString(((FileSystemException) throwable).getReason());
                writeCause = false;
            } else if (throwable instanceof IllegalStateException) {
                writeVInt(14);
            } else if (throwable instanceof LockObtainFailedException) {
                writeVInt(15);
            } else if (throwable instanceof InterruptedException) {
                writeVInt(16);
                writeCause = false;
            } else if (throwable instanceof IOException) {
                writeVInt(17);
            } else if (throwable instanceof EsRejectedExecutionException) {
                writeVInt(18);
                writeBoolean(((EsRejectedExecutionException) throwable).isExecutorShutdown());
                writeCause = false;
            } else {
                final ElasticsearchException ex;
                if (throwable instanceof ElasticsearchException && ElasticsearchException.isRegistered(throwable.getClass(), version)) {
                    ex = (ElasticsearchException) throwable;
                } else {
                    ex = new NotSerializableExceptionWrapper(throwable);
                }
                writeVInt(0);
                writeVInt(ElasticsearchException.getId(ex.getClass()));
                ex.writeTo(this);
                return;
            }
            if (writeMessage) {
                writeOptionalString(throwable.getMessage());
            }
            if (writeCause) {
                writeException(rootException, throwable.getCause(), nestedLevel + 1);
            }
            ElasticsearchException.writeStackTraces(throwable, this, (o, t) -> o.writeException(rootException, t, nestedLevel + 1));
        }
    }","public void writeOptionalWriteable(@Nullable Writeable writeable) throws IOException {
        if (writeable != null) {
            writeBoolean(true);
            writeable.writeTo(this);
        } else {
            writeBoolean(false);
        }
    }",/server/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java
c17de49a6dc1d54fcfee3754211ae67a06bdcec7,570,401,"public void testPercolatorQueryWithHighlighting() throws Exception {
        StringBuilder fieldMapping = new StringBuilder(""type=text"")
                .append("",store="").append(randomBoolean());
        if (randomBoolean()) {
            fieldMapping.append("",term_vector=with_positions_offsets"");
        } else if (randomBoolean()) {
            fieldMapping.append("",index_options=offsets"");
        }
        createIndex(""test"", client().admin().indices().prepareCreate(""test"")
                .addMapping(""type"", ""field1"", fieldMapping)
                .addMapping(""queries"", ""query"", ""type=percolator"")
        );
        client().prepareIndex(""test"", ""queries"", ""1"")
                .setSource(jsonBuilder().startObject().field(""query"", matchQuery(""field1"", ""brown fox"")).endObject())
                .execute().actionGet();
        client().prepareIndex(""test"", ""queries"", ""2"")
                .setSource(jsonBuilder().startObject().field(""query"", matchQuery(""field1"", ""lazy dog"")).endObject())
                .execute().actionGet();
        client().prepareIndex(""test"", ""queries"", ""3"")
                .setSource(jsonBuilder().startObject().field(""query"", termQuery(""field1"", ""jumps"")).endObject())
                .execute().actionGet();
        client().prepareIndex(""test"", ""queries"", ""4"")
                .setSource(jsonBuilder().startObject().field(""query"", termQuery(""field1"", ""dog"")).endObject())
                .execute().actionGet();
        client().prepareIndex(""test"", ""queries"", ""5"")
                .setSource(jsonBuilder().startObject().field(""query"", termQuery(""field1"", ""fox"")).endObject())
                .execute().actionGet();
        client().admin().indices().prepareRefresh().get();

        BytesReference document = jsonBuilder().startObject()
                .field(""field1"", ""The quick brown fox jumps over the lazy dog"")
                .endObject().bytes();
        SearchResponse searchResponse = client().prepareSearch()
                .setQuery(new PercolateQueryBuilder(""query"", ""type"", document, XContentType.JSON))
                .highlighter(new HighlightBuilder().field(""field1""))
                .addSort(""_uid"", SortOrder.ASC)
                .get();
        assertHitCount(searchResponse, 5);

        assertThat(searchResponse.getHits().getAt(0).getHighlightFields().get(""field1"").fragments()[0].string(),
                equalTo(""The quick <em>brown</em> <em>fox</em> jumps over the lazy dog""));
        assertThat(searchResponse.getHits().getAt(1).getHighlightFields().get(""field1"").fragments()[0].string(),
                equalTo(""The quick brown fox jumps over the <em>lazy</em> <em>dog</em>""));
        assertThat(searchResponse.getHits().getAt(2).getHighlightFields().get(""field1"").fragments()[0].string(),
                equalTo(""The quick brown fox <em>jumps</em> over the lazy dog""));
        assertThat(searchResponse.getHits().getAt(3).getHighlightFields().get(""field1"").fragments()[0].string(),
                equalTo(""The quick brown fox jumps over the lazy <em>dog</em>""));
        assertThat(searchResponse.getHits().getAt(4).getHighlightFields().get(""field1"").fragments()[0].string(),
                equalTo(""The quick brown <em>fox</em> jumps over the lazy dog""));
    }","public void testPercolatorSpecificQueries()  throws Exception {
        createIndex(""test"", client().admin().indices().prepareCreate(""test"")
                .addMapping(""type"", ""field1"", ""type=text"", ""field2"", ""type=text"")
                .addMapping(""queries"", ""query"", ""type=percolator"")
        );

        client().prepareIndex(""test"", ""queries"", ""1"")
                .setSource(jsonBuilder().startObject().field(""query"", commonTermsQuery(""field1"", ""quick brown fox"")).endObject())
                .get();
        client().prepareIndex(""test"", ""queries"", ""2"")
                .setSource(jsonBuilder().startObject().field(""query"", multiMatchQuery(""quick brown fox"", ""field1"", ""field2"")
                        .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)).endObject())
                .get();
        client().prepareIndex(""test"", ""queries"", ""3"")
                .setSource(jsonBuilder().startObject().field(""query"",
                        spanNearQuery(spanTermQuery(""field1"", ""quick""), 0)
                                .addClause(spanTermQuery(""field1"", ""brown""))
                                .addClause(spanTermQuery(""field1"", ""fox""))
                                .inOrder(true)
                ).endObject())
                .get();
        client().admin().indices().prepareRefresh().get();

        client().prepareIndex(""test"", ""queries"", ""4"")
                .setSource(jsonBuilder().startObject().field(""query"",
                        spanNotQuery(
                                spanNearQuery(spanTermQuery(""field1"", ""quick""), 0)
                                        .addClause(spanTermQuery(""field1"", ""brown""))
                                        .addClause(spanTermQuery(""field1"", ""fox""))
                                        .inOrder(true),
                                spanNearQuery(spanTermQuery(""field1"", ""the""), 0)
                                        .addClause(spanTermQuery(""field1"", ""lazy""))
                                        .addClause(spanTermQuery(""field1"", ""dog""))
                                        .inOrder(true)).dist(2)
                ).endObject())
                .get();

        // doesn't match
        client().prepareIndex(""test"", ""queries"", ""5"")
                .setSource(jsonBuilder().startObject().field(""query"",
                        spanNotQuery(
                                spanNearQuery(spanTermQuery(""field1"", ""quick""), 0)
                                        .addClause(spanTermQuery(""field1"", ""brown""))
                                        .addClause(spanTermQuery(""field1"", ""fox""))
                                        .inOrder(true),
                                spanNearQuery(spanTermQuery(""field1"", ""the""), 0)
                                        .addClause(spanTermQuery(""field1"", ""lazy""))
                                        .addClause(spanTermQuery(""field1"", ""dog""))
                                        .inOrder(true)).dist(3)
                ).endObject())
                .get();
        client().admin().indices().prepareRefresh().get();

        BytesReference source = jsonBuilder().startObject()
                .field(""field1"", ""the quick brown fox jumps over the lazy dog"")
                .field(""field2"", ""the quick brown fox falls down into the well"")
                .endObject().bytes();
        SearchResponse response = client().prepareSearch()
                .setQuery(new PercolateQueryBuilder(""query"", ""type"", source, XContentType.JSON))
                .addSort(""_uid"", SortOrder.ASC)
                .get();
        assertHitCount(response, 4);
        assertThat(response.getHits().getAt(0).getId(), equalTo(""1""));
        assertThat(response.getHits().getAt(0).getScore(), equalTo(Float.NaN));
        assertThat(response.getHits().getAt(1).getId(), equalTo(""2""));
        assertThat(response.getHits().getAt(1).getScore(), equalTo(Float.NaN));
        assertThat(response.getHits().getAt(2).getId(), equalTo(""3""));
        assertThat(response.getHits().getAt(2).getScore(), equalTo(Float.NaN));
        assertThat(response.getHits().getAt(3).getId(), equalTo(""4""));
        assertThat(response.getHits().getAt(3).getScore(), equalTo(Float.NaN));
    }",/modules/percolator/src/test/java/org/elasticsearch/percolator/PercolatorQuerySearchIT.java
c17de49a6dc1d54fcfee3754211ae67a06bdcec7,563,418,"protected Query doToQuery(QueryShardContext context) throws IOException {
        // Call nowInMillis() so that this query becomes un-cacheable since we
        // can't be sure that it doesn't use now or scripts
        context.nowInMillis();
        if (indexedDocumentIndex != null || indexedDocumentType != null || indexedDocumentId != null) {
            throw new IllegalStateException(""query builder must be rewritten first"");
        }

        if (document == null) {
            throw new IllegalStateException(""no document to percolate"");
        }

        MapperService mapperService = context.getMapperService();
        DocumentMapperForType docMapperForType = mapperService.documentMapperWithAutoCreate(documentType);
        DocumentMapper docMapper = docMapperForType.getDocumentMapper();

        ParsedDocument doc = docMapper.parse(source(context.index().getName(), documentType, ""_temp_id"", document, documentXContentType));

        FieldNameAnalyzer fieldNameAnalyzer = (FieldNameAnalyzer) docMapper.mappers().indexAnalyzer();
        // Need to this custom impl because FieldNameAnalyzer is strict and the percolator sometimes isn't when
        // 'index.percolator.map_unmapped_fields_as_string' is enabled:
        Analyzer analyzer = new DelegatingAnalyzerWrapper(Analyzer.PER_FIELD_REUSE_STRATEGY) {
            @Override
            protected Analyzer getWrappedAnalyzer(String fieldName) {
                Analyzer analyzer = fieldNameAnalyzer.analyzers().get(fieldName);
                if (analyzer != null) {
                    return analyzer;
                } else {
                    return context.getIndexAnalyzers().getDefaultIndexAnalyzer();
                }
            }
        };
        final IndexSearcher docSearcher;
        if (doc.docs().size() > 1) {
            assert docMapper.hasNestedObjects();
            docSearcher = createMultiDocumentSearcher(analyzer, doc);
        } else {
            MemoryIndex memoryIndex = MemoryIndex.fromDocument(doc.rootDoc(), analyzer, true, false);
            docSearcher = memoryIndex.createSearcher();
            docSearcher.setQueryCache(null);
        }

        Version indexVersionCreated = context.getIndexSettings().getIndexVersionCreated();
        boolean mapUnmappedFieldsAsString = context.getIndexSettings()
                .getValue(PercolatorFieldMapper.INDEX_MAP_UNMAPPED_FIELDS_AS_STRING_SETTING);
        // We have to make a copy of the QueryShardContext here so we can have a unfrozen version for parsing the legacy
        // percolator queries
        QueryShardContext percolateShardContext = new QueryShardContext(context);
        MappedFieldType fieldType = context.fieldMapper(field);
        if (fieldType == null) {
            throw new QueryShardException(context, ""field ["" + field + ""] does not exist"");
        }

        if (!(fieldType instanceof PercolatorFieldMapper.FieldType)) {
            throw new QueryShardException(context, ""expected field ["" + field +
                ""] to be of type [percolator], but is of type ["" + fieldType.typeName() + ""]"");
        }
        PercolatorFieldMapper.FieldType pft = (PercolatorFieldMapper.FieldType) fieldType;
        PercolateQuery.QueryStore queryStore = createStore(pft, percolateShardContext, mapUnmappedFieldsAsString);
        return pft.percolateQuery(documentType, queryStore, document, docSearcher);
    }","protected Query doToQuery(QueryShardContext context) throws IOException {
        // Call nowInMillis() so that this query becomes un-cacheable since we
        // can't be sure that it doesn't use now or scripts
        context.nowInMillis();
        if (indexedDocumentIndex != null || indexedDocumentType != null || indexedDocumentId != null) {
            throw new IllegalStateException(""query builder must be rewritten first"");
        }

        if (document == null) {
            throw new IllegalStateException(""no document to percolate"");
        }

        MapperService mapperService = context.getMapperService();
        DocumentMapperForType docMapperForType = mapperService.documentMapperWithAutoCreate(documentType);
        DocumentMapper docMapper = docMapperForType.getDocumentMapper();

        ParsedDocument doc = docMapper.parse(source(context.index().getName(), documentType, ""_temp_id"", document, documentXContentType));

        FieldNameAnalyzer fieldNameAnalyzer = (FieldNameAnalyzer) docMapper.mappers().indexAnalyzer();
        // Need to this custom impl because FieldNameAnalyzer is strict and the percolator sometimes isn't when
        // 'index.percolator.map_unmapped_fields_as_string' is enabled:
        Analyzer analyzer = new DelegatingAnalyzerWrapper(Analyzer.PER_FIELD_REUSE_STRATEGY) {
            @Override
            protected Analyzer getWrappedAnalyzer(String fieldName) {
                Analyzer analyzer = fieldNameAnalyzer.analyzers().get(fieldName);
                if (analyzer != null) {
                    return analyzer;
                } else {
                    return context.getIndexAnalyzers().getDefaultIndexAnalyzer();
                }
            }
        };
        final IndexSearcher docSearcher;
        if (doc.docs().size() > 1) {
            assert docMapper.hasNestedObjects();
            docSearcher = createMultiDocumentSearcher(analyzer, doc);
        } else {
            MemoryIndex memoryIndex = MemoryIndex.fromDocument(doc.rootDoc(), analyzer, true, false);
            docSearcher = memoryIndex.createSearcher();
            docSearcher.setQueryCache(null);
        }

        boolean mapUnmappedFieldsAsString = context.getIndexSettings()
                .getValue(PercolatorFieldMapper.INDEX_MAP_UNMAPPED_FIELDS_AS_STRING_SETTING);
        QueryShardContext percolateShardContext = wrap(context);
        MappedFieldType fieldType = context.fieldMapper(field);
        if (fieldType == null) {
            throw new QueryShardException(context, ""field ["" + field + ""] does not exist"");
        }

        if (!(fieldType instanceof PercolatorFieldMapper.FieldType)) {
            throw new QueryShardException(context, ""expected field ["" + field +
                ""] to be of type [percolator], but is of type ["" + fieldType.typeName() + ""]"");
        }
        PercolatorFieldMapper.FieldType pft = (PercolatorFieldMapper.FieldType) fieldType;
        PercolateQuery.QueryStore queryStore = createStore(pft, percolateShardContext, mapUnmappedFieldsAsString);
        return pft.percolateQuery(documentType, queryStore, document, docSearcher);
    }",/modules/percolator/src/main/java/org/elasticsearch/percolator/PercolateQueryBuilder.java
df2d5846a4ca837fd6cc1958ee3edbf604362455,561,88,"public void execute(Runnable command) {
        final var wrappedCommand = wrapRunnable(command);
        try {
            super.execute(wrappedCommand);
        } catch (EsRejectedExecutionException ex) {
            if (wrappedCommand instanceof AbstractRunnable abstractRunnable) {
                try {
                    abstractRunnable.onRejection(ex);
                } finally {
                    abstractRunnable.onAfter();
                }
            } else {
                throw ex;
            }
        } catch (Exception ex) {
            if (command instanceof AbstractRunnable) {
                assert false : ex;
                logger.error(new ParameterizedMessage(""execution of [{}] failed"", wrappedCommand), ex);
            }
            throw ex;
        }
    }","public void execute(Runnable command) {
        final Runnable wrappedRunnable = wrapRunnable(command);
        try {
            super.execute(wrappedRunnable);
        } catch (Exception e) {
            if (wrappedRunnable instanceof AbstractRunnable abstractRunnable) {
                try {
                    // If we are an abstract runnable we can handle the exception
                    // directly and don't need to rethrow it, but we log and assert
                    // any unexpected exception first.
                    if (e instanceof EsRejectedExecutionException == false) {
                        logException(abstractRunnable, e);
                    }
                    abstractRunnable.onRejection(e);
                } finally {
                    abstractRunnable.onAfter();
                }
            } else {
                throw e;
            }
        }
    }",/server/src/main/java/org/elasticsearch/common/util/concurrent/EsThreadPoolExecutor.java
4c1ee018f62a411f01eac33df6ea0b9c028f94d9,391,91,"public void testBatchExecute() throws Exception {
        // Initialize depedencies of TransportMultiSearchAction
        Settings settings = Settings.builder()
                .put(""node.name"", TransportMultiSearchActionTests.class.getSimpleName())
                .build();
        ActionFilters actionFilters = mock(ActionFilters.class);
        when(actionFilters.filters()).thenReturn(new ActionFilter[0]);
        ThreadPool threadPool = new ThreadPool(settings);
        TaskManager taskManager = mock(TaskManager.class);
        TransportService transportService = new TransportService(Settings.EMPTY, null, null, TransportService.NOOP_TRANSPORT_INTERCEPTOR,
                null) {
            @Override
            public TaskManager getTaskManager() {
                return taskManager;
            }
        };
        ClusterService clusterService = mock(ClusterService.class);
        when(clusterService.state()).thenReturn(ClusterState.builder(new ClusterName(""test"")).build());
        IndexNameExpressionResolver resolver = new IndexNameExpressionResolver(Settings.EMPTY);

        // Keep track of the number of concurrent searches started by multi search api,
        // and if there are more searches than is allowed create an error and remember that.
        int maxAllowedConcurrentSearches = scaledRandomIntBetween(1, 20);
        AtomicInteger counter = new AtomicInteger();
        AtomicReference<AssertionError> errorHolder = new AtomicReference<>();
        TransportAction<SearchRequest, SearchResponse> searchAction = new TransportAction<SearchRequest, SearchResponse>
                (Settings.EMPTY, ""action"", threadPool, actionFilters, resolver, taskManager) {
            @Override
            protected void doExecute(SearchRequest request, ActionListener<SearchResponse> listener) {
                int currentConcurrentSearches = counter.incrementAndGet();
                if (currentConcurrentSearches > maxAllowedConcurrentSearches) {
                    errorHolder.set(new AssertionError(""Current concurrent search ["" + currentConcurrentSearches +
                            ""] is higher than is allowed ["" + maxAllowedConcurrentSearches + ""]""));
                }
                threadPool.executor(ThreadPool.Names.GENERIC).execute(
                        () -> {
                            try {
                                Thread.sleep(scaledRandomIntBetween(10, 1000));
                            } catch (InterruptedException e) {
                            }
                            counter.decrementAndGet();
                            listener.onResponse(new SearchResponse());
                        }
                );
            }
        };
        TransportMultiSearchAction action =
                new TransportMultiSearchAction(threadPool, actionFilters, transportService, clusterService, searchAction, resolver, 10);

        // Execute the multi search api and fail if we find an error after executing:
        try {
            int numSearchRequests = randomIntBetween(16, 128);
            MultiSearchRequest multiSearchRequest = new MultiSearchRequest();
            multiSearchRequest.maxConcurrentSearchRequests(maxAllowedConcurrentSearches);
            for (int i = 0; i < numSearchRequests; i++) {
                multiSearchRequest.add(new SearchRequest());
            }

            MultiSearchResponse response = action.execute(multiSearchRequest).actionGet();
            assertThat(response.getResponses().length, equalTo(numSearchRequests));
            assertThat(errorHolder.get(), nullValue());
        } finally {
            assertTrue(ESTestCase.terminate(threadPool));
        }
    }","public void testBatchExecute() throws Exception {
        // Initialize dependencies of TransportMultiSearchAction
        Settings settings = Settings.builder()
                .put(""node.name"", TransportMultiSearchActionTests.class.getSimpleName())
                .build();
        ActionFilters actionFilters = mock(ActionFilters.class);
        when(actionFilters.filters()).thenReturn(new ActionFilter[0]);
        ThreadPool threadPool = new ThreadPool(settings);
        TaskManager taskManager = mock(TaskManager.class);
        TransportService transportService = new TransportService(Settings.EMPTY, null, null, TransportService.NOOP_TRANSPORT_INTERCEPTOR,
            boundAddress -> DiscoveryNode.createLocal(settings, boundAddress.publishAddress(), UUIDs.randomBase64UUID()), null) {
            @Override
            public TaskManager getTaskManager() {
                return taskManager;
            }
        };
        ClusterService clusterService = mock(ClusterService.class);
        when(clusterService.state()).thenReturn(ClusterState.builder(new ClusterName(""test"")).build());
        IndexNameExpressionResolver resolver = new IndexNameExpressionResolver(Settings.EMPTY);

        // Keep track of the number of concurrent searches started by multi search api,
        // and if there are more searches than is allowed create an error and remember that.
        int maxAllowedConcurrentSearches = scaledRandomIntBetween(1, 20);
        AtomicInteger counter = new AtomicInteger();
        AtomicReference<AssertionError> errorHolder = new AtomicReference<>();
        TransportAction<SearchRequest, SearchResponse> searchAction = new TransportAction<SearchRequest, SearchResponse>
                (Settings.EMPTY, ""action"", threadPool, actionFilters, resolver, taskManager) {
            @Override
            protected void doExecute(SearchRequest request, ActionListener<SearchResponse> listener) {
                int currentConcurrentSearches = counter.incrementAndGet();
                if (currentConcurrentSearches > maxAllowedConcurrentSearches) {
                    errorHolder.set(new AssertionError(""Current concurrent search ["" + currentConcurrentSearches +
                            ""] is higher than is allowed ["" + maxAllowedConcurrentSearches + ""]""));
                }
                threadPool.executor(ThreadPool.Names.GENERIC).execute(
                        () -> {
                            try {
                                Thread.sleep(scaledRandomIntBetween(10, 1000));
                            } catch (InterruptedException e) {
                            }
                            counter.decrementAndGet();
                            listener.onResponse(new SearchResponse());
                        }
                );
            }
        };
        TransportMultiSearchAction action =
                new TransportMultiSearchAction(threadPool, actionFilters, transportService, clusterService, searchAction, resolver, 10);

        // Execute the multi search api and fail if we find an error after executing:
        try {
            int numSearchRequests = randomIntBetween(16, 128);
            MultiSearchRequest multiSearchRequest = new MultiSearchRequest();
            multiSearchRequest.maxConcurrentSearchRequests(maxAllowedConcurrentSearches);
            for (int i = 0; i < numSearchRequests; i++) {
                multiSearchRequest.add(new SearchRequest());
            }

            MultiSearchResponse response = action.execute(multiSearchRequest).actionGet();
            assertThat(response.getResponses().length, equalTo(numSearchRequests));
            assertThat(errorHolder.get(), nullValue());
        } finally {
            assertTrue(ESTestCase.terminate(threadPool));
        }
    }",/core/src/test/java/org/elasticsearch/action/search/TransportMultiSearchActionTests.java
4c1ee018f62a411f01eac33df6ea0b9c028f94d9,563,168,"public void testShardsAllocatorFactoryNull() {
        Settings settings = Settings.builder().put(ClusterModule.SHARDS_ALLOCATOR_TYPE_SETTING.getKey(), ""bad"").build();
        NullPointerException e = expectThrows(NullPointerException.class, () ->
            newClusterModuleWithShardsAllocator(settings, ""bad"", () -> null));
    }","public void testUnknownShardsAllocator() {
        Settings settings = Settings.builder().put(ClusterModule.SHARDS_ALLOCATOR_TYPE_SETTING.getKey(), ""dne"").build();
        IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () ->
            new ClusterModule(settings, clusterService, Collections.emptyList()));
        assertEquals(""Unknown ShardsAllocator [dne]"", e.getMessage());
    }",/core/src/test/java/org/elasticsearch/cluster/ClusterModuleTests.java
4c1ee018f62a411f01eac33df6ea0b9c028f94d9,391,625,"public Node start() throws NodeValidationException {
        if (!lifecycle.moveToStarted()) {
            return this;
        }

        Logger logger = Loggers.getLogger(Node.class, NODE_NAME_SETTING.get(settings));
        logger.info(""starting ..."");
        // hack around dependency injection problem (for now...)
        injector.getInstance(Discovery.class).setAllocationService(injector.getInstance(AllocationService.class));
        pluginLifecycleComponents.forEach(LifecycleComponent::start);

        injector.getInstance(MappingUpdatedAction.class).setClient(client);
        injector.getInstance(IndicesService.class).start();
        injector.getInstance(IndicesClusterStateService.class).start();
        injector.getInstance(SnapshotsService.class).start();
        injector.getInstance(SnapshotShardsService.class).start();
        injector.getInstance(RoutingService.class).start();
        injector.getInstance(SearchService.class).start();
        injector.getInstance(MonitorService.class).start();

        final ClusterService clusterService = injector.getInstance(ClusterService.class);

        final NodeConnectionsService nodeConnectionsService = injector.getInstance(NodeConnectionsService.class);
        nodeConnectionsService.start();
        clusterService.setNodeConnectionsService(nodeConnectionsService);

        // TODO hack around circular dependencies problems
        injector.getInstance(GatewayAllocator.class).setReallocation(clusterService, injector.getInstance(RoutingService.class));

        injector.getInstance(ResourceWatcherService.class).start();
        injector.getInstance(GatewayService.class).start();
        Discovery discovery = injector.getInstance(Discovery.class);
        clusterService.setDiscoverySettings(discovery.getDiscoverySettings());
        clusterService.addInitialStateBlock(discovery.getDiscoverySettings().getNoMasterBlock());
        clusterService.setClusterStatePublisher(discovery::publish);

        // start before the cluster service since it adds/removes initial Cluster state blocks
        final TribeService tribeService = injector.getInstance(TribeService.class);
        tribeService.start();

        // Start the transport service now so the publish address will be added to the local disco node in ClusterService
        TransportService transportService = injector.getInstance(TransportService.class);
        transportService.getTaskManager().setTaskResultsService(injector.getInstance(TaskResultsService.class));
        transportService.start();
        validateNodeBeforeAcceptingRequests(settings, transportService.boundAddress(), pluginsService.filterPlugins(Plugin.class).stream()
            .flatMap(p -> p.getBootstrapChecks().stream()).collect(Collectors.toList()));

        DiscoveryNode localNode = DiscoveryNode.createLocal(settings,
            transportService.boundAddress().publishAddress(), injector.getInstance(NodeEnvironment.class).nodeId());

        // TODO: need to find a cleaner way to start/construct a service with some initial parameters,
        // playing nice with the life cycle interfaces
        clusterService.setLocalNode(localNode);
        transportService.setLocalNode(localNode);
        clusterService.addStateApplier(transportService.getTaskManager());

        clusterService.start();

        // start after cluster service so the local disco is known
        discovery.start();
        transportService.acceptIncomingRequests();
        discovery.startInitialJoin();
        // tribe nodes don't have a master so we shouldn't register an observer         s
        final TimeValue initialStateTimeout = DiscoverySettings.INITIAL_STATE_TIMEOUT_SETTING.get(settings);
        if (initialStateTimeout.millis() > 0) {
            final ThreadPool thread = injector.getInstance(ThreadPool.class);
            ClusterState clusterState = clusterService.state();
            ClusterStateObserver observer = new ClusterStateObserver(clusterState, clusterService, null, logger, thread.getThreadContext());
            if (clusterState.nodes().getMasterNodeId() == null) {
                logger.debug(""waiting to join the cluster. timeout [{}]"", initialStateTimeout);
                final CountDownLatch latch = new CountDownLatch(1);
                observer.waitForNextChange(new ClusterStateObserver.Listener() {
                    @Override
                    public void onNewClusterState(ClusterState state) { latch.countDown(); }

                    @Override
                    public void onClusterServiceClose() {
                        latch.countDown();
                    }

                    @Override
                    public void onTimeout(TimeValue timeout) {
                        logger.warn(""timed out while waiting for initial discovery state - timeout: {}"",
                            initialStateTimeout);
                        latch.countDown();
                    }
                }, state -> state.nodes().getMasterNodeId() != null, initialStateTimeout);

                try {
                    latch.await();
                } catch (InterruptedException e) {
                    throw new ElasticsearchTimeoutException(""Interrupted while waiting for initial discovery state"");
                }
            }
        }

        if (NetworkModule.HTTP_ENABLED.get(settings)) {
            injector.getInstance(HttpServer.class).start();
        }

        // start nodes now, after the http server, because it may take some time
        tribeService.startNodes();

        if (WRITE_PORTS_FIELD_SETTING.get(settings)) {
            if (NetworkModule.HTTP_ENABLED.get(settings)) {
                HttpServerTransport http = injector.getInstance(HttpServerTransport.class);
                writePortsFile(""http"", http.boundAddress());
            }
            TransportService transport = injector.getInstance(TransportService.class);
            writePortsFile(""transport"", transport.boundAddress());
        }

        logger.info(""started"");

        return this;
    }","public Node start() throws NodeValidationException {
        if (!lifecycle.moveToStarted()) {
            return this;
        }

        Logger logger = Loggers.getLogger(Node.class, NODE_NAME_SETTING.get(settings));
        logger.info(""starting ..."");
        // hack around dependency injection problem (for now...)
        injector.getInstance(Discovery.class).setAllocationService(injector.getInstance(AllocationService.class));
        pluginLifecycleComponents.forEach(LifecycleComponent::start);

        injector.getInstance(MappingUpdatedAction.class).setClient(client);
        injector.getInstance(IndicesService.class).start();
        injector.getInstance(IndicesClusterStateService.class).start();
        injector.getInstance(SnapshotsService.class).start();
        injector.getInstance(SnapshotShardsService.class).start();
        injector.getInstance(RoutingService.class).start();
        injector.getInstance(SearchService.class).start();
        injector.getInstance(MonitorService.class).start();

        final ClusterService clusterService = injector.getInstance(ClusterService.class);

        final NodeConnectionsService nodeConnectionsService = injector.getInstance(NodeConnectionsService.class);
        nodeConnectionsService.start();
        clusterService.setNodeConnectionsService(nodeConnectionsService);

        // TODO hack around circular dependencies problems
        injector.getInstance(GatewayAllocator.class).setReallocation(clusterService, injector.getInstance(RoutingService.class));

        injector.getInstance(ResourceWatcherService.class).start();
        injector.getInstance(GatewayService.class).start();
        Discovery discovery = injector.getInstance(Discovery.class);
        clusterService.setDiscoverySettings(discovery.getDiscoverySettings());
        clusterService.addInitialStateBlock(discovery.getDiscoverySettings().getNoMasterBlock());
        clusterService.setClusterStatePublisher(discovery::publish);

        // start before the cluster service since it adds/removes initial Cluster state blocks
        final TribeService tribeService = injector.getInstance(TribeService.class);
        tribeService.start();

        // Start the transport service now so the publish address will be added to the local disco node in ClusterService
        TransportService transportService = injector.getInstance(TransportService.class);
        transportService.getTaskManager().setTaskResultsService(injector.getInstance(TaskResultsService.class));
        transportService.start();
        validateNodeBeforeAcceptingRequests(settings, transportService.boundAddress(), pluginsService.filterPlugins(Plugin.class).stream()
            .flatMap(p -> p.getBootstrapChecks().stream()).collect(Collectors.toList()));

        clusterService.addStateApplier(transportService.getTaskManager());
        clusterService.start();
        assert localNodeFactory.getNode() != null;
        assert transportService.getLocalNode().equals(localNodeFactory.getNode())
            : ""transportService has a different local node than the factory provided"";
        assert clusterService.localNode().equals(localNodeFactory.getNode())
            : ""clusterService has a different local node than the factory provided"";
        // start after cluster service so the local disco is known
        discovery.start();
        transportService.acceptIncomingRequests();
        discovery.startInitialJoin();
        // tribe nodes don't have a master so we shouldn't register an observer         s
        final TimeValue initialStateTimeout = DiscoverySettings.INITIAL_STATE_TIMEOUT_SETTING.get(settings);
        if (initialStateTimeout.millis() > 0) {
            final ThreadPool thread = injector.getInstance(ThreadPool.class);
            ClusterState clusterState = clusterService.state();
            ClusterStateObserver observer = new ClusterStateObserver(clusterState, clusterService, null, logger, thread.getThreadContext());
            if (clusterState.nodes().getMasterNodeId() == null) {
                logger.debug(""waiting to join the cluster. timeout [{}]"", initialStateTimeout);
                final CountDownLatch latch = new CountDownLatch(1);
                observer.waitForNextChange(new ClusterStateObserver.Listener() {
                    @Override
                    public void onNewClusterState(ClusterState state) { latch.countDown(); }

                    @Override
                    public void onClusterServiceClose() {
                        latch.countDown();
                    }

                    @Override
                    public void onTimeout(TimeValue timeout) {
                        logger.warn(""timed out while waiting for initial discovery state - timeout: {}"",
                            initialStateTimeout);
                        latch.countDown();
                    }
                }, state -> state.nodes().getMasterNodeId() != null, initialStateTimeout);

                try {
                    latch.await();
                } catch (InterruptedException e) {
                    throw new ElasticsearchTimeoutException(""Interrupted while waiting for initial discovery state"");
                }
            }
        }

        if (NetworkModule.HTTP_ENABLED.get(settings)) {
            injector.getInstance(HttpServer.class).start();
        }

        // start nodes now, after the http server, because it may take some time
        tribeService.startNodes();

        if (WRITE_PORTS_FIELD_SETTING.get(settings)) {
            if (NetworkModule.HTTP_ENABLED.get(settings)) {
                HttpServerTransport http = injector.getInstance(HttpServerTransport.class);
                writePortsFile(""http"", http.boundAddress());
            }
            TransportService transport = injector.getInstance(TransportService.class);
            writePortsFile(""transport"", transport.boundAddress());
        }

        logger.info(""started"");

        return this;
    }",/core/src/main/java/org/elasticsearch/node/Node.java
4c1ee018f62a411f01eac33df6ea0b9c028f94d9,391,190,"public void tearDown() throws Exception {
        super.tearDown();
        try {
            assertNoPendingHandshakes(serviceA.getOriginalTransport());
            assertNoPendingHandshakes(serviceB.getOriginalTransport());
        } finally {
            IOUtils.close(serviceA, serviceB, () -> {
                try {
                    terminate(threadPool);
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
            });
        }
    }","public void assertNoPendingHandshakes(Transport transport) {
        if (transport instanceof TcpTransport) {
            assertEquals(0, ((TcpTransport) transport).getNumPendingHandshakes());
        }
    }",/test/framework/src/main/java/org/elasticsearch/transport/AbstractSimpleTransportTestCase.java
7b71c94884c1e418a840373e890f3d2c19db126b,685,141,"private void checkModuleServices(ModuleReference mref) {
        getLogger().info(""{} checking module services for {}"", getPath(), mref.descriptor().name());
        Set<String> modServices = mref.descriptor().provides().stream().map(ModuleDescriptor.Provides::service).collect(toSet());
        Path servicesRoot = getResourcesDir().toPath().resolve(""META-INF"").resolve(""services"");
        getLogger().info(""{} servicesRoot {}"", getPath(), servicesRoot);
        if (Files.exists(servicesRoot)) {
            try (var paths = Files.walk(servicesRoot)) {
                paths.filter(Files::isRegularFile)
                    .map(p -> servicesRoot.relativize(p))
                    .map(Path::toString)
                    .peek(s -> getLogger().info(""%s checking service %s"", this, s))
                    .forEach(service -> {
                        if (modServices.contains(service) == false) {
                            throw new GradleException(
                                String.format(
                                    Locale.ROOT,
                                    ""Expected provides {} in module %s with provides {}."",
                                    service,
                                    mref.descriptor().name(),
                                    mref.descriptor().provides()
                                )
                            );
                        }
                    });
            } catch (IOException e) {
                throw new UncheckedIOException(e);
            }
        }
    }","private void checkModuleServices(ModuleReference mref) {
        getLogger().info(""{} checking module services for {}"", getPath(), mref.descriptor().name());
        Set<String> modServices = mref.descriptor().provides().stream().map(ModuleDescriptor.Provides::service).collect(toSet());
        Path servicesRoot = getResourcesDir().toPath().resolve(""META-INF"").resolve(""services"");
        getLogger().info(""{} servicesRoot {}"", getPath(), servicesRoot);
        if (Files.exists(servicesRoot)) {
            try (var paths = Files.walk(servicesRoot)) {
                paths.filter(Files::isRegularFile)
                    .map(p -> servicesRoot.relativize(p))
                    .map(Path::toString)
                    .peek(s -> getLogger().info(""%s checking service %s"", this, s))
                    .forEach(service -> {
                        if (modServices.contains(service) == false) {
                            throw new GradleException(
                                String.format(
                                    Locale.ROOT,
                                    ""Expected provides %s in module %s with provides %s."",
                                    service,
                                    mref.descriptor().name(),
                                    mref.descriptor().provides()
                                )
                            );
                        }
                    });
            } catch (IOException e) {
                throw new UncheckedIOException(e);
            }
        }
    }",/build-tools-internal/src/main/java/org/elasticsearch/gradle/internal/precommit/JavaModulePrecommitTask.java
8191dc77f3bcb62d622b79499e0574d1500af519,563,75,"public static MappingStats of(Metadata metadata, Runnable ensureNotCancelled) {
        Map<String, FieldStats> fieldTypes = new HashMap<>();
        Set<String> concreteFieldNames = new HashSet<>();
        Map<String, RuntimeFieldStats> runtimeFieldTypes = new HashMap<>();
        for (IndexMetadata indexMetadata : metadata) {
            ensureNotCancelled.run();
            if (indexMetadata.isSystem()) {
                // Don't include system indices in statistics about mappings,
                // we care about the user's indices.
                continue;
            }
            Set<String> indexFieldTypes = new HashSet<>();
            Set<String> indexRuntimeFieldTypes = new HashSet<>();
            MappingMetadata mappingMetadata = indexMetadata.mapping();
            if (mappingMetadata != null) {
                MappingVisitor.visitMapping(mappingMetadata.getSourceAsMap(), (field, fieldMapping) -> {
                    concreteFieldNames.add(field);
                    String type = null;
                    Object typeO = fieldMapping.get(""type"");
                    if (typeO != null) {
                        type = typeO.toString();
                    } else if (fieldMapping.containsKey(""properties"")) {
                        type = ""object"";
                    }
                    if (type != null) {
                        FieldStats stats = fieldTypes.computeIfAbsent(type, FieldStats::new);
                        stats.count++;
                        if (indexFieldTypes.add(type)) {
                            stats.indexCount++;
                        }
                        Object scriptObject = fieldMapping.get(""script"");
                        if (scriptObject instanceof Map) {
                            Map<?, ?> script = (Map<?, ?>) scriptObject;
                            Object sourceObject = script.get(""source"");
                            stats.scriptCount++;
                            updateScriptParams(sourceObject, stats.fieldScriptStats);
                            Object langObject = script.get(""lang"");
                            if (langObject != null) {
                                stats.scriptLangs.add(langObject.toString());
                            }
                        }
                    }
                });

                MappingVisitor.visitRuntimeMapping(mappingMetadata.getSourceAsMap(), (field, fieldMapping) -> {
                    Object typeObject = fieldMapping.get(""type"");
                    if (typeObject == null) {
                        return;
                    }
                    String type = typeObject.toString();
                    RuntimeFieldStats stats = runtimeFieldTypes.computeIfAbsent(type, RuntimeFieldStats::new);
                    stats.count++;
                    if (indexRuntimeFieldTypes.add(type)) {
                        stats.indexCount++;
                    }
                    if (concreteFieldNames.contains(field)) {
                        stats.shadowedCount++;
                    }
                    Object scriptObject = fieldMapping.get(""script"");
                    if (scriptObject == null) {
                        stats.scriptLessCount++;
                    } else if (scriptObject instanceof Map) {
                        Map<?, ?> script = (Map<?, ?>) scriptObject;
                        Object sourceObject = script.get(""source"");
                        updateScriptParams(sourceObject, stats.fieldScriptStats);
                        Object langObject = script.get(""lang"");
                        if (langObject != null) {
                            stats.scriptLangs.add(langObject.toString());
                        }
                    }
                });
            }
        }
        return new MappingStats(fieldTypes.values(), runtimeFieldTypes.values());
    }","public static MappingStats of(Metadata metadata, Runnable ensureNotCancelled) {
        Map<String, FieldStats> fieldTypes = new HashMap<>();
        Set<String> concreteFieldNames = new HashSet<>();
        Map<String, RuntimeFieldStats> runtimeFieldTypes = new HashMap<>();
        for (IndexMetadata indexMetadata : metadata) {
            ensureNotCancelled.run();
            if (indexMetadata.isSystem()) {
                // Don't include system indices in statistics about mappings,
                // we care about the user's indices.
                continue;
            }
            Set<String> indexFieldTypes = new HashSet<>();
            Set<String> indexRuntimeFieldTypes = new HashSet<>();
            MappingMetadata mappingMetadata = indexMetadata.mapping();
            if (mappingMetadata != null) {
                final Map<String, Object> map = mappingMetadata.getSourceAsMap();
                MappingVisitor.visitMapping(map, (field, fieldMapping) -> {
                    concreteFieldNames.add(field);
                    String type = null;
                    Object typeO = fieldMapping.get(""type"");
                    if (typeO != null) {
                        type = typeO.toString();
                    } else if (fieldMapping.containsKey(""properties"")) {
                        type = ""object"";
                    }
                    if (type != null) {
                        FieldStats stats = fieldTypes.computeIfAbsent(type, FieldStats::new);
                        stats.count++;
                        if (indexFieldTypes.add(type)) {
                            stats.indexCount++;
                        }
                        Object scriptObject = fieldMapping.get(""script"");
                        if (scriptObject instanceof Map) {
                            Map<?, ?> script = (Map<?, ?>) scriptObject;
                            Object sourceObject = script.get(""source"");
                            stats.scriptCount++;
                            updateScriptParams(sourceObject, stats.fieldScriptStats);
                            Object langObject = script.get(""lang"");
                            if (langObject != null) {
                                stats.scriptLangs.add(langObject.toString());
                            }
                        }
                    }
                });

                MappingVisitor.visitRuntimeMapping(map, (field, fieldMapping) -> {
                    Object typeObject = fieldMapping.get(""type"");
                    if (typeObject == null) {
                        return;
                    }
                    String type = typeObject.toString();
                    RuntimeFieldStats stats = runtimeFieldTypes.computeIfAbsent(type, RuntimeFieldStats::new);
                    stats.count++;
                    if (indexRuntimeFieldTypes.add(type)) {
                        stats.indexCount++;
                    }
                    if (concreteFieldNames.contains(field)) {
                        stats.shadowedCount++;
                    }
                    Object scriptObject = fieldMapping.get(""script"");
                    if (scriptObject == null) {
                        stats.scriptLessCount++;
                    } else if (scriptObject instanceof Map) {
                        Map<?, ?> script = (Map<?, ?>) scriptObject;
                        Object sourceObject = script.get(""source"");
                        updateScriptParams(sourceObject, stats.fieldScriptStats);
                        Object langObject = script.get(""lang"");
                        if (langObject != null) {
                            stats.scriptLangs.add(langObject.toString());
                        }
                    }
                });
            }
        }
        return new MappingStats(fieldTypes.values(), runtimeFieldTypes.values());
    }",/server/src/main/java/org/elasticsearch/action/admin/cluster/stats/MappingStats.java
042424b43ba0e1bf0748e77f9941ccd3ef578f34,704,585,"void assertBasicAggregationWorks() throws IOException {
        // histogram on a long
        String requestBody = ""{ \""aggs\"": { \""histo\"" : {\""histogram\"" : {\""field\"": \""int\"", \""interval\"": 10}} }}"";
        Map<?, ?> searchRsp = toMap(client().performRequest(""GET"", ""/"" + index + ""/_search"", Collections.emptyMap(),
                new StringEntity(requestBody, ContentType.APPLICATION_JSON)));
        assertNoFailures(searchRsp);
        List<?> histoBuckets = (List<?>) XContentMapValues.extractValue(""aggregations.histo.buckets"", searchRsp);
        long totalCount = 0;
        for (Object entry : histoBuckets) {
            Map<?, ?> bucket = (Map<?, ?>) entry;
            totalCount += (Integer) bucket.get(""doc_count"");
        }
        int totalHits = (int) XContentMapValues.extractValue(""hits.total"", searchRsp);
        assertEquals(totalHits, totalCount);

        // terms on a boolean
        requestBody = ""{ \""aggs\"": { \""bool_terms\"" : {\""terms\"" : {\""field\"": \""bool\""}} }}"";
        searchRsp = toMap(client().performRequest(""GET"", ""/"" + index + ""/_search"", Collections.emptyMap(),
                new StringEntity(requestBody, ContentType.APPLICATION_JSON)));
        List<?> termsBuckets = (List<?>) XContentMapValues.extractValue(""aggregations.bool_terms.buckets"", searchRsp);
        totalCount = 0;
        for (Object entry : termsBuckets) {
            Map<?, ?> bucket = (Map<?, ?>) entry;
            totalCount += (Integer) bucket.get(""doc_count"");
        }
        totalHits = (int) XContentMapValues.extractValue(""hits.total"", searchRsp);
        assertEquals(totalHits, totalCount);
    }","void assertRealtimeGetWorks() throws IOException {
        Request disableAutoRefresh = new Request(""PUT"", ""/"" + index + ""/_settings"");
        disableAutoRefresh.setJsonEntity(""{ \""index\"": { \""refresh_interval\"" : -1 }}"");
        client().performRequest(disableAutoRefresh);

        Request searchRequest = new Request(""GET"", ""/"" + index + ""/_search"");
        searchRequest.setJsonEntity(""{ \""query\"": { \""match_all\"" : {} }}"");
        Map<?, ?> searchResponse = entityAsMap(client().performRequest(searchRequest));
        Map<?, ?> hit = (Map<?, ?>) ((List<?>)(XContentMapValues.extractValue(""hits.hits"", searchResponse))).get(0);
        String docId = (String) hit.get(""_id"");

        Request updateRequest = new Request(""POST"", ""/"" + index + ""/doc/"" + docId + ""/_update"");
        updateRequest.setJsonEntity(""{ \""doc\"" : { \""foo\"": \""bar\""}}"");
        client().performRequest(updateRequest);

        Map<String, Object> getRsp = entityAsMap(client().performRequest(new Request(""GET"", ""/"" + index + ""/doc/"" + docId)));
        Map<?, ?> source = (Map<?, ?>) getRsp.get(""_source"");
        assertTrue(""doc does not contain 'foo' key: "" + source, source.containsKey(""foo""));

        Request enableAutoRefresh = new Request(""PUT"", ""/"" + index + ""/_settings"");
        enableAutoRefresh.setJsonEntity(""{ \""index\"": { \""refresh_interval\"" : \""1s\"" }}"");
        client().performRequest(enableAutoRefresh);
    }",/qa/full-cluster-restart/src/test/java/org/elasticsearch/upgrades/FullClusterRestartIT.java
a8aecb8b22d249815ba29b485ea3126e415f47dd,563,46,"public void testCompilationCircuitBreaking() throws Exception {
        String context = randomFrom(
            ScriptModule.CORE_CONTEXTS.values().stream().filter(
                c -> c.maxCompilationRateDefault.equals(ScriptCache.UNLIMITED_COMPILATION_RATE) == false
            ).collect(Collectors.toList())
        ).name;
        final TimeValue expire = ScriptService.SCRIPT_CACHE_EXPIRE_SETTING.getConcreteSettingForNamespace(context).get(Settings.EMPTY);
        final Integer size = ScriptService.SCRIPT_CACHE_SIZE_SETTING.getConcreteSettingForNamespace(context).get(Settings.EMPTY);
        Setting<Tuple<Integer, TimeValue>> rateSetting =
            ScriptService.SCRIPT_MAX_COMPILATIONS_RATE_SETTING.getConcreteSettingForNamespace(context);
        Tuple<Integer, TimeValue> rate =
            ScriptService.SCRIPT_MAX_COMPILATIONS_RATE_SETTING.getConcreteSettingForNamespace(context).get(Settings.EMPTY);
        String rateSettingName = rateSetting.getKey();
        ScriptCache cache = new ScriptCache(size, expire, Tuple.tuple(1, TimeValue.timeValueMinutes(1)), rateSettingName);
        cache.checkCompilationLimit(); // should pass
        expectThrows(CircuitBreakingException.class, cache::checkCompilationLimit);
        cache = new ScriptCache(size, expire, (Tuple.tuple(2, TimeValue.timeValueMinutes(1))), rateSettingName);
        cache.checkCompilationLimit(); // should pass
        cache.checkCompilationLimit(); // should pass
        expectThrows(CircuitBreakingException.class, cache::checkCompilationLimit);
        int count = randomIntBetween(5, 50);
        cache = new ScriptCache(size, expire, (Tuple.tuple(count, TimeValue.timeValueMinutes(1))), rateSettingName);
        for (int i = 0; i < count; i++) {
            cache.checkCompilationLimit(); // should pass
        }
        expectThrows(CircuitBreakingException.class, cache::checkCompilationLimit);
        cache = new ScriptCache(size, expire, (Tuple.tuple(0, TimeValue.timeValueMinutes(1))), rateSettingName);
        expectThrows(CircuitBreakingException.class, cache::checkCompilationLimit);
        cache = new ScriptCache(size, expire, (Tuple.tuple(Integer.MAX_VALUE, TimeValue.timeValueMinutes(1))), rateSettingName);
        int largeLimit = randomIntBetween(1000, 10000);
        for (int i = 0; i < largeLimit; i++) {
            cache.checkCompilationLimit();
        }
    }","public void testCompilationCircuitBreaking() throws Exception {
        String context = randomFrom(
            ScriptModule.CORE_CONTEXTS.values().stream().filter(
                c -> c.maxCompilationRateDefault.equals(ScriptCache.UNLIMITED_COMPILATION_RATE) == false
            ).collect(Collectors.toList())
        ).name;
        final TimeValue expire = ScriptService.SCRIPT_CACHE_EXPIRE_SETTING.getConcreteSettingForNamespace(context).get(Settings.EMPTY);
        final Integer size = ScriptService.SCRIPT_CACHE_SIZE_SETTING.getConcreteSettingForNamespace(context).get(Settings.EMPTY);
        Setting<ScriptCache.CompilationRate> rateSetting =
            ScriptService.SCRIPT_MAX_COMPILATIONS_RATE_SETTING.getConcreteSettingForNamespace(context);
        ScriptCache.CompilationRate rate =
            ScriptService.SCRIPT_MAX_COMPILATIONS_RATE_SETTING.getConcreteSettingForNamespace(context).get(Settings.EMPTY);
        String rateSettingName = rateSetting.getKey();
        ScriptCache cache = new ScriptCache(size, expire,
            new ScriptCache.CompilationRate(1, TimeValue.timeValueMinutes(1)), rateSettingName);
        cache.checkCompilationLimit(); // should pass
        expectThrows(CircuitBreakingException.class, cache::checkCompilationLimit);
        cache = new ScriptCache(size, expire, new ScriptCache.CompilationRate(2, TimeValue.timeValueMinutes(1)), rateSettingName);
        cache.checkCompilationLimit(); // should pass
        cache.checkCompilationLimit(); // should pass
        expectThrows(CircuitBreakingException.class, cache::checkCompilationLimit);
        int count = randomIntBetween(5, 50);
        cache = new ScriptCache(size, expire, new ScriptCache.CompilationRate(count, TimeValue.timeValueMinutes(1)), rateSettingName);
        for (int i = 0; i < count; i++) {
            cache.checkCompilationLimit(); // should pass
        }
        expectThrows(CircuitBreakingException.class, cache::checkCompilationLimit);
        cache = new ScriptCache(size, expire, new ScriptCache.CompilationRate(0, TimeValue.timeValueMinutes(1)), rateSettingName);
        expectThrows(CircuitBreakingException.class, cache::checkCompilationLimit);
        cache = new ScriptCache(size, expire,
                                new ScriptCache.CompilationRate(Integer.MAX_VALUE, TimeValue.timeValueMinutes(1)), rateSettingName);
        int largeLimit = randomIntBetween(1000, 10000);
        for (int i = 0; i < largeLimit; i++) {
            cache.checkCompilationLimit();
        }
    }",/server/src/test/java/org/elasticsearch/script/ScriptCacheTests.java
a8aecb8b22d249815ba29b485ea3126e415f47dd,563,463,"public void testCacheHolderChangeSettings() throws IOException {
        Set<String> contextNames = contexts.keySet();
        String a = randomFrom(contextNames);
        String aRate = ""77/5m"";
        String b = randomValueOtherThan(a, () -> randomFrom(contextNames));
        String bRate = ""78/6m"";
        String c = randomValueOtherThanMany(s -> a.equals(s) || b.equals(s), () -> randomFrom(contextNames));

        buildScriptService(Settings.EMPTY);

        Settings settings = Settings.builder()
            .put(SCRIPT_MAX_COMPILATIONS_RATE_SETTING.getConcreteSettingForNamespace(a).getKey(), aRate)
            .put(SCRIPT_MAX_COMPILATIONS_RATE_SETTING.getConcreteSettingForNamespace(b).getKey(), bRate)
            .put(SCRIPT_MAX_COMPILATIONS_RATE_SETTING.getConcreteSettingForNamespace(c).getKey(),
                ScriptService.UNLIMITED_COMPILATION_RATE_KEY)
            .build();

        assertNotNull(scriptService.cacheHolder.get().contextCache);
        scriptService.cacheHolder.get().set(a, scriptService.contextCache(settings, contexts.get(a)));
        scriptService.cacheHolder.get().set(b, scriptService.contextCache(settings, contexts.get(b)));
        scriptService.cacheHolder.get().set(c, scriptService.contextCache(settings, contexts.get(c)));
        // get of missing context should be null
        assertNull(scriptService.cacheHolder.get().get(
            randomValueOtherThanMany(contexts.keySet()::contains, () -> randomAlphaOfLength(8)))
        );
        assertEquals(contexts.keySet(), scriptService.cacheHolder.get().contextCache.keySet());

        String d = randomValueOtherThanMany(Set.of(a, b, c)::contains, () -> randomFrom(contextNames));
        assertEquals(ScriptService.MAX_COMPILATION_RATE_FUNCTION.apply(aRate),
                     scriptService.cacheHolder.get().contextCache.get(a).get().rate);
        assertEquals(ScriptService.MAX_COMPILATION_RATE_FUNCTION.apply(bRate),
                     scriptService.cacheHolder.get().contextCache.get(b).get().rate);
        assertEquals(ScriptCache.UNLIMITED_COMPILATION_RATE,
                     scriptService.cacheHolder.get().contextCache.get(c).get().rate);

        scriptService.cacheHolder.get().set(b, scriptService.contextCache(Settings.builder()
                .put(SCRIPT_MAX_COMPILATIONS_RATE_SETTING.getConcreteSettingForNamespace(b).getKey(), aRate).build(),
            contexts.get(b)));
        assertEquals(ScriptService.MAX_COMPILATION_RATE_FUNCTION.apply(aRate),
                     scriptService.cacheHolder.get().contextCache.get(b).get().rate);
    }","public void testFallbackToContextDefaults() throws IOException {
        String contextRateStr = randomIntBetween(10, 1024) + ""/"" +  randomIntBetween(10, 200) + ""m"";
        ScriptCache.CompilationRate contextRate = new ScriptCache.CompilationRate(contextRateStr);
        int contextCacheSize = randomIntBetween(1, 1024);
        TimeValue contextExpire = TimeValue.timeValueMinutes(randomIntBetween(10, 200));

        buildScriptService(Settings.EMPTY);

        String name = ""ingest"";

        // Use context specific
        scriptService.cacheHolder.get().set(
            name,
            scriptService.contextCache(Settings.builder()
                    .put(SCRIPT_CACHE_SIZE_SETTING.getConcreteSettingForNamespace(name).getKey(), contextCacheSize)
                    .put(SCRIPT_CACHE_EXPIRE_SETTING.getConcreteSettingForNamespace(name).getKey(), contextExpire)
                    .put(SCRIPT_MAX_COMPILATIONS_RATE_SETTING.getConcreteSettingForNamespace(name).getKey(), contextRateStr)
                    .build(),
                contexts.get(name)
            ));

        ScriptService.CacheHolder holder = scriptService.cacheHolder.get();
        assertNotNull(holder.contextCache);
        assertNotNull(holder.contextCache.get(name));
        assertNotNull(holder.contextCache.get(name).get());

        assertEquals(contextRate, holder.contextCache.get(name).get().rate);
        assertEquals(contextCacheSize, holder.contextCache.get(name).get().cacheSize);
        assertEquals(contextExpire, holder.contextCache.get(name).get().cacheExpire);

        ScriptContext<?> ingest = contexts.get(name);
        // Fallback to context defaults
        buildScriptService(Settings.EMPTY);

        holder = scriptService.cacheHolder.get();
        assertNotNull(holder.contextCache);
        assertNotNull(holder.contextCache.get(name));
        assertNotNull(holder.contextCache.get(name).get());

        assertEquals(ingest.maxCompilationRateDefault, holder.contextCache.get(name).get().rate.asTuple());
        assertEquals(ingest.cacheSizeDefault, holder.contextCache.get(name).get().cacheSize);
        assertEquals(ingest.cacheExpireDefault, holder.contextCache.get(name).get().cacheExpire);
    }",/server/src/test/java/org/elasticsearch/script/ScriptServiceTests.java
824bfd0e5bbd04032e3f5e8c279af6dfa78bcebf,563,1909,"public void flush(boolean force, boolean waitIfOngoing) throws EngineException {
        ensureOpen();
        if (force && waitIfOngoing == false) {
            assert false : ""wait_if_ongoing must be true for a force flush: force="" + force + "" wait_if_ongoing="" + waitIfOngoing;
            throw new IllegalArgumentException(
                ""wait_if_ongoing must be true for a force flush: force="" + force + "" wait_if_ongoing="" + waitIfOngoing
            );
        }
        try (ReleasableLock lock = readLock.acquire()) {
            ensureOpen();
            if (flushLock.tryLock() == false) {
                // if we can't get the lock right away we block if needed otherwise barf
                if (waitIfOngoing == false) {
                    return;
                }
                logger.trace(""waiting for in-flight flush to finish"");
                flushLock.lock();
                logger.trace(""acquired flush lock after blocking"");
            } else {
                logger.trace(""acquired flush lock immediately"");
            }
            try {
                // Only flush if (1) Lucene has uncommitted docs, or (2) forced by caller, or (3) the
                // newly created commit points to a different translog generation (can free translog),
                // or (4) the local checkpoint information in the last commit is stale, which slows down future recoveries.
                boolean hasUncommittedChanges = indexWriter.hasUncommittedChanges();
                boolean shouldPeriodicallyFlush = shouldPeriodicallyFlush();
                if (hasUncommittedChanges
                    || force
                    || shouldPeriodicallyFlush
                    || getProcessedLocalCheckpoint() > Long.parseLong(
                        lastCommittedSegmentInfos.userData.get(SequenceNumbers.LOCAL_CHECKPOINT_KEY)
                    )) {
                    ensureCanFlush();
                    try {
                        translog.rollGeneration();
                        logger.trace(""starting commit for flush; commitTranslog=true"");
                        commitIndexWriter(indexWriter, translog);
                        logger.trace(""finished commit for flush"");

                        // a temporary debugging to investigate test failure - issue#32827. Remove when the issue is resolved
                        logger.debug(
                            ""new commit on flush, hasUncommittedChanges:{}, force:{}, shouldPeriodicallyFlush:{}"",
                            hasUncommittedChanges,
                            force,
                            shouldPeriodicallyFlush
                        );

                        // we need to refresh in order to clear older version values
                        refresh(""version_table_flush"", SearcherScope.INTERNAL, true);
                        translog.trimUnreferencedReaders();
                    } catch (AlreadyClosedException e) {
                        failOnTragicEvent(e);
                        throw e;
                    } catch (Exception e) {
                        throw new FlushFailedEngineException(shardId, e);
                    }
                    refreshLastCommittedSegmentInfos();

                }
            } catch (FlushFailedEngineException ex) {
                maybeFailEngine(""flush"", ex);
                throw ex;
            } finally {
                flushLock.unlock();
            }
        }
        // We don't have to do this here; we do it defensively to make sure that even if wall clock time is misbehaving
        // (e.g., moves backwards) we will at least still sometimes prune deleted tombstones:
        if (engineConfig.isEnableGcDeletes()) {
            pruneDeletedTombstones();
        }
    }","public boolean flush(boolean force, boolean waitIfOngoing) throws EngineException {
        ensureOpen();
        if (force && waitIfOngoing == false) {
            assert false : ""wait_if_ongoing must be true for a force flush: force="" + force + "" wait_if_ongoing="" + waitIfOngoing;
            throw new IllegalArgumentException(
                ""wait_if_ongoing must be true for a force flush: force="" + force + "" wait_if_ongoing="" + waitIfOngoing
            );
        }
        try (ReleasableLock lock = readLock.acquire()) {
            ensureOpen();
            if (flushLock.tryLock() == false) {
                // if we can't get the lock right away we block if needed otherwise barf
                if (waitIfOngoing == false) {
                    logger.trace(""detected an in-flight flush, not blocking to wait for it's completion"");
                    return false;
                }
                logger.trace(""waiting for in-flight flush to finish"");
                flushLock.lock();
                logger.trace(""acquired flush lock after blocking"");
            } else {
                logger.trace(""acquired flush lock immediately"");
            }
            try {
                // Only flush if (1) Lucene has uncommitted docs, or (2) forced by caller, or (3) the
                // newly created commit points to a different translog generation (can free translog),
                // or (4) the local checkpoint information in the last commit is stale, which slows down future recoveries.
                boolean hasUncommittedChanges = indexWriter.hasUncommittedChanges();
                boolean shouldPeriodicallyFlush = shouldPeriodicallyFlush();
                if (hasUncommittedChanges
                    || force
                    || shouldPeriodicallyFlush
                    || getProcessedLocalCheckpoint() > Long.parseLong(
                        lastCommittedSegmentInfos.userData.get(SequenceNumbers.LOCAL_CHECKPOINT_KEY)
                    )) {
                    ensureCanFlush();
                    try {
                        translog.rollGeneration();
                        logger.trace(""starting commit for flush; commitTranslog=true"");
                        commitIndexWriter(indexWriter, translog);
                        logger.trace(""finished commit for flush"");

                        // a temporary debugging to investigate test failure - issue#32827. Remove when the issue is resolved
                        logger.debug(
                            ""new commit on flush, hasUncommittedChanges:{}, force:{}, shouldPeriodicallyFlush:{}"",
                            hasUncommittedChanges,
                            force,
                            shouldPeriodicallyFlush
                        );

                        // we need to refresh in order to clear older version values
                        refresh(""version_table_flush"", SearcherScope.INTERNAL, true);
                        translog.trimUnreferencedReaders();
                    } catch (AlreadyClosedException e) {
                        failOnTragicEvent(e);
                        throw e;
                    } catch (Exception e) {
                        throw new FlushFailedEngineException(shardId, e);
                    }
                    refreshLastCommittedSegmentInfos();

                }
            } catch (FlushFailedEngineException ex) {
                maybeFailEngine(""flush"", ex);
                throw ex;
            } finally {
                flushLock.unlock();
                logger.trace(""released flush lock"");
            }
        }
        // We don't have to do this here; we do it defensively to make sure that even if wall clock time is misbehaving
        // (e.g., moves backwards) we will at least still sometimes prune deleted tombstones:
        if (engineConfig.isEnableGcDeletes()) {
            pruneDeletedTombstones();
        }
        return true;
    }",/server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
dfcdadb59f2b24c78633a45f346f835e808640b0,476,105,"public Map<String, BlobMetaData> listBlobsByPrefix(String account, LocationMode mode, String container, String keyPath, String prefix) {
        MapBuilder<String, BlobMetaData> blobsBuilder = MapBuilder.newMapBuilder();
        for (String blobName : blobs.keySet()) {
            final String checkBlob;
            if (keyPath != null || keyPath.isEmpty()) {
                // strip off key path from the beginning of the blob name
                checkBlob = blobName.replace(keyPath, """");
            } else {
                checkBlob = blobName;
            }
            if (prefix == null || startsWithIgnoreCase(checkBlob, prefix)) {
                blobsBuilder.put(blobName, new PlainBlobMetaData(checkBlob, blobs.get(blobName).size()));
            }
        }
        return blobsBuilder.immutableMap();
    }","public Map<String, BlobMetaData> listBlobsByPrefix(String account, LocationMode mode, String container, String keyPath, String prefix) {
        MapBuilder<String, BlobMetaData> blobsBuilder = MapBuilder.newMapBuilder();
        for (String blobName : blobs.keySet()) {
            final String checkBlob;
            if (keyPath != null && !keyPath.isEmpty()) {
                // strip off key path from the beginning of the blob name
                checkBlob = blobName.replace(keyPath, """");
            } else {
                checkBlob = blobName;
            }
            if (prefix == null || startsWithIgnoreCase(checkBlob, prefix)) {
                blobsBuilder.put(blobName, new PlainBlobMetaData(checkBlob, blobs.get(blobName).size()));
            }
        }
        return blobsBuilder.immutableMap();
    }",/plugins/repository-azure/src/test/java/org/elasticsearch/cloud/azure/storage/AzureStorageServiceMock.java
